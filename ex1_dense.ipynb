{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 17 13:02:45 2018\n",
    "\n",
    "@author: KOK\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,InputLayer,Dropout,Embedding,LSTM\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "27907 95659\n",
      "Concat data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y1_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4bfdef759911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y1_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Loading data...')\n",
    "records1 = list(SeqIO.parse(\"/media/kok/WORK/ML/Tensorflow/jupyter-kok/gencode.v27.lncRNA_transcripts.fa\", \"fasta\"))\n",
    "records2 = list(SeqIO.parse(\"/media/kok/WORK/ML/Tensorflow/jupyter-kok/gencode.v27.pc_transcripts.fa\", \"fasta\"))\n",
    "\n",
    "print(len(records1),len(records2))\n",
    "\n",
    "tmp=[]\n",
    "x1_train=[]\n",
    "n_train=27900-5580\n",
    "n_test=5580\n",
    "output_dense=256\n",
    "batch_size=512\n",
    "\n",
    "for i in records1[:n_train]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x1_train.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "\n",
    "x2_train=[]\n",
    "for i in records2[:n_train]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x2_train.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "    \n",
    "x1_test=[]\n",
    "for i in records1[-n_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x1_test.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "\n",
    "x2_test=[]\n",
    "for i in records2[-n_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x2_test.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "del records1,records2,tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat data...\n"
     ]
    }
   ],
   "source": [
    "print('Concat data...')\n",
    "x_train=np.concatenate((np.array(x1_train),np.array(x2_train)),axis=0)\n",
    "x_test=np.concatenate((np.array(x1_test),np.array(x2_test)),axis=0)\n",
    "y_train=np.concatenate((np.array(len(x1_train)*[[1,0]]),np.array(len(x2_train)*[[0,1]])),axis=0)\n",
    "y_test=np.concatenate((np.array(len(x1_test)*[[1,0]]),np.array(len(x2_test)*[[0,1]])),axis=0)\n",
    "\n",
    "\n",
    "del x1_test,x1_train,x2_test,x2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               349440    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 415,746\n",
      "Trainable params: 415,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 44640 samples, validate on 11160 samples\n",
      "Epoch 1/200\n",
      "44640/44640 [==============================] - 4s 100us/step - loss: 0.6887 - acc: 0.5516 - val_loss: 0.6368 - val_acc: 0.6552\n",
      "Epoch 2/200\n",
      "44640/44640 [==============================] - 3s 77us/step - loss: 0.6212 - acc: 0.6588 - val_loss: 0.4632 - val_acc: 0.7801\n",
      "Epoch 3/200\n",
      "44640/44640 [==============================] - 4s 80us/step - loss: 0.4686 - acc: 0.7886 - val_loss: 0.3435 - val_acc: 0.8536\n",
      "Epoch 4/200\n",
      "44640/44640 [==============================] - 3s 76us/step - loss: 0.4057 - acc: 0.8259 - val_loss: 0.3297 - val_acc: 0.8624\n",
      "Epoch 5/200\n",
      "44640/44640 [==============================] - 3s 77us/step - loss: 0.3785 - acc: 0.8418 - val_loss: 0.3302 - val_acc: 0.8608\n",
      "Epoch 6/200\n",
      "44640/44640 [==============================] - 3s 76us/step - loss: 0.3733 - acc: 0.8431 - val_loss: 0.3290 - val_acc: 0.8634\n",
      "Epoch 7/200\n",
      "44640/44640 [==============================] - 3s 75us/step - loss: 0.3730 - acc: 0.8448 - val_loss: 0.3172 - val_acc: 0.8684\n",
      "Epoch 8/200\n",
      "44640/44640 [==============================] - 4s 82us/step - loss: 0.3590 - acc: 0.8502 - val_loss: 0.3572 - val_acc: 0.8504\n",
      "Epoch 9/200\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.3531 - acc: 0.8520 - val_loss: 0.3114 - val_acc: 0.8711\n",
      "Epoch 10/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3477 - acc: 0.8556 - val_loss: 0.3211 - val_acc: 0.8681\n",
      "Epoch 11/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3440 - acc: 0.8556 - val_loss: 0.3245 - val_acc: 0.8643\n",
      "Epoch 12/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3467 - acc: 0.8553 - val_loss: 0.3142 - val_acc: 0.8703\n",
      "Epoch 13/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3307 - acc: 0.8627 - val_loss: 0.3267 - val_acc: 0.8652\n",
      "Epoch 14/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3322 - acc: 0.8616 - val_loss: 0.3119 - val_acc: 0.8715\n",
      "Epoch 15/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3311 - acc: 0.8627 - val_loss: 0.3117 - val_acc: 0.8725\n",
      "Epoch 16/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3286 - acc: 0.8660 - val_loss: 0.3188 - val_acc: 0.8659\n",
      "Epoch 17/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3279 - acc: 0.8645 - val_loss: 0.3222 - val_acc: 0.8694\n",
      "Epoch 18/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3281 - acc: 0.8631 - val_loss: 0.3109 - val_acc: 0.8721\n",
      "Epoch 19/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.3246 - acc: 0.8659 - val_loss: 0.3102 - val_acc: 0.8711\n",
      "Epoch 20/200\n",
      "44640/44640 [==============================] - 4s 84us/step - loss: 0.3181 - acc: 0.8694 - val_loss: 0.3051 - val_acc: 0.8766\n",
      "Epoch 21/200\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.3172 - acc: 0.8712 - val_loss: 0.3145 - val_acc: 0.8726\n",
      "Epoch 22/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3171 - acc: 0.8700 - val_loss: 0.3228 - val_acc: 0.8668\n",
      "Epoch 23/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3137 - acc: 0.8722 - val_loss: 0.3122 - val_acc: 0.8727\n",
      "Epoch 24/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.3119 - acc: 0.8745 - val_loss: 0.3178 - val_acc: 0.8703\n",
      "Epoch 25/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3162 - acc: 0.8713 - val_loss: 0.3184 - val_acc: 0.8678\n",
      "Epoch 26/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.3276 - acc: 0.8655 - val_loss: 0.3076 - val_acc: 0.8762\n",
      "Epoch 27/200\n",
      "44640/44640 [==============================] - 4s 91us/step - loss: 0.3192 - acc: 0.8714 - val_loss: 0.3051 - val_acc: 0.8758\n",
      "Epoch 28/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.3274 - acc: 0.8657 - val_loss: 0.3109 - val_acc: 0.8728\n",
      "Epoch 29/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.3129 - acc: 0.8741 - val_loss: 0.3185 - val_acc: 0.8668\n",
      "Epoch 30/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3250 - acc: 0.8659 - val_loss: 0.3103 - val_acc: 0.8763\n",
      "Epoch 31/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3168 - acc: 0.8724 - val_loss: 0.3184 - val_acc: 0.8697\n",
      "Epoch 32/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3199 - acc: 0.8705 - val_loss: 0.3022 - val_acc: 0.8775\n",
      "Epoch 33/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.3130 - acc: 0.8734 - val_loss: 0.3047 - val_acc: 0.8752\n",
      "Epoch 34/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3031 - acc: 0.8778 - val_loss: 0.3064 - val_acc: 0.8747\n",
      "Epoch 35/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3015 - acc: 0.8787 - val_loss: 0.3151 - val_acc: 0.8718\n",
      "Epoch 36/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3013 - acc: 0.8790 - val_loss: 0.3133 - val_acc: 0.8722\n",
      "Epoch 37/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3043 - acc: 0.8793 - val_loss: 0.3141 - val_acc: 0.8711\n",
      "Epoch 38/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.2953 - acc: 0.8833 - val_loss: 0.3068 - val_acc: 0.8772\n",
      "Epoch 39/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.3028 - acc: 0.8787 - val_loss: 0.3054 - val_acc: 0.8751\n",
      "Epoch 40/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3006 - acc: 0.8793 - val_loss: 0.3181 - val_acc: 0.8672\n",
      "Epoch 41/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3020 - acc: 0.8777 - val_loss: 0.3126 - val_acc: 0.8721\n",
      "Epoch 42/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2931 - acc: 0.8830 - val_loss: 0.3207 - val_acc: 0.8675\n",
      "Epoch 43/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2945 - acc: 0.8815 - val_loss: 0.3097 - val_acc: 0.8711\n",
      "Epoch 44/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2911 - acc: 0.8852 - val_loss: 0.3223 - val_acc: 0.8653\n",
      "Epoch 45/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2900 - acc: 0.8857 - val_loss: 0.3121 - val_acc: 0.8716\n",
      "Epoch 46/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2911 - acc: 0.8840 - val_loss: 0.3139 - val_acc: 0.8717\n",
      "Epoch 47/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.2914 - acc: 0.8834 - val_loss: 0.3305 - val_acc: 0.8665\n",
      "Epoch 48/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2955 - acc: 0.8815 - val_loss: 0.3108 - val_acc: 0.8730\n",
      "Epoch 49/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2950 - acc: 0.8835 - val_loss: 0.3147 - val_acc: 0.8734\n",
      "Epoch 50/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2890 - acc: 0.8849 - val_loss: 0.3152 - val_acc: 0.8699\n",
      "Epoch 51/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44640/44640 [==============================] - 4s 92us/step - loss: 0.2862 - acc: 0.8858 - val_loss: 0.3219 - val_acc: 0.8653\n",
      "Epoch 52/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2922 - acc: 0.8833 - val_loss: 0.3049 - val_acc: 0.8750\n",
      "Epoch 53/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2856 - acc: 0.8866 - val_loss: 0.3236 - val_acc: 0.8666\n",
      "Epoch 54/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2936 - acc: 0.8844 - val_loss: 0.3360 - val_acc: 0.8618\n",
      "Epoch 55/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2928 - acc: 0.8842 - val_loss: 0.3135 - val_acc: 0.8725\n",
      "Epoch 56/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2859 - acc: 0.8862 - val_loss: 0.3374 - val_acc: 0.8591\n",
      "Epoch 57/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.3005 - acc: 0.8805 - val_loss: 0.3297 - val_acc: 0.8612\n",
      "Epoch 58/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2983 - acc: 0.8819 - val_loss: 0.3175 - val_acc: 0.8703\n",
      "Epoch 59/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2937 - acc: 0.8838 - val_loss: 0.3050 - val_acc: 0.8759\n",
      "Epoch 60/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2862 - acc: 0.8868 - val_loss: 0.3324 - val_acc: 0.8620\n",
      "Epoch 61/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2848 - acc: 0.8870 - val_loss: 0.3056 - val_acc: 0.8755\n",
      "Epoch 62/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.2889 - acc: 0.8859 - val_loss: 0.3264 - val_acc: 0.8644\n",
      "Epoch 63/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2914 - acc: 0.8842 - val_loss: 0.3099 - val_acc: 0.8739\n",
      "Epoch 64/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2953 - acc: 0.8832 - val_loss: 0.3160 - val_acc: 0.8718\n",
      "Epoch 65/200\n",
      "44640/44640 [==============================] - 4s 92us/step - loss: 0.2942 - acc: 0.8831 - val_loss: 0.3561 - val_acc: 0.8493\n",
      "Epoch 66/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2959 - acc: 0.8818 - val_loss: 0.3267 - val_acc: 0.8667\n",
      "Epoch 67/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2980 - acc: 0.8811 - val_loss: 0.3108 - val_acc: 0.8725\n",
      "Epoch 68/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.3030 - acc: 0.8823 - val_loss: 0.3282 - val_acc: 0.8634\n",
      "Epoch 69/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.3000 - acc: 0.8820 - val_loss: 0.3234 - val_acc: 0.8638\n",
      "Epoch 70/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2892 - acc: 0.8865 - val_loss: 0.3299 - val_acc: 0.8626\n",
      "Epoch 71/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2934 - acc: 0.8845 - val_loss: 0.3196 - val_acc: 0.8685\n",
      "Epoch 72/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.3266 - acc: 0.8699 - val_loss: 0.3156 - val_acc: 0.8725\n",
      "Epoch 73/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3110 - acc: 0.8779 - val_loss: 0.3229 - val_acc: 0.8680\n",
      "Epoch 74/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.2960 - acc: 0.8828 - val_loss: 0.3184 - val_acc: 0.8698\n",
      "Epoch 75/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.3054 - acc: 0.8805 - val_loss: 0.3240 - val_acc: 0.8678\n",
      "Epoch 76/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3000 - acc: 0.8837 - val_loss: 0.3137 - val_acc: 0.8726\n",
      "Epoch 77/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2961 - acc: 0.8848 - val_loss: 0.3435 - val_acc: 0.8565\n",
      "Epoch 78/200\n",
      "44640/44640 [==============================] - 4s 91us/step - loss: 0.2921 - acc: 0.8860 - val_loss: 0.3198 - val_acc: 0.8704\n",
      "Epoch 79/200\n",
      "44640/44640 [==============================] - 5s 107us/step - loss: 0.2964 - acc: 0.8847 - val_loss: 0.3367 - val_acc: 0.8582\n",
      "Epoch 80/200\n",
      "44640/44640 [==============================] - 4s 100us/step - loss: 0.2910 - acc: 0.8872 - val_loss: 0.3177 - val_acc: 0.8706\n",
      "Epoch 81/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2980 - acc: 0.8837 - val_loss: 0.3247 - val_acc: 0.8659\n",
      "Epoch 82/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2919 - acc: 0.8860 - val_loss: 0.3337 - val_acc: 0.8635\n",
      "Epoch 83/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.3038 - acc: 0.8812 - val_loss: 0.3181 - val_acc: 0.8703\n",
      "Epoch 84/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3012 - acc: 0.8807 - val_loss: 0.3177 - val_acc: 0.8703\n",
      "Epoch 85/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.2969 - acc: 0.8857 - val_loss: 0.3188 - val_acc: 0.8723\n",
      "Epoch 86/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.2893 - acc: 0.8867 - val_loss: 0.3202 - val_acc: 0.8696\n",
      "Epoch 87/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2855 - acc: 0.8893 - val_loss: 0.3329 - val_acc: 0.8625\n",
      "Epoch 88/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.2832 - acc: 0.8898 - val_loss: 0.3323 - val_acc: 0.8651\n",
      "Epoch 89/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2857 - acc: 0.8896 - val_loss: 0.3143 - val_acc: 0.8724\n",
      "Epoch 90/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2856 - acc: 0.8892 - val_loss: 0.3094 - val_acc: 0.8749\n",
      "Epoch 91/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2794 - acc: 0.8914 - val_loss: 0.3152 - val_acc: 0.8699\n",
      "Epoch 92/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2770 - acc: 0.8920 - val_loss: 0.3181 - val_acc: 0.8702\n",
      "Epoch 93/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2776 - acc: 0.8914 - val_loss: 0.3508 - val_acc: 0.8563\n",
      "Epoch 94/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2927 - acc: 0.8857 - val_loss: 0.3165 - val_acc: 0.8716\n",
      "Epoch 95/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.2864 - acc: 0.8882 - val_loss: 0.3166 - val_acc: 0.8705\n",
      "Epoch 96/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2706 - acc: 0.8941 - val_loss: 0.3272 - val_acc: 0.8676\n",
      "Epoch 97/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2678 - acc: 0.8955 - val_loss: 0.3136 - val_acc: 0.8727\n",
      "Epoch 98/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2770 - acc: 0.8933 - val_loss: 0.3485 - val_acc: 0.8579\n",
      "Epoch 99/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2817 - acc: 0.8890 - val_loss: 0.3279 - val_acc: 0.8673\n",
      "Epoch 100/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2765 - acc: 0.8933 - val_loss: 0.3371 - val_acc: 0.8599\n",
      "Epoch 101/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2710 - acc: 0.8948 - val_loss: 0.3284 - val_acc: 0.8615\n",
      "Epoch 102/200\n",
      "44640/44640 [==============================] - 4s 99us/step - loss: 0.2730 - acc: 0.8945 - val_loss: 0.3215 - val_acc: 0.8677\n",
      "Epoch 103/200\n",
      "44640/44640 [==============================] - 5s 115us/step - loss: 0.2789 - acc: 0.8920 - val_loss: 0.3279 - val_acc: 0.8646\n",
      "Epoch 104/200\n",
      "44640/44640 [==============================] - 4s 95us/step - loss: 0.2735 - acc: 0.8939 - val_loss: 0.3385 - val_acc: 0.8635\n",
      "Epoch 105/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.2678 - acc: 0.8961 - val_loss: 0.3202 - val_acc: 0.8724\n",
      "Epoch 106/200\n",
      "44640/44640 [==============================] - 4s 84us/step - loss: 0.2722 - acc: 0.8938 - val_loss: 0.3356 - val_acc: 0.8634\n",
      "Epoch 107/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.2681 - acc: 0.8950 - val_loss: 0.3299 - val_acc: 0.8647\n",
      "Epoch 108/200\n",
      "44640/44640 [==============================] - 4s 84us/step - loss: 0.2687 - acc: 0.8979 - val_loss: 0.3322 - val_acc: 0.8606\n",
      "Epoch 109/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2736 - acc: 0.8936 - val_loss: 0.3320 - val_acc: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2752 - acc: 0.8936 - val_loss: 0.3256 - val_acc: 0.8692\n",
      "Epoch 111/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2834 - acc: 0.8899 - val_loss: 0.3215 - val_acc: 0.8699\n",
      "Epoch 112/200\n",
      "44640/44640 [==============================] - 4s 91us/step - loss: 0.2810 - acc: 0.8896 - val_loss: 0.3116 - val_acc: 0.8737\n",
      "Epoch 113/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2720 - acc: 0.8945 - val_loss: 0.3379 - val_acc: 0.8609\n",
      "Epoch 114/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2787 - acc: 0.8913 - val_loss: 0.3216 - val_acc: 0.8703\n",
      "Epoch 115/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2808 - acc: 0.8895 - val_loss: 0.3357 - val_acc: 0.8664\n",
      "Epoch 116/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2733 - acc: 0.8947 - val_loss: 0.3616 - val_acc: 0.8522\n",
      "Epoch 117/200\n",
      "44640/44640 [==============================] - 4s 91us/step - loss: 0.2679 - acc: 0.8950 - val_loss: 0.3427 - val_acc: 0.8588\n",
      "Epoch 118/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2639 - acc: 0.8991 - val_loss: 0.3369 - val_acc: 0.8646\n",
      "Epoch 119/200\n",
      "44640/44640 [==============================] - 4s 92us/step - loss: 0.2751 - acc: 0.8942 - val_loss: 0.3373 - val_acc: 0.8646\n",
      "Epoch 120/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2749 - acc: 0.8954 - val_loss: 0.3268 - val_acc: 0.8652\n",
      "Epoch 121/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2732 - acc: 0.8950 - val_loss: 0.3366 - val_acc: 0.8642\n",
      "Epoch 122/200\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.2764 - acc: 0.8925 - val_loss: 0.3443 - val_acc: 0.8570\n",
      "Epoch 123/200\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.2688 - acc: 0.8961 - val_loss: 0.3375 - val_acc: 0.8646\n",
      "Epoch 124/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2750 - acc: 0.8935 - val_loss: 0.3402 - val_acc: 0.8634\n",
      "Epoch 125/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2702 - acc: 0.8958 - val_loss: 0.3307 - val_acc: 0.8677\n",
      "Epoch 126/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2640 - acc: 0.8989 - val_loss: 0.3258 - val_acc: 0.8675\n",
      "Epoch 127/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2673 - acc: 0.8961 - val_loss: 0.3292 - val_acc: 0.8666\n",
      "Epoch 128/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2656 - acc: 0.8973 - val_loss: 0.3341 - val_acc: 0.8673\n",
      "Epoch 129/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2777 - acc: 0.8929 - val_loss: 0.3302 - val_acc: 0.8662\n",
      "Epoch 130/200\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.2707 - acc: 0.8961 - val_loss: 0.3243 - val_acc: 0.8722\n",
      "Epoch 131/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2641 - acc: 0.8981 - val_loss: 0.3447 - val_acc: 0.8603\n",
      "Epoch 132/200\n",
      "44640/44640 [==============================] - 4s 94us/step - loss: 0.2796 - acc: 0.8903 - val_loss: 0.3574 - val_acc: 0.8542\n",
      "Epoch 133/200\n",
      "44640/44640 [==============================] - 5s 110us/step - loss: 0.2739 - acc: 0.8945 - val_loss: 0.3637 - val_acc: 0.8529\n",
      "Epoch 134/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2777 - acc: 0.8923 - val_loss: 0.3293 - val_acc: 0.8677\n",
      "Epoch 135/200\n",
      "44640/44640 [==============================] - 4s 96us/step - loss: 0.2787 - acc: 0.8923 - val_loss: 0.3442 - val_acc: 0.8637\n",
      "Epoch 136/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2722 - acc: 0.8960 - val_loss: 0.3291 - val_acc: 0.8685\n",
      "Epoch 137/200\n",
      "44640/44640 [==============================] - 4s 95us/step - loss: 0.2693 - acc: 0.8950 - val_loss: 0.3265 - val_acc: 0.8670\n",
      "Epoch 138/200\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.2699 - acc: 0.8949 - val_loss: 0.3342 - val_acc: 0.8662\n",
      "Epoch 139/200\n",
      "44640/44640 [==============================] - 5s 109us/step - loss: 0.2675 - acc: 0.8966 - val_loss: 0.3221 - val_acc: 0.8717\n",
      "Epoch 140/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.2663 - acc: 0.8976 - val_loss: 0.3541 - val_acc: 0.8576\n",
      "Epoch 141/200\n",
      "44640/44640 [==============================] - 5s 106us/step - loss: 0.2728 - acc: 0.8941 - val_loss: 0.3386 - val_acc: 0.8610\n",
      "Epoch 142/200\n",
      "44640/44640 [==============================] - 5s 106us/step - loss: 0.2803 - acc: 0.8904 - val_loss: 0.3386 - val_acc: 0.8596\n",
      "Epoch 143/200\n",
      "44640/44640 [==============================] - 5s 111us/step - loss: 0.2862 - acc: 0.8869 - val_loss: 0.3568 - val_acc: 0.8525\n",
      "Epoch 144/200\n",
      "44640/44640 [==============================] - 5s 112us/step - loss: 0.2800 - acc: 0.8921 - val_loss: 0.3505 - val_acc: 0.8605\n",
      "Epoch 145/200\n",
      "44640/44640 [==============================] - 5s 107us/step - loss: 0.2797 - acc: 0.8912 - val_loss: 0.3653 - val_acc: 0.8501\n",
      "Epoch 146/200\n",
      "44640/44640 [==============================] - 5s 108us/step - loss: 0.2773 - acc: 0.8919 - val_loss: 0.3545 - val_acc: 0.8540\n",
      "Epoch 147/200\n",
      "44640/44640 [==============================] - 5s 111us/step - loss: 0.2748 - acc: 0.8939 - val_loss: 0.3435 - val_acc: 0.8565\n",
      "Epoch 148/200\n",
      "44640/44640 [==============================] - 5s 110us/step - loss: 0.2815 - acc: 0.8907 - val_loss: 0.3518 - val_acc: 0.8598\n",
      "Epoch 149/200\n",
      "44640/44640 [==============================] - 5s 108us/step - loss: 0.2763 - acc: 0.8924 - val_loss: 0.3383 - val_acc: 0.8643\n",
      "Epoch 150/200\n",
      "44640/44640 [==============================] - 5s 111us/step - loss: 0.2667 - acc: 0.8974 - val_loss: 0.3269 - val_acc: 0.8696\n",
      "Epoch 151/200\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.2717 - acc: 0.8954 - val_loss: 0.3690 - val_acc: 0.8508\n",
      "Epoch 152/200\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.2659 - acc: 0.8986 - val_loss: 0.3529 - val_acc: 0.8558\n",
      "Epoch 153/200\n",
      "44640/44640 [==============================] - 6s 140us/step - loss: 0.2698 - acc: 0.8954 - val_loss: 0.3326 - val_acc: 0.8677\n",
      "Epoch 154/200\n",
      "44640/44640 [==============================] - 9s 201us/step - loss: 0.2671 - acc: 0.8981 - val_loss: 0.3389 - val_acc: 0.8646\n",
      "Epoch 155/200\n",
      "44640/44640 [==============================] - 9s 203us/step - loss: 0.2694 - acc: 0.8976 - val_loss: 0.3497 - val_acc: 0.8599\n",
      "Epoch 156/200\n",
      "44640/44640 [==============================] - 8s 177us/step - loss: 0.2779 - acc: 0.8931 - val_loss: 0.3239 - val_acc: 0.8705\n",
      "Epoch 157/200\n",
      "44640/44640 [==============================] - 6s 132us/step - loss: 0.2671 - acc: 0.8986 - val_loss: 0.3399 - val_acc: 0.8654\n",
      "Epoch 158/200\n",
      "44640/44640 [==============================] - 5s 115us/step - loss: 0.2729 - acc: 0.8960 - val_loss: 0.3555 - val_acc: 0.8527\n",
      "Epoch 159/200\n",
      "44640/44640 [==============================] - 5s 116us/step - loss: 0.2711 - acc: 0.8955 - val_loss: 0.3425 - val_acc: 0.8664\n",
      "Epoch 160/200\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.2639 - acc: 0.8997 - val_loss: 0.3409 - val_acc: 0.8662\n",
      "Epoch 161/200\n",
      "44640/44640 [==============================] - 6s 123us/step - loss: 0.2636 - acc: 0.8995 - val_loss: 0.3293 - val_acc: 0.8689\n",
      "Epoch 162/200\n",
      "44640/44640 [==============================] - 5s 121us/step - loss: 0.2656 - acc: 0.8981 - val_loss: 0.3292 - val_acc: 0.8645\n",
      "Epoch 163/200\n",
      "44640/44640 [==============================] - 6s 126us/step - loss: 0.2640 - acc: 0.8990 - val_loss: 0.3455 - val_acc: 0.8634\n",
      "Epoch 164/200\n",
      "44640/44640 [==============================] - 5s 123us/step - loss: 0.2671 - acc: 0.8980 - val_loss: 0.3478 - val_acc: 0.8575\n",
      "Epoch 165/200\n",
      "44640/44640 [==============================] - 5s 114us/step - loss: 0.2680 - acc: 0.8974 - val_loss: 0.3371 - val_acc: 0.8680\n",
      "Epoch 166/200\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.2676 - acc: 0.8959 - val_loss: 0.3367 - val_acc: 0.8640\n",
      "Epoch 167/200\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.2595 - acc: 0.9006 - val_loss: 0.3706 - val_acc: 0.8450\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2771 - acc: 0.8926 - val_loss: 0.3385 - val_acc: 0.8625\n",
      "Epoch 169/200\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2628 - acc: 0.8998 - val_loss: 0.3478 - val_acc: 0.8603\n",
      "Epoch 170/200\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2621 - acc: 0.8998 - val_loss: 0.3650 - val_acc: 0.8527\n",
      "Epoch 171/200\n",
      "44640/44640 [==============================] - 4s 93us/step - loss: 0.2660 - acc: 0.8973 - val_loss: 0.3510 - val_acc: 0.8584\n",
      "Epoch 172/200\n",
      "44640/44640 [==============================] - 4s 96us/step - loss: 0.2636 - acc: 0.8984 - val_loss: 0.3557 - val_acc: 0.8536\n",
      "Epoch 173/200\n",
      "44640/44640 [==============================] - 4s 97us/step - loss: 0.2659 - acc: 0.8982 - val_loss: 0.3519 - val_acc: 0.8545\n",
      "Epoch 174/200\n",
      "44640/44640 [==============================] - 4s 97us/step - loss: 0.2690 - acc: 0.8967 - val_loss: 0.3388 - val_acc: 0.8686\n",
      "Epoch 175/200\n",
      "44640/44640 [==============================] - 4s 100us/step - loss: 0.2678 - acc: 0.8963 - val_loss: 0.3302 - val_acc: 0.8680\n",
      "Epoch 176/200\n",
      "44640/44640 [==============================] - 4s 99us/step - loss: 0.2640 - acc: 0.8981 - val_loss: 0.3527 - val_acc: 0.8575\n",
      "Epoch 177/200\n",
      "44640/44640 [==============================] - 4s 97us/step - loss: 0.2686 - acc: 0.8963 - val_loss: 0.3358 - val_acc: 0.8640\n",
      "Epoch 178/200\n",
      "44640/44640 [==============================] - 4s 95us/step - loss: 0.2737 - acc: 0.8940 - val_loss: 0.3351 - val_acc: 0.8664\n",
      "Epoch 179/200\n",
      "44640/44640 [==============================] - 4s 98us/step - loss: 0.2633 - acc: 0.8985 - val_loss: 0.3361 - val_acc: 0.8685\n",
      "Epoch 180/200\n",
      "44640/44640 [==============================] - 4s 97us/step - loss: 0.2602 - acc: 0.9008 - val_loss: 0.3406 - val_acc: 0.8633\n",
      "Epoch 181/200\n",
      "44640/44640 [==============================] - 4s 96us/step - loss: 0.2671 - acc: 0.8977 - val_loss: 0.3393 - val_acc: 0.8642\n",
      "Epoch 182/200\n",
      "44640/44640 [==============================] - 4s 98us/step - loss: 0.2714 - acc: 0.8954 - val_loss: 0.3762 - val_acc: 0.8448\n",
      "Epoch 183/200\n",
      "44640/44640 [==============================] - 4s 97us/step - loss: 0.2632 - acc: 0.8987 - val_loss: 0.3527 - val_acc: 0.8616\n",
      "Epoch 184/200\n",
      "43008/44640 [===========================>..] - ETA: 0s - loss: 0.2513 - acc: 0.9042"
     ]
    }
   ],
   "source": [
    "print('Buidl model...')\n",
    "model=Sequential()\n",
    "model.add(InputLayer(input_shape=(1364,)))\n",
    "model.add(Dense(output_dense, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_dense, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=200,validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 16)          3200000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 3,202,146\n",
      "Trainable params: 3,202,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 44640 samples, validate on 11160 samples\n",
      "Epoch 1/50\n",
      "44640/44640 [==============================] - 163s 4ms/step - loss: 0.6498 - acc: 0.6494 - val_loss: 0.6060 - val_acc: 0.6832\n",
      "Epoch 2/50\n",
      "44640/44640 [==============================] - 154s 3ms/step - loss: 0.5972 - acc: 0.7094 - val_loss: 0.5857 - val_acc: 0.7117\n",
      "Epoch 3/50\n",
      "44640/44640 [==============================] - 154s 3ms/step - loss: 0.5908 - acc: 0.7109 - val_loss: 0.5846 - val_acc: 0.7065\n",
      "Epoch 4/50\n",
      "44640/44640 [==============================] - 155s 3ms/step - loss: 0.5871 - acc: 0.7098 - val_loss: 0.5914 - val_acc: 0.6986\n",
      "Epoch 5/50\n",
      "44640/44640 [==============================] - 153s 3ms/step - loss: 0.5855 - acc: 0.7057 - val_loss: 0.5865 - val_acc: 0.7028\n",
      "Epoch 6/50\n",
      "44640/44640 [==============================] - 156s 3ms/step - loss: 0.5807 - acc: 0.7119 - val_loss: 0.5737 - val_acc: 0.7068\n",
      "Epoch 7/50\n",
      "44640/44640 [==============================] - 167s 4ms/step - loss: 0.5795 - acc: 0.7111 - val_loss: 0.5780 - val_acc: 0.7075\n",
      "Epoch 8/50\n",
      "44640/44640 [==============================] - 156s 4ms/step - loss: 0.5775 - acc: 0.7117 - val_loss: 0.5857 - val_acc: 0.7044\n",
      "Epoch 9/50\n",
      "44640/44640 [==============================] - 167s 4ms/step - loss: 0.5756 - acc: 0.7107 - val_loss: 0.5735 - val_acc: 0.7080\n",
      "Epoch 10/50\n",
      "38912/44640 [=========================>....] - ETA: 19s - loss: 0.5800 - acc: 0.7086"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-85a1e4bb2865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_features=200000\n",
    "print('Buidl model...')\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features, output_dim=16))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=50,validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidl model...softmax softmax  softmax\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               349440    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 481,281\n",
      "Trainable params: 481,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 44640 samples, validate on 11160 samples\n",
      "Epoch 1/120\n",
      "44640/44640 [==============================] - 6s 130us/step - loss: 0.6932 - acc: 0.4977 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/120\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.6932 - acc: 0.4981 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 3/120\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 4/120\n",
      "44640/44640 [==============================] - 5s 114us/step - loss: 0.6931 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 5/120\n",
      "44640/44640 [==============================] - 5s 117us/step - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 6/120\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 7/120\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 8/120\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.6931 - acc: 0.5030 - val_loss: 0.6931 - val_acc: 0.7680\n",
      "Epoch 9/120\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.6930 - acc: 0.5188 - val_loss: 0.6927 - val_acc: 0.7728\n",
      "Epoch 10/120\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.6921 - acc: 0.5846 - val_loss: 0.6913 - val_acc: 0.7159\n",
      "Epoch 11/120\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.6928 - acc: 0.5231 - val_loss: 0.6914 - val_acc: 0.7668\n",
      "Epoch 12/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6893 - acc: 0.6271 - val_loss: 0.6842 - val_acc: 0.8040\n",
      "Epoch 13/120\n",
      "44640/44640 [==============================] - 6s 144us/step - loss: 0.6796 - acc: 0.6391 - val_loss: 0.6720 - val_acc: 0.7134\n",
      "Epoch 14/120\n",
      "44640/44640 [==============================] - 6s 140us/step - loss: 0.6661 - acc: 0.6304 - val_loss: 0.6309 - val_acc: 0.8084\n",
      "Epoch 15/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6513 - acc: 0.6352 - val_loss: 0.6025 - val_acc: 0.7997\n",
      "Epoch 16/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6351 - acc: 0.6442 - val_loss: 0.6086 - val_acc: 0.7306\n",
      "Epoch 17/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6261 - acc: 0.6453 - val_loss: 0.5546 - val_acc: 0.8065\n",
      "Epoch 18/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6094 - acc: 0.6573 - val_loss: 0.5624 - val_acc: 0.7716\n",
      "Epoch 19/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.6167 - acc: 0.6428 - val_loss: 0.5683 - val_acc: 0.7566\n",
      "Epoch 20/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6071 - acc: 0.6515 - val_loss: 0.5577 - val_acc: 0.7585\n",
      "Epoch 21/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.6056 - acc: 0.6505 - val_loss: 0.5282 - val_acc: 0.7915\n",
      "Epoch 22/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.5956 - acc: 0.6597 - val_loss: 0.4980 - val_acc: 0.8204\n",
      "Epoch 23/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.5938 - acc: 0.6585 - val_loss: 0.4991 - val_acc: 0.8153\n",
      "Epoch 24/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.5900 - acc: 0.6601 - val_loss: 0.5808 - val_acc: 0.7211\n",
      "Epoch 25/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5987 - acc: 0.6540 - val_loss: 0.4871 - val_acc: 0.8230\n",
      "Epoch 26/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5937 - acc: 0.6546 - val_loss: 0.5154 - val_acc: 0.7991\n",
      "Epoch 27/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5848 - acc: 0.6615 - val_loss: 0.4789 - val_acc: 0.8289\n",
      "Epoch 28/120\n",
      "44640/44640 [==============================] - 7s 150us/step - loss: 0.5850 - acc: 0.6620 - val_loss: 0.4847 - val_acc: 0.8263\n",
      "Epoch 29/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5761 - acc: 0.6673 - val_loss: 0.4994 - val_acc: 0.8116\n",
      "Epoch 30/120\n",
      "44640/44640 [==============================] - 7s 150us/step - loss: 0.5818 - acc: 0.6630 - val_loss: 0.4775 - val_acc: 0.8255\n",
      "Epoch 31/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5820 - acc: 0.6627 - val_loss: 0.4750 - val_acc: 0.8302\n",
      "Epoch 32/120\n",
      "44640/44640 [==============================] - 8s 169us/step - loss: 0.5876 - acc: 0.6599 - val_loss: 0.4864 - val_acc: 0.8269\n",
      "Epoch 33/120\n",
      "44640/44640 [==============================] - 7s 158us/step - loss: 0.5900 - acc: 0.6583 - val_loss: 0.7143 - val_acc: 0.5325\n",
      "Epoch 34/120\n",
      "44640/44640 [==============================] - 7s 158us/step - loss: 0.6966 - acc: 0.5034 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 35/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6963 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 36/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6958 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 37/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6955 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 38/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6957 - acc: 0.5029 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 39/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6957 - acc: 0.4987 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 40/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6958 - acc: 0.4969 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 41/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6956 - acc: 0.4986 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 42/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6958 - acc: 0.4959 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 43/120\n",
      "44640/44640 [==============================] - 7s 161us/step - loss: 0.6954 - acc: 0.4962 - val_loss: 0.6931 - val_acc: 0.4999\n",
      "Epoch 44/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6952 - acc: 0.4976 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 45/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6955 - acc: 0.4958 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 46/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6945 - acc: 0.5011 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 47/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6950 - acc: 0.4974 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 48/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6945 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6948 - acc: 0.4988 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 50/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6948 - acc: 0.4970 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 51/120\n",
      "44640/44640 [==============================] - 6s 142us/step - loss: 0.6945 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 52/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6947 - acc: 0.4976 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 53/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6947 - acc: 0.4965 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 54/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6943 - acc: 0.5013 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 55/120\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.6942 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 56/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6946 - acc: 0.4961 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 57/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6942 - acc: 0.4971 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 58/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6939 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.4999\n",
      "Epoch 59/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6941 - acc: 0.4992 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 60/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6941 - acc: 0.4982 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 61/120\n",
      "44640/44640 [==============================] - 6s 137us/step - loss: 0.6939 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 62/120\n",
      "44640/44640 [==============================] - 6s 137us/step - loss: 0.6939 - acc: 0.4991 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 63/120\n",
      "44640/44640 [==============================] - 7s 158us/step - loss: 0.6941 - acc: 0.4945 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 64/120\n",
      "44640/44640 [==============================] - 6s 142us/step - loss: 0.6942 - acc: 0.4949 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 65/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6935 - acc: 0.5043 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 66/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6939 - acc: 0.4980 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 67/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6937 - acc: 0.5006 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 68/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6938 - acc: 0.4994 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 69/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6937 - acc: 0.4983 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 70/120\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.6935 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 71/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6936 - acc: 0.4998 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 72/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6938 - acc: 0.4976 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 73/120\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.6936 - acc: 0.4998 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 74/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6936 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 75/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6934 - acc: 0.5019 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 76/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6935 - acc: 0.4986 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 77/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 78/120\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.6934 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 79/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6936 - acc: 0.4983 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 80/120\n",
      "44640/44640 [==============================] - 6s 144us/step - loss: 0.6935 - acc: 0.5018 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 81/120\n",
      "44640/44640 [==============================] - 7s 151us/step - loss: 0.6934 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 82/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6934 - acc: 0.4986 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 83/120\n",
      "44640/44640 [==============================] - 6s 142us/step - loss: 0.6935 - acc: 0.4959 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 84/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.6934 - acc: 0.5017 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 85/120\n",
      "44640/44640 [==============================] - 8s 177us/step - loss: 0.6933 - acc: 0.5007 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 86/120\n",
      "44640/44640 [==============================] - 7s 165us/step - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 87/120\n",
      "44640/44640 [==============================] - 6s 145us/step - loss: 0.6932 - acc: 0.5041 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 88/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6936 - acc: 0.4930 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 89/120\n",
      "44640/44640 [==============================] - 7s 146us/step - loss: 0.6934 - acc: 0.4979 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 90/120\n",
      "44640/44640 [==============================] - 6s 144us/step - loss: 0.6934 - acc: 0.4978 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 91/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6934 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 92/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6933 - acc: 0.4966 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 93/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6933 - acc: 0.4986 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 94/120\n",
      "44640/44640 [==============================] - 6s 143us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 95/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 96/120\n",
      "44640/44640 [==============================] - 6s 144us/step - loss: 0.6933 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 97/120\n",
      "44640/44640 [==============================] - 6s 142us/step - loss: 0.6934 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 98/120\n",
      "44640/44640 [==============================] - 7s 155us/step - loss: 0.6931 - acc: 0.5057 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 99/120\n",
      " 1024/44640 [..............................] - ETA: 6s - loss: 0.6935 - acc: 0.4893"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bea865b599cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l_activate=['softmax','elu','selu','softplus','softsign','relu','tanh','sigmoid','hard_sigmoid','linear']\n",
    "for i in l_activate:\n",
    "    for j in l_activate:\n",
    "        for k in l_activate:\n",
    "            print('Buidl model...'+i+' '+j+' '+' '+k)\n",
    "            model=Sequential()\n",
    "            model.add(InputLayer(input_shape=(1364,)))\n",
    "            model.add(Dense(output_dense, activation=i))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(output_dense, activation=j))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(output_dense, activation=k))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(1,activation='sigmoid'))\n",
    "            model.summary()\n",
    "            model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            print('Train...')\n",
    "            model.fit(x_train, y_train,batch_size=batch_size,epochs=120,validation_data=(x_test, y_test))\n",
    "            score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "            print('Test score:', score)\n",
    "            print('Test accuracy:', acc)\n",
    "\n",
    "            pred=model.predict(x_test)\n",
    "            del model,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
