{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 17 13:02:45 2018\n",
    "\n",
    "@author: KOK\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,InputLayer,Dropout,Embedding,LSTM\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "27907 95659\n",
      "Concat data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y1_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4bfdef759911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y1_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Loading data...')\n",
    "records1 = list(SeqIO.parse(\"/media/kok/WORK/ML/Tensorflow/jupyter-kok/gencode.v27.lncRNA_transcripts.fa\", \"fasta\"))\n",
    "records2 = list(SeqIO.parse(\"/media/kok/WORK/ML/Tensorflow/jupyter-kok/gencode.v27.pc_transcripts.fa\", \"fasta\"))\n",
    "\n",
    "print(len(records1),len(records2))\n",
    "\n",
    "tmp=[]\n",
    "x1_train=[]\n",
    "n_train=27900-5580\n",
    "n_test=5580\n",
    "output_dense=256\n",
    "batch_size=512\n",
    "\n",
    "for i in records1[:n_train]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x1_train.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "\n",
    "x2_train=[]\n",
    "for i in records2[:n_train]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x2_train.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "    \n",
    "x1_test=[]\n",
    "for i in records1[-n_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x1_test.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "\n",
    "x2_test=[]\n",
    "for i in records2[-n_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x2_test.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "del records1,records2,tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat data...\n"
     ]
    }
   ],
   "source": [
    "print('Concat data...')\n",
    "x_train=np.concatenate((np.array(x1_train),np.array(x2_train)),axis=0)\n",
    "x_test=np.concatenate((np.array(x1_test),np.array(x2_test)),axis=0)\n",
    "y_train=np.concatenate((np.array(len(x1_train)*[[1,0]]),np.array(len(x2_train)*[[0,1]])),axis=0)\n",
    "y_test=np.concatenate((np.array(len(x1_test)*[[1,0]]),np.array(len(x2_test)*[[0,1]])),axis=0)\n",
    "\n",
    "\n",
    "del x1_test,x1_train,x2_test,x2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               349440    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 481,538\n",
      "Trainable params: 481,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 44640 samples, validate on 11160 samples\n",
      "Epoch 1/200\n",
      "44640/44640 [==============================] - 5s 115us/step - loss: 0.6944 - acc: 0.5118 - val_loss: 0.6921 - val_acc: 0.5711\n",
      "Epoch 2/200\n",
      "44640/44640 [==============================] - 5s 102us/step - loss: 0.6665 - acc: 0.5930 - val_loss: 0.5559 - val_acc: 0.7334\n",
      "Epoch 3/200\n",
      "44640/44640 [==============================] - 5s 107us/step - loss: 0.5137 - acc: 0.7549 - val_loss: 0.3916 - val_acc: 0.8234\n",
      "Epoch 4/200\n",
      "44640/44640 [==============================] - 5s 108us/step - loss: 0.4086 - acc: 0.8246 - val_loss: 0.3284 - val_acc: 0.8629\n",
      "Epoch 5/200\n",
      "44640/44640 [==============================] - 5s 102us/step - loss: 0.3838 - acc: 0.8381 - val_loss: 0.3729 - val_acc: 0.8436\n",
      "Epoch 6/200\n",
      "44640/44640 [==============================] - 5s 110us/step - loss: 0.3787 - acc: 0.8404 - val_loss: 0.3433 - val_acc: 0.8601\n",
      "Epoch 7/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.3637 - acc: 0.8483 - val_loss: 0.3236 - val_acc: 0.8659\n",
      "Epoch 8/200\n",
      "44640/44640 [==============================] - 6s 130us/step - loss: 0.3577 - acc: 0.8509 - val_loss: 0.3208 - val_acc: 0.8683\n",
      "Epoch 9/200\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.3531 - acc: 0.8524 - val_loss: 0.3246 - val_acc: 0.8661\n",
      "Epoch 10/200\n",
      "44640/44640 [==============================] - 6s 127us/step - loss: 0.3508 - acc: 0.8535 - val_loss: 0.3422 - val_acc: 0.8512\n",
      "Epoch 11/200\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.3396 - acc: 0.8588 - val_loss: 0.3180 - val_acc: 0.8689\n",
      "Epoch 12/200\n",
      "44640/44640 [==============================] - 5s 102us/step - loss: 0.3331 - acc: 0.8611 - val_loss: 0.3180 - val_acc: 0.8678\n",
      "Epoch 13/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.3323 - acc: 0.8635 - val_loss: 0.3249 - val_acc: 0.8663\n",
      "Epoch 14/200\n",
      "44640/44640 [==============================] - 5s 109us/step - loss: 0.3384 - acc: 0.8611 - val_loss: 0.3192 - val_acc: 0.8695\n",
      "Epoch 15/200\n",
      "44640/44640 [==============================] - 5s 108us/step - loss: 0.3344 - acc: 0.8638 - val_loss: 0.3223 - val_acc: 0.8636\n",
      "Epoch 16/200\n",
      "44640/44640 [==============================] - 5s 109us/step - loss: 0.3254 - acc: 0.8673 - val_loss: 0.3260 - val_acc: 0.8672\n",
      "Epoch 17/200\n",
      "44640/44640 [==============================] - 5s 108us/step - loss: 0.3226 - acc: 0.8672 - val_loss: 0.3145 - val_acc: 0.8700\n",
      "Epoch 18/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.3194 - acc: 0.8691 - val_loss: 0.3098 - val_acc: 0.8712\n",
      "Epoch 19/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.3153 - acc: 0.8714 - val_loss: 0.3110 - val_acc: 0.8724\n",
      "Epoch 20/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.3150 - acc: 0.8694 - val_loss: 0.3125 - val_acc: 0.8713\n",
      "Epoch 21/200\n",
      "44640/44640 [==============================] - 5s 108us/step - loss: 0.3254 - acc: 0.8654 - val_loss: 0.3200 - val_acc: 0.8711\n",
      "Epoch 22/200\n",
      "44640/44640 [==============================] - 5s 112us/step - loss: 0.3212 - acc: 0.8681 - val_loss: 0.3095 - val_acc: 0.8736\n",
      "Epoch 23/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.3153 - acc: 0.8718 - val_loss: 0.3205 - val_acc: 0.8683\n",
      "Epoch 24/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.3186 - acc: 0.8701 - val_loss: 0.3183 - val_acc: 0.8721\n",
      "Epoch 25/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.3169 - acc: 0.8729 - val_loss: 0.3240 - val_acc: 0.8676\n",
      "Epoch 26/200\n",
      "44640/44640 [==============================] - 5s 108us/step - loss: 0.3152 - acc: 0.8724 - val_loss: 0.3094 - val_acc: 0.8732\n",
      "Epoch 27/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.3107 - acc: 0.8739 - val_loss: 0.3099 - val_acc: 0.8726\n",
      "Epoch 28/200\n",
      "44640/44640 [==============================] - 5s 101us/step - loss: 0.3058 - acc: 0.8763 - val_loss: 0.3213 - val_acc: 0.8653\n",
      "Epoch 29/200\n",
      "44640/44640 [==============================] - 5s 115us/step - loss: 0.3157 - acc: 0.8713 - val_loss: 0.3103 - val_acc: 0.8733\n",
      "Epoch 30/200\n",
      "44640/44640 [==============================] - 6s 140us/step - loss: 0.3098 - acc: 0.8745 - val_loss: 0.3169 - val_acc: 0.8693\n",
      "Epoch 31/200\n",
      "44640/44640 [==============================] - 5s 115us/step - loss: 0.3127 - acc: 0.8731 - val_loss: 0.3213 - val_acc: 0.8675\n",
      "Epoch 32/200\n",
      "44640/44640 [==============================] - 6s 132us/step - loss: 0.3101 - acc: 0.8739 - val_loss: 0.3145 - val_acc: 0.8707\n",
      "Epoch 33/200\n",
      "44640/44640 [==============================] - 6s 137us/step - loss: 0.3057 - acc: 0.8773 - val_loss: 0.3292 - val_acc: 0.8644\n",
      "Epoch 34/200\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.3074 - acc: 0.8761 - val_loss: 0.3198 - val_acc: 0.8665\n",
      "Epoch 35/200\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.3176 - acc: 0.8696 - val_loss: 0.3133 - val_acc: 0.8702\n",
      "Epoch 36/200\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.3009 - acc: 0.8792 - val_loss: 0.3156 - val_acc: 0.8692\n",
      "Epoch 37/200\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.3155 - acc: 0.8726 - val_loss: 0.3196 - val_acc: 0.8659\n",
      "Epoch 38/200\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.3057 - acc: 0.8773 - val_loss: 0.3230 - val_acc: 0.8642\n",
      "Epoch 39/200\n",
      "44640/44640 [==============================] - 6s 140us/step - loss: 0.3064 - acc: 0.8759 - val_loss: 0.3125 - val_acc: 0.8713\n",
      "Epoch 40/200\n",
      "44640/44640 [==============================] - 6s 132us/step - loss: 0.2986 - acc: 0.8811 - val_loss: 0.3120 - val_acc: 0.8704\n",
      "Epoch 41/200\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.2969 - acc: 0.8809 - val_loss: 0.3124 - val_acc: 0.8700\n",
      "Epoch 42/200\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.2986 - acc: 0.8814 - val_loss: 0.3174 - val_acc: 0.8684\n",
      "Epoch 43/200\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.3093 - acc: 0.8770 - val_loss: 0.3129 - val_acc: 0.8712\n",
      "Epoch 44/200\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.3058 - acc: 0.8782 - val_loss: 0.3108 - val_acc: 0.8741\n",
      "Epoch 45/200\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.2964 - acc: 0.8810 - val_loss: 0.3187 - val_acc: 0.8680\n",
      "Epoch 46/200\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.2947 - acc: 0.8829 - val_loss: 0.3175 - val_acc: 0.8705\n",
      "Epoch 47/200\n",
      "44640/44640 [==============================] - 6s 132us/step - loss: 0.2970 - acc: 0.8821 - val_loss: 0.3041 - val_acc: 0.8749\n",
      "Epoch 48/200\n",
      "44640/44640 [==============================] - 5s 106us/step - loss: 0.3067 - acc: 0.8765 - val_loss: 0.3168 - val_acc: 0.8674\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.3005 - acc: 0.8810 - val_loss: 0.3108 - val_acc: 0.8735\n",
      "Epoch 50/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2941 - acc: 0.8835 - val_loss: 0.3169 - val_acc: 0.8703\n",
      "Epoch 51/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2981 - acc: 0.8822 - val_loss: 0.3376 - val_acc: 0.8567\n",
      "Epoch 52/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2999 - acc: 0.8815 - val_loss: 0.3126 - val_acc: 0.8685\n",
      "Epoch 53/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2995 - acc: 0.8801 - val_loss: 0.3541 - val_acc: 0.8487\n",
      "Epoch 54/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.3099 - acc: 0.8770 - val_loss: 0.3198 - val_acc: 0.8670\n",
      "Epoch 55/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.3100 - acc: 0.8752 - val_loss: 0.3141 - val_acc: 0.8711\n",
      "Epoch 56/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2956 - acc: 0.8828 - val_loss: 0.3183 - val_acc: 0.8692\n",
      "Epoch 57/200\n",
      "44640/44640 [==============================] - 5s 107us/step - loss: 0.2956 - acc: 0.8829 - val_loss: 0.3150 - val_acc: 0.8721\n",
      "Epoch 58/200\n",
      "44640/44640 [==============================] - 4s 100us/step - loss: 0.2976 - acc: 0.8833 - val_loss: 0.3192 - val_acc: 0.8671\n",
      "Epoch 59/200\n",
      "44640/44640 [==============================] - 5s 120us/step - loss: 0.3002 - acc: 0.8807 - val_loss: 0.3189 - val_acc: 0.8680\n",
      "Epoch 60/200\n",
      "44640/44640 [==============================] - 5s 115us/step - loss: 0.2874 - acc: 0.8873 - val_loss: 0.3330 - val_acc: 0.8588\n",
      "Epoch 61/200\n",
      "44640/44640 [==============================] - 5s 119us/step - loss: 0.2906 - acc: 0.8850 - val_loss: 0.3184 - val_acc: 0.8669\n",
      "Epoch 62/200\n",
      "44640/44640 [==============================] - 5s 107us/step - loss: 0.2896 - acc: 0.8850 - val_loss: 0.3276 - val_acc: 0.8597\n",
      "Epoch 63/200\n",
      "44640/44640 [==============================] - 5s 106us/step - loss: 0.2882 - acc: 0.8863 - val_loss: 0.3199 - val_acc: 0.8665\n",
      "Epoch 64/200\n",
      "44640/44640 [==============================] - 5s 122us/step - loss: 0.2945 - acc: 0.8837 - val_loss: 0.3418 - val_acc: 0.8566\n",
      "Epoch 65/200\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.2871 - acc: 0.8871 - val_loss: 0.3344 - val_acc: 0.8592\n",
      "Epoch 66/200\n",
      "44640/44640 [==============================] - 7s 158us/step - loss: 0.2961 - acc: 0.8832 - val_loss: 0.3134 - val_acc: 0.8711\n",
      "Epoch 67/200\n",
      "44640/44640 [==============================] - 5s 123us/step - loss: 0.2843 - acc: 0.8874 - val_loss: 0.3168 - val_acc: 0.8706\n",
      "Epoch 68/200\n",
      "44640/44640 [==============================] - 5s 122us/step - loss: 0.2877 - acc: 0.8867 - val_loss: 0.3167 - val_acc: 0.8682\n",
      "Epoch 69/200\n",
      "44640/44640 [==============================] - 7s 153us/step - loss: 0.2783 - acc: 0.8913 - val_loss: 0.3153 - val_acc: 0.8695\n",
      "Epoch 70/200\n",
      "44640/44640 [==============================] - 7s 150us/step - loss: 0.2817 - acc: 0.8899 - val_loss: 0.3185 - val_acc: 0.8694\n",
      "Epoch 71/200\n",
      "44640/44640 [==============================] - 6s 143us/step - loss: 0.2845 - acc: 0.8890 - val_loss: 0.3131 - val_acc: 0.8707\n",
      "Epoch 72/200\n",
      "44640/44640 [==============================] - 7s 150us/step - loss: 0.2862 - acc: 0.8875 - val_loss: 0.3247 - val_acc: 0.8663\n",
      "Epoch 73/200\n",
      "44640/44640 [==============================] - 8s 175us/step - loss: 0.2935 - acc: 0.8860 - val_loss: 0.3224 - val_acc: 0.8670\n",
      "Epoch 74/200\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.2920 - acc: 0.8852 - val_loss: 0.3368 - val_acc: 0.8542\n",
      "Epoch 75/200\n",
      "44640/44640 [==============================] - 5s 123us/step - loss: 0.2991 - acc: 0.8827 - val_loss: 0.3223 - val_acc: 0.8657\n",
      "Epoch 76/200\n",
      "44640/44640 [==============================] - 7s 146us/step - loss: 0.2868 - acc: 0.8877 - val_loss: 0.3187 - val_acc: 0.8659\n",
      "Epoch 77/200\n",
      "44640/44640 [==============================] - 7s 151us/step - loss: 0.2858 - acc: 0.8888 - val_loss: 0.3186 - val_acc: 0.8669\n",
      "Epoch 78/200\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.2861 - acc: 0.8890 - val_loss: 0.3173 - val_acc: 0.8689\n",
      "Epoch 79/200\n",
      "44640/44640 [==============================] - 6s 140us/step - loss: 0.2843 - acc: 0.8874 - val_loss: 0.3292 - val_acc: 0.8642\n",
      "Epoch 80/200\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.2867 - acc: 0.8874 - val_loss: 0.3176 - val_acc: 0.8692\n",
      "Epoch 81/200\n",
      "44640/44640 [==============================] - 6s 137us/step - loss: 0.2802 - acc: 0.8902 - val_loss: 0.3263 - val_acc: 0.8664\n",
      "Epoch 82/200\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.2750 - acc: 0.8948 - val_loss: 0.3359 - val_acc: 0.8628\n",
      "Epoch 83/200\n",
      "44640/44640 [==============================] - 6s 132us/step - loss: 0.2770 - acc: 0.8921 - val_loss: 0.3359 - val_acc: 0.8573\n",
      "Epoch 84/200\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.2747 - acc: 0.8940 - val_loss: 0.3376 - val_acc: 0.8564\n",
      "Epoch 85/200\n",
      "44640/44640 [==============================] - 6s 137us/step - loss: 0.2735 - acc: 0.8938 - val_loss: 0.3282 - val_acc: 0.8650\n",
      "Epoch 86/200\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.2764 - acc: 0.8915 - val_loss: 0.3426 - val_acc: 0.8552\n",
      "Epoch 87/200\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.2744 - acc: 0.8945 - val_loss: 0.3224 - val_acc: 0.8682\n",
      "Epoch 88/200\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.2733 - acc: 0.8934 - val_loss: 0.3160 - val_acc: 0.8720\n",
      "Epoch 89/200\n",
      "44640/44640 [==============================] - 6s 132us/step - loss: 0.2845 - acc: 0.8876 - val_loss: 0.3416 - val_acc: 0.8571\n",
      "Epoch 90/200\n",
      "44640/44640 [==============================] - 6s 140us/step - loss: 0.2818 - acc: 0.8894 - val_loss: 0.3177 - val_acc: 0.8743\n",
      "Epoch 91/200\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.2812 - acc: 0.8912 - val_loss: 0.3350 - val_acc: 0.8614\n",
      "Epoch 92/200\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.2814 - acc: 0.8898 - val_loss: 0.3264 - val_acc: 0.8681\n",
      "Epoch 93/200\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.2851 - acc: 0.8891 - val_loss: 0.3209 - val_acc: 0.8654\n",
      "Epoch 94/200\n",
      "44640/44640 [==============================] - 6s 140us/step - loss: 0.2776 - acc: 0.8914 - val_loss: 0.3493 - val_acc: 0.8563\n",
      "Epoch 95/200\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.2822 - acc: 0.8897 - val_loss: 0.3202 - val_acc: 0.8698\n",
      "Epoch 96/200\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.2758 - acc: 0.8931 - val_loss: 0.3335 - val_acc: 0.8657\n",
      "Epoch 97/200\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.2835 - acc: 0.8886 - val_loss: 0.3198 - val_acc: 0.8736\n",
      "Epoch 98/200\n",
      "44640/44640 [==============================] - 6s 132us/step - loss: 0.2792 - acc: 0.8916 - val_loss: 0.3204 - val_acc: 0.8705\n",
      "Epoch 99/200\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.2689 - acc: 0.8961 - val_loss: 0.3434 - val_acc: 0.8615\n",
      "Epoch 100/200\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.2786 - acc: 0.8909 - val_loss: 0.3363 - val_acc: 0.8617\n",
      "Epoch 101/200\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.2788 - acc: 0.8914 - val_loss: 0.3214 - val_acc: 0.8695\n",
      "Epoch 102/200\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.2851 - acc: 0.8888 - val_loss: 0.3429 - val_acc: 0.8592\n",
      "Epoch 103/200\n",
      "44640/44640 [==============================] - 6s 144us/step - loss: 0.2784 - acc: 0.8920 - val_loss: 0.3442 - val_acc: 0.8592\n",
      "Epoch 104/200\n",
      "44640/44640 [==============================] - 6s 143us/step - loss: 0.2701 - acc: 0.8945 - val_loss: 0.3312 - val_acc: 0.8720\n",
      "Epoch 105/200\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.2799 - acc: 0.8902 - val_loss: 0.3357 - val_acc: 0.8636\n",
      "Epoch 106/200\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.2829 - acc: 0.8893 - val_loss: 0.3332 - val_acc: 0.8635\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44640/44640 [==============================] - 5s 116us/step - loss: 0.2768 - acc: 0.8929 - val_loss: 0.3390 - val_acc: 0.8642\n",
      "Epoch 108/200\n",
      "44640/44640 [==============================] - 5s 118us/step - loss: 0.2713 - acc: 0.8946 - val_loss: 0.3187 - val_acc: 0.8728\n",
      "Epoch 109/200\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.2806 - acc: 0.8895 - val_loss: 0.3358 - val_acc: 0.8618\n",
      "Epoch 110/200\n",
      "44640/44640 [==============================] - 5s 121us/step - loss: 0.2748 - acc: 0.8933 - val_loss: 0.3321 - val_acc: 0.8660\n",
      "Epoch 111/200\n",
      "44640/44640 [==============================] - 5s 121us/step - loss: 0.2685 - acc: 0.8975 - val_loss: 0.3536 - val_acc: 0.8546\n",
      "Epoch 112/200\n",
      "44640/44640 [==============================] - 5s 117us/step - loss: 0.2703 - acc: 0.8960 - val_loss: 0.3432 - val_acc: 0.8638\n",
      "Epoch 113/200\n",
      "44640/44640 [==============================] - 5s 121us/step - loss: 0.2769 - acc: 0.8916 - val_loss: 0.3280 - val_acc: 0.8688\n",
      "Epoch 114/200\n",
      "44640/44640 [==============================] - 5s 117us/step - loss: 0.2786 - acc: 0.8917 - val_loss: 0.3471 - val_acc: 0.8599\n",
      "Epoch 115/200\n",
      "44640/44640 [==============================] - 5s 117us/step - loss: 0.2795 - acc: 0.8915 - val_loss: 0.3360 - val_acc: 0.8649\n",
      "Epoch 116/200\n",
      "44640/44640 [==============================] - 5s 121us/step - loss: 0.2740 - acc: 0.8949 - val_loss: 0.3543 - val_acc: 0.8559\n",
      "Epoch 117/200\n",
      "44640/44640 [==============================] - 5s 118us/step - loss: 0.2724 - acc: 0.8950 - val_loss: 0.3419 - val_acc: 0.8644\n",
      "Epoch 118/200\n",
      "44640/44640 [==============================] - 5s 120us/step - loss: 0.2670 - acc: 0.8986 - val_loss: 0.3353 - val_acc: 0.8696\n",
      "Epoch 119/200\n",
      "44640/44640 [==============================] - 5s 119us/step - loss: 0.2674 - acc: 0.8981 - val_loss: 0.3333 - val_acc: 0.8685\n",
      "Epoch 120/200\n",
      "44640/44640 [==============================] - 5s 118us/step - loss: 0.2756 - acc: 0.8929 - val_loss: 0.3284 - val_acc: 0.8641\n",
      "Epoch 121/200\n",
      "44640/44640 [==============================] - 5s 118us/step - loss: 0.2651 - acc: 0.8975 - val_loss: 0.3601 - val_acc: 0.8523\n",
      "Epoch 122/200\n",
      "44640/44640 [==============================] - 5s 120us/step - loss: 0.2700 - acc: 0.8960 - val_loss: 0.3356 - val_acc: 0.8665\n",
      "Epoch 123/200\n",
      "44640/44640 [==============================] - 5s 119us/step - loss: 0.2636 - acc: 0.8994 - val_loss: 0.3519 - val_acc: 0.8588\n",
      "Epoch 124/200\n",
      "44640/44640 [==============================] - 5s 123us/step - loss: 0.2645 - acc: 0.8981 - val_loss: 0.3282 - val_acc: 0.8717\n",
      "Epoch 125/200\n",
      "44640/44640 [==============================] - 6s 125us/step - loss: 0.2684 - acc: 0.8975 - val_loss: 0.3482 - val_acc: 0.8594\n",
      "Epoch 126/200\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.2643 - acc: 0.8985 - val_loss: 0.3396 - val_acc: 0.8653\n",
      "Epoch 127/200\n",
      "44640/44640 [==============================] - 5s 117us/step - loss: 0.2701 - acc: 0.8959 - val_loss: 0.3362 - val_acc: 0.8682\n",
      "Epoch 128/200\n",
      "44640/44640 [==============================] - 5s 123us/step - loss: 0.2765 - acc: 0.8933 - val_loss: 0.3472 - val_acc: 0.8613\n",
      "Epoch 129/200\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.2710 - acc: 0.8957 - val_loss: 0.3278 - val_acc: 0.8705\n",
      "Epoch 130/200\n",
      "44640/44640 [==============================] - 5s 119us/step - loss: 0.2680 - acc: 0.8967 - val_loss: 0.3471 - val_acc: 0.8638\n",
      "Epoch 131/200\n",
      "44640/44640 [==============================] - 5s 117us/step - loss: 0.2674 - acc: 0.8982 - val_loss: 0.3380 - val_acc: 0.8591\n",
      "Epoch 132/200\n",
      "44640/44640 [==============================] - 5s 109us/step - loss: 0.2736 - acc: 0.8939 - val_loss: 0.3494 - val_acc: 0.8588\n",
      "Epoch 133/200\n",
      "44640/44640 [==============================] - 5s 110us/step - loss: 0.2682 - acc: 0.8962 - val_loss: 0.3451 - val_acc: 0.8601\n",
      "Epoch 134/200\n",
      "44640/44640 [==============================] - 5s 108us/step - loss: 0.2786 - acc: 0.8927 - val_loss: 0.3211 - val_acc: 0.8709\n",
      "Epoch 135/200\n",
      "44640/44640 [==============================] - 5s 111us/step - loss: 0.2674 - acc: 0.8989 - val_loss: 0.3467 - val_acc: 0.8641\n",
      "Epoch 136/200\n",
      "44640/44640 [==============================] - 5s 114us/step - loss: 0.2661 - acc: 0.8978 - val_loss: 0.3435 - val_acc: 0.8624\n",
      "Epoch 137/200\n",
      "44640/44640 [==============================] - 6s 124us/step - loss: 0.2621 - acc: 0.9006 - val_loss: 0.3339 - val_acc: 0.8677\n",
      "Epoch 138/200\n",
      "44640/44640 [==============================] - 5s 109us/step - loss: 0.2611 - acc: 0.9008 - val_loss: 0.3451 - val_acc: 0.8642\n",
      "Epoch 139/200\n",
      "44640/44640 [==============================] - 5s 117us/step - loss: 0.2585 - acc: 0.9020 - val_loss: 0.3579 - val_acc: 0.8569\n",
      "Epoch 140/200\n",
      "44640/44640 [==============================] - 5s 119us/step - loss: 0.2641 - acc: 0.8987 - val_loss: 0.3356 - val_acc: 0.8699\n",
      "Epoch 141/200\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.2580 - acc: 0.9025 - val_loss: 0.3476 - val_acc: 0.8667\n",
      "Epoch 142/200\n",
      "44640/44640 [==============================] - 5s 107us/step - loss: 0.2620 - acc: 0.8996 - val_loss: 0.3452 - val_acc: 0.8625\n",
      "Epoch 143/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.2617 - acc: 0.9008 - val_loss: 0.3374 - val_acc: 0.8676\n",
      "Epoch 144/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2640 - acc: 0.8991 - val_loss: 0.3387 - val_acc: 0.8681\n",
      "Epoch 145/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.2653 - acc: 0.8964 - val_loss: 0.3596 - val_acc: 0.8617\n",
      "Epoch 146/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.2698 - acc: 0.8976 - val_loss: 0.3514 - val_acc: 0.8570\n",
      "Epoch 147/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.2752 - acc: 0.8950 - val_loss: 0.3263 - val_acc: 0.8700\n",
      "Epoch 148/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.2733 - acc: 0.8944 - val_loss: 0.3278 - val_acc: 0.8735\n",
      "Epoch 149/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.2746 - acc: 0.8944 - val_loss: 0.3311 - val_acc: 0.8656\n",
      "Epoch 150/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2669 - acc: 0.8965 - val_loss: 0.3399 - val_acc: 0.8677\n",
      "Epoch 151/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2624 - acc: 0.9006 - val_loss: 0.3340 - val_acc: 0.8683\n",
      "Epoch 152/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2625 - acc: 0.8997 - val_loss: 0.3572 - val_acc: 0.8582\n",
      "Epoch 153/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2727 - acc: 0.8944 - val_loss: 0.3428 - val_acc: 0.8613\n",
      "Epoch 154/200\n",
      "44640/44640 [==============================] - 5s 107us/step - loss: 0.2675 - acc: 0.8980 - val_loss: 0.3437 - val_acc: 0.8616\n",
      "Epoch 155/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.2661 - acc: 0.8984 - val_loss: 0.3395 - val_acc: 0.8628\n",
      "Epoch 156/200\n",
      "44640/44640 [==============================] - 5s 102us/step - loss: 0.2671 - acc: 0.8975 - val_loss: 0.3211 - val_acc: 0.8736\n",
      "Epoch 157/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.2649 - acc: 0.8981 - val_loss: 0.3267 - val_acc: 0.8736\n",
      "Epoch 158/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2657 - acc: 0.8985 - val_loss: 0.3441 - val_acc: 0.8647\n",
      "Epoch 159/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.2672 - acc: 0.8977 - val_loss: 0.3261 - val_acc: 0.8726\n",
      "Epoch 160/200\n",
      "44640/44640 [==============================] - 5s 107us/step - loss: 0.2605 - acc: 0.9008 - val_loss: 0.3341 - val_acc: 0.8720\n",
      "Epoch 161/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.2593 - acc: 0.9008 - val_loss: 0.3492 - val_acc: 0.8639\n",
      "Epoch 162/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2588 - acc: 0.9010 - val_loss: 0.3323 - val_acc: 0.8678\n",
      "Epoch 163/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.2651 - acc: 0.9000 - val_loss: 0.3491 - val_acc: 0.8623\n",
      "Epoch 164/200\n",
      "44640/44640 [==============================] - 5s 102us/step - loss: 0.2593 - acc: 0.9020 - val_loss: 0.3386 - val_acc: 0.8726\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44640/44640 [==============================] - 5s 106us/step - loss: 0.2521 - acc: 0.9055 - val_loss: 0.3452 - val_acc: 0.8625\n",
      "Epoch 166/200\n",
      "44640/44640 [==============================] - 5s 104us/step - loss: 0.2570 - acc: 0.9017 - val_loss: 0.3565 - val_acc: 0.8581\n",
      "Epoch 167/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.2590 - acc: 0.9021 - val_loss: 0.3402 - val_acc: 0.8671\n",
      "Epoch 168/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.2533 - acc: 0.9035 - val_loss: 0.3481 - val_acc: 0.8666\n",
      "Epoch 169/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.2586 - acc: 0.9031 - val_loss: 0.3532 - val_acc: 0.8587\n",
      "Epoch 170/200\n",
      "44640/44640 [==============================] - 5s 106us/step - loss: 0.2593 - acc: 0.9014 - val_loss: 0.3552 - val_acc: 0.8634\n",
      "Epoch 171/200\n",
      "44640/44640 [==============================] - 5s 108us/step - loss: 0.2626 - acc: 0.8998 - val_loss: 0.3321 - val_acc: 0.8715\n",
      "Epoch 172/200\n",
      "44640/44640 [==============================] - 5s 105us/step - loss: 0.2650 - acc: 0.8997 - val_loss: 0.3505 - val_acc: 0.8620\n",
      "Epoch 173/200\n",
      "44640/44640 [==============================] - 5s 111us/step - loss: 0.2632 - acc: 0.9004 - val_loss: 0.3442 - val_acc: 0.8638\n",
      "Epoch 174/200\n",
      "44640/44640 [==============================] - 5s 116us/step - loss: 0.2576 - acc: 0.9030 - val_loss: 0.3512 - val_acc: 0.8685\n",
      "Epoch 175/200\n",
      "44640/44640 [==============================] - 5s 103us/step - loss: 0.2541 - acc: 0.9034 - val_loss: 0.3536 - val_acc: 0.8611\n",
      "Epoch 176/200\n",
      "44640/44640 [==============================] - 5s 102us/step - loss: 0.2511 - acc: 0.9052 - val_loss: 0.3555 - val_acc: 0.8611\n",
      "Epoch 177/200\n",
      "44640/44640 [==============================] - 5s 107us/step - loss: 0.2463 - acc: 0.9074 - val_loss: 0.3511 - val_acc: 0.8631\n",
      "Epoch 178/200\n",
      "44640/44640 [==============================] - 6s 124us/step - loss: 0.2481 - acc: 0.9066 - val_loss: 0.3387 - val_acc: 0.8701\n",
      "Epoch 179/200\n",
      "39936/44640 [=========================>....] - ETA: 0s - loss: 0.2515 - acc: 0.9041"
     ]
    }
   ],
   "source": [
    "print('Buidl model...')\n",
    "model=Sequential()\n",
    "model.add(InputLayer(input_shape=(1364,)))\n",
    "model.add(Dense(output_dense, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_dense, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_dense, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=200,validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 16)          3200000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 3,202,146\n",
      "Trainable params: 3,202,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 44640 samples, validate on 11160 samples\n",
      "Epoch 1/50\n",
      "44640/44640 [==============================] - 163s 4ms/step - loss: 0.6498 - acc: 0.6494 - val_loss: 0.6060 - val_acc: 0.6832\n",
      "Epoch 2/50\n",
      "44640/44640 [==============================] - 154s 3ms/step - loss: 0.5972 - acc: 0.7094 - val_loss: 0.5857 - val_acc: 0.7117\n",
      "Epoch 3/50\n",
      "44640/44640 [==============================] - 154s 3ms/step - loss: 0.5908 - acc: 0.7109 - val_loss: 0.5846 - val_acc: 0.7065\n",
      "Epoch 4/50\n",
      "44640/44640 [==============================] - 155s 3ms/step - loss: 0.5871 - acc: 0.7098 - val_loss: 0.5914 - val_acc: 0.6986\n",
      "Epoch 5/50\n",
      "44640/44640 [==============================] - 153s 3ms/step - loss: 0.5855 - acc: 0.7057 - val_loss: 0.5865 - val_acc: 0.7028\n",
      "Epoch 6/50\n",
      "44640/44640 [==============================] - 156s 3ms/step - loss: 0.5807 - acc: 0.7119 - val_loss: 0.5737 - val_acc: 0.7068\n",
      "Epoch 7/50\n",
      "44640/44640 [==============================] - 167s 4ms/step - loss: 0.5795 - acc: 0.7111 - val_loss: 0.5780 - val_acc: 0.7075\n",
      "Epoch 8/50\n",
      "44640/44640 [==============================] - 156s 4ms/step - loss: 0.5775 - acc: 0.7117 - val_loss: 0.5857 - val_acc: 0.7044\n",
      "Epoch 9/50\n",
      "44640/44640 [==============================] - 167s 4ms/step - loss: 0.5756 - acc: 0.7107 - val_loss: 0.5735 - val_acc: 0.7080\n",
      "Epoch 10/50\n",
      "38912/44640 [=========================>....] - ETA: 19s - loss: 0.5800 - acc: 0.7086"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-85a1e4bb2865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_features=200000\n",
    "print('Buidl model...')\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features, output_dim=16))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=50,validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidl model...softmax softmax  softmax\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               349440    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 481,281\n",
      "Trainable params: 481,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 44640 samples, validate on 11160 samples\n",
      "Epoch 1/120\n",
      "44640/44640 [==============================] - 6s 130us/step - loss: 0.6932 - acc: 0.4977 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 2/120\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.6932 - acc: 0.4981 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 3/120\n",
      "44640/44640 [==============================] - 5s 113us/step - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 4/120\n",
      "44640/44640 [==============================] - 5s 114us/step - loss: 0.6931 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 5/120\n",
      "44640/44640 [==============================] - 5s 117us/step - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 6/120\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.6932 - acc: 0.5010 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 7/120\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 8/120\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.6931 - acc: 0.5030 - val_loss: 0.6931 - val_acc: 0.7680\n",
      "Epoch 9/120\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.6930 - acc: 0.5188 - val_loss: 0.6927 - val_acc: 0.7728\n",
      "Epoch 10/120\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.6921 - acc: 0.5846 - val_loss: 0.6913 - val_acc: 0.7159\n",
      "Epoch 11/120\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.6928 - acc: 0.5231 - val_loss: 0.6914 - val_acc: 0.7668\n",
      "Epoch 12/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6893 - acc: 0.6271 - val_loss: 0.6842 - val_acc: 0.8040\n",
      "Epoch 13/120\n",
      "44640/44640 [==============================] - 6s 144us/step - loss: 0.6796 - acc: 0.6391 - val_loss: 0.6720 - val_acc: 0.7134\n",
      "Epoch 14/120\n",
      "44640/44640 [==============================] - 6s 140us/step - loss: 0.6661 - acc: 0.6304 - val_loss: 0.6309 - val_acc: 0.8084\n",
      "Epoch 15/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6513 - acc: 0.6352 - val_loss: 0.6025 - val_acc: 0.7997\n",
      "Epoch 16/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6351 - acc: 0.6442 - val_loss: 0.6086 - val_acc: 0.7306\n",
      "Epoch 17/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6261 - acc: 0.6453 - val_loss: 0.5546 - val_acc: 0.8065\n",
      "Epoch 18/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6094 - acc: 0.6573 - val_loss: 0.5624 - val_acc: 0.7716\n",
      "Epoch 19/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.6167 - acc: 0.6428 - val_loss: 0.5683 - val_acc: 0.7566\n",
      "Epoch 20/120\n",
      "44640/44640 [==============================] - 7s 147us/step - loss: 0.6071 - acc: 0.6515 - val_loss: 0.5577 - val_acc: 0.7585\n",
      "Epoch 21/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.6056 - acc: 0.6505 - val_loss: 0.5282 - val_acc: 0.7915\n",
      "Epoch 22/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.5956 - acc: 0.6597 - val_loss: 0.4980 - val_acc: 0.8204\n",
      "Epoch 23/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.5938 - acc: 0.6585 - val_loss: 0.4991 - val_acc: 0.8153\n",
      "Epoch 24/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.5900 - acc: 0.6601 - val_loss: 0.5808 - val_acc: 0.7211\n",
      "Epoch 25/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5987 - acc: 0.6540 - val_loss: 0.4871 - val_acc: 0.8230\n",
      "Epoch 26/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5937 - acc: 0.6546 - val_loss: 0.5154 - val_acc: 0.7991\n",
      "Epoch 27/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5848 - acc: 0.6615 - val_loss: 0.4789 - val_acc: 0.8289\n",
      "Epoch 28/120\n",
      "44640/44640 [==============================] - 7s 150us/step - loss: 0.5850 - acc: 0.6620 - val_loss: 0.4847 - val_acc: 0.8263\n",
      "Epoch 29/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5761 - acc: 0.6673 - val_loss: 0.4994 - val_acc: 0.8116\n",
      "Epoch 30/120\n",
      "44640/44640 [==============================] - 7s 150us/step - loss: 0.5818 - acc: 0.6630 - val_loss: 0.4775 - val_acc: 0.8255\n",
      "Epoch 31/120\n",
      "44640/44640 [==============================] - 7s 149us/step - loss: 0.5820 - acc: 0.6627 - val_loss: 0.4750 - val_acc: 0.8302\n",
      "Epoch 32/120\n",
      "44640/44640 [==============================] - 8s 169us/step - loss: 0.5876 - acc: 0.6599 - val_loss: 0.4864 - val_acc: 0.8269\n",
      "Epoch 33/120\n",
      "44640/44640 [==============================] - 7s 158us/step - loss: 0.5900 - acc: 0.6583 - val_loss: 0.7143 - val_acc: 0.5325\n",
      "Epoch 34/120\n",
      "44640/44640 [==============================] - 7s 158us/step - loss: 0.6966 - acc: 0.5034 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 35/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6963 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 36/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6958 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 37/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6955 - acc: 0.5014 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 38/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6957 - acc: 0.5029 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 39/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6957 - acc: 0.4987 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 40/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6958 - acc: 0.4969 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 41/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6956 - acc: 0.4986 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 42/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6958 - acc: 0.4959 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 43/120\n",
      "44640/44640 [==============================] - 7s 161us/step - loss: 0.6954 - acc: 0.4962 - val_loss: 0.6931 - val_acc: 0.4999\n",
      "Epoch 44/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6952 - acc: 0.4976 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 45/120\n",
      "44640/44640 [==============================] - 7s 159us/step - loss: 0.6955 - acc: 0.4958 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 46/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6945 - acc: 0.5011 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 47/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6950 - acc: 0.4974 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 48/120\n",
      "44640/44640 [==============================] - 7s 160us/step - loss: 0.6945 - acc: 0.5001 - val_loss: 0.6931 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6948 - acc: 0.4988 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 50/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6948 - acc: 0.4970 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 51/120\n",
      "44640/44640 [==============================] - 6s 142us/step - loss: 0.6945 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 52/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6947 - acc: 0.4976 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 53/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6947 - acc: 0.4965 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 54/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6943 - acc: 0.5013 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 55/120\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.6942 - acc: 0.4997 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 56/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6946 - acc: 0.4961 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 57/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6942 - acc: 0.4971 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 58/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6939 - acc: 0.4990 - val_loss: 0.6931 - val_acc: 0.4999\n",
      "Epoch 59/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6941 - acc: 0.4992 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 60/120\n",
      "44640/44640 [==============================] - 6s 136us/step - loss: 0.6941 - acc: 0.4982 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 61/120\n",
      "44640/44640 [==============================] - 6s 137us/step - loss: 0.6939 - acc: 0.5003 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 62/120\n",
      "44640/44640 [==============================] - 6s 137us/step - loss: 0.6939 - acc: 0.4991 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 63/120\n",
      "44640/44640 [==============================] - 7s 158us/step - loss: 0.6941 - acc: 0.4945 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 64/120\n",
      "44640/44640 [==============================] - 6s 142us/step - loss: 0.6942 - acc: 0.4949 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 65/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6935 - acc: 0.5043 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 66/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6939 - acc: 0.4980 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 67/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6937 - acc: 0.5006 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 68/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6938 - acc: 0.4994 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 69/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6937 - acc: 0.4983 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 70/120\n",
      "44640/44640 [==============================] - 6s 133us/step - loss: 0.6935 - acc: 0.5005 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 71/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6936 - acc: 0.4998 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 72/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6938 - acc: 0.4976 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 73/120\n",
      "44640/44640 [==============================] - 6s 134us/step - loss: 0.6936 - acc: 0.4998 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 74/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6936 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 75/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6934 - acc: 0.5019 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 76/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6935 - acc: 0.4986 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 77/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 78/120\n",
      "44640/44640 [==============================] - 6s 135us/step - loss: 0.6934 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 79/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6936 - acc: 0.4983 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 80/120\n",
      "44640/44640 [==============================] - 6s 144us/step - loss: 0.6935 - acc: 0.5018 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 81/120\n",
      "44640/44640 [==============================] - 7s 151us/step - loss: 0.6934 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 82/120\n",
      "44640/44640 [==============================] - 6s 139us/step - loss: 0.6934 - acc: 0.4986 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 83/120\n",
      "44640/44640 [==============================] - 6s 142us/step - loss: 0.6935 - acc: 0.4959 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 84/120\n",
      "44640/44640 [==============================] - 7s 148us/step - loss: 0.6934 - acc: 0.5017 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 85/120\n",
      "44640/44640 [==============================] - 8s 177us/step - loss: 0.6933 - acc: 0.5007 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 86/120\n",
      "44640/44640 [==============================] - 7s 165us/step - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 87/120\n",
      "44640/44640 [==============================] - 6s 145us/step - loss: 0.6932 - acc: 0.5041 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 88/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6936 - acc: 0.4930 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 89/120\n",
      "44640/44640 [==============================] - 7s 146us/step - loss: 0.6934 - acc: 0.4979 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 90/120\n",
      "44640/44640 [==============================] - 6s 144us/step - loss: 0.6934 - acc: 0.4978 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 91/120\n",
      "44640/44640 [==============================] - 6s 141us/step - loss: 0.6934 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 92/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6933 - acc: 0.4966 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 93/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6933 - acc: 0.4986 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 94/120\n",
      "44640/44640 [==============================] - 6s 143us/step - loss: 0.6934 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "Epoch 95/120\n",
      "44640/44640 [==============================] - 6s 138us/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 96/120\n",
      "44640/44640 [==============================] - 6s 144us/step - loss: 0.6933 - acc: 0.5004 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 97/120\n",
      "44640/44640 [==============================] - 6s 142us/step - loss: 0.6934 - acc: 0.4999 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 98/120\n",
      "44640/44640 [==============================] - 7s 155us/step - loss: 0.6931 - acc: 0.5057 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 99/120\n",
      " 1024/44640 [..............................] - ETA: 6s - loss: 0.6935 - acc: 0.4893"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bea865b599cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "l_activate=['softmax','elu','selu','softplus','softsign','relu','tanh','sigmoid','hard_sigmoid','linear']\n",
    "for i in l_activate:\n",
    "    for j in l_activate:\n",
    "        for k in l_activate:\n",
    "            print('Buidl model...'+i+' '+j+' '+' '+k)\n",
    "            model=Sequential()\n",
    "            model.add(InputLayer(input_shape=(1364,)))\n",
    "            model.add(Dense(output_dense, activation=i))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(output_dense, activation=j))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(output_dense, activation=k))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(1,activation='sigmoid'))\n",
    "            model.summary()\n",
    "            model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            print('Train...')\n",
    "            model.fit(x_train, y_train,batch_size=batch_size,epochs=120,validation_data=(x_test, y_test))\n",
    "            score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "            print('Test score:', score)\n",
    "            print('Test accuracy:', acc)\n",
    "\n",
    "            pred=model.predict(x_test)\n",
    "            del model,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
