{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 17 13:02:45 2018\n",
    "\n",
    "@author: KOK\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,InputLayer,Dropout,Embedding,LSTM,regularizers\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "27907 95659\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('Loading data...')\n",
    "records1 = list(SeqIO.parse(\"/media/kok/WORK/ML/Tensorflow/jupyter-kok/gencode.v27.lncRNA_transcripts.fa\", \"fasta\"))\n",
    "records2 = list(SeqIO.parse(\"/media/kok/WORK/ML/Tensorflow/jupyter-kok/gencode.v27.pc_transcripts.fa\", \"fasta\"))\n",
    "\n",
    "print(len(records1),len(records2))\n",
    "\n",
    "tmp=[]\n",
    "x1_train=[]\n",
    "n_train=27900-5580\n",
    "n_test=5580\n",
    "output_dense=256\n",
    "batch_size=512\n",
    "\n",
    "for i in records1[:n_train]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x1_train.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "\n",
    "x2_train=[]\n",
    "for i in records2[:n_train]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x2_train.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "    \n",
    "x1_test=[]\n",
    "for i in records1[-n_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x1_test.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "\n",
    "x2_test=[]\n",
    "for i in records2[-n_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x2_test.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "del records1,records2,tmp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "print('Loading data...')\n",
    "records1 = list(SeqIO.parse(\"D:\\ML\\Tensorflow\\jupyter-kok\\gencode.v27.lncRNA_transcripts.fa\", \"fasta\"))\n",
    "records2 = list(SeqIO.parse(\"D:\\ML\\Tensorflow\\jupyter-kok\\gencode.v27.pc_transcripts.fa\", \"fasta\"))\n",
    "\n",
    "print(len(records1),len(records2))\n",
    "\n",
    "tmp=[]\n",
    "x1_train=[]\n",
    "n_train=27900-5580\n",
    "n_test=5580\n",
    "output_dense=256\n",
    "batch_size=512\n",
    "\n",
    "for i in records1[:n_train]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x1_train.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "\n",
    "x2_train=[]\n",
    "for i in records2[:n_train]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x2_train.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "    \n",
    "x1_test=[]\n",
    "for i in records1[-n_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x1_test.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "\n",
    "x2_test=[]\n",
    "for i in records2[-n_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    x2_test.append(np.array(tmp))\n",
    "    tmp=[]\n",
    "del records1,records2,tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat data...\n"
     ]
    }
   ],
   "source": [
    "print('Concat data...')\n",
    "x_train=np.concatenate((np.array(x1_train),np.array(x2_train)),axis=0)\n",
    "x_test=np.concatenate((np.array(x1_test),np.array(x2_test)),axis=0)\n",
    "y_train=np.concatenate((np.array(len(x1_train)*[[1,0]]),np.array(len(x2_train)*[[0,1]])),axis=0)\n",
    "y_test=np.concatenate((np.array(len(x1_test)*[[1,0]]),np.array(len(x2_test)*[[0,1]])),axis=0)\n",
    "\n",
    "\n",
    "del x1_test,x1_train,x2_test,x2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               349440    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 415,746\n",
      "Trainable params: 415,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 44640 samples, validate on 11160 samples\n",
      "Epoch 1/70\n",
      "44640/44640 [==============================] - 4s 101us/step - loss: 0.7083 - acc: 0.5348 - val_loss: 0.6780 - val_acc: 0.6136\n",
      "Epoch 2/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.6674 - acc: 0.6006 - val_loss: 0.5912 - val_acc: 0.6920\n",
      "Epoch 3/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.5688 - acc: 0.7142 - val_loss: 0.4420 - val_acc: 0.7884\n",
      "Epoch 4/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.4630 - acc: 0.7891 - val_loss: 0.3427 - val_acc: 0.8547\n",
      "Epoch 5/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3979 - acc: 0.8298 - val_loss: 0.3316 - val_acc: 0.8636\n",
      "Epoch 6/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3846 - acc: 0.8374 - val_loss: 0.3326 - val_acc: 0.8587\n",
      "Epoch 7/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3663 - acc: 0.8472 - val_loss: 0.3323 - val_acc: 0.8572\n",
      "Epoch 8/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3580 - acc: 0.8502 - val_loss: 0.3242 - val_acc: 0.8635\n",
      "Epoch 9/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3502 - acc: 0.8544 - val_loss: 0.3345 - val_acc: 0.8594\n",
      "Epoch 10/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3470 - acc: 0.8557 - val_loss: 0.3242 - val_acc: 0.8644\n",
      "Epoch 11/70\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3426 - acc: 0.8571 - val_loss: 0.3151 - val_acc: 0.8684\n",
      "Epoch 12/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3362 - acc: 0.8617 - val_loss: 0.3355 - val_acc: 0.8596\n",
      "Epoch 13/70\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3339 - acc: 0.8606 - val_loss: 0.3230 - val_acc: 0.8654\n",
      "Epoch 14/70\n",
      "44640/44640 [==============================] - 4s 101us/step - loss: 0.3372 - acc: 0.8589 - val_loss: 0.3152 - val_acc: 0.8693\n",
      "Epoch 15/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3226 - acc: 0.8664 - val_loss: 0.3200 - val_acc: 0.8656\n",
      "Epoch 16/70\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3210 - acc: 0.8656 - val_loss: 0.3162 - val_acc: 0.8705\n",
      "Epoch 17/70\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3222 - acc: 0.8679 - val_loss: 0.3131 - val_acc: 0.8698\n",
      "Epoch 18/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3204 - acc: 0.8677 - val_loss: 0.3120 - val_acc: 0.8700\n",
      "Epoch 19/70\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3234 - acc: 0.8671 - val_loss: 0.3246 - val_acc: 0.8642\n",
      "Epoch 20/70\n",
      "44640/44640 [==============================] - 4s 85us/step - loss: 0.3196 - acc: 0.8688 - val_loss: 0.3206 - val_acc: 0.8657\n",
      "Epoch 21/70\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3208 - acc: 0.8684 - val_loss: 0.3158 - val_acc: 0.8698\n",
      "Epoch 22/70\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3142 - acc: 0.8720 - val_loss: 0.3154 - val_acc: 0.8703\n",
      "Epoch 23/70\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3144 - acc: 0.8706 - val_loss: 0.3163 - val_acc: 0.8703\n",
      "Epoch 24/70\n",
      "44640/44640 [==============================] - 4s 87us/step - loss: 0.3156 - acc: 0.8718 - val_loss: 0.3095 - val_acc: 0.8720\n",
      "Epoch 25/70\n",
      "44640/44640 [==============================] - 4s 91us/step - loss: 0.3134 - acc: 0.8708 - val_loss: 0.3145 - val_acc: 0.8685\n",
      "Epoch 26/70\n",
      "44640/44640 [==============================] - 4s 99us/step - loss: 0.3084 - acc: 0.8716 - val_loss: 0.3120 - val_acc: 0.8703\n",
      "Epoch 27/70\n",
      "44640/44640 [==============================] - 4s 98us/step - loss: 0.3126 - acc: 0.8718 - val_loss: 0.3107 - val_acc: 0.8722\n",
      "Epoch 28/70\n",
      "44640/44640 [==============================] - 4s 86us/step - loss: 0.3090 - acc: 0.8720 - val_loss: 0.3147 - val_acc: 0.8681\n",
      "Epoch 29/70\n",
      "44640/44640 [==============================] - 4s 95us/step - loss: 0.3066 - acc: 0.8764 - val_loss: 0.3138 - val_acc: 0.8713\n",
      "Epoch 30/70\n",
      "44640/44640 [==============================] - 4s 94us/step - loss: 0.3026 - acc: 0.8750 - val_loss: 0.3160 - val_acc: 0.8696\n",
      "Epoch 31/70\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3052 - acc: 0.8748 - val_loss: 0.3099 - val_acc: 0.8719\n",
      "Epoch 32/70\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.3058 - acc: 0.8750 - val_loss: 0.3161 - val_acc: 0.8683\n",
      "Epoch 33/70\n",
      "44640/44640 [==============================] - 4s 88us/step - loss: 0.3059 - acc: 0.8750 - val_loss: 0.3219 - val_acc: 0.8667\n",
      "Epoch 34/70\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.3109 - acc: 0.8711 - val_loss: 0.3082 - val_acc: 0.8719\n",
      "Epoch 35/70\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.3060 - acc: 0.8753 - val_loss: 0.3092 - val_acc: 0.8712\n",
      "Epoch 36/70\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.3033 - acc: 0.8755 - val_loss: 0.3081 - val_acc: 0.8726\n",
      "Epoch 37/70\n",
      "44640/44640 [==============================] - 4s 96us/step - loss: 0.3013 - acc: 0.8766 - val_loss: 0.3134 - val_acc: 0.8689\n",
      "Epoch 38/70\n",
      "44640/44640 [==============================] - 4s 97us/step - loss: 0.2934 - acc: 0.8810 - val_loss: 0.3103 - val_acc: 0.8719\n",
      "Epoch 39/70\n",
      "44640/44640 [==============================] - 4s 93us/step - loss: 0.2945 - acc: 0.8798 - val_loss: 0.3121 - val_acc: 0.8699\n",
      "Epoch 40/70\n",
      "44640/44640 [==============================] - 4s 92us/step - loss: 0.2943 - acc: 0.8804 - val_loss: 0.3082 - val_acc: 0.8751\n",
      "Epoch 41/70\n",
      "44640/44640 [==============================] - 4s 92us/step - loss: 0.2933 - acc: 0.8810 - val_loss: 0.3098 - val_acc: 0.8722\n",
      "Epoch 42/70\n",
      "44640/44640 [==============================] - 4s 92us/step - loss: 0.3023 - acc: 0.8761 - val_loss: 0.3134 - val_acc: 0.8694\n",
      "Epoch 43/70\n",
      "44640/44640 [==============================] - 4s 92us/step - loss: 0.2903 - acc: 0.8822 - val_loss: 0.3114 - val_acc: 0.8700\n",
      "Epoch 44/70\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2912 - acc: 0.8812 - val_loss: 0.3117 - val_acc: 0.8716\n",
      "Epoch 45/70\n",
      "44640/44640 [==============================] - 4s 91us/step - loss: 0.2963 - acc: 0.8794 - val_loss: 0.3158 - val_acc: 0.8686\n",
      "Epoch 46/70\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2915 - acc: 0.8816 - val_loss: 0.3110 - val_acc: 0.8713\n",
      "Epoch 47/70\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2855 - acc: 0.8844 - val_loss: 0.3076 - val_acc: 0.8725\n",
      "Epoch 48/70\n",
      "44640/44640 [==============================] - 4s 89us/step - loss: 0.2935 - acc: 0.8805 - val_loss: 0.3135 - val_acc: 0.8693\n",
      "Epoch 49/70\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2904 - acc: 0.8838 - val_loss: 0.3065 - val_acc: 0.8746\n",
      "Epoch 50/70\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2915 - acc: 0.8831 - val_loss: 0.3097 - val_acc: 0.8692\n",
      "Epoch 51/70\n",
      "44640/44640 [==============================] - 4s 90us/step - loss: 0.2881 - acc: 0.8830 - val_loss: 0.3154 - val_acc: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2848 - acc: 0.8869 - val_loss: 0.3147 - val_acc: 0.8683\n",
      "Epoch 53/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2795 - acc: 0.8874 - val_loss: 0.3114 - val_acc: 0.8704\n",
      "Epoch 54/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2878 - acc: 0.8842 - val_loss: 0.3112 - val_acc: 0.8688\n",
      "Epoch 55/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2884 - acc: 0.8831 - val_loss: 0.3117 - val_acc: 0.8685\n",
      "Epoch 56/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2879 - acc: 0.8846 - val_loss: 0.3092 - val_acc: 0.8746\n",
      "Epoch 57/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2889 - acc: 0.8841 - val_loss: 0.3111 - val_acc: 0.8720\n",
      "Epoch 58/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2876 - acc: 0.8859 - val_loss: 0.3207 - val_acc: 0.8671\n",
      "Epoch 59/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2831 - acc: 0.8877 - val_loss: 0.3142 - val_acc: 0.8705\n",
      "Epoch 60/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2787 - acc: 0.8886 - val_loss: 0.3111 - val_acc: 0.8731\n",
      "Epoch 61/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2796 - acc: 0.8889 - val_loss: 0.3147 - val_acc: 0.8704\n",
      "Epoch 62/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2759 - acc: 0.8896 - val_loss: 0.3092 - val_acc: 0.8733\n",
      "Epoch 63/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2773 - acc: 0.8879 - val_loss: 0.3066 - val_acc: 0.8722\n",
      "Epoch 64/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2783 - acc: 0.8897 - val_loss: 0.3128 - val_acc: 0.8696\n",
      "Epoch 65/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2771 - acc: 0.8898 - val_loss: 0.3114 - val_acc: 0.8713\n",
      "Epoch 66/70\n",
      "44640/44640 [==============================] - 4s 84us/step - loss: 0.2713 - acc: 0.8921 - val_loss: 0.3120 - val_acc: 0.8707\n",
      "Epoch 67/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2821 - acc: 0.8879 - val_loss: 0.3154 - val_acc: 0.8734\n",
      "Epoch 68/70\n",
      "44640/44640 [==============================] - 4s 84us/step - loss: 0.2783 - acc: 0.8892 - val_loss: 0.3244 - val_acc: 0.8668\n",
      "Epoch 69/70\n",
      "44640/44640 [==============================] - 4s 84us/step - loss: 0.2846 - acc: 0.8850 - val_loss: 0.3126 - val_acc: 0.8762\n",
      "Epoch 70/70\n",
      "44640/44640 [==============================] - 4s 83us/step - loss: 0.2835 - acc: 0.8860 - val_loss: 0.3123 - val_acc: 0.8716\n",
      "11160/11160 [==============================] - 0s 34us/step\n",
      "Test score: 0.3123101264131539\n",
      "Test accuracy: 0.8715949840443109\n"
     ]
    }
   ],
   "source": [
    "print('Buidl model...')\n",
    "batch_size=1024\n",
    "model=Sequential()\n",
    "model.add(InputLayer(input_shape=(1364,)))\n",
    "model.add(Dense(output_dense, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_dense, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=70,validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 8)           1600000   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 8)                 544       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 1,600,562\n",
      "Trainable params: 1,600,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 44640 samples, validate on 11160 samples\n",
      "Epoch 1/10\n",
      "44640/44640 [==============================] - 71s 2ms/step - loss: 0.6925 - acc: 0.5435 - val_loss: 0.6906 - val_acc: 0.6258\n",
      "Epoch 2/10\n",
      "44640/44640 [==============================] - 63s 1ms/step - loss: 0.6880 - acc: 0.6228 - val_loss: 0.6838 - val_acc: 0.6341\n",
      "Epoch 3/10\n",
      "44640/44640 [==============================] - 63s 1ms/step - loss: 0.6737 - acc: 0.6326 - val_loss: 0.6569 - val_acc: 0.6570\n",
      "Epoch 4/10\n",
      "44640/44640 [==============================] - 64s 1ms/step - loss: 0.6392 - acc: 0.6858 - val_loss: 0.6203 - val_acc: 0.7072\n",
      "Epoch 5/10\n",
      "44640/44640 [==============================] - 63s 1ms/step - loss: 0.6151 - acc: 0.7030 - val_loss: 0.6087 - val_acc: 0.6992\n",
      "Epoch 6/10\n",
      "44640/44640 [==============================] - 63s 1ms/step - loss: 0.6148 - acc: 0.7035 - val_loss: 0.6272 - val_acc: 0.6854\n",
      "Epoch 7/10\n",
      "44640/44640 [==============================] - 63s 1ms/step - loss: 0.6144 - acc: 0.7008 - val_loss: 0.6023 - val_acc: 0.7095\n",
      "Epoch 8/10\n",
      "44640/44640 [==============================] - 63s 1ms/step - loss: 0.5993 - acc: 0.7107 - val_loss: 0.5983 - val_acc: 0.7086\n",
      "Epoch 9/10\n",
      "44640/44640 [==============================] - 63s 1ms/step - loss: 0.5974 - acc: 0.7105 - val_loss: 0.5967 - val_acc: 0.7096\n",
      "Epoch 10/10\n",
      "44640/44640 [==============================] - 64s 1ms/step - loss: 0.5925 - acc: 0.7131 - val_loss: 0.5950 - val_acc: 0.7116\n",
      "11160/11160 [==============================] - 5s 408us/step\n",
      "Test score: 0.5949788842577234\n",
      "Test accuracy: 0.7115591376913064\n"
     ]
    }
   ],
   "source": [
    "max_features=200000\n",
    "batch_size=2048\n",
    "print('Buidl model...')\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features, output_dim=8))\n",
    "model.add(LSTM(8))\n",
    "model.add(Dense(2,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=10,validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "\n",
    "pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "l_activate=['softmax','elu','selu','softplus','softsign','relu','tanh','sigmoid','hard_sigmoid','linear']\n",
    "for i in l_activate:\n",
    "    for j in l_activate:\n",
    "        for k in l_activate:\n",
    "            print('Buidl model...'+i+' '+j+' '+' '+k)\n",
    "            model=Sequential()\n",
    "            model.add(InputLayer(input_shape=(1364,)))\n",
    "            model.add(Dense(output_dense, activation=i))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(output_dense, activation=j))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(output_dense, activation=k))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(1,activation='sigmoid'))\n",
    "            model.summary()\n",
    "            model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            print('Train...')\n",
    "            model.fit(x_train, y_train,batch_size=batch_size,epochs=120,validation_data=(x_test, y_test))\n",
    "            score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "            print('Test score:', score)\n",
    "            print('Test accuracy:', acc)\n",
    "\n",
    "            pred=model.predict(x_test)\n",
    "            del model,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
