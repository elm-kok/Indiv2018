{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM,InputLayer\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordCytoplasm = list(SeqIO.parse(\"/media/kok/WORK/ML/lncrna_location_database/Cytoplasm\", \"fasta\"))\n",
    "recordCytosol = list(SeqIO.parse(\"/media/kok/WORK/ML/lncrna_location_database/Cytosol\", \"fasta\"))\n",
    "recordExosome = list(SeqIO.parse(\"/media/kok/WORK/ML/lncrna_location_database/Exosome\", \"fasta\"))\n",
    "recordNucleus = list(SeqIO.parse(\"/media/kok/WORK/ML/lncrna_location_database/Nucleus\", \"fasta\"))\n",
    "recordRibosome = list(SeqIO.parse(\"/media/kok/WORK/ML/lncrna_location_database/Ribosome\", \"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_Cytoplasm=[]\n",
    "l_Cytosol=[]\n",
    "l_Exosome=[]\n",
    "l_Nucleus=[]\n",
    "l_Ribosome=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in recordCytoplasm:\n",
    "    l_Cytoplasm.append(i.seq)\n",
    "for i in recordCytosol:\n",
    "    l_Cytosol.append(i.seq)\n",
    "for i in recordExosome:\n",
    "    l_Exosome.append(i.seq)\n",
    "for i in recordNucleus:\n",
    "    l_Nucleus.append(i.seq)\n",
    "for i in recordRibosome:\n",
    "    l_Ribosome.append(i.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 91 25 152 43\n"
     ]
    }
   ],
   "source": [
    "print(len(l_Cytoplasm),len(l_Cytosol),len(l_Exosome),len(l_Nucleus),len(l_Ribosome))\n",
    "del l_Cytoplasm,l_Cytosol,l_Exosome,l_Nucleus,l_Ribosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cytoplasm_test=-80\n",
    "n_cytosol_test=-18\n",
    "n_exosome_test=-5\n",
    "n_nucleus_test=-30\n",
    "n_ribosome_test=-8\n",
    "l_Cytoplasm=[]\n",
    "l_Cytosol=[]\n",
    "l_Exosome=[]\n",
    "l_Nucleus=[]\n",
    "l_Ribosome=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=[]\n",
    "for i in recordCytoplasm[:n_cytoplasm_test]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_Cytoplasm.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "\n",
    "for i in recordCytosol[:n_cytosol_test]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_Cytosol.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "\n",
    "for i in recordExosome[:n_exosome_test]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_Exosome.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "                    \n",
    "for i in recordNucleus[:n_nucleus_test]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_Nucleus.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "                    \n",
    "for i in recordRibosome[:n_ribosome_test]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_Ribosome.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "    \n",
    "l_Cytoplasm=np.array(l_Cytoplasm)\n",
    "l_Cytosol=np.array(l_Cytosol)\n",
    "l_Exosome=np.array(l_Exosome)\n",
    "l_Nucleus=np.array(l_Nucleus)\n",
    "l_Ribosome=np.array(l_Ribosome)\n",
    "x_train=np.concatenate((l_Cytoplasm,l_Cytosol,l_Exosome,l_Nucleus,l_Ribosome),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_test_Cytoplasm=[]\n",
    "l_test_Cytosol=[]\n",
    "l_test_Exosome=[]\n",
    "l_test_Nucleus=[]\n",
    "l_test_Ribosome=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=[]\n",
    "for i in recordCytoplasm[n_cytoplasm_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_test_Cytoplasm.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "\n",
    "for i in recordCytosol[n_cytosol_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_test_Cytosol.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "\n",
    "for i in recordExosome[n_exosome_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_test_Exosome.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "                    \n",
    "for i in recordNucleus[n_nucleus_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_test_Nucleus.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "                    \n",
    "for i in recordRibosome[n_ribosome_test:]:\n",
    "    for a in 'ATCG':\n",
    "        tmp.append(i.seq.count(a))\n",
    "        for b in 'ATCG':\n",
    "            tmp.append(i.seq.count(a+b))\n",
    "            for c in 'ATCG':\n",
    "                tmp.append(i.seq.count(a+b+c))\n",
    "                for d in 'ATCG':\n",
    "                    tmp.append(i.seq.count(a+b+c+d))\n",
    "                    for e in 'ATCG':\n",
    "                        tmp.append(i.seq.count(a+b+c+d+e))\n",
    "    l_test_Ribosome.append(np.array(tmp))\n",
    "    del tmp\n",
    "    tmp=[]\n",
    "\n",
    "l_test_Cytoplasm=np.array(l_test_Cytoplasm)\n",
    "l_test_Cytosol=np.array(l_test_Cytosol)\n",
    "l_test_Exosome=np.array(l_test_Exosome)\n",
    "l_test_Nucleus=np.array(l_test_Nucleus)\n",
    "l_test_Ribosome=np.array(l_test_Ribosome)\n",
    "x_test=np.concatenate((l_test_Cytoplasm,l_test_Cytosol,l_test_Exosome,l_test_Nucleus,l_test_Ribosome),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_code_Cytoplasm=np.array([0,0,0,0])\n",
    "target_code_Cytosol=np.array([0,0,0,1])\n",
    "target_code_Exosome=np.array([0,0,1,0])\n",
    "target_code_Nucleus=np.array([0,1,0,0])\n",
    "target_code_Ribosome=np.array([1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.concatenate((np.tile(target_code_Cytoplasm,(len(l_Cytoplasm),1)),np.tile(target_code_Cytosol,(len(l_Cytosol),1)),np.tile(target_code_Exosome,(len(l_Exosome),1)),np.tile(target_code_Nucleus,(len(l_Nucleus),1)),np.tile(target_code_Ribosome,(len(l_Ribosome),1))),axis=0)\n",
    "y_test=np.concatenate((np.tile(target_code_Cytoplasm,(len(l_test_Cytoplasm),1)),np.tile(target_code_Cytosol,(len(l_test_Cytosol),1)),np.tile(target_code_Exosome,(len(l_test_Exosome),1)),np.tile(target_code_Nucleus,(len(l_test_Nucleus),1)),np.tile(target_code_Ribosome,(len(l_test_Ribosome),1))),axis=0)\n",
    "del l_test_Cytoplasm,l_test_Cytosol,l_test_Exosome,l_test_Nucleus,l_test_Ribosome,tmp\n",
    "del l_Cytoplasm,l_Cytosol,l_Exosome,l_Nucleus,l_Ribosome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Buidl model...')\n",
    "max_features=100000\n",
    "batch_size=512\n",
    "model=Sequential()\n",
    "model.add(Embedding(max_features, output_dim=128))\n",
    "model.add(Dense(128,activation='sigmoid'))\n",
    "model.add(Dense(4,activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=100,validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output_dense=128\n",
    "batch_size=128\n",
    "l_activation=['softmax','elu','selu','softplus','softsign','relu','tanh','sigmoid','hard_sigmoid','linear']\n",
    "for i in l_activation:\n",
    "    for j in l_activation:\n",
    "        for k in l_activation:\n",
    "            print('Buidl model...')\n",
    "            model=Sequential()\n",
    "            model.add(InputLayer(input_shape=(340,)))\n",
    "            model.add(Dense(output_dense, activation=i))\n",
    "            model.add(Dropout(0.1))\n",
    "            model.add(Dense(output_dense, activation=j))\n",
    "            model.add(Dropout(0.1))\n",
    "            model.add(Dense(output_dense, activation=k))\n",
    "            model.add(Dropout(0.1))\n",
    "            model.add(Dense(4,activation='sigmoid'))\n",
    "            model.summary()\n",
    "            model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            print('Train...')\n",
    "            model.fit(x_train, y_train,batch_size=batch_size,epochs=120,validation_data=(x_test, y_test))\n",
    "            score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "            print('Test score:', score)\n",
    "            print('Look! '+i+' '+j+' '+k+' Test accuracy:', acc)\n",
    "            del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_149 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_596 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_450 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_597 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_451 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_598 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 39ms/step - loss: 0.7332 - acc: 0.1635 - val_loss: 0.5966 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7312 - acc: 0.1890 - val_loss: 0.5948 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.7293 - acc: 0.1890 - val_loss: 0.5930 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7268 - acc: 0.1996 - val_loss: 0.5911 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7243 - acc: 0.2059 - val_loss: 0.5894 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.7227 - acc: 0.1953 - val_loss: 0.5876 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7205 - acc: 0.2569 - val_loss: 0.5859 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7181 - acc: 0.2314 - val_loss: 0.5842 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7176 - acc: 0.2229 - val_loss: 0.5825 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7146 - acc: 0.2357 - val_loss: 0.5809 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7127 - acc: 0.2484 - val_loss: 0.5793 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.7109 - acc: 0.2590 - val_loss: 0.5778 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7088 - acc: 0.2611 - val_loss: 0.5763 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.7074 - acc: 0.2569 - val_loss: 0.5748 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.7056 - acc: 0.2569 - val_loss: 0.5734 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7038 - acc: 0.2569 - val_loss: 0.5720 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7019 - acc: 0.2590 - val_loss: 0.5706 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.7007 - acc: 0.2590 - val_loss: 0.5692 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6987 - acc: 0.2590 - val_loss: 0.5679 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6974 - acc: 0.2590 - val_loss: 0.5666 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6961 - acc: 0.2590 - val_loss: 0.5653 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6945 - acc: 0.2590 - val_loss: 0.5640 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6919 - acc: 0.2590 - val_loss: 0.5628 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6913 - acc: 0.2590 - val_loss: 0.5616 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6894 - acc: 0.2590 - val_loss: 0.5604 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6884 - acc: 0.2590 - val_loss: 0.5592 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: 0.6867 - acc: 0.2590 - val_loss: 0.5581 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6855 - acc: 0.2590 - val_loss: 0.5570 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6842 - acc: 0.2590 - val_loss: 0.5559 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6832 - acc: 0.2590 - val_loss: 0.5548 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6815 - acc: 0.2590 - val_loss: 0.5538 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6795 - acc: 0.2590 - val_loss: 0.5528 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6794 - acc: 0.2590 - val_loss: 0.5518 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6784 - acc: 0.2590 - val_loss: 0.5508 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6777 - acc: 0.2590 - val_loss: 0.5498 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6763 - acc: 0.2590 - val_loss: 0.5488 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6747 - acc: 0.2590 - val_loss: 0.5479 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6732 - acc: 0.2590 - val_loss: 0.5470 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6721 - acc: 0.2590 - val_loss: 0.5461 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6712 - acc: 0.2590 - val_loss: 0.5452 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6696 - acc: 0.2590 - val_loss: 0.5444 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6690 - acc: 0.2590 - val_loss: 0.5435 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6683 - acc: 0.2590 - val_loss: 0.5427 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6678 - acc: 0.2590 - val_loss: 0.5419 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6680 - acc: 0.2590 - val_loss: 0.5411 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6659 - acc: 0.2590 - val_loss: 0.5404 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6624 - acc: 0.2590 - val_loss: 0.5397 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6639 - acc: 0.2590 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6627 - acc: 0.2590 - val_loss: 0.5383 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6628 - acc: 0.2590 - val_loss: 0.5376 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6614 - acc: 0.2590 - val_loss: 0.5369 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6597 - acc: 0.2590 - val_loss: 0.5362 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6593 - acc: 0.2590 - val_loss: 0.5356 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6576 - acc: 0.2590 - val_loss: 0.5349 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6580 - acc: 0.2590 - val_loss: 0.5343 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6561 - acc: 0.2590 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6572 - acc: 0.2590 - val_loss: 0.5332 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6560 - acc: 0.2590 - val_loss: 0.5338 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6553 - acc: 0.2590 - val_loss: 0.5320 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6546 - acc: 0.2590 - val_loss: 0.5314 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6540 - acc: 0.2590 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6545 - acc: 0.2590 - val_loss: 0.5304 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6542 - acc: 0.2590 - val_loss: 0.5299 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 145us/step - loss: 0.6525 - acc: 0.2590 - val_loss: 0.5294 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6514 - acc: 0.2590 - val_loss: 0.5289 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6510 - acc: 0.2590 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6492 - acc: 0.2590 - val_loss: 0.5279 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6497 - acc: 0.2590 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6508 - acc: 0.2590 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6510 - acc: 0.2590 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6484 - acc: 0.2590 - val_loss: 0.5262 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6484 - acc: 0.2590 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6486 - acc: 0.2590 - val_loss: 0.5254 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6475 - acc: 0.2590 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6471 - acc: 0.2590 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6461 - acc: 0.2590 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6452 - acc: 0.2590 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6453 - acc: 0.2590 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6466 - acc: 0.2590 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6458 - acc: 0.2590 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6448 - acc: 0.2590 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6437 - acc: 0.2590 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6442 - acc: 0.2590 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6435 - acc: 0.2590 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6428 - acc: 0.2590 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6433 - acc: 0.2590 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6427 - acc: 0.2590 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6412 - acc: 0.2590 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6413 - acc: 0.2590 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6410 - acc: 0.2590 - val_loss: 0.5201 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6411 - acc: 0.2590 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6404 - acc: 0.2590 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6399 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6402 - acc: 0.2590 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6404 - acc: 0.2590 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6398 - acc: 0.2590 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6383 - acc: 0.2590 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6392 - acc: 0.2590 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6371 - acc: 0.2590 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6402 - acc: 0.2590 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6374 - acc: 0.2590 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6388 - acc: 0.2590 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6387 - acc: 0.2590 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5169 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6385 - acc: 0.2590 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6375 - acc: 0.2590 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 112/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 160us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6353 - acc: 0.2590 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6376 - acc: 0.2590 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6363 - acc: 0.2590 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6366 - acc: 0.2590 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 133us/step\n",
      "Test score: 0.5149440266561847\n",
      "Look! softmax softmax softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.21276595808090049 softmax softmax softmax\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_150 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_599 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_452 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_600 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_453 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_601 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: 3.7192 - acc: 0.2420 - val_loss: 2.6936 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.7439 - acc: 0.3057 - val_loss: 2.7077 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 2.6688 - acc: 0.3142 - val_loss: 1.0172 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 2.2630 - acc: 0.3079 - val_loss: 0.9886 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.9510 - acc: 0.3079 - val_loss: 0.9641 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.8269 - acc: 0.2951 - val_loss: 0.9701 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.5856 - acc: 0.2696 - val_loss: 0.9705 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.4325 - acc: 0.3227 - val_loss: 0.9698 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.3263 - acc: 0.3291 - val_loss: 0.9653 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.2354 - acc: 0.3015 - val_loss: 0.9565 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 1.2481 - acc: 0.3248 - val_loss: 0.9532 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.2446 - acc: 0.3079 - val_loss: 0.9508 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.2518 - acc: 0.2845 - val_loss: 0.9438 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.2415 - acc: 0.2718 - val_loss: 0.9328 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.1934 - acc: 0.3015 - val_loss: 0.9259 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.1382 - acc: 0.3015 - val_loss: 0.9171 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.2767 - acc: 0.2972 - val_loss: 0.9034 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 1.0678 - acc: 0.2824 - val_loss: 0.8877 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.2408 - acc: 0.2718 - val_loss: 0.8705 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.2109 - acc: 0.2611 - val_loss: 0.8496 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.1017 - acc: 0.2633 - val_loss: 0.8236 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.2107 - acc: 0.2569 - val_loss: 0.7930 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.1537 - acc: 0.2484 - val_loss: 0.7649 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.2426 - acc: 0.2951 - val_loss: 0.7302 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 1.2665 - acc: 0.2718 - val_loss: 0.6853 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.4580 - acc: 0.3015 - val_loss: 0.6376 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.4462 - acc: 0.2887 - val_loss: 0.5969 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.7115 - acc: 0.2951 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.0018 - acc: 0.3206 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 2.8779 - acc: 0.3227 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.1500 - acc: 0.2951 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 4.2085 - acc: 0.2718 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 4.7077 - acc: 0.3057 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 5.1454 - acc: 0.2739 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 5.1882 - acc: 0.3291 - val_loss: 6.4015 - val_acc: 0.1277\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 5.6980 - acc: 0.2930 - val_loss: 6.4015 - val_acc: 0.1277\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 6.3463 - acc: 0.3524 - val_loss: 6.4015 - val_acc: 0.1277\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 5.7324 - acc: 0.3397 - val_loss: 3.5722 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 5.0161 - acc: 0.3312 - val_loss: 3.2800 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 4.4539 - acc: 0.3673 - val_loss: 3.1839 - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 3.9139 - acc: 0.4352 - val_loss: 3.1367 - val_acc: 0.6241\n",
      "Epoch 42/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 163us/step - loss: 3.6603 - acc: 0.3970 - val_loss: 3.1084 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 3.6813 - acc: 0.3843 - val_loss: 3.0895 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 3.6216 - acc: 0.3970 - val_loss: 3.0739 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 3.5898 - acc: 0.4352 - val_loss: 3.0604 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 3.5678 - acc: 0.4268 - val_loss: 3.0479 - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 3.5095 - acc: 0.4883 - val_loss: 3.0419 - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 3.2887 - acc: 0.4713 - val_loss: 3.0423 - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.1415 - acc: 0.4989 - val_loss: 3.0422 - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.2298 - acc: 0.5138 - val_loss: 3.0416 - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 2.8196 - acc: 0.5074 - val_loss: 1.6008 - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 2.7896 - acc: 0.5329 - val_loss: 1.3464 - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.3875 - acc: 0.5265 - val_loss: 1.2612 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.1722 - acc: 0.5393 - val_loss: 1.2114 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.7720 - acc: 0.5414 - val_loss: 1.1702 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.4677 - acc: 0.5414 - val_loss: 1.1420 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.5569 - acc: 0.5435 - val_loss: 1.1179 - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.4502 - acc: 0.5414 - val_loss: 1.0973 - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.5035 - acc: 0.5414 - val_loss: 1.0775 - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.7161 - acc: 0.5414 - val_loss: 1.0669 - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.7056 - acc: 0.5393 - val_loss: 1.0655 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.5383 - acc: 0.5393 - val_loss: 1.0649 - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.5556 - acc: 0.5435 - val_loss: 1.0574 - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.5178 - acc: 0.5435 - val_loss: 1.0423 - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.5928 - acc: 0.5435 - val_loss: 1.0218 - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.5598 - acc: 0.5435 - val_loss: 1.0008 - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.5797 - acc: 0.5435 - val_loss: 0.9925 - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.6770 - acc: 0.5435 - val_loss: 0.9849 - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.7438 - acc: 0.5435 - val_loss: 0.9781 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 1.7583 - acc: 0.5414 - val_loss: 0.9717 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 1.7126 - acc: 0.5435 - val_loss: 0.9647 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 1.8107 - acc: 0.5435 - val_loss: 0.9558 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.9511 - acc: 0.5435 - val_loss: 0.9489 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.9183 - acc: 0.5435 - val_loss: 0.9492 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.2862 - acc: 0.5435 - val_loss: 0.9494 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.5243 - acc: 0.5435 - val_loss: 0.9501 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 2.5799 - acc: 0.5435 - val_loss: 0.9490 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.8255 - acc: 0.5435 - val_loss: 0.9487 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.4789 - acc: 0.5435 - val_loss: 0.9473 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.3102 - acc: 0.5435 - val_loss: 1.4861 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 3.1685 - acc: 0.5435 - val_loss: 0.9577 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 2.9890 - acc: 0.5435 - val_loss: 0.9296 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.7286 - acc: 0.5435 - val_loss: 0.9194 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.8902 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 3.1894 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 3.6267 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 4.2396 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 3.9629 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 4.0604 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 4.5592 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 4.3954 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 4.1456 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.7237 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.2842 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 3.6279 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 3.1567 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 3.1194 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.9880 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 4.2115 - acc: 0.5435 - val_loss: 0.9145 - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 4.1050 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 4.1763 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 4.4459 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 4.8779 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 5.0054 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 5.2420 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 5.4052 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 5.4117 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 6.0299 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 5.7729 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 6.0753 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 6.2510 - acc: 0.5435 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 5.9439 - acc: 0.5435 - val_loss: 3.9415 - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 5.3822 - acc: 0.5435 - val_loss: 3.7600 - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 5.1363 - acc: 0.5414 - val_loss: 3.6980 - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 4.7220 - acc: 0.5456 - val_loss: 3.6669 - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 4.5766 - acc: 0.5372 - val_loss: 3.6501 - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 4.5031 - acc: 0.5435 - val_loss: 3.6419 - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 4.5190 - acc: 0.5393 - val_loss: 3.6361 - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 4.3731 - acc: 0.5287 - val_loss: 3.6318 - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 4.5005 - acc: 0.5372 - val_loss: 3.6286 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 142us/step\n",
      "Test score: 3.6285626972820744\n",
      "Look! softmax softmax elu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax softmax elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_151 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_602 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_454 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_603 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_455 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_604 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: 3.6255 - acc: 0.1635 - val_loss: 2.6879 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 3.6510 - acc: 0.1189 - val_loss: 2.6417 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 3.0277 - acc: 0.1380 - val_loss: 2.6292 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 3.4213 - acc: 0.1083 - val_loss: 2.6292 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 3.5379 - acc: 0.0977 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.6014 - acc: 0.1062 - val_loss: 4.3439 - val_acc: 0.1277\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 3.5328 - acc: 0.1104 - val_loss: 4.3439 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 3.8343 - acc: 0.1231 - val_loss: 1.2246 - val_acc: 0.1277\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 3.5201 - acc: 0.1062 - val_loss: 0.9594 - val_acc: 0.1277\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.9549 - acc: 0.1465 - val_loss: 6.0586 - val_acc: 0.1277\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 3.2750 - acc: 0.1168 - val_loss: 6.0586 - val_acc: 0.1277\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 3.8414 - acc: 0.1189 - val_loss: 6.0586 - val_acc: 0.1277\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 4.2049 - acc: 0.1083 - val_loss: 3.2250 - val_acc: 0.0355\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 3.5784 - acc: 0.1316 - val_loss: 3.0390 - val_acc: 0.0355\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 3.2688 - acc: 0.0977 - val_loss: 1.1365 - val_acc: 0.0355\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.8226 - acc: 0.0616 - val_loss: 1.0494 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.5877 - acc: 0.0552 - val_loss: 0.9917 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.7200 - acc: 0.0531 - val_loss: 0.9835 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.5515 - acc: 0.0552 - val_loss: 0.9788 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.8221 - acc: 0.0786 - val_loss: 0.9743 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: 1.4099 - acc: 0.0786 - val_loss: 0.9737 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.2755 - acc: 0.0892 - val_loss: 0.9703 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 1.3892 - acc: 0.0913 - val_loss: 0.9628 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 1.3162 - acc: 0.0786 - val_loss: 0.9536 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 1.2359 - acc: 0.0786 - val_loss: 0.9420 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.1870 - acc: 0.0573 - val_loss: 0.9314 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.2626 - acc: 0.0701 - val_loss: 0.9197 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.2172 - acc: 0.0467 - val_loss: 0.9075 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.1550 - acc: 0.0510 - val_loss: 0.8956 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 1.1397 - acc: 0.0488 - val_loss: 0.8960 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.2115 - acc: 0.0510 - val_loss: 0.8935 - val_acc: 0.0355\n",
      "Epoch 32/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 150us/step - loss: 1.2003 - acc: 0.0446 - val_loss: 0.8892 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.2388 - acc: 0.0425 - val_loss: 0.8812 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.1908 - acc: 0.0467 - val_loss: 0.8798 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 1.1741 - acc: 0.0425 - val_loss: 0.8795 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 1.2057 - acc: 0.0425 - val_loss: 0.8760 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.1507 - acc: 0.0425 - val_loss: 0.8709 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.1554 - acc: 0.0425 - val_loss: 0.8639 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.1213 - acc: 0.0425 - val_loss: 0.8564 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.1520 - acc: 0.0425 - val_loss: 0.8466 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 1.0988 - acc: 0.0425 - val_loss: 0.8384 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.1030 - acc: 0.0425 - val_loss: 0.8284 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 1.0076 - acc: 0.0425 - val_loss: 0.8171 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 1.0585 - acc: 0.0425 - val_loss: 0.8034 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 1.0953 - acc: 0.0425 - val_loss: 0.7927 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.0278 - acc: 0.0425 - val_loss: 0.7858 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.9589 - acc: 0.0425 - val_loss: 0.7751 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.9255 - acc: 0.0425 - val_loss: 0.7566 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.9607 - acc: 0.0425 - val_loss: 0.7343 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.9188 - acc: 0.0425 - val_loss: 0.7070 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.0977 - acc: 0.0425 - val_loss: 0.6757 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.2892 - acc: 0.0425 - val_loss: 0.6409 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.3934 - acc: 0.0425 - val_loss: 0.6141 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.2730 - acc: 0.0425 - val_loss: 0.6103 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.4603 - acc: 0.0425 - val_loss: 0.6065 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.4880 - acc: 0.0425 - val_loss: 0.6004 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.6218 - acc: 0.0425 - val_loss: 0.5915 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.6826 - acc: 0.0425 - val_loss: 0.5863 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.4054 - acc: 0.0425 - val_loss: 0.5813 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 2.0750 - acc: 0.0425 - val_loss: 0.5755 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.2011 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.3390 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.0841 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.8250 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.0047 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 3.4896 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 4.0075 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 3.3268 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 3.3609 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 4.0273 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.8447 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 4.1886 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 3.9721 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 4.7443 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 4.9052 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 4.6532 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 5.5812 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 6.0287 - acc: 0.0425 - val_loss: 5.7989 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 6.0589 - acc: 0.0425 - val_loss: 5.6086 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 6.0028 - acc: 0.0425 - val_loss: 5.5837 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 6.0342 - acc: 0.0425 - val_loss: 5.5690 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 6.2832 - acc: 0.0425 - val_loss: 5.5486 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 5.9613 - acc: 0.0425 - val_loss: 5.5345 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 6.4940 - acc: 0.0425 - val_loss: 5.5251 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 6.4307 - acc: 0.0425 - val_loss: 5.5187 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 6.5818 - acc: 0.0425 - val_loss: 5.5142 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 6.2736 - acc: 0.0425 - val_loss: 5.5109 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 6.0347 - acc: 0.0425 - val_loss: 5.5079 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 6.3631 - acc: 0.0425 - val_loss: 5.5055 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 6.3602 - acc: 0.0425 - val_loss: 5.5031 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 6.3526 - acc: 0.0425 - val_loss: 5.5009 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 6.1563 - acc: 0.0425 - val_loss: 5.4986 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 6.2640 - acc: 0.0425 - val_loss: 5.4970 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 6.3417 - acc: 0.0425 - val_loss: 5.4958 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 6.1679 - acc: 0.0425 - val_loss: 5.4950 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 6.1515 - acc: 0.0425 - val_loss: 5.4937 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 6.2934 - acc: 0.0425 - val_loss: 5.4924 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 6.2352 - acc: 0.0425 - val_loss: 5.4912 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 6.0617 - acc: 0.0425 - val_loss: 5.4899 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 6.1769 - acc: 0.0425 - val_loss: 5.4884 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 6.0919 - acc: 0.0425 - val_loss: 5.4872 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 6.5256 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 6.2115 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 5.9620 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 6.0354 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 6.1645 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 5.7789 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 5.8656 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 6.2194 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 5.6240 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 5.8195 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 5.9068 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 5.7443 - acc: 0.0425 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 6.0521 - acc: 0.0446 - val_loss: 5.4891 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 5.7356 - acc: 0.0425 - val_loss: 5.4955 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 5.9551 - acc: 0.0425 - val_loss: 5.5106 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 4.7359 - acc: 0.0425 - val_loss: 2.6013 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 3.7936 - acc: 0.0446 - val_loss: 2.4296 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 3.3321 - acc: 0.0425 - val_loss: 2.3556 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 2.8649 - acc: 0.0446 - val_loss: 2.3067 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 130us/step\n",
      "Test score: 2.3066964770885225\n",
      "Look! softmax softmax selu Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax softmax elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_152 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_605 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_456 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_606 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_457 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_607 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 37ms/step - loss: 0.7348 - acc: 0.3758 - val_loss: 0.5981 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7330 - acc: 0.3036 - val_loss: 0.5967 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7320 - acc: 0.2548 - val_loss: 0.5953 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7299 - acc: 0.2611 - val_loss: 0.5940 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7282 - acc: 0.2569 - val_loss: 0.5926 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7266 - acc: 0.2569 - val_loss: 0.5913 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7249 - acc: 0.2590 - val_loss: 0.5900 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7236 - acc: 0.2590 - val_loss: 0.5888 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7219 - acc: 0.2590 - val_loss: 0.5875 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.7205 - acc: 0.2590 - val_loss: 0.5862 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.7194 - acc: 0.2590 - val_loss: 0.5850 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7177 - acc: 0.2590 - val_loss: 0.5838 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7162 - acc: 0.2590 - val_loss: 0.5826 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.7145 - acc: 0.2590 - val_loss: 0.5814 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7132 - acc: 0.2590 - val_loss: 0.5802 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.7126 - acc: 0.2590 - val_loss: 0.5791 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7107 - acc: 0.2590 - val_loss: 0.5780 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.7092 - acc: 0.2590 - val_loss: 0.5769 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.7086 - acc: 0.2590 - val_loss: 0.5758 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7069 - acc: 0.2590 - val_loss: 0.5747 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.7052 - acc: 0.2590 - val_loss: 0.5736 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7046 - acc: 0.2590 - val_loss: 0.5726 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7025 - acc: 0.2590 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7017 - acc: 0.2590 - val_loss: 0.5705 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7008 - acc: 0.2590 - val_loss: 0.5695 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6992 - acc: 0.2590 - val_loss: 0.5685 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6980 - acc: 0.2590 - val_loss: 0.5675 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6967 - acc: 0.2590 - val_loss: 0.5666 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6955 - acc: 0.2590 - val_loss: 0.5656 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6941 - acc: 0.2590 - val_loss: 0.5647 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6936 - acc: 0.2590 - val_loss: 0.5644 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6926 - acc: 0.2590 - val_loss: 0.5628 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6915 - acc: 0.2590 - val_loss: 0.5619 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6898 - acc: 0.2590 - val_loss: 0.5611 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6884 - acc: 0.2590 - val_loss: 0.5602 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6884 - acc: 0.2590 - val_loss: 0.5593 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6870 - acc: 0.2590 - val_loss: 0.5585 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6861 - acc: 0.2590 - val_loss: 0.5576 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6849 - acc: 0.2590 - val_loss: 0.5568 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6837 - acc: 0.2590 - val_loss: 0.5560 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6833 - acc: 0.2590 - val_loss: 0.5552 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6818 - acc: 0.2590 - val_loss: 0.5545 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6811 - acc: 0.2590 - val_loss: 0.5537 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6801 - acc: 0.2590 - val_loss: 0.5530 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6796 - acc: 0.2590 - val_loss: 0.5522 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6792 - acc: 0.2590 - val_loss: 0.5515 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6776 - acc: 0.2590 - val_loss: 0.5507 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6766 - acc: 0.2590 - val_loss: 0.5500 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6763 - acc: 0.2590 - val_loss: 0.5493 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6762 - acc: 0.2590 - val_loss: 0.5487 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6745 - acc: 0.2590 - val_loss: 0.5480 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6737 - acc: 0.2590 - val_loss: 0.5473 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6722 - acc: 0.2590 - val_loss: 0.5467 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6721 - acc: 0.2590 - val_loss: 0.5461 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6718 - acc: 0.2590 - val_loss: 0.5454 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6712 - acc: 0.2590 - val_loss: 0.5448 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6700 - acc: 0.2590 - val_loss: 0.5442 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6681 - acc: 0.2590 - val_loss: 0.5436 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6682 - acc: 0.2590 - val_loss: 0.5430 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6679 - acc: 0.2590 - val_loss: 0.5424 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6669 - acc: 0.2590 - val_loss: 0.5419 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6667 - acc: 0.2590 - val_loss: 0.5413 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6656 - acc: 0.2590 - val_loss: 0.5407 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6650 - acc: 0.2590 - val_loss: 0.5402 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6639 - acc: 0.2590 - val_loss: 0.5396 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6642 - acc: 0.2590 - val_loss: 0.5391 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6639 - acc: 0.2590 - val_loss: 0.5386 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6632 - acc: 0.2590 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6635 - acc: 0.2590 - val_loss: 0.5376 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6605 - acc: 0.2590 - val_loss: 0.5371 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6606 - acc: 0.2590 - val_loss: 0.5366 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6595 - acc: 0.2590 - val_loss: 0.5362 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6592 - acc: 0.2590 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6584 - acc: 0.2590 - val_loss: 0.5352 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6587 - acc: 0.2590 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6579 - acc: 0.2590 - val_loss: 0.5343 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6572 - acc: 0.2590 - val_loss: 0.5338 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6569 - acc: 0.2590 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6569 - acc: 0.2590 - val_loss: 0.5330 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6557 - acc: 0.2590 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6563 - acc: 0.2590 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6570 - acc: 0.2590 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6536 - acc: 0.2590 - val_loss: 0.5314 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6547 - acc: 0.2590 - val_loss: 0.5310 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6550 - acc: 0.2590 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6523 - acc: 0.2590 - val_loss: 0.5302 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6532 - acc: 0.2590 - val_loss: 0.5299 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6525 - acc: 0.2590 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6517 - acc: 0.2590 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6528 - acc: 0.2590 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6510 - acc: 0.2590 - val_loss: 0.5285 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6511 - acc: 0.2590 - val_loss: 0.5281 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6509 - acc: 0.2590 - val_loss: 0.5278 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6499 - acc: 0.2590 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6483 - acc: 0.2590 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6482 - acc: 0.2590 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6489 - acc: 0.2590 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6466 - acc: 0.2590 - val_loss: 0.5262 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6470 - acc: 0.2590 - val_loss: 0.5259 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6486 - acc: 0.2590 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6475 - acc: 0.2590 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6470 - acc: 0.2590 - val_loss: 0.5251 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6458 - acc: 0.2590 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6460 - acc: 0.2590 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6475 - acc: 0.2590 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6461 - acc: 0.2590 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6452 - acc: 0.2590 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6445 - acc: 0.2590 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6445 - acc: 0.2590 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6451 - acc: 0.2590 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6443 - acc: 0.2590 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6445 - acc: 0.2590 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6438 - acc: 0.2590 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6446 - acc: 0.2590 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6443 - acc: 0.2590 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6437 - acc: 0.2590 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6419 - acc: 0.2590 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6408 - acc: 0.2590 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6402 - acc: 0.2590 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 142us/step\n",
      "Test score: 0.5207202755813057\n",
      "Look! softmax softmax softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax softmax elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_153 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_608 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_458 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_609 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_459 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_610 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 37ms/step - loss: 4.0362 - acc: 0.2399 - val_loss: 5.5298 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 4.5306 - acc: 0.2357 - val_loss: 5.5139 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 4.5596 - acc: 0.1868 - val_loss: 5.5141 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 4.1821 - acc: 0.1911 - val_loss: 2.5917 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 4.1711 - acc: 0.1720 - val_loss: 2.3956 - val_acc: 0.1277\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.3370 - acc: 0.1592 - val_loss: 2.3335 - val_acc: 0.1277\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 3.0559 - acc: 0.1423 - val_loss: 2.8164 - val_acc: 0.1277\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 2.6456 - acc: 0.1231 - val_loss: 2.8005 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 2.0369 - acc: 0.0722 - val_loss: 1.0871 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.6295 - acc: 0.0679 - val_loss: 1.0215 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.5134 - acc: 0.0892 - val_loss: 1.0111 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.1628 - acc: 0.0807 - val_loss: 0.5580 - val_acc: 0.0355\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.1234 - acc: 0.1062 - val_loss: 0.5420 - val_acc: 0.0355\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.0380 - acc: 0.1316 - val_loss: 0.5344 - val_acc: 0.0355\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.0306 - acc: 0.1529 - val_loss: 0.5307 - val_acc: 0.0355\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.9094 - acc: 0.1614 - val_loss: 0.5282 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.9501 - acc: 0.1316 - val_loss: 0.5261 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.9547 - acc: 0.1486 - val_loss: 0.5245 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.9649 - acc: 0.1868 - val_loss: 0.5241 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.9012 - acc: 0.1890 - val_loss: 0.5230 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.8742 - acc: 0.1783 - val_loss: 0.5220 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.9294 - acc: 0.1953 - val_loss: 0.5213 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6922 - acc: 0.1996 - val_loss: 0.5208 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.8303 - acc: 0.1783 - val_loss: 0.5210 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.8102 - acc: 0.1614 - val_loss: 0.5225 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.8855 - acc: 0.1932 - val_loss: 0.5251 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.8595 - acc: 0.1231 - val_loss: 0.5266 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.8084 - acc: 0.1083 - val_loss: 0.5270 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.8635 - acc: 0.1338 - val_loss: 0.5276 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.8150 - acc: 0.1338 - val_loss: 0.5282 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.8356 - acc: 0.1465 - val_loss: 0.5284 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7338 - acc: 0.1444 - val_loss: 0.5278 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7977 - acc: 0.1316 - val_loss: 0.5272 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7863 - acc: 0.1444 - val_loss: 0.5266 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7473 - acc: 0.1359 - val_loss: 0.5259 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7507 - acc: 0.1635 - val_loss: 0.5255 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7187 - acc: 0.1656 - val_loss: 0.5266 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7206 - acc: 0.1465 - val_loss: 0.5302 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7804 - acc: 0.1316 - val_loss: 0.5320 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.7082 - acc: 0.1231 - val_loss: 0.5324 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7137 - acc: 0.1444 - val_loss: 0.5324 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7176 - acc: 0.1253 - val_loss: 0.5334 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6894 - acc: 0.1486 - val_loss: 0.5349 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6956 - acc: 0.1783 - val_loss: 0.5350 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7811 - acc: 0.2038 - val_loss: 0.5345 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7078 - acc: 0.2293 - val_loss: 0.5335 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.7497 - acc: 0.2251 - val_loss: 0.5324 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7523 - acc: 0.2293 - val_loss: 0.5318 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6846 - acc: 0.2229 - val_loss: 0.5309 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6711 - acc: 0.2166 - val_loss: 0.5299 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6459 - acc: 0.1975 - val_loss: 0.5287 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7014 - acc: 0.2102 - val_loss: 0.5275 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7457 - acc: 0.2293 - val_loss: 0.5304 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6648 - acc: 0.2272 - val_loss: 0.5332 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7122 - acc: 0.2866 - val_loss: 0.5355 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.7365 - acc: 0.2803 - val_loss: 0.5368 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7152 - acc: 0.2824 - val_loss: 0.5370 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7121 - acc: 0.2824 - val_loss: 0.5366 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.7031 - acc: 0.2569 - val_loss: 0.5360 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6854 - acc: 0.2442 - val_loss: 0.5353 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6979 - acc: 0.2059 - val_loss: 0.5345 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7039 - acc: 0.2739 - val_loss: 0.5342 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6974 - acc: 0.1868 - val_loss: 0.5350 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6821 - acc: 0.2059 - val_loss: 0.5346 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7034 - acc: 0.2102 - val_loss: 0.5338 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6973 - acc: 0.2484 - val_loss: 0.5328 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6878 - acc: 0.2739 - val_loss: 0.5317 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7211 - acc: 0.2378 - val_loss: 0.5306 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6692 - acc: 0.2314 - val_loss: 0.5294 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6759 - acc: 0.2611 - val_loss: 0.5290 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6735 - acc: 0.2229 - val_loss: 0.5285 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: 0.6625 - acc: 0.1953 - val_loss: 0.5275 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6795 - acc: 0.1720 - val_loss: 0.5265 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7006 - acc: 0.2102 - val_loss: 0.5254 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6537 - acc: 0.1741 - val_loss: 0.5243 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6522 - acc: 0.1911 - val_loss: 0.5232 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6953 - acc: 0.1975 - val_loss: 0.5223 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6910 - acc: 0.1975 - val_loss: 0.5217 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6918 - acc: 0.1656 - val_loss: 0.5226 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7115 - acc: 0.1423 - val_loss: 0.5237 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6460 - acc: 0.1359 - val_loss: 0.5241 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6863 - acc: 0.1231 - val_loss: 0.5244 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6663 - acc: 0.1062 - val_loss: 0.5242 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6451 - acc: 0.0998 - val_loss: 0.5237 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6965 - acc: 0.1274 - val_loss: 0.5230 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6518 - acc: 0.1210 - val_loss: 0.5234 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6803 - acc: 0.1529 - val_loss: 0.5259 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6532 - acc: 0.1805 - val_loss: 0.5275 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6598 - acc: 0.2293 - val_loss: 0.5283 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6605 - acc: 0.2399 - val_loss: 0.5284 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6554 - acc: 0.2675 - val_loss: 0.5281 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6625 - acc: 0.2378 - val_loss: 0.5274 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6616 - acc: 0.2505 - val_loss: 0.5266 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6610 - acc: 0.2696 - val_loss: 0.5260 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6573 - acc: 0.2357 - val_loss: 0.5252 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6476 - acc: 0.2442 - val_loss: 0.5244 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6646 - acc: 0.2144 - val_loss: 0.5236 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6388 - acc: 0.2081 - val_loss: 0.5226 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6920 - acc: 0.2335 - val_loss: 0.5217 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6584 - acc: 0.2081 - val_loss: 0.5212 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6398 - acc: 0.2081 - val_loss: 0.5206 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6496 - acc: 0.2272 - val_loss: 0.5199 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6799 - acc: 0.1805 - val_loss: 0.5195 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6635 - acc: 0.1953 - val_loss: 0.5191 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6626 - acc: 0.2272 - val_loss: 0.5189 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6719 - acc: 0.1847 - val_loss: 0.5185 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6632 - acc: 0.2081 - val_loss: 0.5186 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6901 - acc: 0.2166 - val_loss: 0.5190 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6528 - acc: 0.1996 - val_loss: 0.5193 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6670 - acc: 0.2208 - val_loss: 0.5193 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 137us/step - loss: 0.6586 - acc: 0.1953 - val_loss: 0.5193 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: 0.6456 - acc: 0.2123 - val_loss: 0.5191 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: 0.6461 - acc: 0.1975 - val_loss: 0.5187 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: 0.6882 - acc: 0.1911 - val_loss: 0.5187 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 142us/step - loss: 0.7158 - acc: 0.2166 - val_loss: 0.5186 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: 0.6567 - acc: 0.2229 - val_loss: 0.5184 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6520 - acc: 0.1656 - val_loss: 0.5181 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6480 - acc: 0.1486 - val_loss: 0.5179 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6474 - acc: 0.1507 - val_loss: 0.5179 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6470 - acc: 0.1720 - val_loss: 0.5177 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 134us/step\n",
      "Test score: 0.517734853088433\n",
      "Look! softmax softmax softsign Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax softmax elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_154 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_611 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_460 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_612 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_461 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_613 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 37ms/step - loss: nan - acc: 0.4522 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 141us/step\n",
      "Test score: nan\n",
      "Look! softmax softmax relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax softmax relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_155 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_614 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_462 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_615 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_463 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_616 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 17s 37ms/step - loss: 3.8710 - acc: 0.2548 - val_loss: 2.6307 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 3.6811 - acc: 0.2017 - val_loss: 2.4121 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.4386 - acc: 0.1911 - val_loss: 1.3688 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.9574 - acc: 0.2166 - val_loss: 1.2213 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.2632 - acc: 0.2059 - val_loss: 1.1555 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.2800 - acc: 0.2059 - val_loss: 1.5664 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 3.0809 - acc: 0.2251 - val_loss: 1.5209 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.5485 - acc: 0.2081 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.2136 - acc: 0.2166 - val_loss: 1.5159 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 2.3083 - acc: 0.2144 - val_loss: 1.5352 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.0028 - acc: 0.2123 - val_loss: 1.5473 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 2.1887 - acc: 0.2017 - val_loss: 1.5695 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.2300 - acc: 0.2399 - val_loss: 1.5733 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.1529 - acc: 0.2123 - val_loss: 1.5630 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.0406 - acc: 0.2187 - val_loss: 1.5457 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.9768 - acc: 0.2420 - val_loss: 1.5261 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 1.9139 - acc: 0.2293 - val_loss: 1.3348 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 2.0633 - acc: 0.2144 - val_loss: 1.3322 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 2.2788 - acc: 0.2166 - val_loss: 1.0489 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 2.7052 - acc: 0.2187 - val_loss: 1.0432 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 2.7675 - acc: 0.2293 - val_loss: 1.0340 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.2882 - acc: 0.2081 - val_loss: 1.0516 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.4032 - acc: 0.2208 - val_loss: 1.0427 - val_acc: 0.1277\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 2.3062 - acc: 0.2272 - val_loss: 1.0056 - val_acc: 0.1277\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 2.1872 - acc: 0.2335 - val_loss: 0.9870 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 2.1411 - acc: 0.1868 - val_loss: 0.9736 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.3397 - acc: 0.1847 - val_loss: 0.9656 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.0253 - acc: 0.1975 - val_loss: 0.9602 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.0081 - acc: 0.2017 - val_loss: 0.9557 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.8562 - acc: 0.2229 - val_loss: 0.9511 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 2.5646 - acc: 0.2081 - val_loss: 0.9453 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 2.4464 - acc: 0.2017 - val_loss: 0.9372 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 2.4039 - acc: 0.2123 - val_loss: 0.9265 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.3421 - acc: 0.1975 - val_loss: 0.9145 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 3.5382 - acc: 0.2272 - val_loss: 0.9145 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 3.7523 - acc: 0.1890 - val_loss: 0.9145 - val_acc: 0.1277\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.5779 - acc: 0.2144 - val_loss: 6.0586 - val_acc: 0.1277\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 4.3608 - acc: 0.2017 - val_loss: 6.0586 - val_acc: 0.1277\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 4.9953 - acc: 0.1847 - val_loss: 6.0586 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 5.4277 - acc: 0.2059 - val_loss: 6.0586 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 5.1666 - acc: 0.2144 - val_loss: 5.5898 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 5.5359 - acc: 0.2081 - val_loss: 5.5657 - val_acc: 0.1277\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 6.0591 - acc: 0.1975 - val_loss: 5.5601 - val_acc: 0.1277\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 5.9284 - acc: 0.2102 - val_loss: 5.5590 - val_acc: 0.1277\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 5.6603 - acc: 0.1656 - val_loss: 5.5578 - val_acc: 0.1277\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 4.5779 - acc: 0.1529 - val_loss: 2.5376 - val_acc: 0.1277\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 3.6222 - acc: 0.1507 - val_loss: 2.4202 - val_acc: 0.1277\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.9661 - acc: 0.1571 - val_loss: 2.3771 - val_acc: 0.1277\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.9217 - acc: 0.1507 - val_loss: 2.3538 - val_acc: 0.1277\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 2.7603 - acc: 0.1444 - val_loss: 2.3382 - val_acc: 0.1277\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.7495 - acc: 0.1507 - val_loss: 2.3269 - val_acc: 0.1277\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 2.7209 - acc: 0.1507 - val_loss: 2.3185 - val_acc: 0.1277\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.7251 - acc: 0.1465 - val_loss: 2.3123 - val_acc: 0.1277\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.5865 - acc: 0.1465 - val_loss: 2.3072 - val_acc: 0.1277\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.8027 - acc: 0.1486 - val_loss: 2.3034 - val_acc: 0.1277\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.7738 - acc: 0.1529 - val_loss: 2.2989 - val_acc: 0.1277\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 2.7080 - acc: 0.1507 - val_loss: 2.2939 - val_acc: 0.1277\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 2.6198 - acc: 0.1444 - val_loss: 2.2891 - val_acc: 0.1277\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.7395 - acc: 0.1507 - val_loss: 2.2845 - val_acc: 0.1277\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.7346 - acc: 0.1507 - val_loss: 2.2803 - val_acc: 0.1277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 2.6100 - acc: 0.1507 - val_loss: 2.2762 - val_acc: 0.1277\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 2.8073 - acc: 0.1550 - val_loss: 2.2719 - val_acc: 0.1277\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 2.5509 - acc: 0.1486 - val_loss: 2.2814 - val_acc: 0.1277\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 2.5991 - acc: 0.1465 - val_loss: 2.2897 - val_acc: 0.1277\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 2.3241 - acc: 0.1507 - val_loss: 2.3020 - val_acc: 0.1277\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.0585 - acc: 0.1338 - val_loss: 0.8414 - val_acc: 0.1277\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.4894 - acc: 0.1189 - val_loss: 0.6076 - val_acc: 0.1277\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.4975 - acc: 0.1295 - val_loss: 0.5562 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 1.0681 - acc: 0.1295 - val_loss: 0.5360 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.0664 - acc: 0.1571 - val_loss: 0.5273 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.9071 - acc: 0.1805 - val_loss: 0.5223 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.8247 - acc: 0.1401 - val_loss: 0.5191 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.8852 - acc: 0.1677 - val_loss: 0.5177 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.8975 - acc: 0.1699 - val_loss: 0.5217 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7877 - acc: 0.1274 - val_loss: 0.5263 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6831 - acc: 0.1019 - val_loss: 0.5288 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.9375 - acc: 0.0913 - val_loss: 0.5304 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.7371 - acc: 0.0913 - val_loss: 0.5312 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.7603 - acc: 0.0998 - val_loss: 0.5323 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7899 - acc: 0.0998 - val_loss: 0.5332 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7402 - acc: 0.1189 - val_loss: 0.5332 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.7545 - acc: 0.1423 - val_loss: 0.5334 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: 0.8091 - acc: 0.1592 - val_loss: 0.5333 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6623 - acc: 0.1720 - val_loss: 0.5325 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6930 - acc: 0.1783 - val_loss: 0.5313 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6725 - acc: 0.1444 - val_loss: 0.5304 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7700 - acc: 0.1890 - val_loss: 0.5302 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6734 - acc: 0.1614 - val_loss: 0.5301 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.7829 - acc: 0.1656 - val_loss: 0.5295 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6970 - acc: 0.1635 - val_loss: 0.5287 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: 0.7102 - acc: 0.1783 - val_loss: 0.5281 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6807 - acc: 0.1423 - val_loss: 0.5291 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.7437 - acc: 0.1868 - val_loss: 0.5301 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.7529 - acc: 0.1380 - val_loss: 0.5308 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.8363 - acc: 0.1316 - val_loss: 0.5307 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6980 - acc: 0.1168 - val_loss: 0.5301 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6631 - acc: 0.1295 - val_loss: 0.5292 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6805 - acc: 0.1614 - val_loss: 0.5283 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7327 - acc: 0.1656 - val_loss: 0.5275 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6596 - acc: 0.1295 - val_loss: 0.5266 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.8140 - acc: 0.1529 - val_loss: 0.5254 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.7357 - acc: 0.1274 - val_loss: 0.5249 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: 0.7009 - acc: 0.1359 - val_loss: 0.5244 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.7279 - acc: 0.1741 - val_loss: 0.5236 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6861 - acc: 0.1401 - val_loss: 0.5230 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: 0.7082 - acc: 0.1444 - val_loss: 0.5228 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7630 - acc: 0.1550 - val_loss: 0.5233 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6637 - acc: 0.1656 - val_loss: 0.5236 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7199 - acc: 0.1486 - val_loss: 0.5235 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7866 - acc: 0.1571 - val_loss: 0.5232 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7490 - acc: 0.1635 - val_loss: 0.5247 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7776 - acc: 0.1444 - val_loss: 0.5296 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6935 - acc: 0.1656 - val_loss: 0.5326 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7082 - acc: 0.1507 - val_loss: 0.5345 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6662 - acc: 0.1295 - val_loss: 0.5350 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6754 - acc: 0.1486 - val_loss: 0.5350 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6683 - acc: 0.1189 - val_loss: 0.5345 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6632 - acc: 0.1274 - val_loss: 0.5335 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: 0.6691 - acc: 0.1189 - val_loss: 0.5324 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.7052 - acc: 0.1210 - val_loss: 0.5314 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 119us/step\n",
      "Test score: 0.531353938664105\n",
      "Look! softmax softmax tanh Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax softmax relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_156 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_617 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_464 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_618 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_465 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_619 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 17s 37ms/step - loss: 0.7348 - acc: 0.2781 - val_loss: 0.5984 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7338 - acc: 0.2463 - val_loss: 0.5974 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.7328 - acc: 0.2144 - val_loss: 0.5964 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7314 - acc: 0.2590 - val_loss: 0.5954 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7306 - acc: 0.2420 - val_loss: 0.5945 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7292 - acc: 0.2399 - val_loss: 0.5936 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7283 - acc: 0.2442 - val_loss: 0.5926 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7270 - acc: 0.2590 - val_loss: 0.5917 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7259 - acc: 0.2463 - val_loss: 0.5908 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7248 - acc: 0.2611 - val_loss: 0.5900 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7236 - acc: 0.2590 - val_loss: 0.5891 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.7225 - acc: 0.2590 - val_loss: 0.5882 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.7215 - acc: 0.2590 - val_loss: 0.5874 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7202 - acc: 0.2590 - val_loss: 0.5865 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7193 - acc: 0.2590 - val_loss: 0.5857 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.7185 - acc: 0.2590 - val_loss: 0.5848 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7175 - acc: 0.2590 - val_loss: 0.5840 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.7162 - acc: 0.2590 - val_loss: 0.5832 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7158 - acc: 0.2590 - val_loss: 0.5824 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7146 - acc: 0.2590 - val_loss: 0.5816 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7134 - acc: 0.2590 - val_loss: 0.5808 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7127 - acc: 0.2590 - val_loss: 0.5800 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7120 - acc: 0.2590 - val_loss: 0.5792 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7110 - acc: 0.2590 - val_loss: 0.5784 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.7101 - acc: 0.2590 - val_loss: 0.5776 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7092 - acc: 0.2590 - val_loss: 0.5769 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7078 - acc: 0.2590 - val_loss: 0.5761 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7066 - acc: 0.2590 - val_loss: 0.5753 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.7066 - acc: 0.2590 - val_loss: 0.5746 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7049 - acc: 0.2590 - val_loss: 0.5739 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7045 - acc: 0.2590 - val_loss: 0.5731 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7032 - acc: 0.2590 - val_loss: 0.5724 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7029 - acc: 0.2590 - val_loss: 0.5717 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7020 - acc: 0.2590 - val_loss: 0.5710 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7009 - acc: 0.2590 - val_loss: 0.5703 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7002 - acc: 0.2590 - val_loss: 0.5696 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6989 - acc: 0.2590 - val_loss: 0.5689 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6988 - acc: 0.2590 - val_loss: 0.5682 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6978 - acc: 0.2590 - val_loss: 0.5676 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6975 - acc: 0.2590 - val_loss: 0.5669 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6962 - acc: 0.2590 - val_loss: 0.5663 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6956 - acc: 0.2590 - val_loss: 0.5656 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6946 - acc: 0.2590 - val_loss: 0.5650 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6937 - acc: 0.2590 - val_loss: 0.5644 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6935 - acc: 0.2590 - val_loss: 0.5637 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6927 - acc: 0.2590 - val_loss: 0.5631 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6914 - acc: 0.2590 - val_loss: 0.5625 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6909 - acc: 0.2590 - val_loss: 0.5619 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6904 - acc: 0.2590 - val_loss: 0.5613 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6904 - acc: 0.2590 - val_loss: 0.5607 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 159us/step - loss: 0.6885 - acc: 0.2590 - val_loss: 0.5601 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6886 - acc: 0.2590 - val_loss: 0.5595 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6874 - acc: 0.2590 - val_loss: 0.5589 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6872 - acc: 0.2590 - val_loss: 0.5583 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6864 - acc: 0.2590 - val_loss: 0.5577 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6847 - acc: 0.2590 - val_loss: 0.5571 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6849 - acc: 0.2590 - val_loss: 0.5566 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6836 - acc: 0.2590 - val_loss: 0.5560 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6835 - acc: 0.2590 - val_loss: 0.5554 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6829 - acc: 0.2590 - val_loss: 0.5549 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6822 - acc: 0.2590 - val_loss: 0.5544 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6814 - acc: 0.2590 - val_loss: 0.5539 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6802 - acc: 0.2590 - val_loss: 0.5533 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6800 - acc: 0.2590 - val_loss: 0.5528 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6793 - acc: 0.2590 - val_loss: 0.5523 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6793 - acc: 0.2590 - val_loss: 0.5518 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6784 - acc: 0.2590 - val_loss: 0.5513 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6776 - acc: 0.2590 - val_loss: 0.5508 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6770 - acc: 0.2590 - val_loss: 0.5503 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6765 - acc: 0.2590 - val_loss: 0.5498 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6754 - acc: 0.2590 - val_loss: 0.5493 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6756 - acc: 0.2590 - val_loss: 0.5488 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6750 - acc: 0.2590 - val_loss: 0.5483 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6739 - acc: 0.2590 - val_loss: 0.5478 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6732 - acc: 0.2590 - val_loss: 0.5473 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6733 - acc: 0.2590 - val_loss: 0.5468 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6721 - acc: 0.2590 - val_loss: 0.5464 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6718 - acc: 0.2590 - val_loss: 0.5459 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6720 - acc: 0.2590 - val_loss: 0.5455 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6710 - acc: 0.2590 - val_loss: 0.5450 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6700 - acc: 0.2590 - val_loss: 0.5446 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6693 - acc: 0.2590 - val_loss: 0.5441 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6702 - acc: 0.2590 - val_loss: 0.5437 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6687 - acc: 0.2590 - val_loss: 0.5433 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6686 - acc: 0.2590 - val_loss: 0.5428 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6677 - acc: 0.2590 - val_loss: 0.5424 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6666 - acc: 0.2590 - val_loss: 0.5420 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6660 - acc: 0.2590 - val_loss: 0.5416 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6673 - acc: 0.2590 - val_loss: 0.5412 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6646 - acc: 0.2590 - val_loss: 0.5408 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6653 - acc: 0.2590 - val_loss: 0.5404 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6643 - acc: 0.2590 - val_loss: 0.5400 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6642 - acc: 0.2590 - val_loss: 0.5396 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6632 - acc: 0.2590 - val_loss: 0.5392 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6634 - acc: 0.2590 - val_loss: 0.5388 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6626 - acc: 0.2590 - val_loss: 0.5384 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6637 - acc: 0.2590 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6633 - acc: 0.2590 - val_loss: 0.5377 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6610 - acc: 0.2590 - val_loss: 0.5374 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6614 - acc: 0.2590 - val_loss: 0.5370 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6614 - acc: 0.2590 - val_loss: 0.5367 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6606 - acc: 0.2590 - val_loss: 0.5363 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6607 - acc: 0.2590 - val_loss: 0.5360 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6601 - acc: 0.2590 - val_loss: 0.5356 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6602 - acc: 0.2590 - val_loss: 0.5353 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6588 - acc: 0.2590 - val_loss: 0.5350 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6575 - acc: 0.2590 - val_loss: 0.5346 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: 0.6578 - acc: 0.2590 - val_loss: 0.5343 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: 0.6570 - acc: 0.2590 - val_loss: 0.5340 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6574 - acc: 0.2590 - val_loss: 0.5336 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6567 - acc: 0.2590 - val_loss: 0.5333 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: 0.6579 - acc: 0.2590 - val_loss: 0.5330 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6571 - acc: 0.2590 - val_loss: 0.5327 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6554 - acc: 0.2590 - val_loss: 0.5324 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6559 - acc: 0.2590 - val_loss: 0.5321 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 145us/step - loss: 0.6557 - acc: 0.2590 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: 0.6550 - acc: 0.2590 - val_loss: 0.5315 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 142us/step - loss: 0.6545 - acc: 0.2590 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6543 - acc: 0.2590 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6532 - acc: 0.2590 - val_loss: 0.5307 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 120us/step\n",
      "Test score: 0.5306686822404253\n",
      "Look! softmax softmax sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax softmax relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_157 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_620 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_466 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_621 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_467 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_622 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 37ms/step - loss: 0.7348 - acc: 0.3291 - val_loss: 0.5984 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7340 - acc: 0.2654 - val_loss: 0.5977 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7331 - acc: 0.2527 - val_loss: 0.5969 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7322 - acc: 0.2484 - val_loss: 0.5962 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7312 - acc: 0.2654 - val_loss: 0.5955 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.7305 - acc: 0.2548 - val_loss: 0.5947 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7296 - acc: 0.2569 - val_loss: 0.5940 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7285 - acc: 0.2611 - val_loss: 0.5932 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7280 - acc: 0.2590 - val_loss: 0.5925 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7268 - acc: 0.2590 - val_loss: 0.5918 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7262 - acc: 0.2611 - val_loss: 0.5911 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.7250 - acc: 0.2590 - val_loss: 0.5904 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7243 - acc: 0.2590 - val_loss: 0.5897 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7235 - acc: 0.2590 - val_loss: 0.5890 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7225 - acc: 0.2590 - val_loss: 0.5883 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7219 - acc: 0.2590 - val_loss: 0.5876 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7208 - acc: 0.2590 - val_loss: 0.5869 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7200 - acc: 0.2590 - val_loss: 0.5863 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7191 - acc: 0.2590 - val_loss: 0.5856 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7184 - acc: 0.2590 - val_loss: 0.5849 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7177 - acc: 0.2590 - val_loss: 0.5843 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7168 - acc: 0.2590 - val_loss: 0.5836 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7160 - acc: 0.2590 - val_loss: 0.5829 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7154 - acc: 0.2590 - val_loss: 0.5823 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7149 - acc: 0.2590 - val_loss: 0.5816 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7141 - acc: 0.2590 - val_loss: 0.5810 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7130 - acc: 0.2590 - val_loss: 0.5804 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7121 - acc: 0.2590 - val_loss: 0.5798 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7115 - acc: 0.2590 - val_loss: 0.5791 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7108 - acc: 0.2590 - val_loss: 0.5785 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.7107 - acc: 0.2590 - val_loss: 0.5779 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7093 - acc: 0.2590 - val_loss: 0.5773 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7089 - acc: 0.2590 - val_loss: 0.5767 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7077 - acc: 0.2590 - val_loss: 0.5761 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.7074 - acc: 0.2590 - val_loss: 0.5755 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7067 - acc: 0.2590 - val_loss: 0.5749 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7055 - acc: 0.2590 - val_loss: 0.5743 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7050 - acc: 0.2590 - val_loss: 0.5737 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7039 - acc: 0.2590 - val_loss: 0.5731 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7036 - acc: 0.2590 - val_loss: 0.5725 - val_acc: 0.2128\n",
      "Epoch 41/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 172us/step - loss: 0.7027 - acc: 0.2590 - val_loss: 0.5719 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7023 - acc: 0.2590 - val_loss: 0.5713 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7017 - acc: 0.2590 - val_loss: 0.5707 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7008 - acc: 0.2590 - val_loss: 0.5702 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.7000 - acc: 0.2590 - val_loss: 0.5696 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6997 - acc: 0.2590 - val_loss: 0.5691 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6989 - acc: 0.2590 - val_loss: 0.5685 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6980 - acc: 0.2590 - val_loss: 0.5679 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6978 - acc: 0.2590 - val_loss: 0.5674 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6971 - acc: 0.2590 - val_loss: 0.5668 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6959 - acc: 0.2590 - val_loss: 0.5663 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6949 - acc: 0.2590 - val_loss: 0.5658 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6950 - acc: 0.2590 - val_loss: 0.5652 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6944 - acc: 0.2590 - val_loss: 0.5647 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6937 - acc: 0.2590 - val_loss: 0.5642 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6933 - acc: 0.2590 - val_loss: 0.5636 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6919 - acc: 0.2590 - val_loss: 0.5631 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6919 - acc: 0.2590 - val_loss: 0.5626 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6915 - acc: 0.2590 - val_loss: 0.5621 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6910 - acc: 0.2590 - val_loss: 0.5616 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6900 - acc: 0.2590 - val_loss: 0.5611 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6892 - acc: 0.2590 - val_loss: 0.5606 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6890 - acc: 0.2590 - val_loss: 0.5600 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6873 - acc: 0.2590 - val_loss: 0.5595 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6873 - acc: 0.2590 - val_loss: 0.5590 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6872 - acc: 0.2590 - val_loss: 0.5585 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6864 - acc: 0.2590 - val_loss: 0.5580 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6858 - acc: 0.2590 - val_loss: 0.5575 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6851 - acc: 0.2590 - val_loss: 0.5570 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6837 - acc: 0.2590 - val_loss: 0.5565 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6848 - acc: 0.2590 - val_loss: 0.5560 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6833 - acc: 0.2590 - val_loss: 0.5556 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6828 - acc: 0.2590 - val_loss: 0.5551 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6826 - acc: 0.2590 - val_loss: 0.5546 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6814 - acc: 0.2590 - val_loss: 0.5541 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6816 - acc: 0.2590 - val_loss: 0.5537 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6804 - acc: 0.2590 - val_loss: 0.5532 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6802 - acc: 0.2590 - val_loss: 0.5527 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6796 - acc: 0.2590 - val_loss: 0.5523 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6782 - acc: 0.2590 - val_loss: 0.5518 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6780 - acc: 0.2590 - val_loss: 0.5514 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6781 - acc: 0.2590 - val_loss: 0.5509 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6772 - acc: 0.2590 - val_loss: 0.5505 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6764 - acc: 0.2590 - val_loss: 0.5500 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6768 - acc: 0.2590 - val_loss: 0.5496 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6760 - acc: 0.2590 - val_loss: 0.5492 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6751 - acc: 0.2590 - val_loss: 0.5487 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6742 - acc: 0.2590 - val_loss: 0.5483 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6755 - acc: 0.2590 - val_loss: 0.5479 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6734 - acc: 0.2590 - val_loss: 0.5475 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6726 - acc: 0.2590 - val_loss: 0.5470 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6713 - acc: 0.2590 - val_loss: 0.5466 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6724 - acc: 0.2590 - val_loss: 0.5462 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6723 - acc: 0.2590 - val_loss: 0.5458 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6721 - acc: 0.2590 - val_loss: 0.5454 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6705 - acc: 0.2590 - val_loss: 0.5450 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6704 - acc: 0.2590 - val_loss: 0.5446 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6703 - acc: 0.2590 - val_loss: 0.5442 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6689 - acc: 0.2590 - val_loss: 0.5438 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6692 - acc: 0.2590 - val_loss: 0.5434 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6681 - acc: 0.2590 - val_loss: 0.5430 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6680 - acc: 0.2590 - val_loss: 0.5426 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6668 - acc: 0.2590 - val_loss: 0.5422 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6669 - acc: 0.2590 - val_loss: 0.5418 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6683 - acc: 0.2590 - val_loss: 0.5414 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6656 - acc: 0.2590 - val_loss: 0.5410 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6661 - acc: 0.2590 - val_loss: 0.5407 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6644 - acc: 0.2590 - val_loss: 0.5403 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6654 - acc: 0.2590 - val_loss: 0.5399 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6647 - acc: 0.2590 - val_loss: 0.5395 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6641 - acc: 0.2590 - val_loss: 0.5392 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6634 - acc: 0.2590 - val_loss: 0.5388 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6625 - acc: 0.2590 - val_loss: 0.5385 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6614 - acc: 0.2590 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6633 - acc: 0.2590 - val_loss: 0.5378 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6630 - acc: 0.2590 - val_loss: 0.5374 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6603 - acc: 0.2590 - val_loss: 0.5371 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6616 - acc: 0.2590 - val_loss: 0.5367 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6599 - acc: 0.2590 - val_loss: 0.5364 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6599 - acc: 0.2590 - val_loss: 0.5360 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 155us/step\n",
      "Test score: 0.5360293506730532\n",
      "Look! softmax softmax hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax softmax relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_158 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_623 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_468 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_624 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_469 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_625 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 37ms/step - loss: 4.5923 - acc: 0.3779 - val_loss: 4.0113 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 4.4518 - acc: 0.3079 - val_loss: 4.0293 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 4.3359 - acc: 0.2335 - val_loss: 4.0468 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.8425 - acc: 0.1847 - val_loss: 4.0778 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.4464 - acc: 0.1911 - val_loss: 3.6684 - val_acc: 0.1277\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 2.7781 - acc: 0.1847 - val_loss: 0.7320 - val_acc: 0.1277\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.4544 - acc: 0.1868 - val_loss: 0.6100 - val_acc: 0.1277\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.5467 - acc: 0.2251 - val_loss: 0.5777 - val_acc: 0.1277\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.2809 - acc: 0.2251 - val_loss: 0.5715 - val_acc: 0.1277\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.1943 - acc: 0.2590 - val_loss: 0.5475 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.0061 - acc: 0.2696 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.9182 - acc: 0.2611 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.1166 - acc: 0.2420 - val_loss: 0.5249 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.1082 - acc: 0.2633 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.9003 - acc: 0.2633 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.0864 - acc: 0.2760 - val_loss: 0.5278 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.8993 - acc: 0.2569 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.9594 - acc: 0.2654 - val_loss: 0.5407 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7796 - acc: 0.2930 - val_loss: 0.5430 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.8093 - acc: 0.2675 - val_loss: 0.5441 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.8559 - acc: 0.3248 - val_loss: 0.5438 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7797 - acc: 0.2569 - val_loss: 0.5424 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.8780 - acc: 0.2611 - val_loss: 0.5405 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7532 - acc: 0.3015 - val_loss: 0.5389 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7813 - acc: 0.2484 - val_loss: 0.5371 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7143 - acc: 0.3057 - val_loss: 0.5349 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7537 - acc: 0.2909 - val_loss: 0.5327 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6959 - acc: 0.2357 - val_loss: 0.5304 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7291 - acc: 0.2569 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.8222 - acc: 0.2314 - val_loss: 0.5281 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7679 - acc: 0.2335 - val_loss: 0.5283 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.8533 - acc: 0.2335 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.8355 - acc: 0.2484 - val_loss: 0.5324 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.8404 - acc: 0.2420 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6696 - acc: 0.2569 - val_loss: 0.5451 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6983 - acc: 0.2675 - val_loss: 0.5483 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6876 - acc: 0.2994 - val_loss: 0.5497 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7325 - acc: 0.3121 - val_loss: 0.5497 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7803 - acc: 0.2739 - val_loss: 0.5487 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7375 - acc: 0.3227 - val_loss: 0.5473 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7464 - acc: 0.2760 - val_loss: 0.5455 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7140 - acc: 0.2781 - val_loss: 0.5435 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.8036 - acc: 0.2357 - val_loss: 0.5412 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7649 - acc: 0.2909 - val_loss: 0.5389 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.8218 - acc: 0.3015 - val_loss: 0.5371 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7379 - acc: 0.2463 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.7458 - acc: 0.2484 - val_loss: 0.5348 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7314 - acc: 0.2548 - val_loss: 0.5342 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6698 - acc: 0.2463 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7012 - acc: 0.2187 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7549 - acc: 0.2378 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6998 - acc: 0.1996 - val_loss: 0.5319 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6764 - acc: 0.2420 - val_loss: 0.5323 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7399 - acc: 0.2357 - val_loss: 0.5324 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7053 - acc: 0.2293 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7116 - acc: 0.2357 - val_loss: 0.5325 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7243 - acc: 0.2293 - val_loss: 0.5324 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6612 - acc: 0.2484 - val_loss: 0.5319 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7616 - acc: 0.2590 - val_loss: 0.5313 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6644 - acc: 0.2272 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.7192 - acc: 0.2484 - val_loss: 0.5302 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7086 - acc: 0.2293 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6793 - acc: 0.2378 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7115 - acc: 0.2569 - val_loss: 0.5292 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7319 - acc: 0.2569 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6940 - acc: 0.2399 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7234 - acc: 0.2251 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6922 - acc: 0.2357 - val_loss: 0.5281 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6508 - acc: 0.2548 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7212 - acc: 0.2378 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6718 - acc: 0.2633 - val_loss: 0.5356 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7029 - acc: 0.2420 - val_loss: 0.5447 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 142us/step - loss: 0.6895 - acc: 0.2229 - val_loss: 0.5505 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.7687 - acc: 0.2187 - val_loss: 0.5539 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6947 - acc: 0.2166 - val_loss: 0.5558 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6916 - acc: 0.2357 - val_loss: 0.5566 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7112 - acc: 0.1932 - val_loss: 0.5567 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6926 - acc: 0.2229 - val_loss: 0.5564 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6908 - acc: 0.2293 - val_loss: 0.5557 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7581 - acc: 0.2144 - val_loss: 0.5549 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6929 - acc: 0.2378 - val_loss: 0.5540 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6931 - acc: 0.2251 - val_loss: 0.5531 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6942 - acc: 0.2251 - val_loss: 0.5522 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6999 - acc: 0.1996 - val_loss: 0.5513 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6969 - acc: 0.2017 - val_loss: 0.5503 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6993 - acc: 0.2420 - val_loss: 0.5493 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6891 - acc: 0.2442 - val_loss: 0.5484 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6831 - acc: 0.2229 - val_loss: 0.5475 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6906 - acc: 0.2102 - val_loss: 0.5465 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7060 - acc: 0.2335 - val_loss: 0.5456 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6821 - acc: 0.2123 - val_loss: 0.5446 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6723 - acc: 0.2378 - val_loss: 0.5436 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6696 - acc: 0.2527 - val_loss: 0.5427 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6986 - acc: 0.2251 - val_loss: 0.5419 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.7138 - acc: 0.2272 - val_loss: 0.5410 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6781 - acc: 0.2378 - val_loss: 0.5403 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7070 - acc: 0.2123 - val_loss: 0.5395 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6787 - acc: 0.2527 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6738 - acc: 0.2357 - val_loss: 0.5385 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6801 - acc: 0.2293 - val_loss: 0.5379 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6746 - acc: 0.2378 - val_loss: 0.5373 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6618 - acc: 0.2527 - val_loss: 0.5367 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6650 - acc: 0.2442 - val_loss: 0.5361 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6707 - acc: 0.2293 - val_loss: 0.5354 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6573 - acc: 0.2527 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6726 - acc: 0.2335 - val_loss: 0.5340 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6982 - acc: 0.2420 - val_loss: 0.5332 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6744 - acc: 0.2144 - val_loss: 0.5325 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6697 - acc: 0.2399 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6738 - acc: 0.2251 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6645 - acc: 0.2463 - val_loss: 0.5305 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6731 - acc: 0.2399 - val_loss: 0.5299 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6680 - acc: 0.2293 - val_loss: 0.5293 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.6631 - acc: 0.2527 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6634 - acc: 0.2527 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.7193 - acc: 0.2357 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6692 - acc: 0.2569 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6660 - acc: 0.2314 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6539 - acc: 0.2420 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: 0.6534 - acc: 0.2484 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 115us/step\n",
      "Test score: 0.5260276016614116\n",
      "Look! softmax softmax linear Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax softmax relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_159 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_626 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_470 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_627 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_471 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_628 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 37ms/step - loss: 0.7348 - acc: 0.2038 - val_loss: 0.5893 - val_acc: 0.2057\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7137 - acc: 0.2102 - val_loss: 0.5674 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7029 - acc: 0.2272 - val_loss: 0.5541 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6834 - acc: 0.2208 - val_loss: 0.5422 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7001 - acc: 0.2442 - val_loss: 0.5330 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6672 - acc: 0.2463 - val_loss: 0.5283 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6715 - acc: 0.2590 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6700 - acc: 0.2611 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6628 - acc: 0.2569 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6625 - acc: 0.2527 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6290 - acc: 0.2633 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6496 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6441 - acc: 0.2527 - val_loss: 0.5079 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6405 - acc: 0.2357 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6309 - acc: 0.2527 - val_loss: 0.5001 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6319 - acc: 0.2505 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6377 - acc: 0.2548 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6283 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6284 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6357 - acc: 0.2548 - val_loss: 0.5113 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6257 - acc: 0.2569 - val_loss: 0.5076 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6385 - acc: 0.2611 - val_loss: 0.5050 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6229 - acc: 0.2590 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6216 - acc: 0.2633 - val_loss: 0.5090 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6238 - acc: 0.2569 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6335 - acc: 0.2611 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6080 - acc: 0.2569 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6185 - acc: 0.2718 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6310 - acc: 0.2654 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6121 - acc: 0.2654 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6215 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6301 - acc: 0.2633 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: 0.6314 - acc: 0.2527 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6355 - acc: 0.2654 - val_loss: 0.5033 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6182 - acc: 0.2611 - val_loss: 0.5058 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.6376 - acc: 0.2548 - val_loss: 0.5085 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6256 - acc: 0.2463 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6201 - acc: 0.2611 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6261 - acc: 0.2611 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6301 - acc: 0.2633 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6335 - acc: 0.2611 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: 0.6213 - acc: 0.2654 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6385 - acc: 0.2611 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6300 - acc: 0.2633 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6282 - acc: 0.2548 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6211 - acc: 0.2654 - val_loss: 0.4981 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6262 - acc: 0.2633 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6235 - acc: 0.2654 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6209 - acc: 0.2675 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6287 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6365 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6311 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6110 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6159 - acc: 0.2654 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6129 - acc: 0.2654 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6154 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6178 - acc: 0.2675 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6148 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6279 - acc: 0.2569 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6194 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.6088 - acc: 0.2696 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 145us/step - loss: 0.6174 - acc: 0.2675 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6131 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6188 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6251 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6092 - acc: 0.2611 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6131 - acc: 0.2654 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6113 - acc: 0.2675 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6329 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6224 - acc: 0.2675 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6077 - acc: 0.2675 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6021 - acc: 0.2675 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6188 - acc: 0.2654 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6162 - acc: 0.2675 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6213 - acc: 0.2611 - val_loss: 0.5359 - val_acc: 0.1986\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6137 - acc: 0.2696 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6198 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6085 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6109 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6114 - acc: 0.2675 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6196 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6234 - acc: 0.2633 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6213 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6277 - acc: 0.2675 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6109 - acc: 0.2718 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6088 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6097 - acc: 0.2675 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6219 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6130 - acc: 0.2675 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6223 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6045 - acc: 0.2696 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6303 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6237 - acc: 0.2611 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.5953 - acc: 0.2718 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6114 - acc: 0.2675 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6249 - acc: 0.2633 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6152 - acc: 0.2675 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6243 - acc: 0.2654 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6073 - acc: 0.2654 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6107 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6165 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6204 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6060 - acc: 0.2675 - val_loss: 0.5356 - val_acc: 0.2057\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6523 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6310 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6292 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6336 - acc: 0.2569 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6280 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6440 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6317 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6314 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6329 - acc: 0.2569 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6290 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6329 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6303 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6377 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6338 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 136us/step\n",
      "Test score: 0.5111437613236989\n",
      "Look! softmax elu softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax softmax relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_160 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_629 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_472 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_630 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_473 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_631 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 17s 37ms/step - loss: nan - acc: 0.4820 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 138us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 143us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 145us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 143us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 145us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 130us/step\n",
      "Test score: nan\n",
      "Look! softmax elu elu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax elu elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_161 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_632 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_474 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_633 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_475 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_634 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: nan - acc: 0.4713 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 145us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 131us/step\n",
      "Test score: nan\n",
      "Look! softmax elu selu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax elu selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_162 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_635 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_476 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_636 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_477 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_637 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 18s 38ms/step - loss: 0.7237 - acc: 0.2420 - val_loss: 0.5645 - val_acc: 0.2340\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7019 - acc: 0.2463 - val_loss: 0.5563 - val_acc: 0.2411\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6784 - acc: 0.2633 - val_loss: 0.5471 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6763 - acc: 0.2611 - val_loss: 0.5392 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6672 - acc: 0.2654 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6800 - acc: 0.2590 - val_loss: 0.5393 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6709 - acc: 0.2611 - val_loss: 0.5313 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6720 - acc: 0.2696 - val_loss: 0.5246 - val_acc: 0.2270\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6499 - acc: 0.2633 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6372 - acc: 0.2696 - val_loss: 0.5135 - val_acc: 0.2553\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6372 - acc: 0.2760 - val_loss: 0.5024 - val_acc: 0.2340\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6397 - acc: 0.2739 - val_loss: 0.5113 - val_acc: 0.2199\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6299 - acc: 0.2781 - val_loss: 0.5186 - val_acc: 0.2340\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6453 - acc: 0.2590 - val_loss: 0.4949 - val_acc: 0.2340\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6270 - acc: 0.2611 - val_loss: 0.4978 - val_acc: 0.2340\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6374 - acc: 0.2675 - val_loss: 0.4907 - val_acc: 0.2340\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6349 - acc: 0.2696 - val_loss: 0.4859 - val_acc: 0.2766\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6277 - acc: 0.2718 - val_loss: 0.4902 - val_acc: 0.2624\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.6326 - acc: 0.2696 - val_loss: 0.4915 - val_acc: 0.2340\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6358 - acc: 0.2760 - val_loss: 0.4822 - val_acc: 0.2482\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6166 - acc: 0.2803 - val_loss: 0.5015 - val_acc: 0.2624\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6307 - acc: 0.2696 - val_loss: 0.4851 - val_acc: 0.2340\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.5820 - acc: 0.2930 - val_loss: 0.4808 - val_acc: 0.2553\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: 0.5988 - acc: 0.2845 - val_loss: 0.4814 - val_acc: 0.2624\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6463 - acc: 0.2251 - val_loss: 0.4904 - val_acc: 0.2766\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6016 - acc: 0.2760 - val_loss: 0.5027 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6315 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6606 - acc: 0.2611 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6419 - acc: 0.2590 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6545 - acc: 0.2611 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6314 - acc: 0.2590 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6666 - acc: 0.2484 - val_loss: 0.5355 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6653 - acc: 0.2505 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6488 - acc: 0.2357 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6447 - acc: 0.2569 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6348 - acc: 0.2527 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6370 - acc: 0.2548 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6397 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6428 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6413 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6347 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6340 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6334 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6412 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.6339 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.6359 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6269 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6309 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6342 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6340 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6325 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6394 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6320 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6395 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6289 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6350 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6308 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 140us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6260 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6347 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6359 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6334 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6317 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6354 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6278 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6361 - acc: 0.2633 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6322 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6278 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6335 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6239 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6298 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6299 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6288 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6362 - acc: 0.2611 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6288 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6334 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6339 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6283 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6336 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6306 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6269 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6373 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6371 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6365 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6401 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6341 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6276 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6317 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6290 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6271 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 145us/step - loss: 0.6286 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6244 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6311 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6269 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6365 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6375 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6274 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6372 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6327 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6297 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6296 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: 0.6325 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6295 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6332 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6322 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6345 - acc: 0.2590 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6365 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6356 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6289 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 130us/step\n",
      "Test score: 0.5109256193147483\n",
      "Look! softmax elu softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax elu selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_163 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_638 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_478 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_639 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_479 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_640 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 37ms/step - loss: nan - acc: 0.4352 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 145us/step\n",
      "Test score: nan\n",
      "Look! softmax elu softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax elu softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_164 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_641 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_480 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_642 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_481 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_643 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 17s 36ms/step - loss: nan - acc: 0.4713 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 140us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 141us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 140us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 131us/step\n",
      "Test score: nan\n",
      "Look! softmax elu relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax elu relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_165 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_644 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_482 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_645 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_483 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_646 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 17s 37ms/step - loss: nan - acc: 0.4904 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 143us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 148us/step\n",
      "Test score: nan\n",
      "Look! softmax elu tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax elu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_166 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_647 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_484 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_648 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_485 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_649 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 37ms/step - loss: 0.7478 - acc: 0.2378 - val_loss: 0.5876 - val_acc: 0.1631\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7230 - acc: 0.1975 - val_loss: 0.5793 - val_acc: 0.1418\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7154 - acc: 0.2293 - val_loss: 0.5721 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.7054 - acc: 0.1762 - val_loss: 0.5650 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7000 - acc: 0.2399 - val_loss: 0.5584 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6898 - acc: 0.2442 - val_loss: 0.5522 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6781 - acc: 0.2463 - val_loss: 0.5465 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6706 - acc: 0.2611 - val_loss: 0.5413 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6824 - acc: 0.2569 - val_loss: 0.5378 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6763 - acc: 0.2611 - val_loss: 0.5389 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6826 - acc: 0.2633 - val_loss: 0.5466 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6949 - acc: 0.2527 - val_loss: 0.5630 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7001 - acc: 0.2590 - val_loss: 0.5556 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6787 - acc: 0.2590 - val_loss: 0.5480 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6762 - acc: 0.2590 - val_loss: 0.5413 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6733 - acc: 0.2590 - val_loss: 0.5355 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6590 - acc: 0.2590 - val_loss: 0.5307 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6538 - acc: 0.2590 - val_loss: 0.5267 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6550 - acc: 0.2590 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6507 - acc: 0.2590 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6524 - acc: 0.2590 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6461 - acc: 0.2590 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6540 - acc: 0.2590 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6361 - acc: 0.2590 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6385 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6430 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6540 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6415 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6403 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6412 - acc: 0.2590 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6570 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6441 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6337 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6363 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6453 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6451 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6336 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6390 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6343 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6398 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6413 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6391 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6376 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6399 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6292 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6340 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: 0.6270 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6291 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6309 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6309 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6374 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6345 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6339 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6404 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6347 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6362 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6329 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6326 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6320 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6338 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6363 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6317 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6398 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6299 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6403 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6358 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6334 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6308 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6293 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6322 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6338 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6292 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6350 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6298 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6338 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6315 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6387 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6307 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6187 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6413 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6347 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.6324 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6324 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: 0.6306 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6343 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6329 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6351 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6325 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6264 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6338 - acc: 0.2590 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6306 - acc: 0.2590 - val_loss: 0.5299 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6636 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6351 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6278 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6383 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6336 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: 0.6261 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6317 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 144us/step\n",
      "Test score: 0.5110395977683101\n",
      "Look! softmax elu sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax elu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_167 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_650 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_486 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_651 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_487 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_652 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: 0.7467 - acc: 0.1911 - val_loss: 0.5988 - val_acc: 0.1348\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7281 - acc: 0.2527 - val_loss: 0.5908 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7208 - acc: 0.2463 - val_loss: 0.5842 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.7198 - acc: 0.2442 - val_loss: 0.5779 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7091 - acc: 0.2548 - val_loss: 0.5720 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7077 - acc: 0.2569 - val_loss: 0.5668 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6997 - acc: 0.2611 - val_loss: 0.5617 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6887 - acc: 0.2527 - val_loss: 0.5568 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6866 - acc: 0.2611 - val_loss: 0.5519 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6783 - acc: 0.2590 - val_loss: 0.5471 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6817 - acc: 0.2548 - val_loss: 0.5430 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6726 - acc: 0.2611 - val_loss: 0.5386 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6750 - acc: 0.2590 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6699 - acc: 0.2633 - val_loss: 0.5317 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6613 - acc: 0.2611 - val_loss: 0.5292 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6715 - acc: 0.2611 - val_loss: 0.5278 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6594 - acc: 0.2611 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6606 - acc: 0.2611 - val_loss: 0.5259 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6395 - acc: 0.2590 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6572 - acc: 0.2590 - val_loss: 0.5308 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6386 - acc: 0.2633 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6663 - acc: 0.2675 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6643 - acc: 0.2633 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6772 - acc: 0.2611 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6364 - acc: 0.2611 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6792 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6475 - acc: 0.2654 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6418 - acc: 0.2675 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6465 - acc: 0.2654 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6415 - acc: 0.2633 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6348 - acc: 0.2675 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6581 - acc: 0.2505 - val_loss: 0.5645 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6930 - acc: 0.1741 - val_loss: 0.5548 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6569 - acc: 0.2378 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6322 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6709 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6517 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6541 - acc: 0.2590 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6303 - acc: 0.2590 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6432 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6302 - acc: 0.2611 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6435 - acc: 0.2590 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6397 - acc: 0.2611 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6334 - acc: 0.2590 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6452 - acc: 0.2590 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6372 - acc: 0.2590 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6576 - acc: 0.2611 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6357 - acc: 0.2569 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6345 - acc: 0.2548 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6674 - acc: 0.2569 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6236 - acc: 0.2569 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6279 - acc: 0.2569 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6218 - acc: 0.2569 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6867 - acc: 0.2569 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6210 - acc: 0.2633 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6228 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6176 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6575 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6228 - acc: 0.2633 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6609 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6566 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6277 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6234 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6262 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6203 - acc: 0.2675 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6311 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6577 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6220 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6278 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6223 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6156 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6335 - acc: 0.2633 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6249 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6269 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6305 - acc: 0.2675 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6282 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6265 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6276 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6287 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6225 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6237 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6234 - acc: 0.2675 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6260 - acc: 0.2633 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6313 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6240 - acc: 0.2654 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6277 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6214 - acc: 0.2633 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6199 - acc: 0.2633 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6196 - acc: 0.2696 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6193 - acc: 0.2675 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6232 - acc: 0.2675 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6305 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6220 - acc: 0.2718 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6113 - acc: 0.2718 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6248 - acc: 0.2675 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6334 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6145 - acc: 0.2718 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6486 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6269 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6256 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6172 - acc: 0.2718 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6141 - acc: 0.2718 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6108 - acc: 0.2718 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6216 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6262 - acc: 0.2633 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6215 - acc: 0.2718 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6313 - acc: 0.2611 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6172 - acc: 0.2675 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6181 - acc: 0.2675 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6228 - acc: 0.2675 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6261 - acc: 0.2654 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6307 - acc: 0.2654 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6244 - acc: 0.2654 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6104 - acc: 0.2760 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6253 - acc: 0.2675 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6183 - acc: 0.2696 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6136 - acc: 0.2718 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6332 - acc: 0.2633 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6150 - acc: 0.2675 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 157us/step\n",
      "Test score: 0.5130586818600378\n",
      "Look! softmax elu hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax elu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_168 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_653 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_488 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_654 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_489 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_655 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: nan - acc: 0.4756 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 142us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 145us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 148us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 133us/step\n",
      "Test score: nan\n",
      "Look! softmax elu linear Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax elu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_169 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_656 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_490 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_657 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_491 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_658 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 17s 37ms/step - loss: 0.7554 - acc: 0.2633 - val_loss: 0.5764 - val_acc: 0.2199\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7113 - acc: 0.2611 - val_loss: 0.5602 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6985 - acc: 0.2654 - val_loss: 0.5442 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6821 - acc: 0.2463 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6805 - acc: 0.2484 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6768 - acc: 0.2505 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6640 - acc: 0.2611 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6610 - acc: 0.2633 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6678 - acc: 0.2654 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6591 - acc: 0.2548 - val_loss: 0.5205 - val_acc: 0.1986\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6534 - acc: 0.2442 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6483 - acc: 0.2484 - val_loss: 0.5127 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6637 - acc: 0.2527 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6452 - acc: 0.2527 - val_loss: 0.5360 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6402 - acc: 0.2611 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6486 - acc: 0.2505 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6509 - acc: 0.2527 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6419 - acc: 0.2463 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6501 - acc: 0.2569 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6366 - acc: 0.2527 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6552 - acc: 0.2548 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6739 - acc: 0.2378 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6531 - acc: 0.2633 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6459 - acc: 0.2548 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6417 - acc: 0.2527 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6492 - acc: 0.2505 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6378 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6431 - acc: 0.2548 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6484 - acc: 0.2442 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6434 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6378 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6428 - acc: 0.2463 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6434 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6420 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6343 - acc: 0.2420 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6316 - acc: 0.2505 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6394 - acc: 0.2442 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6293 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6374 - acc: 0.2463 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6532 - acc: 0.2399 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6395 - acc: 0.2548 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6456 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6283 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6349 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6406 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6404 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6395 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6382 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6318 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6428 - acc: 0.2569 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6491 - acc: 0.2527 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6413 - acc: 0.2569 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6398 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6315 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6380 - acc: 0.2463 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6335 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6441 - acc: 0.2505 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6352 - acc: 0.2548 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6419 - acc: 0.2505 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6397 - acc: 0.2548 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6394 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6367 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6411 - acc: 0.2548 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6314 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6359 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6330 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6408 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6392 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6428 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6295 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6399 - acc: 0.2505 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6392 - acc: 0.2633 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6342 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6338 - acc: 0.2548 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6334 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6218 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6348 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6377 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6392 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6395 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6219 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6287 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6294 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6382 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6330 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6384 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6301 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6300 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6325 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6369 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6352 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6293 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6325 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6345 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6362 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6376 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6270 - acc: 0.2654 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6323 - acc: 0.2633 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6426 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6288 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6365 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6314 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6372 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6402 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6362 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6371 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6363 - acc: 0.2633 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6312 - acc: 0.2633 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6370 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6389 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6283 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6316 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6284 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 134us/step\n",
      "Test score: 0.510975293233885\n",
      "Look! softmax selu softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax elu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_170 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_659 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_492 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_660 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_493 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_661 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 37ms/step - loss: nan - acc: 0.4713 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 145us/step\n",
      "Test score: nan\n",
      "Look! softmax selu elu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax selu elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_171 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_662 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_494 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_663 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_495 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_664 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: nan - acc: 0.4480 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 148us/step\n",
      "Test score: nan\n",
      "Look! softmax selu selu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax selu selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_172 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_665 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_496 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_666 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_497 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_667 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: 0.7466 - acc: 0.2442 - val_loss: 0.5940 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7244 - acc: 0.2590 - val_loss: 0.5742 - val_acc: 0.1844\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7198 - acc: 0.2760 - val_loss: 0.5737 - val_acc: 0.2270\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7103 - acc: 0.2951 - val_loss: 0.5710 - val_acc: 0.2270\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6900 - acc: 0.2781 - val_loss: 0.5393 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6793 - acc: 0.2569 - val_loss: 0.5293 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6536 - acc: 0.2569 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6689 - acc: 0.2569 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6731 - acc: 0.2505 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6542 - acc: 0.2484 - val_loss: 0.4988 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6279 - acc: 0.2739 - val_loss: 0.5022 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6321 - acc: 0.2696 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6315 - acc: 0.2654 - val_loss: 0.4960 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6257 - acc: 0.2718 - val_loss: 0.4884 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6517 - acc: 0.2633 - val_loss: 0.5015 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6505 - acc: 0.2293 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6620 - acc: 0.2335 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6451 - acc: 0.2420 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6438 - acc: 0.2314 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6374 - acc: 0.2527 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6405 - acc: 0.2590 - val_loss: 0.5267 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6406 - acc: 0.2420 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6315 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6450 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6407 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6359 - acc: 0.2569 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6291 - acc: 0.2590 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6323 - acc: 0.2569 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6283 - acc: 0.2548 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6279 - acc: 0.2633 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6265 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6235 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6409 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6272 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6344 - acc: 0.2633 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6267 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6249 - acc: 0.2696 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6207 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6244 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6264 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6212 - acc: 0.2569 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6308 - acc: 0.2633 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6047 - acc: 0.2675 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6143 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6279 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6254 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6280 - acc: 0.2654 - val_loss: 0.5272 - val_acc: 0.1915\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6342 - acc: 0.2548 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6139 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6178 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6219 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6213 - acc: 0.2654 - val_loss: 0.5397 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6289 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6282 - acc: 0.2611 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6297 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6269 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6183 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6324 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6197 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6160 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6255 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6192 - acc: 0.2696 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6212 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6275 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6180 - acc: 0.2654 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6303 - acc: 0.2611 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6207 - acc: 0.2654 - val_loss: 0.5239 - val_acc: 0.1915\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6118 - acc: 0.2675 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6168 - acc: 0.2654 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6276 - acc: 0.2654 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6166 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6055 - acc: 0.2696 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6119 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6187 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6141 - acc: 0.2696 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6194 - acc: 0.2675 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6167 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6238 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6192 - acc: 0.2696 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6129 - acc: 0.2675 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6227 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6163 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6163 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6138 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6184 - acc: 0.2675 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6190 - acc: 0.2654 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6178 - acc: 0.2654 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6135 - acc: 0.2696 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6218 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6036 - acc: 0.2696 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6159 - acc: 0.2654 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6138 - acc: 0.2696 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6095 - acc: 0.2654 - val_loss: 0.5336 - val_acc: 0.1915\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6104 - acc: 0.2696 - val_loss: 0.5237 - val_acc: 0.1986\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6071 - acc: 0.2654 - val_loss: 0.5204 - val_acc: 0.2057\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6259 - acc: 0.2633 - val_loss: 0.5452 - val_acc: 0.1773\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6182 - acc: 0.2633 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6142 - acc: 0.2675 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6180 - acc: 0.2654 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6307 - acc: 0.2633 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6158 - acc: 0.2654 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6242 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6168 - acc: 0.2654 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6200 - acc: 0.2654 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6287 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6244 - acc: 0.2633 - val_loss: 0.5174 - val_acc: 0.2057\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6146 - acc: 0.2654 - val_loss: 0.5212 - val_acc: 0.2057\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6050 - acc: 0.2696 - val_loss: 0.5246 - val_acc: 0.1986\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6159 - acc: 0.2675 - val_loss: 0.5191 - val_acc: 0.2057\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6230 - acc: 0.2654 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6032 - acc: 0.2696 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6032 - acc: 0.2718 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6120 - acc: 0.2696 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6145 - acc: 0.2675 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6139 - acc: 0.2675 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6162 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6118 - acc: 0.2675 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6020 - acc: 0.2696 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 141us/step\n",
      "Test score: 0.5118122734922044\n",
      "Look! softmax selu softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_173 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_668 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_498 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_669 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_499 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_670 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: nan - acc: 0.4650 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 150us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 140us/step\n",
      "Test score: nan\n",
      "Look! softmax selu softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax selu softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_174 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_671 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_500 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_672 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_501 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_673 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: nan - acc: 0.4416 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 171us/step\n",
      "Test score: nan\n",
      "Look! softmax selu relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax selu relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_175 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_674 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_502 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_675 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_503 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_676 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: nan - acc: 0.4671 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 151us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 140us/step\n",
      "Test score: nan\n",
      "Look! softmax selu tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax selu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_176 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_677 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_504 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_678 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_505 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_679 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 39ms/step - loss: 0.7283 - acc: 0.2654 - val_loss: 0.5865 - val_acc: 0.1418\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7192 - acc: 0.2399 - val_loss: 0.5816 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7167 - acc: 0.2187 - val_loss: 0.5701 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7126 - acc: 0.2484 - val_loss: 0.5636 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6909 - acc: 0.2569 - val_loss: 0.5552 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6886 - acc: 0.2527 - val_loss: 0.5482 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6922 - acc: 0.2590 - val_loss: 0.5429 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6767 - acc: 0.2527 - val_loss: 0.5389 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6702 - acc: 0.2484 - val_loss: 0.5327 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6628 - acc: 0.2527 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6618 - acc: 0.2569 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6584 - acc: 0.2611 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6591 - acc: 0.2590 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6452 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6623 - acc: 0.2590 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6337 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6533 - acc: 0.2611 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6567 - acc: 0.2590 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6463 - acc: 0.2590 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6487 - acc: 0.2611 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6252 - acc: 0.2569 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6507 - acc: 0.2611 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6441 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6372 - acc: 0.2590 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6508 - acc: 0.2590 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6519 - acc: 0.2611 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6157 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6406 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6460 - acc: 0.2611 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6222 - acc: 0.2633 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6282 - acc: 0.2611 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6300 - acc: 0.2611 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6260 - acc: 0.2654 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6274 - acc: 0.2675 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6299 - acc: 0.2633 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6288 - acc: 0.2611 - val_loss: 0.5125 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6090 - acc: 0.2696 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6305 - acc: 0.2654 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6197 - acc: 0.2696 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6224 - acc: 0.2696 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6232 - acc: 0.2675 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6125 - acc: 0.2718 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6186 - acc: 0.2675 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6193 - acc: 0.2633 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6256 - acc: 0.2675 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6117 - acc: 0.2696 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6156 - acc: 0.2675 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6215 - acc: 0.2675 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6004 - acc: 0.2739 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6219 - acc: 0.2696 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6212 - acc: 0.2654 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6115 - acc: 0.2675 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6091 - acc: 0.2696 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6082 - acc: 0.2718 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6027 - acc: 0.2718 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6280 - acc: 0.2654 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6286 - acc: 0.2611 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6148 - acc: 0.2675 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6313 - acc: 0.2654 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6206 - acc: 0.2654 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6099 - acc: 0.2696 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6097 - acc: 0.2696 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6156 - acc: 0.2675 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6018 - acc: 0.2718 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6135 - acc: 0.2696 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6066 - acc: 0.2696 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6093 - acc: 0.2654 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6217 - acc: 0.2654 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6042 - acc: 0.2718 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6005 - acc: 0.2718 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6122 - acc: 0.2675 - val_loss: 0.5188 - val_acc: 0.2057\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6052 - acc: 0.2675 - val_loss: 0.5194 - val_acc: 0.2057\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6195 - acc: 0.2633 - val_loss: 0.5196 - val_acc: 0.2057\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6180 - acc: 0.2675 - val_loss: 0.5194 - val_acc: 0.2057\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6123 - acc: 0.2675 - val_loss: 0.5200 - val_acc: 0.2057\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6101 - acc: 0.2675 - val_loss: 0.5205 - val_acc: 0.2057\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6187 - acc: 0.2633 - val_loss: 0.5177 - val_acc: 0.2057\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6209 - acc: 0.2633 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6059 - acc: 0.2718 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6064 - acc: 0.2696 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6309 - acc: 0.2675 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6104 - acc: 0.2675 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6124 - acc: 0.2675 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6068 - acc: 0.2696 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6038 - acc: 0.2739 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6251 - acc: 0.2654 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6171 - acc: 0.2654 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6116 - acc: 0.2696 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6206 - acc: 0.2654 - val_loss: 0.5147 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6106 - acc: 0.2696 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6102 - acc: 0.2675 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6038 - acc: 0.2718 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6050 - acc: 0.2718 - val_loss: 0.5163 - val_acc: 0.2057\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6063 - acc: 0.2696 - val_loss: 0.5168 - val_acc: 0.2057\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6153 - acc: 0.2675 - val_loss: 0.5172 - val_acc: 0.2057\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6233 - acc: 0.2654 - val_loss: 0.5185 - val_acc: 0.2057\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6014 - acc: 0.2696 - val_loss: 0.5192 - val_acc: 0.2057\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6164 - acc: 0.2675 - val_loss: 0.5200 - val_acc: 0.2057\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6058 - acc: 0.2675 - val_loss: 0.5213 - val_acc: 0.2057\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6166 - acc: 0.2654 - val_loss: 0.5226 - val_acc: 0.2057\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6019 - acc: 0.2718 - val_loss: 0.5216 - val_acc: 0.2057\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6207 - acc: 0.2675 - val_loss: 0.5202 - val_acc: 0.2057\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.5914 - acc: 0.2739 - val_loss: 0.5192 - val_acc: 0.2057\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6115 - acc: 0.2675 - val_loss: 0.5186 - val_acc: 0.2057\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6049 - acc: 0.2696 - val_loss: 0.5183 - val_acc: 0.2057\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.5962 - acc: 0.2718 - val_loss: 0.5180 - val_acc: 0.2057\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6150 - acc: 0.2696 - val_loss: 0.5182 - val_acc: 0.2057\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6092 - acc: 0.2675 - val_loss: 0.5183 - val_acc: 0.2057\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6185 - acc: 0.2696 - val_loss: 0.5186 - val_acc: 0.2057\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6080 - acc: 0.2675 - val_loss: 0.5191 - val_acc: 0.2057\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6124 - acc: 0.2675 - val_loss: 0.5197 - val_acc: 0.2057\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6069 - acc: 0.2718 - val_loss: 0.5203 - val_acc: 0.2057\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.5949 - acc: 0.2760 - val_loss: 0.5214 - val_acc: 0.2057\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6162 - acc: 0.2675 - val_loss: 0.5217 - val_acc: 0.2057\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6123 - acc: 0.2654 - val_loss: 0.5209 - val_acc: 0.2057\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6045 - acc: 0.2696 - val_loss: 0.5195 - val_acc: 0.2057\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6086 - acc: 0.2675 - val_loss: 0.5190 - val_acc: 0.2057\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6087 - acc: 0.2675 - val_loss: 0.5185 - val_acc: 0.2057\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6022 - acc: 0.2718 - val_loss: 0.5182 - val_acc: 0.2057\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.5958 - acc: 0.2718 - val_loss: 0.5183 - val_acc: 0.2057\n",
      "141/141 [==============================] - 0s 152us/step\n",
      "Test score: 0.5183356416986343\n",
      "Look! softmax selu sigmoid Test accuracy: 0.20567375992206818\n",
      "max there  0.6241134772909448 softmax selu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_177 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_680 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_506 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_681 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_507 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_682 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: 0.7149 - acc: 0.2654 - val_loss: 0.5758 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7051 - acc: 0.2654 - val_loss: 0.5751 - val_acc: 0.2199\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.7104 - acc: 0.2611 - val_loss: 0.5685 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7072 - acc: 0.2484 - val_loss: 0.5594 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6950 - acc: 0.2654 - val_loss: 0.5513 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6813 - acc: 0.2633 - val_loss: 0.5474 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6718 - acc: 0.2675 - val_loss: 0.5430 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6847 - acc: 0.2611 - val_loss: 0.5377 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6624 - acc: 0.2611 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6718 - acc: 0.2611 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6917 - acc: 0.2569 - val_loss: 0.5197 - val_acc: 0.2695\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6647 - acc: 0.2675 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6747 - acc: 0.2633 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6555 - acc: 0.2633 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6504 - acc: 0.2654 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6624 - acc: 0.2611 - val_loss: 0.5036 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6459 - acc: 0.2611 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6538 - acc: 0.2378 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6477 - acc: 0.2803 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6649 - acc: 0.2696 - val_loss: 0.4981 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6680 - acc: 0.2611 - val_loss: 0.4975 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6684 - acc: 0.2718 - val_loss: 0.4972 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6391 - acc: 0.2675 - val_loss: 0.4925 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6402 - acc: 0.2718 - val_loss: 0.4920 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6171 - acc: 0.2760 - val_loss: 0.4872 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6390 - acc: 0.2569 - val_loss: 0.4864 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6304 - acc: 0.2824 - val_loss: 0.4867 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6351 - acc: 0.2718 - val_loss: 0.4887 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6147 - acc: 0.2781 - val_loss: 0.4846 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6143 - acc: 0.2972 - val_loss: 0.4912 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6232 - acc: 0.2739 - val_loss: 0.4815 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6181 - acc: 0.2739 - val_loss: 0.4883 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6380 - acc: 0.2824 - val_loss: 0.4840 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6352 - acc: 0.2696 - val_loss: 0.5415 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6651 - acc: 0.2187 - val_loss: 0.4740 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6366 - acc: 0.2824 - val_loss: 0.4790 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6463 - acc: 0.2718 - val_loss: 0.4682 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6581 - acc: 0.2824 - val_loss: 0.4986 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6807 - acc: 0.2166 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6823 - acc: 0.2187 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6736 - acc: 0.2208 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6507 - acc: 0.2335 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6772 - acc: 0.2293 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6660 - acc: 0.2484 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6452 - acc: 0.2505 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6468 - acc: 0.2548 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6408 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6358 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6507 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6342 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6367 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6358 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6384 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6297 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6340 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6365 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6334 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6258 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6309 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6367 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6323 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6467 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6311 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6637 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6371 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6295 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6365 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6320 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6331 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6361 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6320 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6367 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6264 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6367 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6363 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6374 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6261 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6390 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6286 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6374 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6359 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6362 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6300 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6442 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 0.6278 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6302 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6337 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6373 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6371 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6415 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6340 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6386 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6329 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6271 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6306 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6388 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6370 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6339 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6313 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6358 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6380 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 140us/step\n",
      "Test score: 0.5112129060934621\n",
      "Look! softmax selu hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_178 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_683 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_508 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_684 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_509 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_685 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 38ms/step - loss: nan - acc: 0.4798 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 152us/step\n",
      "Test score: nan\n",
      "Look! softmax selu linear Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_179 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_686 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_510 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_687 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_511 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_688 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 18s 39ms/step - loss: 1.2395 - acc: 0.3227 - val_loss: 0.7241 - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.9726 - acc: 0.2994 - val_loss: 0.6206 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.8840 - acc: 0.2654 - val_loss: 0.5555 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.8327 - acc: 0.2314 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7743 - acc: 0.2633 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.8268 - acc: 0.2208 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7590 - acc: 0.2569 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7537 - acc: 0.2590 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7639 - acc: 0.2420 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.8219 - acc: 0.2272 - val_loss: 0.5267 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7411 - acc: 0.2442 - val_loss: 0.5240 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7339 - acc: 0.2739 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7787 - acc: 0.2251 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7925 - acc: 0.2335 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7114 - acc: 0.2718 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7519 - acc: 0.2548 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7645 - acc: 0.2484 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7242 - acc: 0.2611 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7272 - acc: 0.2548 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7310 - acc: 0.2378 - val_loss: 0.5078 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7133 - acc: 0.2548 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7313 - acc: 0.2739 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7078 - acc: 0.2633 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.7643 - acc: 0.2335 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7483 - acc: 0.2569 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7890 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7700 - acc: 0.2335 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7369 - acc: 0.2696 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7467 - acc: 0.2293 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7383 - acc: 0.2399 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7610 - acc: 0.2251 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7142 - acc: 0.2527 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7140 - acc: 0.2654 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7693 - acc: 0.2484 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7224 - acc: 0.2378 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7366 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7196 - acc: 0.2633 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7410 - acc: 0.2548 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7464 - acc: 0.2463 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7229 - acc: 0.2357 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7213 - acc: 0.2399 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7032 - acc: 0.2527 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7464 - acc: 0.2081 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7084 - acc: 0.2569 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7409 - acc: 0.2378 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7375 - acc: 0.2505 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7119 - acc: 0.2803 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6973 - acc: 0.2760 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7397 - acc: 0.2272 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7091 - acc: 0.2463 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7079 - acc: 0.2335 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6892 - acc: 0.2548 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6856 - acc: 0.2718 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6553 - acc: 0.2505 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6914 - acc: 0.2378 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7057 - acc: 0.2696 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7104 - acc: 0.2272 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.7118 - acc: 0.2484 - val_loss: 0.5147 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6928 - acc: 0.2420 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7060 - acc: 0.2484 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.7055 - acc: 0.2314 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7137 - acc: 0.2803 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7122 - acc: 0.2463 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7198 - acc: 0.2229 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6864 - acc: 0.2484 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7142 - acc: 0.2229 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7203 - acc: 0.2251 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7081 - acc: 0.2548 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6828 - acc: 0.2399 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6919 - acc: 0.2420 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7070 - acc: 0.2357 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6863 - acc: 0.2378 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6755 - acc: 0.2654 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6974 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7154 - acc: 0.2442 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6922 - acc: 0.2442 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.7080 - acc: 0.2399 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6783 - acc: 0.2463 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6908 - acc: 0.2633 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6766 - acc: 0.2611 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7001 - acc: 0.2548 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6423 - acc: 0.2739 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6749 - acc: 0.2463 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6928 - acc: 0.2293 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6904 - acc: 0.2420 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6774 - acc: 0.2251 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6721 - acc: 0.2718 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6637 - acc: 0.2463 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6656 - acc: 0.2548 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6743 - acc: 0.2548 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6610 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6923 - acc: 0.2420 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6680 - acc: 0.2569 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6818 - acc: 0.2399 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6735 - acc: 0.2378 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6737 - acc: 0.2527 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6570 - acc: 0.2442 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6778 - acc: 0.2548 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6515 - acc: 0.2399 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6803 - acc: 0.2569 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6629 - acc: 0.2569 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6702 - acc: 0.2675 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6738 - acc: 0.2654 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6816 - acc: 0.2335 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6828 - acc: 0.2357 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6888 - acc: 0.2229 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6739 - acc: 0.2357 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6536 - acc: 0.2527 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6520 - acc: 0.2505 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6767 - acc: 0.2272 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6883 - acc: 0.2463 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6679 - acc: 0.2399 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6495 - acc: 0.2442 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6498 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6621 - acc: 0.2378 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6640 - acc: 0.2505 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6583 - acc: 0.2463 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6544 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6615 - acc: 0.2548 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6623 - acc: 0.2484 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 137us/step\n",
      "Test score: 0.5116864079279257\n",
      "Look! softmax softplus softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_180 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_689 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_512 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_690 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_513 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_691 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 19s 40ms/step - loss: 2.9394 - acc: 0.1953 - val_loss: 0.6394 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 2.6058 - acc: 0.2102 - val_loss: 0.8785 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 3.1121 - acc: 0.2017 - val_loss: 0.7091 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 3.9804 - acc: 0.2123 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 3.4284 - acc: 0.1401 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 3.4837 - acc: 0.1677 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 4.4115 - acc: 0.1868 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 3.8061 - acc: 0.1677 - val_loss: 4.6996 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 3.4104 - acc: 0.1890 - val_loss: 1.6078 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 3.8151 - acc: 0.2229 - val_loss: 0.7295 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.2111 - acc: 0.1826 - val_loss: 0.5959 - val_acc: 0.0355\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.8643 - acc: 0.2059 - val_loss: 0.5476 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 2.5056 - acc: 0.2357 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 2.8792 - acc: 0.2484 - val_loss: 0.5329 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 2.3002 - acc: 0.2781 - val_loss: 0.9787 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.6892 - acc: 0.2760 - val_loss: 0.9612 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.0378 - acc: 0.3036 - val_loss: 0.9480 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.6778 - acc: 0.2887 - val_loss: 0.9376 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.5957 - acc: 0.2739 - val_loss: 0.9296 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.5688 - acc: 0.3270 - val_loss: 0.9214 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.6988 - acc: 0.2951 - val_loss: 0.9143 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.6175 - acc: 0.2930 - val_loss: 0.9074 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.6332 - acc: 0.2463 - val_loss: 0.9019 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.2446 - acc: 0.2930 - val_loss: 0.8976 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.4656 - acc: 0.2484 - val_loss: 0.8971 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.4078 - acc: 0.2463 - val_loss: 0.9010 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.4194 - acc: 0.2866 - val_loss: 0.9061 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.4149 - acc: 0.2548 - val_loss: 0.9095 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.2866 - acc: 0.2781 - val_loss: 0.9149 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.2068 - acc: 0.2590 - val_loss: 0.9188 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.3295 - acc: 0.2463 - val_loss: 0.9212 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.2271 - acc: 0.2845 - val_loss: 0.9227 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.1312 - acc: 0.2654 - val_loss: 0.9239 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.3470 - acc: 0.2654 - val_loss: 0.9252 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.2336 - acc: 0.2781 - val_loss: 0.9259 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.1743 - acc: 0.2866 - val_loss: 0.9261 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.1653 - acc: 0.2484 - val_loss: 0.9258 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.2072 - acc: 0.2803 - val_loss: 0.9255 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.3248 - acc: 0.2611 - val_loss: 0.9247 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.2274 - acc: 0.2718 - val_loss: 0.9246 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.1099 - acc: 0.2633 - val_loss: 0.9246 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.2366 - acc: 0.2696 - val_loss: 0.9249 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.2448 - acc: 0.2272 - val_loss: 0.9248 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.2163 - acc: 0.2696 - val_loss: 0.9254 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.2322 - acc: 0.2739 - val_loss: 0.9251 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.0163 - acc: 0.2611 - val_loss: 0.9246 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.1883 - acc: 0.2569 - val_loss: 0.9239 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.1880 - acc: 0.2654 - val_loss: 0.9244 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.1784 - acc: 0.2718 - val_loss: 0.9268 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.0668 - acc: 0.2484 - val_loss: 0.9281 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.2091 - acc: 0.2420 - val_loss: 0.9288 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.1979 - acc: 0.2548 - val_loss: 0.9285 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.2377 - acc: 0.2654 - val_loss: 0.9286 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.1991 - acc: 0.2718 - val_loss: 0.9285 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.3302 - acc: 0.2463 - val_loss: 0.9278 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.0852 - acc: 0.2590 - val_loss: 0.9275 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.2220 - acc: 0.2335 - val_loss: 0.9268 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.3043 - acc: 0.2803 - val_loss: 0.9260 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.1726 - acc: 0.2548 - val_loss: 0.9252 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.0642 - acc: 0.2760 - val_loss: 0.9246 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.2264 - acc: 0.2399 - val_loss: 0.9243 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.3203 - acc: 0.2378 - val_loss: 0.9242 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.1725 - acc: 0.2378 - val_loss: 0.9243 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.0661 - acc: 0.2442 - val_loss: 0.9242 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.2182 - acc: 0.2442 - val_loss: 0.9241 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.2580 - acc: 0.2505 - val_loss: 0.9238 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.2173 - acc: 0.2548 - val_loss: 0.9233 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.2048 - acc: 0.2420 - val_loss: 0.9228 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.2148 - acc: 0.2718 - val_loss: 0.9225 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.9890 - acc: 0.2463 - val_loss: 0.9227 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.0918 - acc: 0.2484 - val_loss: 0.9235 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.3004 - acc: 0.2633 - val_loss: 0.9243 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.2565 - acc: 0.2378 - val_loss: 0.9244 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.2289 - acc: 0.2633 - val_loss: 0.9244 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.1896 - acc: 0.3163 - val_loss: 0.9255 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.2364 - acc: 0.2569 - val_loss: 0.9264 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.1467 - acc: 0.2718 - val_loss: 0.9273 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.1189 - acc: 0.2484 - val_loss: 0.9280 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.2055 - acc: 0.2335 - val_loss: 0.9282 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.0610 - acc: 0.2739 - val_loss: 0.9284 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.2642 - acc: 0.2420 - val_loss: 0.9280 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.1581 - acc: 0.2803 - val_loss: 0.9277 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.1342 - acc: 0.2675 - val_loss: 0.9271 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.1854 - acc: 0.2378 - val_loss: 0.9264 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.0865 - acc: 0.2442 - val_loss: 0.9260 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.1612 - acc: 0.2548 - val_loss: 0.9257 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.1245 - acc: 0.2611 - val_loss: 0.9266 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.1446 - acc: 0.2314 - val_loss: 0.9277 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.1091 - acc: 0.2611 - val_loss: 0.9288 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.2517 - acc: 0.2505 - val_loss: 0.9297 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.2684 - acc: 0.2633 - val_loss: 0.9302 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.1322 - acc: 0.2463 - val_loss: 0.9300 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.2311 - acc: 0.2718 - val_loss: 0.9294 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.0178 - acc: 0.2357 - val_loss: 0.9288 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.1545 - acc: 0.2718 - val_loss: 0.9286 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.0136 - acc: 0.2739 - val_loss: 0.9306 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.1379 - acc: 0.2633 - val_loss: 0.9330 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.0332 - acc: 0.2654 - val_loss: 0.9357 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.1336 - acc: 0.2675 - val_loss: 0.9380 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.0886 - acc: 0.2590 - val_loss: 0.9465 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.0339 - acc: 0.2590 - val_loss: 0.9578 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.9171 - acc: 0.2229 - val_loss: 0.5320 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.8414 - acc: 0.2527 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6959 - acc: 0.2972 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.8002 - acc: 0.2505 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.8822 - acc: 0.2548 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7780 - acc: 0.2420 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.8328 - acc: 0.2590 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.8417 - acc: 0.2527 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7942 - acc: 0.2590 - val_loss: 0.5249 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7172 - acc: 0.2357 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.7450 - acc: 0.2484 - val_loss: 0.5283 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6800 - acc: 0.2590 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7858 - acc: 0.2527 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6956 - acc: 0.2357 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6642 - acc: 0.2718 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.8359 - acc: 0.2357 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.7999 - acc: 0.2335 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7991 - acc: 0.2569 - val_loss: 0.5294 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7273 - acc: 0.2314 - val_loss: 0.5297 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 145us/step\n",
      "Test score: 0.5296546220779419\n",
      "Look! softmax softplus elu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_181 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_692 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_514 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_693 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_515 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_694 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 19s 40ms/step - loss: 3.0972 - acc: 0.1953 - val_loss: 1.7904 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 2.7328 - acc: 0.1953 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 3.2245 - acc: 0.2229 - val_loss: 1.6004 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 3.0743 - acc: 0.2251 - val_loss: 5.5039 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 3.1463 - acc: 0.2484 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.6371 - acc: 0.2824 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.0681 - acc: 0.3503 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 3.7759 - acc: 0.3185 - val_loss: 6.4015 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.1612 - acc: 0.3036 - val_loss: 6.4015 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 3.2408 - acc: 0.3248 - val_loss: 6.4015 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.8003 - acc: 0.3100 - val_loss: 6.4015 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.9805 - acc: 0.3291 - val_loss: 3.8099 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 2.9543 - acc: 0.3079 - val_loss: 3.2394 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.0989 - acc: 0.3376 - val_loss: 3.1993 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.7651 - acc: 0.3397 - val_loss: 3.2105 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.9707 - acc: 0.2951 - val_loss: 1.5834 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 3.1861 - acc: 0.3524 - val_loss: 1.4369 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 3.0300 - acc: 0.3312 - val_loss: 1.3910 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.1994 - acc: 0.3503 - val_loss: 1.3590 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 2.8339 - acc: 0.3206 - val_loss: 1.3388 - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.1148 - acc: 0.3376 - val_loss: 1.3248 - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 2.9691 - acc: 0.3588 - val_loss: 1.3372 - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.5985 - acc: 0.3567 - val_loss: 1.3500 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.5196 - acc: 0.3885 - val_loss: 1.3582 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.6306 - acc: 0.3631 - val_loss: 1.3479 - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 2.5443 - acc: 0.3779 - val_loss: 1.3421 - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 3.0175 - acc: 0.3864 - val_loss: 1.3211 - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 3.1618 - acc: 0.3673 - val_loss: 1.3053 - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.3410 - acc: 0.3270 - val_loss: 1.2917 - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.9349 - acc: 0.3588 - val_loss: 1.2798 - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.6079 - acc: 0.3694 - val_loss: 1.2720 - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.4700 - acc: 0.3694 - val_loss: 1.2709 - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.4809 - acc: 0.3461 - val_loss: 1.2660 - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 2.7845 - acc: 0.3503 - val_loss: 1.2606 - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 2.2753 - acc: 0.3673 - val_loss: 1.2520 - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 2.2155 - acc: 0.3949 - val_loss: 1.2428 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 2.4732 - acc: 0.3779 - val_loss: 1.2334 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.5579 - acc: 0.3885 - val_loss: 1.2172 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.2107 - acc: 0.3588 - val_loss: 1.2051 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 2.0896 - acc: 0.3992 - val_loss: 1.1975 - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.4613 - acc: 0.3376 - val_loss: 1.2084 - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.9770 - acc: 0.3970 - val_loss: 1.2105 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 2.4563 - acc: 0.4013 - val_loss: 1.2086 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 2.1698 - acc: 0.3779 - val_loss: 1.2223 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.2839 - acc: 0.4013 - val_loss: 1.2419 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 2.1968 - acc: 0.3694 - val_loss: 1.2587 - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 2.2173 - acc: 0.3609 - val_loss: 1.2674 - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.7221 - acc: 0.3864 - val_loss: 1.2705 - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.8191 - acc: 0.3546 - val_loss: 1.2709 - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.8579 - acc: 0.3652 - val_loss: 1.2725 - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 2.0906 - acc: 0.3885 - val_loss: 1.2705 - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.8205 - acc: 0.3673 - val_loss: 1.2752 - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 2.1162 - acc: 0.3397 - val_loss: 1.2749 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.9040 - acc: 0.3567 - val_loss: 1.2730 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 2.0575 - acc: 0.3631 - val_loss: 1.2689 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.6560 - acc: 0.3291 - val_loss: 1.2631 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.1157 - acc: 0.3822 - val_loss: 1.2567 - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.7885 - acc: 0.3482 - val_loss: 1.2566 - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.8861 - acc: 0.3673 - val_loss: 1.2609 - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.6143 - acc: 0.3397 - val_loss: 0.5693 - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.5851 - acc: 0.2845 - val_loss: 0.5355 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.7584 - acc: 0.3079 - val_loss: 0.5401 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.6778 - acc: 0.2505 - val_loss: 0.5439 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.4131 - acc: 0.2611 - val_loss: 0.5445 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.6119 - acc: 0.2696 - val_loss: 0.5466 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.3315 - acc: 0.2251 - val_loss: 0.5478 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.2955 - acc: 0.2017 - val_loss: 0.5510 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.2917 - acc: 0.2038 - val_loss: 0.5533 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.2677 - acc: 0.1932 - val_loss: 0.5544 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.4074 - acc: 0.2038 - val_loss: 0.5549 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.2004 - acc: 0.1741 - val_loss: 0.5552 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.2782 - acc: 0.1741 - val_loss: 0.5551 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.5514 - acc: 0.1401 - val_loss: 0.5547 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.2873 - acc: 0.1592 - val_loss: 0.5546 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.9834 - acc: 0.1295 - val_loss: 0.5548 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.1278 - acc: 0.1720 - val_loss: 0.5559 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.3887 - acc: 0.1571 - val_loss: 0.5585 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.3100 - acc: 0.1338 - val_loss: 0.5622 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.1263 - acc: 0.1295 - val_loss: 0.5680 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.1666 - acc: 0.1231 - val_loss: 0.5794 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.1978 - acc: 0.1359 - val_loss: 0.6162 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.2106 - acc: 0.1359 - val_loss: 1.0010 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.3415 - acc: 0.1423 - val_loss: 0.9968 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.0767 - acc: 0.1168 - val_loss: 0.9931 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.3119 - acc: 0.1316 - val_loss: 0.9954 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.2061 - acc: 0.1125 - val_loss: 0.9970 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.3288 - acc: 0.1295 - val_loss: 0.9966 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.0498 - acc: 0.1295 - val_loss: 0.9960 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.2104 - acc: 0.1210 - val_loss: 0.9943 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.0544 - acc: 0.1168 - val_loss: 0.9915 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.1813 - acc: 0.1444 - val_loss: 0.9890 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.2474 - acc: 0.1104 - val_loss: 0.9851 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.4072 - acc: 0.1210 - val_loss: 0.9796 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.3869 - acc: 0.1168 - val_loss: 0.9742 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.3319 - acc: 0.1231 - val_loss: 0.9692 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.2877 - acc: 0.0998 - val_loss: 0.9642 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.0913 - acc: 0.1253 - val_loss: 0.9587 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.3408 - acc: 0.0892 - val_loss: 0.9531 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.2279 - acc: 0.1104 - val_loss: 0.9517 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.4168 - acc: 0.0977 - val_loss: 0.9506 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.3834 - acc: 0.0955 - val_loss: 0.9480 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.2256 - acc: 0.0807 - val_loss: 0.9437 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.1429 - acc: 0.0658 - val_loss: 0.9514 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.1578 - acc: 0.0637 - val_loss: 0.9324 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.0631 - acc: 0.0594 - val_loss: 0.9266 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.3590 - acc: 0.0722 - val_loss: 0.9214 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.0541 - acc: 0.0701 - val_loss: 0.9154 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.0468 - acc: 0.0658 - val_loss: 0.9095 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.2488 - acc: 0.0594 - val_loss: 0.9025 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.0638 - acc: 0.0679 - val_loss: 0.8952 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.2320 - acc: 0.0658 - val_loss: 0.8873 - val_acc: 0.0355\n",
      "Epoch 112/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 158us/step - loss: 1.2786 - acc: 0.0573 - val_loss: 0.8781 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.2830 - acc: 0.0531 - val_loss: 0.8680 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.2920 - acc: 0.0594 - val_loss: 0.8573 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.3595 - acc: 0.0488 - val_loss: 0.8456 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.4869 - acc: 0.0467 - val_loss: 0.8330 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.1948 - acc: 0.0573 - val_loss: 0.8198 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.1606 - acc: 0.0467 - val_loss: 0.8097 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.4470 - acc: 0.0467 - val_loss: 0.7992 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.5045 - acc: 0.0510 - val_loss: 0.7875 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 136us/step\n",
      "Test score: 0.7874537435829216\n",
      "Look! softmax softplus selu Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_182 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_695 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_516 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_696 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_517 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_697 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 19s 40ms/step - loss: 0.8564 - acc: 0.3907 - val_loss: 0.6038 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7728 - acc: 0.3270 - val_loss: 0.5558 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7270 - acc: 0.2611 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6904 - acc: 0.2654 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6801 - acc: 0.2569 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7019 - acc: 0.2378 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6742 - acc: 0.2484 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6855 - acc: 0.2548 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6950 - acc: 0.2314 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6697 - acc: 0.2420 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6816 - acc: 0.2505 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6562 - acc: 0.2569 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6642 - acc: 0.2442 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6548 - acc: 0.2484 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6718 - acc: 0.2484 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6547 - acc: 0.2442 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6678 - acc: 0.2420 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6461 - acc: 0.2484 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6513 - acc: 0.2505 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6745 - acc: 0.2357 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6574 - acc: 0.2442 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6693 - acc: 0.2420 - val_loss: 0.5106 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6675 - acc: 0.2399 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6748 - acc: 0.2378 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6778 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6508 - acc: 0.2378 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6584 - acc: 0.2484 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6550 - acc: 0.2505 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6419 - acc: 0.2548 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6627 - acc: 0.2335 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 149us/step - loss: 0.6660 - acc: 0.2335 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6622 - acc: 0.2484 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 147us/step - loss: 0.6567 - acc: 0.2505 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6702 - acc: 0.2420 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6655 - acc: 0.2569 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6470 - acc: 0.2505 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6473 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6446 - acc: 0.2442 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6563 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6662 - acc: 0.2463 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6560 - acc: 0.2378 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 42/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 166us/step - loss: 0.6472 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6494 - acc: 0.2569 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6646 - acc: 0.2420 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6621 - acc: 0.2442 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6485 - acc: 0.2569 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6553 - acc: 0.2378 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6515 - acc: 0.2420 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6454 - acc: 0.2399 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6484 - acc: 0.2420 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6491 - acc: 0.2335 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6474 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6349 - acc: 0.2527 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6488 - acc: 0.2527 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6417 - acc: 0.2505 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6450 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6561 - acc: 0.2420 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6407 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6571 - acc: 0.2654 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6470 - acc: 0.2548 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6487 - acc: 0.2569 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6321 - acc: 0.2484 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6445 - acc: 0.2505 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6493 - acc: 0.2548 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6519 - acc: 0.2527 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6359 - acc: 0.2505 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6384 - acc: 0.2527 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6428 - acc: 0.2505 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6384 - acc: 0.2548 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6428 - acc: 0.2548 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6343 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6508 - acc: 0.2548 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6485 - acc: 0.2548 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6327 - acc: 0.2633 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6417 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6438 - acc: 0.2420 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6356 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6309 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6377 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6335 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6397 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6313 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6426 - acc: 0.2548 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6446 - acc: 0.2548 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6352 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6391 - acc: 0.2611 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6364 - acc: 0.2548 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6395 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6426 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6413 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6220 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6309 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6559 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6332 - acc: 0.2527 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6338 - acc: 0.2527 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6304 - acc: 0.2548 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6483 - acc: 0.2633 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6380 - acc: 0.2548 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6468 - acc: 0.2611 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6491 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6483 - acc: 0.2569 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6452 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6392 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6387 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6449 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6271 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6241 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6364 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6544 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6382 - acc: 0.2654 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6406 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6385 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6445 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6340 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6383 - acc: 0.2654 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6311 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6361 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 134us/step\n",
      "Test score: 0.5110505853138917\n",
      "Look! softmax softplus softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_183 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_698 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_518 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_699 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_519 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_700 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 19s 41ms/step - loss: 3.5596 - acc: 0.3694 - val_loss: 4.3535 - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.9331 - acc: 0.3928 - val_loss: 1.0636 - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 3.0580 - acc: 0.4013 - val_loss: 0.9926 - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 3.0534 - acc: 0.3907 - val_loss: 1.4861 - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 2.9864 - acc: 0.3885 - val_loss: 5.4870 - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 3.6463 - acc: 0.4161 - val_loss: 5.4891 - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.6496 - acc: 0.4076 - val_loss: 5.5071 - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.0887 - acc: 0.4268 - val_loss: 2.5418 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.0843 - acc: 0.3652 - val_loss: 2.4233 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 3.7275 - acc: 0.3715 - val_loss: 2.3786 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.3226 - acc: 0.3461 - val_loss: 2.3617 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.7126 - acc: 0.3907 - val_loss: 2.3627 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 3.0185 - acc: 0.4268 - val_loss: 2.3654 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.7692 - acc: 0.4098 - val_loss: 0.7839 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.6244 - acc: 0.3503 - val_loss: 0.7027 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.1525 - acc: 0.3992 - val_loss: 0.6493 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 2.1328 - acc: 0.3418 - val_loss: 0.6195 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.3365 - acc: 0.3609 - val_loss: 0.6084 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.1854 - acc: 0.3461 - val_loss: 1.0347 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.1913 - acc: 0.3439 - val_loss: 1.0173 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.2648 - acc: 0.3439 - val_loss: 0.9946 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.9099 - acc: 0.3355 - val_loss: 0.9816 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.9275 - acc: 0.3503 - val_loss: 0.9627 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.3874 - acc: 0.3694 - val_loss: 0.9519 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.8726 - acc: 0.3312 - val_loss: 0.9339 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.7632 - acc: 0.3163 - val_loss: 0.9392 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.8927 - acc: 0.3206 - val_loss: 0.9222 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.7814 - acc: 0.3015 - val_loss: 0.8898 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.8129 - acc: 0.2696 - val_loss: 0.8747 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.9947 - acc: 0.3100 - val_loss: 0.8583 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.7693 - acc: 0.2442 - val_loss: 0.8407 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.7618 - acc: 0.2569 - val_loss: 0.8259 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.9975 - acc: 0.2930 - val_loss: 0.8168 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.7240 - acc: 0.2781 - val_loss: 0.8077 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.6683 - acc: 0.2696 - val_loss: 0.7965 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.7397 - acc: 0.2845 - val_loss: 0.7894 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.9941 - acc: 0.2399 - val_loss: 0.7807 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.8526 - acc: 0.2654 - val_loss: 0.7726 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.7471 - acc: 0.2994 - val_loss: 0.7733 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.6368 - acc: 0.2803 - val_loss: 0.7713 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.7820 - acc: 0.2527 - val_loss: 0.7697 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.6359 - acc: 0.2824 - val_loss: 0.7696 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.5862 - acc: 0.3057 - val_loss: 0.7683 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.6871 - acc: 0.2930 - val_loss: 0.7794 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.9849 - acc: 0.3057 - val_loss: 0.7870 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.6946 - acc: 0.2718 - val_loss: 0.7900 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.3966 - acc: 0.2824 - val_loss: 0.7898 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.5357 - acc: 0.3057 - val_loss: 0.7898 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.5770 - acc: 0.2781 - val_loss: 0.7938 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.8330 - acc: 0.2781 - val_loss: 0.7936 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.5084 - acc: 0.3036 - val_loss: 0.7995 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.5394 - acc: 0.2675 - val_loss: 0.8051 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.5996 - acc: 0.2845 - val_loss: 0.8075 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.2472 - acc: 0.2442 - val_loss: 0.8104 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.3892 - acc: 0.2951 - val_loss: 0.8112 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.3284 - acc: 0.2781 - val_loss: 0.8103 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.2754 - acc: 0.2930 - val_loss: 0.8085 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.3419 - acc: 0.2569 - val_loss: 0.8063 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.1986 - acc: 0.2972 - val_loss: 0.8040 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.1617 - acc: 0.2696 - val_loss: 0.8020 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.1786 - acc: 0.2633 - val_loss: 0.8000 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.3207 - acc: 0.2781 - val_loss: 0.7988 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.4442 - acc: 0.2930 - val_loss: 0.7978 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.2622 - acc: 0.2930 - val_loss: 0.7961 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.3366 - acc: 0.2845 - val_loss: 0.7955 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.0785 - acc: 0.2527 - val_loss: 0.7945 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.3650 - acc: 0.2484 - val_loss: 0.7929 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.2579 - acc: 0.2951 - val_loss: 0.7913 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.1850 - acc: 0.2505 - val_loss: 0.7891 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.1043 - acc: 0.2442 - val_loss: 0.7869 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.1745 - acc: 0.2463 - val_loss: 0.7844 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.0765 - acc: 0.2399 - val_loss: 0.7819 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.1804 - acc: 0.2569 - val_loss: 0.7794 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.2537 - acc: 0.2505 - val_loss: 0.7778 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.2750 - acc: 0.2229 - val_loss: 0.7760 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.3296 - acc: 0.2357 - val_loss: 0.7742 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.1733 - acc: 0.2357 - val_loss: 0.7758 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.2169 - acc: 0.2420 - val_loss: 0.7762 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.2738 - acc: 0.2548 - val_loss: 0.7757 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.1862 - acc: 0.2442 - val_loss: 0.7749 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.1069 - acc: 0.2442 - val_loss: 0.7740 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.2364 - acc: 0.2569 - val_loss: 0.7733 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.1690 - acc: 0.2654 - val_loss: 0.7728 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.3112 - acc: 0.2824 - val_loss: 0.7724 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.0661 - acc: 0.2696 - val_loss: 0.7727 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.1394 - acc: 0.2378 - val_loss: 0.7731 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.1568 - acc: 0.2654 - val_loss: 0.7736 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.3076 - acc: 0.2590 - val_loss: 0.7736 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.0502 - acc: 0.2718 - val_loss: 0.7731 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.1961 - acc: 0.2527 - val_loss: 0.7723 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.1349 - acc: 0.2760 - val_loss: 0.7713 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.0359 - acc: 0.2463 - val_loss: 0.7700 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.1760 - acc: 0.2696 - val_loss: 0.7684 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.0975 - acc: 0.2760 - val_loss: 0.7668 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.0325 - acc: 0.2251 - val_loss: 0.7650 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.1009 - acc: 0.2442 - val_loss: 0.7641 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.1601 - acc: 0.2548 - val_loss: 0.7629 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.1570 - acc: 0.2527 - val_loss: 0.7614 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.2494 - acc: 0.2675 - val_loss: 0.7597 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.1255 - acc: 0.2442 - val_loss: 0.7582 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.2086 - acc: 0.2696 - val_loss: 0.7614 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.2993 - acc: 0.2739 - val_loss: 0.7632 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.0947 - acc: 0.2527 - val_loss: 0.7640 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.1161 - acc: 0.2696 - val_loss: 0.7639 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.0710 - acc: 0.2569 - val_loss: 0.7636 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.0414 - acc: 0.2803 - val_loss: 0.7630 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.0928 - acc: 0.2696 - val_loss: 0.7620 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.2277 - acc: 0.2420 - val_loss: 0.7613 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.1574 - acc: 0.2272 - val_loss: 0.7602 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.2655 - acc: 0.2548 - val_loss: 0.7590 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.2254 - acc: 0.2548 - val_loss: 0.7584 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.2271 - acc: 0.2420 - val_loss: 0.7580 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.1582 - acc: 0.2633 - val_loss: 0.7574 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.1751 - acc: 0.2654 - val_loss: 0.7580 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.3277 - acc: 0.2335 - val_loss: 0.7584 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.1230 - acc: 0.2527 - val_loss: 0.7585 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.1833 - acc: 0.2527 - val_loss: 0.7579 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.1458 - acc: 0.2590 - val_loss: 0.7568 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.2275 - acc: 0.2611 - val_loss: 0.7557 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.1279 - acc: 0.2357 - val_loss: 0.7543 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 148us/step\n",
      "Test score: 0.7542730096384143\n",
      "Look! softmax softplus softsign Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_184 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_701 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_520 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_702 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_521 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_703 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 19s 40ms/step - loss: 3.4335 - acc: 0.2251 - val_loss: 3.0824 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 3.2678 - acc: 0.2505 - val_loss: 3.0769 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.2131 - acc: 0.2548 - val_loss: 3.0751 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.6416 - acc: 0.2590 - val_loss: 3.0761 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.7830 - acc: 0.2527 - val_loss: 3.0752 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.3513 - acc: 0.2569 - val_loss: 0.7540 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 2.1785 - acc: 0.2505 - val_loss: 0.6284 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.7944 - acc: 0.2611 - val_loss: 0.5798 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.5900 - acc: 0.2654 - val_loss: 0.5572 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.4171 - acc: 0.2505 - val_loss: 0.5451 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.1852 - acc: 0.2760 - val_loss: 0.5382 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.0710 - acc: 0.2548 - val_loss: 0.5308 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.9221 - acc: 0.2548 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.8864 - acc: 0.2675 - val_loss: 0.5271 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.0569 - acc: 0.2420 - val_loss: 0.5255 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.0814 - acc: 0.2590 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.8417 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.8030 - acc: 0.2527 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7266 - acc: 0.2505 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.8381 - acc: 0.2739 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.8036 - acc: 0.2611 - val_loss: 0.5184 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7487 - acc: 0.2548 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7065 - acc: 0.2484 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.7454 - acc: 0.2590 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.7080 - acc: 0.2633 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.8337 - acc: 0.2590 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.8651 - acc: 0.2548 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7432 - acc: 0.2654 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.7696 - acc: 0.2463 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7642 - acc: 0.2505 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7028 - acc: 0.2527 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7484 - acc: 0.2548 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6836 - acc: 0.2590 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7271 - acc: 0.2590 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6683 - acc: 0.2484 - val_loss: 0.5201 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7462 - acc: 0.2569 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6523 - acc: 0.2548 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6826 - acc: 0.2548 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6640 - acc: 0.2548 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.7340 - acc: 0.2633 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6560 - acc: 0.2548 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6631 - acc: 0.2569 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7096 - acc: 0.2590 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6862 - acc: 0.2611 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6873 - acc: 0.2611 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6572 - acc: 0.2569 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6674 - acc: 0.2590 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7539 - acc: 0.2569 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6588 - acc: 0.2569 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6764 - acc: 0.2590 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6632 - acc: 0.2590 - val_loss: 0.5201 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6529 - acc: 0.2569 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6547 - acc: 0.2548 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6523 - acc: 0.2590 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6650 - acc: 0.2590 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6587 - acc: 0.2611 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6521 - acc: 0.2590 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6531 - acc: 0.2569 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6832 - acc: 0.2590 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6733 - acc: 0.2548 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6822 - acc: 0.2611 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6638 - acc: 0.2590 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6640 - acc: 0.2569 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6598 - acc: 0.2569 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7328 - acc: 0.2590 - val_loss: 0.5255 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6574 - acc: 0.2590 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6644 - acc: 0.2569 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6660 - acc: 0.2590 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6549 - acc: 0.2611 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6634 - acc: 0.2548 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6533 - acc: 0.2611 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6519 - acc: 0.2590 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6573 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6588 - acc: 0.2590 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6697 - acc: 0.2590 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6622 - acc: 0.2611 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6479 - acc: 0.2590 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6595 - acc: 0.2590 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6466 - acc: 0.2590 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6778 - acc: 0.2590 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6534 - acc: 0.2590 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6524 - acc: 0.2611 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6697 - acc: 0.2569 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6542 - acc: 0.2590 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6422 - acc: 0.2590 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6521 - acc: 0.2590 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6492 - acc: 0.2590 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6380 - acc: 0.2590 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6386 - acc: 0.2611 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6499 - acc: 0.2590 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6518 - acc: 0.2590 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6491 - acc: 0.2611 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6470 - acc: 0.2590 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6484 - acc: 0.2590 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6489 - acc: 0.2590 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6372 - acc: 0.2590 - val_loss: 0.5169 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6475 - acc: 0.2590 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6765 - acc: 0.2590 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7146 - acc: 0.2590 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6457 - acc: 0.2590 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6843 - acc: 0.2590 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6445 - acc: 0.2590 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6466 - acc: 0.2590 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6421 - acc: 0.2590 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6373 - acc: 0.2590 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6612 - acc: 0.2590 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6611 - acc: 0.2611 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 144us/step - loss: 0.6556 - acc: 0.2590 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6465 - acc: 0.2590 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6537 - acc: 0.2590 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6493 - acc: 0.2590 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6662 - acc: 0.2590 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7098 - acc: 0.2590 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6523 - acc: 0.2590 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6617 - acc: 0.2590 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6513 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6619 - acc: 0.2590 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6409 - acc: 0.2590 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6500 - acc: 0.2590 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 144us/step\n",
      "Test score: 0.5185596122809336\n",
      "Look! softmax softplus relu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_185 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_704 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_522 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_705 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_523 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_706 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 19s 40ms/step - loss: 2.8108 - acc: 0.1614 - val_loss: 1.1427 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.5056 - acc: 0.1677 - val_loss: 1.0837 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.5813 - acc: 0.1635 - val_loss: 1.2433 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.6274 - acc: 0.1911 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.9883 - acc: 0.1847 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.4783 - acc: 0.1783 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.0162 - acc: 0.1847 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.9362 - acc: 0.1614 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.7679 - acc: 0.1868 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 2.9441 - acc: 0.1783 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.8021 - acc: 0.1656 - val_loss: 1.4861 - val_acc: 0.1277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 3.2498 - acc: 0.1975 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 2.9653 - acc: 0.1975 - val_loss: 1.3718 - val_acc: 0.1277\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 3.7640 - acc: 0.1932 - val_loss: 1.3718 - val_acc: 0.1277\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 3.0937 - acc: 0.1826 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 3.1852 - acc: 0.1805 - val_loss: 5.4896 - val_acc: 0.1277\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 3.2820 - acc: 0.1699 - val_loss: 5.0497 - val_acc: 0.1277\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 3.6172 - acc: 0.1571 - val_loss: 2.4727 - val_acc: 0.1277\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 3.3717 - acc: 0.1805 - val_loss: 2.4281 - val_acc: 0.1277\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 3.8157 - acc: 0.1805 - val_loss: 2.4080 - val_acc: 0.1277\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 3.1940 - acc: 0.1699 - val_loss: 2.3942 - val_acc: 0.1277\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.6510 - acc: 0.1401 - val_loss: 2.3878 - val_acc: 0.1277\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.5558 - acc: 0.1529 - val_loss: 0.8391 - val_acc: 0.1277\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.2878 - acc: 0.1486 - val_loss: 0.6547 - val_acc: 0.1277\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 2.5102 - acc: 0.1826 - val_loss: 0.6119 - val_acc: 0.1277\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.7994 - acc: 0.1529 - val_loss: 0.5918 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.9527 - acc: 0.1932 - val_loss: 0.5798 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.4433 - acc: 0.1401 - val_loss: 0.5704 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.7245 - acc: 0.1465 - val_loss: 0.5639 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.6031 - acc: 0.1571 - val_loss: 0.5585 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.4322 - acc: 0.1614 - val_loss: 0.5545 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.4793 - acc: 0.1741 - val_loss: 0.5562 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.2272 - acc: 0.1507 - val_loss: 0.5629 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.5300 - acc: 0.1550 - val_loss: 0.6019 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.2731 - acc: 0.1592 - val_loss: 0.9924 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.3556 - acc: 0.1507 - val_loss: 0.9813 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.3967 - acc: 0.1359 - val_loss: 0.9662 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.2470 - acc: 0.0977 - val_loss: 0.9464 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.3301 - acc: 0.1338 - val_loss: 0.9196 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.3735 - acc: 0.1104 - val_loss: 0.8960 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.5469 - acc: 0.1741 - val_loss: 0.8780 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.9492 - acc: 0.1316 - val_loss: 0.8562 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.8581 - acc: 0.1295 - val_loss: 0.8429 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.2699 - acc: 0.1253 - val_loss: 0.8448 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 1.3495 - acc: 0.0913 - val_loss: 0.8416 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.6025 - acc: 0.0764 - val_loss: 0.8367 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.3707 - acc: 0.0637 - val_loss: 0.8291 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 1.3592 - acc: 0.0764 - val_loss: 0.8216 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 1.6281 - acc: 0.0786 - val_loss: 0.8109 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.4185 - acc: 0.0807 - val_loss: 0.8004 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.5911 - acc: 0.0531 - val_loss: 0.7911 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.5622 - acc: 0.0934 - val_loss: 0.7702 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.6577 - acc: 0.0955 - val_loss: 0.7456 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.7632 - acc: 0.0849 - val_loss: 0.7310 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.7137 - acc: 0.1125 - val_loss: 0.7324 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 2.1000 - acc: 0.0892 - val_loss: 0.9342 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 2.2256 - acc: 0.0977 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.9042 - acc: 0.0722 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 2.6326 - acc: 0.0998 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 2.3880 - acc: 0.1019 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 2.6082 - acc: 0.0743 - val_loss: 0.8991 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 2.2409 - acc: 0.0701 - val_loss: 0.7187 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 2.1483 - acc: 0.0764 - val_loss: 0.7514 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.8132 - acc: 0.0637 - val_loss: 0.7775 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.8310 - acc: 0.0594 - val_loss: 0.7911 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.5576 - acc: 0.0467 - val_loss: 0.7978 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.3170 - acc: 0.0446 - val_loss: 0.8000 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.7482 - acc: 0.0467 - val_loss: 0.8089 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.4258 - acc: 0.0446 - val_loss: 0.8156 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.3412 - acc: 0.0467 - val_loss: 0.8259 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.3529 - acc: 0.0446 - val_loss: 0.8309 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.2830 - acc: 0.0467 - val_loss: 0.8332 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 1.3054 - acc: 0.0425 - val_loss: 0.8343 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.2370 - acc: 0.0425 - val_loss: 0.8347 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.0559 - acc: 0.0425 - val_loss: 0.8347 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.1474 - acc: 0.0425 - val_loss: 0.8347 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.3619 - acc: 0.0425 - val_loss: 0.8346 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 1.1880 - acc: 0.0425 - val_loss: 0.8353 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.2521 - acc: 0.0425 - val_loss: 0.8355 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.2078 - acc: 0.0425 - val_loss: 0.8354 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.1701 - acc: 0.0425 - val_loss: 0.8355 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 1.2093 - acc: 0.0446 - val_loss: 0.8354 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.3223 - acc: 0.0425 - val_loss: 0.8351 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.1196 - acc: 0.0403 - val_loss: 0.8346 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.1701 - acc: 0.0446 - val_loss: 0.8342 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.1731 - acc: 0.0425 - val_loss: 0.8336 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.0024 - acc: 0.0425 - val_loss: 0.8334 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.2819 - acc: 0.0403 - val_loss: 0.8331 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.1611 - acc: 0.0425 - val_loss: 0.8343 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.0878 - acc: 0.0425 - val_loss: 0.8360 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 1.1326 - acc: 0.0425 - val_loss: 0.8369 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.1065 - acc: 0.0425 - val_loss: 0.8374 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.1950 - acc: 0.0425 - val_loss: 0.8376 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.1095 - acc: 0.0425 - val_loss: 0.8376 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.1308 - acc: 0.0446 - val_loss: 0.8375 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.0957 - acc: 0.0446 - val_loss: 0.8373 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.1217 - acc: 0.0425 - val_loss: 0.8370 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.1154 - acc: 0.0425 - val_loss: 0.8367 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.1791 - acc: 0.0425 - val_loss: 0.8362 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.1167 - acc: 0.0425 - val_loss: 0.8356 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.2139 - acc: 0.0425 - val_loss: 0.8350 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.0444 - acc: 0.0425 - val_loss: 0.8348 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.1904 - acc: 0.0425 - val_loss: 0.8353 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 1.0784 - acc: 0.0425 - val_loss: 0.8354 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.1931 - acc: 0.0425 - val_loss: 0.8359 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.1578 - acc: 0.0425 - val_loss: 0.8358 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.1146 - acc: 0.0425 - val_loss: 0.8355 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.1058 - acc: 0.0425 - val_loss: 0.8351 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.9720 - acc: 0.0425 - val_loss: 0.8347 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.0063 - acc: 0.0425 - val_loss: 0.8350 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.0968 - acc: 0.0425 - val_loss: 0.8349 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.0247 - acc: 0.0425 - val_loss: 0.8344 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.1379 - acc: 0.0425 - val_loss: 0.8348 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.1376 - acc: 0.0425 - val_loss: 0.8347 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: 1.0760 - acc: 0.0425 - val_loss: 0.8343 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 1.1017 - acc: 0.0425 - val_loss: 0.8336 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 1.1384 - acc: 0.0425 - val_loss: 0.8314 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 1.0332 - acc: 0.0425 - val_loss: 0.8292 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 1.1554 - acc: 0.0446 - val_loss: 0.8269 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 1.0995 - acc: 0.0446 - val_loss: 0.8250 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 140us/step\n",
      "Test score: 0.8249842668256016\n",
      "Look! softmax softplus tanh Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_186 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_707 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_524 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_708 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_525 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_709 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 19s 40ms/step - loss: 0.7710 - acc: 0.3057 - val_loss: 0.5854 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7404 - acc: 0.2760 - val_loss: 0.5538 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7307 - acc: 0.2866 - val_loss: 0.5323 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6649 - acc: 0.2803 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6731 - acc: 0.2548 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6787 - acc: 0.2527 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6872 - acc: 0.2569 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6730 - acc: 0.2463 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6623 - acc: 0.2442 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6450 - acc: 0.2527 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6562 - acc: 0.2548 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6577 - acc: 0.2505 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6743 - acc: 0.2527 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6562 - acc: 0.2548 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6423 - acc: 0.2611 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6513 - acc: 0.2548 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6525 - acc: 0.2590 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6431 - acc: 0.2611 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6390 - acc: 0.2569 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6525 - acc: 0.2590 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6614 - acc: 0.2505 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6452 - acc: 0.2569 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6570 - acc: 0.2569 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6553 - acc: 0.2527 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6469 - acc: 0.2611 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6719 - acc: 0.2548 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6685 - acc: 0.2590 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6423 - acc: 0.2569 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6453 - acc: 0.2548 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6568 - acc: 0.2590 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6692 - acc: 0.2569 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6549 - acc: 0.2590 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6567 - acc: 0.2590 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6396 - acc: 0.2569 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6472 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6607 - acc: 0.2590 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6871 - acc: 0.2590 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6591 - acc: 0.2590 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6570 - acc: 0.2569 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6613 - acc: 0.2611 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6622 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6443 - acc: 0.2590 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6592 - acc: 0.2569 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6310 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6456 - acc: 0.2569 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6523 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6485 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6371 - acc: 0.2590 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6528 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6307 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6509 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6722 - acc: 0.2590 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6659 - acc: 0.2590 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6569 - acc: 0.2590 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6729 - acc: 0.2590 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6474 - acc: 0.2590 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6599 - acc: 0.2590 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6541 - acc: 0.2590 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6627 - acc: 0.2590 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6571 - acc: 0.2569 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6417 - acc: 0.2590 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6459 - acc: 0.2611 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6340 - acc: 0.2548 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6313 - acc: 0.2590 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6709 - acc: 0.2590 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6462 - acc: 0.2590 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6603 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6701 - acc: 0.2590 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6604 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6535 - acc: 0.2590 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6618 - acc: 0.2590 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6433 - acc: 0.2590 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6405 - acc: 0.2590 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6560 - acc: 0.2590 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6478 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6495 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6475 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6394 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6544 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6551 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6454 - acc: 0.2590 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6635 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6410 - acc: 0.2590 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6545 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6505 - acc: 0.2590 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6336 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6481 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6406 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6571 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6482 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6391 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6392 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6585 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6477 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6521 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6460 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6530 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6376 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6473 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6442 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6438 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6518 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6396 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6351 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6442 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6514 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6582 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6504 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6411 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6487 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6646 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6537 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6377 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6460 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6544 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6420 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6523 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6453 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6407 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6310 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 166us/step\n",
      "Test score: 0.5135086800189729\n",
      "Look! softmax softplus sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_187 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_710 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_526 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_711 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_527 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_712 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 41ms/step - loss: 0.6979 - acc: 0.2951 - val_loss: 0.5407 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6717 - acc: 0.2781 - val_loss: 0.5321 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7240 - acc: 0.2887 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.8329 - acc: 0.2505 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.8317 - acc: 0.2590 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7454 - acc: 0.2484 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7094 - acc: 0.2463 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6925 - acc: 0.2548 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6695 - acc: 0.2505 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6566 - acc: 0.2569 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6553 - acc: 0.2654 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6828 - acc: 0.2633 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6880 - acc: 0.2505 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.7189 - acc: 0.2590 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6632 - acc: 0.2527 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6548 - acc: 0.2633 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6808 - acc: 0.2527 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7162 - acc: 0.2569 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6759 - acc: 0.2654 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6523 - acc: 0.2548 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7134 - acc: 0.2590 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.7743 - acc: 0.2569 - val_loss: 0.5254 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6899 - acc: 0.2590 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6596 - acc: 0.2548 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6633 - acc: 0.2569 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6667 - acc: 0.2590 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6519 - acc: 0.2611 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7033 - acc: 0.2548 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6644 - acc: 0.2484 - val_loss: 0.5298 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6569 - acc: 0.2569 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6709 - acc: 0.2505 - val_loss: 0.5305 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6673 - acc: 0.2527 - val_loss: 0.5315 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6688 - acc: 0.2569 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6618 - acc: 0.2590 - val_loss: 0.5316 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6593 - acc: 0.2548 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6780 - acc: 0.2590 - val_loss: 0.5313 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6661 - acc: 0.2569 - val_loss: 0.5323 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6562 - acc: 0.2611 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6605 - acc: 0.2633 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6532 - acc: 0.2548 - val_loss: 0.5316 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7094 - acc: 0.2569 - val_loss: 0.5308 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6749 - acc: 0.2590 - val_loss: 0.5305 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6960 - acc: 0.2590 - val_loss: 0.5304 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6879 - acc: 0.2611 - val_loss: 0.5299 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6617 - acc: 0.2654 - val_loss: 0.5298 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6536 - acc: 0.2611 - val_loss: 0.5297 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6567 - acc: 0.2590 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6858 - acc: 0.2548 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6606 - acc: 0.2611 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6884 - acc: 0.2611 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6624 - acc: 0.2611 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6663 - acc: 0.2654 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6631 - acc: 0.2505 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.7153 - acc: 0.2611 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6971 - acc: 0.2590 - val_loss: 0.5319 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6680 - acc: 0.2633 - val_loss: 0.5324 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6657 - acc: 0.2590 - val_loss: 0.5324 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6741 - acc: 0.2569 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6841 - acc: 0.2654 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6584 - acc: 0.2633 - val_loss: 0.5311 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6640 - acc: 0.2548 - val_loss: 0.5304 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6491 - acc: 0.2611 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6454 - acc: 0.2611 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6860 - acc: 0.2590 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6624 - acc: 0.2548 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6709 - acc: 0.2590 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6458 - acc: 0.2590 - val_loss: 0.5267 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6810 - acc: 0.2611 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6608 - acc: 0.2590 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6565 - acc: 0.2569 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6446 - acc: 0.2633 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6601 - acc: 0.2590 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6556 - acc: 0.2611 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6626 - acc: 0.2590 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6714 - acc: 0.2548 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6768 - acc: 0.2590 - val_loss: 0.5249 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6595 - acc: 0.2611 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6471 - acc: 0.2611 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6656 - acc: 0.2590 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6650 - acc: 0.2590 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6593 - acc: 0.2590 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6602 - acc: 0.2633 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6580 - acc: 0.2590 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6759 - acc: 0.2590 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6714 - acc: 0.2590 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6497 - acc: 0.2590 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6875 - acc: 0.2590 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6864 - acc: 0.2590 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6431 - acc: 0.2590 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6597 - acc: 0.2590 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6786 - acc: 0.2590 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7283 - acc: 0.2590 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6455 - acc: 0.2611 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6590 - acc: 0.2590 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6959 - acc: 0.2590 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6563 - acc: 0.2611 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6517 - acc: 0.2590 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6472 - acc: 0.2569 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6603 - acc: 0.2590 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6592 - acc: 0.2569 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6901 - acc: 0.2590 - val_loss: 0.5263 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6556 - acc: 0.2611 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6703 - acc: 0.2633 - val_loss: 0.5297 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6529 - acc: 0.2590 - val_loss: 0.5302 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6517 - acc: 0.2611 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6583 - acc: 0.2633 - val_loss: 0.5298 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6843 - acc: 0.2611 - val_loss: 0.5292 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6878 - acc: 0.2569 - val_loss: 0.5285 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6433 - acc: 0.2611 - val_loss: 0.5276 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6497 - acc: 0.2611 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7091 - acc: 0.2590 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 112/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 163us/step - loss: 0.6955 - acc: 0.2590 - val_loss: 0.5262 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6420 - acc: 0.2590 - val_loss: 0.5259 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6581 - acc: 0.2590 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6488 - acc: 0.2590 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6741 - acc: 0.2569 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6468 - acc: 0.2590 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6569 - acc: 0.2590 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6540 - acc: 0.2590 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6615 - acc: 0.2590 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 160us/step\n",
      "Test score: 0.5236219852528674\n",
      "Look! softmax softplus hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_188 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_713 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_528 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_714 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_529 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_715 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 19s 41ms/step - loss: 2.9930 - acc: 0.3121 - val_loss: 2.2850 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 3.2920 - acc: 0.3036 - val_loss: 2.2715 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.4627 - acc: 0.2654 - val_loss: 2.5737 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 2.9475 - acc: 0.2569 - val_loss: 1.2254 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.7148 - acc: 0.2654 - val_loss: 1.6323 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.8656 - acc: 0.3163 - val_loss: 1.5659 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 3.2053 - acc: 0.2335 - val_loss: 1.5595 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.0081 - acc: 0.2357 - val_loss: 1.5573 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.2188 - acc: 0.2463 - val_loss: 1.5294 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.4303 - acc: 0.2633 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.1421 - acc: 0.2187 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.1625 - acc: 0.2399 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.7756 - acc: 0.2611 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.2816 - acc: 0.2718 - val_loss: 3.6160 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 3.3892 - acc: 0.2378 - val_loss: 3.5936 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 3.2978 - acc: 0.2760 - val_loss: 3.6225 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.6367 - acc: 0.2420 - val_loss: 3.6323 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.4529 - acc: 0.2527 - val_loss: 3.6418 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.8024 - acc: 0.2463 - val_loss: 3.6493 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.8890 - acc: 0.2187 - val_loss: 3.6532 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 3.4231 - acc: 0.2166 - val_loss: 3.6580 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.2210 - acc: 0.2123 - val_loss: 1.0362 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.7090 - acc: 0.1911 - val_loss: 0.7821 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.3782 - acc: 0.2272 - val_loss: 0.6888 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.5014 - acc: 0.1847 - val_loss: 0.6533 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.8163 - acc: 0.1699 - val_loss: 1.0360 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.6561 - acc: 0.1996 - val_loss: 0.9880 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 2.9181 - acc: 0.1656 - val_loss: 0.9427 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.4271 - acc: 0.2038 - val_loss: 0.9332 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 2.4181 - acc: 0.2059 - val_loss: 0.9394 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.6780 - acc: 0.2123 - val_loss: 0.9381 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.4267 - acc: 0.2272 - val_loss: 0.9871 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.2971 - acc: 0.2760 - val_loss: 1.6778 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.2407 - acc: 0.2845 - val_loss: 1.6566 - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 2.7623 - acc: 0.3185 - val_loss: 1.6425 - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.3008 - acc: 0.3036 - val_loss: 1.6443 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 2.5608 - acc: 0.2866 - val_loss: 1.6475 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.7226 - acc: 0.3057 - val_loss: 1.6566 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.0620 - acc: 0.2994 - val_loss: 1.6768 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.9984 - acc: 0.2357 - val_loss: 1.0448 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.3581 - acc: 0.2484 - val_loss: 0.9884 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.8894 - acc: 0.2399 - val_loss: 0.9512 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.6481 - acc: 0.2251 - val_loss: 0.9494 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.8352 - acc: 0.1911 - val_loss: 0.9531 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.8848 - acc: 0.1635 - val_loss: 0.9534 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.6616 - acc: 0.1444 - val_loss: 0.9511 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.8521 - acc: 0.1486 - val_loss: 0.9509 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.7203 - acc: 0.1465 - val_loss: 0.9582 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.8356 - acc: 0.1507 - val_loss: 0.9613 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.7210 - acc: 0.1465 - val_loss: 0.9604 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.9230 - acc: 0.1656 - val_loss: 0.9633 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.5915 - acc: 0.1550 - val_loss: 0.9649 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.6511 - acc: 0.1486 - val_loss: 0.9643 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.4291 - acc: 0.1529 - val_loss: 0.9612 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.7373 - acc: 0.1465 - val_loss: 0.9561 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.6464 - acc: 0.1423 - val_loss: 0.9495 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.7735 - acc: 0.1486 - val_loss: 0.9412 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.6367 - acc: 0.1401 - val_loss: 0.9325 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.8102 - acc: 0.1635 - val_loss: 0.9246 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.6834 - acc: 0.1274 - val_loss: 0.9169 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.6914 - acc: 0.1401 - val_loss: 0.9110 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.6396 - acc: 0.0998 - val_loss: 0.9046 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.6658 - acc: 0.1231 - val_loss: 0.9040 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.4620 - acc: 0.1083 - val_loss: 0.9167 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.4271 - acc: 0.1359 - val_loss: 0.9226 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.6285 - acc: 0.1444 - val_loss: 0.9246 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.5540 - acc: 0.1274 - val_loss: 0.9290 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.4254 - acc: 0.1486 - val_loss: 0.9334 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.3826 - acc: 0.1231 - val_loss: 0.9360 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.4609 - acc: 0.1168 - val_loss: 0.9355 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.4995 - acc: 0.1783 - val_loss: 0.9294 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.5007 - acc: 0.1592 - val_loss: 0.9254 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.4813 - acc: 0.1380 - val_loss: 0.9255 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.5138 - acc: 0.1295 - val_loss: 0.9253 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.5478 - acc: 0.1019 - val_loss: 0.9262 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.3077 - acc: 0.1083 - val_loss: 0.9270 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.2452 - acc: 0.0786 - val_loss: 0.9266 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.3811 - acc: 0.0701 - val_loss: 0.9253 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.1020 - acc: 0.0658 - val_loss: 0.9230 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.3791 - acc: 0.0637 - val_loss: 0.9197 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.3774 - acc: 0.0637 - val_loss: 0.9160 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.1616 - acc: 0.0679 - val_loss: 0.9110 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.4082 - acc: 0.0573 - val_loss: 0.9053 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 1.2615 - acc: 0.0552 - val_loss: 0.8992 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.2631 - acc: 0.0510 - val_loss: 0.8928 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.3289 - acc: 0.0552 - val_loss: 0.8866 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.1928 - acc: 0.0552 - val_loss: 0.8802 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.1649 - acc: 0.0510 - val_loss: 0.8740 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.3424 - acc: 0.0467 - val_loss: 0.8682 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.2905 - acc: 0.0510 - val_loss: 0.8617 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.3276 - acc: 0.0552 - val_loss: 0.8550 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.3710 - acc: 0.0552 - val_loss: 0.8509 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.3804 - acc: 0.0531 - val_loss: 0.8479 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.0683 - acc: 0.0510 - val_loss: 0.8445 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.1801 - acc: 0.0382 - val_loss: 0.8407 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 1.2497 - acc: 0.0446 - val_loss: 0.8356 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 1.3175 - acc: 0.0467 - val_loss: 0.8295 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.4017 - acc: 0.0467 - val_loss: 0.8228 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.2451 - acc: 0.0467 - val_loss: 0.8152 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.3480 - acc: 0.0467 - val_loss: 0.8068 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.2113 - acc: 0.0467 - val_loss: 0.7977 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.3491 - acc: 0.0488 - val_loss: 0.7887 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.5335 - acc: 0.0425 - val_loss: 0.7793 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.4111 - acc: 0.0446 - val_loss: 0.7690 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.3520 - acc: 0.0510 - val_loss: 0.7585 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.4312 - acc: 0.0446 - val_loss: 0.7477 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.4980 - acc: 0.0446 - val_loss: 0.7370 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.5468 - acc: 0.0425 - val_loss: 0.7256 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.4323 - acc: 0.0446 - val_loss: 0.7174 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.3846 - acc: 0.0446 - val_loss: 0.7111 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.4442 - acc: 0.0446 - val_loss: 0.7018 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.1993 - acc: 0.0446 - val_loss: 0.6906 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 1.4150 - acc: 0.0425 - val_loss: 0.6784 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.6201 - acc: 0.0446 - val_loss: 0.6657 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.7088 - acc: 0.0446 - val_loss: 0.6529 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.8808 - acc: 0.0425 - val_loss: 0.6401 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.6565 - acc: 0.0446 - val_loss: 0.6261 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.9816 - acc: 0.0425 - val_loss: 0.6141 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.8076 - acc: 0.0425 - val_loss: 0.6106 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.0952 - acc: 0.0425 - val_loss: 0.6080 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 173us/step\n",
      "Test score: 0.6080113074458238\n",
      "Look! softmax softplus linear Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_189 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_716 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_530 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_717 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_531 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_718 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 42ms/step - loss: 0.7245 - acc: 0.3100 - val_loss: 0.5738 - val_acc: 0.2199\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7074 - acc: 0.2527 - val_loss: 0.5599 - val_acc: 0.2270\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7013 - acc: 0.2633 - val_loss: 0.5465 - val_acc: 0.2199\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6767 - acc: 0.2569 - val_loss: 0.5415 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6725 - acc: 0.2463 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6624 - acc: 0.2633 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6685 - acc: 0.2569 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6535 - acc: 0.2590 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6506 - acc: 0.2569 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6619 - acc: 0.2611 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6417 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6477 - acc: 0.2569 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6731 - acc: 0.2569 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6626 - acc: 0.2548 - val_loss: 0.5509 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6668 - acc: 0.2548 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6398 - acc: 0.2590 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6331 - acc: 0.2527 - val_loss: 0.5107 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6367 - acc: 0.2696 - val_loss: 0.5037 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6258 - acc: 0.2718 - val_loss: 0.5029 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6294 - acc: 0.2803 - val_loss: 0.5004 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6212 - acc: 0.2739 - val_loss: 0.4975 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6137 - acc: 0.2803 - val_loss: 0.4951 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6297 - acc: 0.2718 - val_loss: 0.5011 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6390 - acc: 0.2399 - val_loss: 0.4958 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6155 - acc: 0.2675 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6374 - acc: 0.2654 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6263 - acc: 0.2675 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6397 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6216 - acc: 0.2675 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6240 - acc: 0.2654 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6198 - acc: 0.2696 - val_loss: 0.5114 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6119 - acc: 0.2633 - val_loss: 0.5088 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6134 - acc: 0.2718 - val_loss: 0.5142 - val_acc: 0.2057\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6186 - acc: 0.2675 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6076 - acc: 0.2633 - val_loss: 0.5039 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6155 - acc: 0.2654 - val_loss: 0.5018 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.5995 - acc: 0.2760 - val_loss: 0.5066 - val_acc: 0.2057\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6118 - acc: 0.2760 - val_loss: 0.4979 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.5963 - acc: 0.2824 - val_loss: 0.4943 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6196 - acc: 0.2781 - val_loss: 0.4905 - val_acc: 0.2482\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6015 - acc: 0.2739 - val_loss: 0.4826 - val_acc: 0.2766\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6059 - acc: 0.2845 - val_loss: 0.4779 - val_acc: 0.2766\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.5845 - acc: 0.2930 - val_loss: 0.4734 - val_acc: 0.2766\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6167 - acc: 0.2675 - val_loss: 0.5059 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6493 - acc: 0.2123 - val_loss: 0.5076 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6634 - acc: 0.2102 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6533 - acc: 0.2335 - val_loss: 0.5068 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6323 - acc: 0.2654 - val_loss: 0.5069 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6257 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6483 - acc: 0.2484 - val_loss: 0.5392 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6355 - acc: 0.2548 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6272 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6265 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6396 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6204 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6222 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6264 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6345 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6283 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6341 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6289 - acc: 0.2527 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6302 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6260 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6365 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6277 - acc: 0.2611 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6219 - acc: 0.2654 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6305 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6299 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6334 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6287 - acc: 0.2633 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6158 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6287 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6238 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6188 - acc: 0.2633 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6272 - acc: 0.2611 - val_loss: 0.5147 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6343 - acc: 0.2633 - val_loss: 0.5234 - val_acc: 0.2057\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6206 - acc: 0.2696 - val_loss: 0.5194 - val_acc: 0.2057\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6287 - acc: 0.2675 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6186 - acc: 0.2675 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6349 - acc: 0.2611 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6239 - acc: 0.2633 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6273 - acc: 0.2675 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6248 - acc: 0.2654 - val_loss: 0.5242 - val_acc: 0.2057\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6257 - acc: 0.2633 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6268 - acc: 0.2633 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6087 - acc: 0.2675 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6288 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6219 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6260 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6283 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6217 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6249 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6387 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6192 - acc: 0.2696 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6230 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6184 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6210 - acc: 0.2675 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6149 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6172 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6140 - acc: 0.2675 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6144 - acc: 0.2633 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6211 - acc: 0.2633 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6250 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: 0.6107 - acc: 0.2675 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6149 - acc: 0.2696 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6156 - acc: 0.2675 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6160 - acc: 0.2633 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6224 - acc: 0.2654 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6274 - acc: 0.2611 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6115 - acc: 0.2654 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6161 - acc: 0.2633 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6215 - acc: 0.2654 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6191 - acc: 0.2654 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6182 - acc: 0.2675 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6115 - acc: 0.2675 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6030 - acc: 0.2675 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6244 - acc: 0.2611 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6120 - acc: 0.2654 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 149us/step\n",
      "Test score: 0.5125331464388692\n",
      "Look! softmax softsign softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_190 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_719 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_532 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_720 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_533 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_721 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 42ms/step - loss: nan - acc: 0.4395 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 160us/step\n",
      "Test score: nan\n",
      "Look! softmax softsign elu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax softsign elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_191 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_722 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_534 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_723 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_535 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_724 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 42ms/step - loss: 3.2800 - acc: 0.2442 - val_loss: 2.1145 - val_acc: 0.0780\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.5100 - acc: 0.2251 - val_loss: 2.7287 - val_acc: 0.1489\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 3.8331 - acc: 0.2633 - val_loss: 2.2588 - val_acc: 0.1206\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 3.7536 - acc: 0.2527 - val_loss: 2.1517 - val_acc: 0.1560\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.4933 - acc: 0.2845 - val_loss: 1.8381 - val_acc: 0.1915\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 3.5230 - acc: 0.2951 - val_loss: 1.5870 - val_acc: 0.2199\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 3.6000 - acc: 0.3121 - val_loss: 1.4731 - val_acc: 0.2553\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.5530 - acc: 0.3355 - val_loss: 1.3659 - val_acc: 0.3546\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.2378 - acc: 0.3567 - val_loss: 1.2611 - val_acc: 0.5035\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 3.2240 - acc: 0.3715 - val_loss: 1.2459 - val_acc: 0.6028\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 3.2774 - acc: 0.3864 - val_loss: 1.3452 - val_acc: 0.5887\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 3.4301 - acc: 0.4055 - val_loss: 1.1004 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 3.5029 - acc: 0.4289 - val_loss: 1.0863 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.6318 - acc: 0.4544 - val_loss: 1.1121 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.4777 - acc: 0.3715 - val_loss: 1.0789 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 3.4826 - acc: 0.4076 - val_loss: 1.0296 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.4982 - acc: 0.4055 - val_loss: 1.0049 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.0525 - acc: 0.3631 - val_loss: 0.9921 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.3891 - acc: 0.4013 - val_loss: 0.9957 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.8665 - acc: 0.4204 - val_loss: 1.0073 - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 4.2272 - acc: 0.4098 - val_loss: 1.0375 - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.6331 - acc: 0.3907 - val_loss: 1.4861 - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 4.0292 - acc: 0.3843 - val_loss: 1.4861 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 4.0332 - acc: 0.3907 - val_loss: 1.4861 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 4.2514 - acc: 0.3800 - val_loss: 2.0576 - val_acc: 0.6170\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 4.5085 - acc: 0.3864 - val_loss: 4.7320 - val_acc: 0.3617\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.5997 - acc: 0.2887 - val_loss: 2.7411 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.9986 - acc: 0.2909 - val_loss: 0.6339 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.1289 - acc: 0.2696 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 3.4327 - acc: 0.2718 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 3.2817 - acc: 0.2718 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 3.9850 - acc: 0.2548 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 4.6052 - acc: 0.2505 - val_loss: 5.6815 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 4.9437 - acc: 0.2293 - val_loss: 5.5984 - val_acc: 0.1277\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 4.8763 - acc: 0.2229 - val_loss: 5.5554 - val_acc: 0.1277\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 5.0632 - acc: 0.1953 - val_loss: 5.5466 - val_acc: 0.1277\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 4.6840 - acc: 0.2017 - val_loss: 5.5463 - val_acc: 0.1277\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 5.2533 - acc: 0.2293 - val_loss: 5.5473 - val_acc: 0.1277\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 4.6640 - acc: 0.2229 - val_loss: 2.5299 - val_acc: 0.1277\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 3.7791 - acc: 0.1783 - val_loss: 2.4203 - val_acc: 0.1277\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.9585 - acc: 0.2187 - val_loss: 2.3695 - val_acc: 0.1277\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 3.8150 - acc: 0.2123 - val_loss: 2.3418 - val_acc: 0.1277\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 3.2877 - acc: 0.1826 - val_loss: 2.3234 - val_acc: 0.1277\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.3323 - acc: 0.1868 - val_loss: 2.3100 - val_acc: 0.1277\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.4881 - acc: 0.1975 - val_loss: 2.2991 - val_acc: 0.1277\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.4346 - acc: 0.1975 - val_loss: 2.2893 - val_acc: 0.1277\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.8343 - acc: 0.2208 - val_loss: 2.2825 - val_acc: 0.1277\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.9668 - acc: 0.2293 - val_loss: 2.2834 - val_acc: 0.1277\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 3.5866 - acc: 0.2081 - val_loss: 2.2843 - val_acc: 0.1277\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.2487 - acc: 0.1847 - val_loss: 2.2829 - val_acc: 0.1277\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 3.6906 - acc: 0.2166 - val_loss: 2.2803 - val_acc: 0.1277\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 3.3343 - acc: 0.1932 - val_loss: 2.2765 - val_acc: 0.1277\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.5495 - acc: 0.2081 - val_loss: 2.2714 - val_acc: 0.1277\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.2197 - acc: 0.1868 - val_loss: 2.2652 - val_acc: 0.1277\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.4784 - acc: 0.2038 - val_loss: 2.2584 - val_acc: 0.1277\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 3.6753 - acc: 0.2166 - val_loss: 2.2508 - val_acc: 0.1277\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.4381 - acc: 0.2017 - val_loss: 2.2437 - val_acc: 0.1277\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.3673 - acc: 0.1975 - val_loss: 2.2359 - val_acc: 0.1277\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.4333 - acc: 0.2017 - val_loss: 2.2274 - val_acc: 0.1277\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.7400 - acc: 0.2229 - val_loss: 2.2181 - val_acc: 0.1277\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.8125 - acc: 0.2272 - val_loss: 2.2083 - val_acc: 0.1277\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 3.4054 - acc: 0.2017 - val_loss: 2.1979 - val_acc: 0.1277\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.4887 - acc: 0.2059 - val_loss: 2.1870 - val_acc: 0.1277\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.4554 - acc: 0.2059 - val_loss: 2.1783 - val_acc: 0.1277\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.3736 - acc: 0.1975 - val_loss: 2.1681 - val_acc: 0.1277\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 3.1928 - acc: 0.1868 - val_loss: 2.1572 - val_acc: 0.1277\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 3.3793 - acc: 0.1996 - val_loss: 2.1450 - val_acc: 0.1277\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.8041 - acc: 0.2251 - val_loss: 2.1314 - val_acc: 0.1277\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 3.3870 - acc: 0.2038 - val_loss: 2.1173 - val_acc: 0.1277\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 3.3731 - acc: 0.1996 - val_loss: 2.1036 - val_acc: 0.1277\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.3238 - acc: 0.1890 - val_loss: 2.0932 - val_acc: 0.1277\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.3794 - acc: 0.2038 - val_loss: 2.0894 - val_acc: 0.1277\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 3.1721 - acc: 0.1741 - val_loss: 2.0858 - val_acc: 0.1277\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 3.7511 - acc: 0.2208 - val_loss: 2.0828 - val_acc: 0.1277\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.7691 - acc: 0.2251 - val_loss: 2.0793 - val_acc: 0.1277\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 4.2180 - acc: 0.2314 - val_loss: 2.0750 - val_acc: 0.1277\n",
      "Epoch 77/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 176us/step - loss: 3.6341 - acc: 0.2038 - val_loss: 2.0709 - val_acc: 0.1277\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 4.3093 - acc: 0.2166 - val_loss: 2.0703 - val_acc: 0.1277\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 3.9901 - acc: 0.2272 - val_loss: 2.0696 - val_acc: 0.1277\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 4.1232 - acc: 0.2123 - val_loss: 2.0688 - val_acc: 0.1277\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.8076 - acc: 0.2187 - val_loss: 2.0675 - val_acc: 0.1277\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 4.0633 - acc: 0.2272 - val_loss: 2.0664 - val_acc: 0.1277\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.8879 - acc: 0.2102 - val_loss: 2.0657 - val_acc: 0.1277\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 3.4083 - acc: 0.1953 - val_loss: 2.0647 - val_acc: 0.1277\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 4.0546 - acc: 0.2123 - val_loss: 2.0638 - val_acc: 0.1277\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 3.7416 - acc: 0.1932 - val_loss: 2.0634 - val_acc: 0.1277\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 4.4976 - acc: 0.2293 - val_loss: 2.0628 - val_acc: 0.1277\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 4.4251 - acc: 0.2251 - val_loss: 2.0625 - val_acc: 0.1277\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 4.1899 - acc: 0.2081 - val_loss: 2.0621 - val_acc: 0.1277\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 4.4034 - acc: 0.2017 - val_loss: 2.0612 - val_acc: 0.1277\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 4.4580 - acc: 0.2144 - val_loss: 2.0603 - val_acc: 0.1277\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 4.1534 - acc: 0.2017 - val_loss: 2.0576 - val_acc: 0.1277\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 4.3506 - acc: 0.2187 - val_loss: 2.0576 - val_acc: 0.1277\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 3.9472 - acc: 0.1975 - val_loss: 2.0576 - val_acc: 0.1277\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 4.4882 - acc: 0.2166 - val_loss: 2.0576 - val_acc: 0.1277\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 4.3725 - acc: 0.1996 - val_loss: 2.0576 - val_acc: 0.1277\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 4.1834 - acc: 0.2059 - val_loss: 2.0576 - val_acc: 0.1277\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 4.6895 - acc: 0.1783 - val_loss: 2.0576 - val_acc: 0.1277\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 4.6089 - acc: 0.1996 - val_loss: 4.9154 - val_acc: 0.1277\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 4.9341 - acc: 0.2293 - val_loss: 4.9154 - val_acc: 0.1277\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 4.6531 - acc: 0.2123 - val_loss: 4.9154 - val_acc: 0.1277\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 4.5236 - acc: 0.1890 - val_loss: 4.3875 - val_acc: 0.1277\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 4.9156 - acc: 0.2251 - val_loss: 4.3739 - val_acc: 0.1277\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 4.7765 - acc: 0.1932 - val_loss: 4.3681 - val_acc: 0.1277\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 4.7972 - acc: 0.1614 - val_loss: 4.3642 - val_acc: 0.1277\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 4.9535 - acc: 0.1975 - val_loss: 4.3615 - val_acc: 0.1277\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 4.6327 - acc: 0.2059 - val_loss: 4.3589 - val_acc: 0.1277\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 4.4425 - acc: 0.1932 - val_loss: 4.3564 - val_acc: 0.1277\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 4.8295 - acc: 0.1975 - val_loss: 4.3547 - val_acc: 0.1277\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 4.4821 - acc: 0.2081 - val_loss: 4.3535 - val_acc: 0.1277\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 4.2819 - acc: 0.1911 - val_loss: 4.3520 - val_acc: 0.1277\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 4.3522 - acc: 0.1975 - val_loss: 4.3504 - val_acc: 0.1277\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 4.6111 - acc: 0.2102 - val_loss: 4.3489 - val_acc: 0.1277\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 4.4048 - acc: 0.1911 - val_loss: 4.3475 - val_acc: 0.1277\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 4.5419 - acc: 0.1996 - val_loss: 4.3461 - val_acc: 0.1277\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 4.3198 - acc: 0.2081 - val_loss: 4.3449 - val_acc: 0.1277\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 4.8739 - acc: 0.1635 - val_loss: 4.3439 - val_acc: 0.1277\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 4.4889 - acc: 0.2017 - val_loss: 4.3439 - val_acc: 0.1277\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 4.4279 - acc: 0.2123 - val_loss: 4.3439 - val_acc: 0.1277\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 3.9120 - acc: 0.2335 - val_loss: 4.3439 - val_acc: 0.1277\n",
      "141/141 [==============================] - 0s 160us/step\n",
      "Test score: 4.3438839202231545\n",
      "Look! softmax softsign selu Test accuracy: 0.1276595744680851\n",
      "max there  0.6241134772909448 softmax softsign elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_192 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_725 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_536 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_726 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_537 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_727 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 42ms/step - loss: 0.7431 - acc: 0.2442 - val_loss: 0.5936 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7271 - acc: 0.2696 - val_loss: 0.5815 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7126 - acc: 0.2718 - val_loss: 0.5701 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.7020 - acc: 0.2611 - val_loss: 0.5599 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6912 - acc: 0.2548 - val_loss: 0.5511 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6877 - acc: 0.2548 - val_loss: 0.5438 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6722 - acc: 0.2569 - val_loss: 0.5380 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6786 - acc: 0.2611 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6660 - acc: 0.2569 - val_loss: 0.5419 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6657 - acc: 0.2548 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6538 - acc: 0.2569 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6573 - acc: 0.2590 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6478 - acc: 0.2590 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6520 - acc: 0.2633 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6592 - acc: 0.2633 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6477 - acc: 0.2611 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6448 - acc: 0.2611 - val_loss: 0.5317 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6318 - acc: 0.2654 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6325 - acc: 0.2611 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6251 - acc: 0.2654 - val_loss: 0.4969 - val_acc: 0.2340\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6514 - acc: 0.2442 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6585 - acc: 0.2293 - val_loss: 0.4909 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6218 - acc: 0.2696 - val_loss: 0.4978 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6073 - acc: 0.2654 - val_loss: 0.4962 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6192 - acc: 0.2633 - val_loss: 0.4925 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6207 - acc: 0.2611 - val_loss: 0.4936 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6177 - acc: 0.2654 - val_loss: 0.4936 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6217 - acc: 0.2739 - val_loss: 0.5014 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6111 - acc: 0.2633 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6037 - acc: 0.2739 - val_loss: 0.4972 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6130 - acc: 0.2781 - val_loss: 0.4994 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6071 - acc: 0.2675 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6017 - acc: 0.2760 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.5973 - acc: 0.2718 - val_loss: 0.4910 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6097 - acc: 0.2675 - val_loss: 0.4862 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.5992 - acc: 0.2696 - val_loss: 0.4767 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6195 - acc: 0.2718 - val_loss: 0.4935 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6242 - acc: 0.2611 - val_loss: 0.4863 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6077 - acc: 0.2739 - val_loss: 0.4742 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6275 - acc: 0.2866 - val_loss: 0.4755 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6146 - acc: 0.2654 - val_loss: 0.4811 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6061 - acc: 0.2718 - val_loss: 0.4773 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.5989 - acc: 0.2866 - val_loss: 0.4876 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.5791 - acc: 0.2909 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.5823 - acc: 0.2887 - val_loss: 0.5030 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6077 - acc: 0.2845 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.5935 - acc: 0.2803 - val_loss: 0.4975 - val_acc: 0.1986\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.5882 - acc: 0.2845 - val_loss: 0.4878 - val_acc: 0.1986\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.5954 - acc: 0.2824 - val_loss: 0.4933 - val_acc: 0.2057\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.5773 - acc: 0.2803 - val_loss: 0.5050 - val_acc: 0.1986\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.5908 - acc: 0.2887 - val_loss: 0.4939 - val_acc: 0.2057\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.5726 - acc: 0.3036 - val_loss: 0.5007 - val_acc: 0.2340\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.5974 - acc: 0.2803 - val_loss: 0.4792 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.5962 - acc: 0.2909 - val_loss: 0.4679 - val_acc: 0.2270\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.5782 - acc: 0.2887 - val_loss: 0.4988 - val_acc: 0.2766\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6145 - acc: 0.2633 - val_loss: 0.4658 - val_acc: 0.2199\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6015 - acc: 0.2803 - val_loss: 0.4850 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.5949 - acc: 0.2824 - val_loss: 0.4964 - val_acc: 0.2270\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.5989 - acc: 0.2739 - val_loss: 0.4880 - val_acc: 0.2624\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6023 - acc: 0.2887 - val_loss: 0.4895 - val_acc: 0.2766\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.5932 - acc: 0.2866 - val_loss: 0.5090 - val_acc: 0.2624\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.5943 - acc: 0.2739 - val_loss: 0.4986 - val_acc: 0.2482\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.5931 - acc: 0.2866 - val_loss: 0.4877 - val_acc: 0.2695\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.5741 - acc: 0.3142 - val_loss: 0.4679 - val_acc: 0.2837\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.5738 - acc: 0.3036 - val_loss: 0.4629 - val_acc: 0.2908\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.5930 - acc: 0.2909 - val_loss: 0.4640 - val_acc: 0.2908\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.5986 - acc: 0.2824 - val_loss: 0.4603 - val_acc: 0.2979\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.5991 - acc: 0.2739 - val_loss: 0.4618 - val_acc: 0.2979\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6083 - acc: 0.2739 - val_loss: 0.4775 - val_acc: 0.2482\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6117 - acc: 0.2611 - val_loss: 0.4637 - val_acc: 0.2908\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6046 - acc: 0.2590 - val_loss: 0.4815 - val_acc: 0.2553\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6133 - acc: 0.2696 - val_loss: 0.5059 - val_acc: 0.2340\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6204 - acc: 0.2654 - val_loss: 0.5090 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6296 - acc: 0.2675 - val_loss: 0.5103 - val_acc: 0.2199\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6179 - acc: 0.2675 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6332 - acc: 0.2611 - val_loss: 0.5106 - val_acc: 0.2199\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6313 - acc: 0.2611 - val_loss: 0.5075 - val_acc: 0.2199\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6022 - acc: 0.2718 - val_loss: 0.5082 - val_acc: 0.2199\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6112 - acc: 0.2696 - val_loss: 0.5055 - val_acc: 0.2270\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.5902 - acc: 0.2760 - val_loss: 0.5100 - val_acc: 0.2270\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.5875 - acc: 0.2760 - val_loss: 0.5087 - val_acc: 0.2270\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6014 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.5983 - acc: 0.2675 - val_loss: 0.5049 - val_acc: 0.2340\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.5937 - acc: 0.2718 - val_loss: 0.5052 - val_acc: 0.2908\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.5826 - acc: 0.2803 - val_loss: 0.5036 - val_acc: 0.2411\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.5961 - acc: 0.2718 - val_loss: 0.5023 - val_acc: 0.2411\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.5795 - acc: 0.2887 - val_loss: 0.4984 - val_acc: 0.3050\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.5894 - acc: 0.2866 - val_loss: 0.5005 - val_acc: 0.2411\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.5837 - acc: 0.2994 - val_loss: 0.4994 - val_acc: 0.2340\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6067 - acc: 0.2739 - val_loss: 0.4988 - val_acc: 0.2482\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.5781 - acc: 0.2887 - val_loss: 0.5008 - val_acc: 0.2908\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6082 - acc: 0.2951 - val_loss: 0.4956 - val_acc: 0.3404\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6017 - acc: 0.2909 - val_loss: 0.4997 - val_acc: 0.2482\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.5914 - acc: 0.2718 - val_loss: 0.4988 - val_acc: 0.2340\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6100 - acc: 0.2718 - val_loss: 0.4938 - val_acc: 0.2482\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.5842 - acc: 0.2994 - val_loss: 0.4875 - val_acc: 0.2624\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.5663 - acc: 0.3057 - val_loss: 0.4830 - val_acc: 0.3333\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.5726 - acc: 0.3079 - val_loss: 0.4843 - val_acc: 0.2837\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.5776 - acc: 0.2994 - val_loss: 0.4769 - val_acc: 0.2979\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.5693 - acc: 0.3206 - val_loss: 0.4715 - val_acc: 0.3333\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.5599 - acc: 0.3163 - val_loss: 0.4937 - val_acc: 0.3617\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.5869 - acc: 0.3015 - val_loss: 0.4804 - val_acc: 0.2766\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.5835 - acc: 0.2909 - val_loss: 0.4835 - val_acc: 0.2553\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6094 - acc: 0.2930 - val_loss: 0.4727 - val_acc: 0.2908\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.5979 - acc: 0.2845 - val_loss: 0.4623 - val_acc: 0.2837\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6114 - acc: 0.2590 - val_loss: 0.4640 - val_acc: 0.2908\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6041 - acc: 0.2654 - val_loss: 0.4647 - val_acc: 0.2979\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.5893 - acc: 0.2845 - val_loss: 0.4632 - val_acc: 0.3050\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.5851 - acc: 0.2696 - val_loss: 0.4561 - val_acc: 0.3191\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.5779 - acc: 0.2824 - val_loss: 0.4681 - val_acc: 0.2908\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.5628 - acc: 0.2887 - val_loss: 0.4797 - val_acc: 0.2766\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.5835 - acc: 0.3100 - val_loss: 0.4858 - val_acc: 0.2553\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6126 - acc: 0.2781 - val_loss: 0.4870 - val_acc: 0.2553\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6237 - acc: 0.2781 - val_loss: 0.4765 - val_acc: 0.2766\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6156 - acc: 0.2739 - val_loss: 0.4581 - val_acc: 0.2979\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.5980 - acc: 0.2887 - val_loss: 0.4784 - val_acc: 0.2411\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6346 - acc: 0.2548 - val_loss: 0.4942 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6326 - acc: 0.2484 - val_loss: 0.4737 - val_acc: 0.2979\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6104 - acc: 0.2675 - val_loss: 0.4641 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6082 - acc: 0.2909 - val_loss: 0.4732 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 147us/step\n",
      "Test score: 0.4731989414133924\n",
      "Look! softmax softsign softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax softsign elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_193 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_728 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_538 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_729 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_539 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_730 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 43ms/step - loss: nan - acc: 0.4501 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 146us/step\n",
      "Test score: nan\n",
      "Look! softmax softsign softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax softsign softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_194 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_731 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_540 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_732 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_541 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_733 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 42ms/step - loss: nan - acc: 0.4820 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 141us/step\n",
      "Test score: nan\n",
      "Look! softmax softsign relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_195 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_734 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_542 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_735 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_543 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_736 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 42ms/step - loss: nan - acc: 0.4310 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 175us/step\n",
      "Test score: nan\n",
      "Look! softmax softsign tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax softsign tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_196 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_737 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_544 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_738 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_545 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_739 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 43ms/step - loss: 0.7257 - acc: 0.2569 - val_loss: 0.5815 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7173 - acc: 0.2611 - val_loss: 0.5744 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7096 - acc: 0.2527 - val_loss: 0.5677 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7060 - acc: 0.2611 - val_loss: 0.5611 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6936 - acc: 0.2548 - val_loss: 0.5550 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6854 - acc: 0.2548 - val_loss: 0.5524 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6712 - acc: 0.2590 - val_loss: 0.5443 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6659 - acc: 0.2590 - val_loss: 0.5411 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6648 - acc: 0.2569 - val_loss: 0.5349 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6702 - acc: 0.2569 - val_loss: 0.5344 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6612 - acc: 0.2590 - val_loss: 0.5278 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6634 - acc: 0.2590 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6459 - acc: 0.2590 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6566 - acc: 0.2590 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6579 - acc: 0.2590 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6539 - acc: 0.2590 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6508 - acc: 0.2590 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6430 - acc: 0.2611 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6555 - acc: 0.2590 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6401 - acc: 0.2611 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6301 - acc: 0.2654 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6417 - acc: 0.2633 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6251 - acc: 0.2654 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6409 - acc: 0.2611 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6260 - acc: 0.2633 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6231 - acc: 0.2654 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6396 - acc: 0.2633 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6455 - acc: 0.2611 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6265 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6345 - acc: 0.2611 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6278 - acc: 0.2611 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6187 - acc: 0.2654 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6379 - acc: 0.2654 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6242 - acc: 0.2675 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6268 - acc: 0.2675 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6284 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6192 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6179 - acc: 0.2675 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6178 - acc: 0.2675 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6222 - acc: 0.2654 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6137 - acc: 0.2675 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6212 - acc: 0.2696 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6165 - acc: 0.2696 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6256 - acc: 0.2633 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6225 - acc: 0.2654 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6205 - acc: 0.2633 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6238 - acc: 0.2654 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6246 - acc: 0.2633 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6168 - acc: 0.2654 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6105 - acc: 0.2696 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6165 - acc: 0.2654 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6227 - acc: 0.2675 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6341 - acc: 0.2611 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6118 - acc: 0.2696 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6183 - acc: 0.2696 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6038 - acc: 0.2696 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6254 - acc: 0.2654 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6211 - acc: 0.2633 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6158 - acc: 0.2675 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6206 - acc: 0.2633 - val_loss: 0.5189 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6224 - acc: 0.2696 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6201 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6185 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6063 - acc: 0.2696 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6189 - acc: 0.2654 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6135 - acc: 0.2675 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6196 - acc: 0.2654 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6168 - acc: 0.2654 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6156 - acc: 0.2633 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6155 - acc: 0.2654 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6236 - acc: 0.2633 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6115 - acc: 0.2696 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6170 - acc: 0.2633 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6194 - acc: 0.2633 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6294 - acc: 0.2611 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6210 - acc: 0.2654 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6210 - acc: 0.2654 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6073 - acc: 0.2675 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6077 - acc: 0.2675 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6104 - acc: 0.2675 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6086 - acc: 0.2675 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6155 - acc: 0.2696 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6082 - acc: 0.2696 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6107 - acc: 0.2675 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6212 - acc: 0.2654 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6136 - acc: 0.2675 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6065 - acc: 0.2718 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6202 - acc: 0.2654 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6078 - acc: 0.2696 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6173 - acc: 0.2675 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6122 - acc: 0.2675 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6122 - acc: 0.2675 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6123 - acc: 0.2654 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6084 - acc: 0.2696 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6018 - acc: 0.2718 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6290 - acc: 0.2590 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6183 - acc: 0.2654 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6263 - acc: 0.2633 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6114 - acc: 0.2654 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6207 - acc: 0.2611 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6246 - acc: 0.2611 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6054 - acc: 0.2696 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6250 - acc: 0.2611 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6217 - acc: 0.2654 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6170 - acc: 0.2654 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6255 - acc: 0.2654 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6141 - acc: 0.2654 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6135 - acc: 0.2675 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6128 - acc: 0.2675 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6145 - acc: 0.2654 - val_loss: 0.5276 - val_acc: 0.2057\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6195 - acc: 0.2611 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6059 - acc: 0.2696 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6146 - acc: 0.2675 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6160 - acc: 0.2654 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6150 - acc: 0.2654 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6111 - acc: 0.2654 - val_loss: 0.5594 - val_acc: 0.1773\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6367 - acc: 0.2569 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6249 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6304 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 144us/step\n",
      "Test score: 0.5118402496297308\n",
      "Look! softmax softsign sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax softsign tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_197 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_740 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_546 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_741 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_547 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_742 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 44ms/step - loss: 0.7427 - acc: 0.2675 - val_loss: 0.6001 - val_acc: 0.0567\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7313 - acc: 0.2845 - val_loss: 0.5869 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.7201 - acc: 0.2569 - val_loss: 0.5817 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7134 - acc: 0.2548 - val_loss: 0.5762 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7085 - acc: 0.2590 - val_loss: 0.5709 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6998 - acc: 0.2590 - val_loss: 0.5654 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6964 - acc: 0.2569 - val_loss: 0.5601 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6942 - acc: 0.2611 - val_loss: 0.5562 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6870 - acc: 0.2569 - val_loss: 0.5521 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6781 - acc: 0.2611 - val_loss: 0.5455 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6782 - acc: 0.2590 - val_loss: 0.5409 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6702 - acc: 0.2590 - val_loss: 0.5367 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6652 - acc: 0.2590 - val_loss: 0.5330 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6648 - acc: 0.2590 - val_loss: 0.5297 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6654 - acc: 0.2590 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6955 - acc: 0.2590 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6579 - acc: 0.2590 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6837 - acc: 0.2590 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6714 - acc: 0.2590 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6867 - acc: 0.2590 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6466 - acc: 0.2611 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6440 - acc: 0.2611 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6413 - acc: 0.2590 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6416 - acc: 0.2590 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6443 - acc: 0.2484 - val_loss: 0.5086 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6357 - acc: 0.2633 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6329 - acc: 0.2611 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6517 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6365 - acc: 0.2654 - val_loss: 0.5055 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6272 - acc: 0.2654 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6281 - acc: 0.2654 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6471 - acc: 0.2633 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6345 - acc: 0.2611 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6334 - acc: 0.2611 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6308 - acc: 0.2718 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6409 - acc: 0.2675 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6331 - acc: 0.2696 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6350 - acc: 0.2611 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6273 - acc: 0.2696 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6176 - acc: 0.2718 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6246 - acc: 0.2760 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6225 - acc: 0.2718 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6169 - acc: 0.2675 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6188 - acc: 0.2718 - val_loss: 0.5042 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6116 - acc: 0.2611 - val_loss: 0.4950 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6250 - acc: 0.2654 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6156 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6264 - acc: 0.2633 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6722 - acc: 0.2654 - val_loss: 0.5126 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6216 - acc: 0.2633 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6226 - acc: 0.2654 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6170 - acc: 0.2654 - val_loss: 0.4963 - val_acc: 0.2411\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6936 - acc: 0.2038 - val_loss: 0.5360 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6800 - acc: 0.1996 - val_loss: 0.4967 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6279 - acc: 0.2569 - val_loss: 0.5034 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6270 - acc: 0.2654 - val_loss: 0.5074 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6368 - acc: 0.2675 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6330 - acc: 0.2611 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6334 - acc: 0.2611 - val_loss: 0.5036 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6211 - acc: 0.2590 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6205 - acc: 0.2739 - val_loss: 0.5020 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6116 - acc: 0.2718 - val_loss: 0.4982 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6221 - acc: 0.2590 - val_loss: 0.4974 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6173 - acc: 0.2654 - val_loss: 0.4974 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6173 - acc: 0.2718 - val_loss: 0.5018 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6218 - acc: 0.2633 - val_loss: 0.5018 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6195 - acc: 0.2696 - val_loss: 0.5016 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6208 - acc: 0.2760 - val_loss: 0.5065 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6714 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6188 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6168 - acc: 0.2654 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6169 - acc: 0.2675 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6108 - acc: 0.2675 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6133 - acc: 0.2696 - val_loss: 0.5012 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6164 - acc: 0.2633 - val_loss: 0.5006 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6120 - acc: 0.2781 - val_loss: 0.4951 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6256 - acc: 0.2696 - val_loss: 0.4923 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6287 - acc: 0.2909 - val_loss: 0.4951 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6059 - acc: 0.2887 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6126 - acc: 0.2633 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6066 - acc: 0.2675 - val_loss: 0.5062 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6098 - acc: 0.2654 - val_loss: 0.5082 - val_acc: 0.2199\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6072 - acc: 0.2760 - val_loss: 0.5141 - val_acc: 0.2199\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6171 - acc: 0.2633 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6416 - acc: 0.2718 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6079 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6051 - acc: 0.2739 - val_loss: 0.5012 - val_acc: 0.2199\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.5974 - acc: 0.2803 - val_loss: 0.5016 - val_acc: 0.2270\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6227 - acc: 0.2654 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6298 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6341 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6319 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6096 - acc: 0.2718 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6110 - acc: 0.2696 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.5952 - acc: 0.2803 - val_loss: 0.4931 - val_acc: 0.2411\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6078 - acc: 0.2718 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6055 - acc: 0.2760 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6121 - acc: 0.2696 - val_loss: 0.5035 - val_acc: 0.2270\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.5904 - acc: 0.2845 - val_loss: 0.4898 - val_acc: 0.2482\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.5935 - acc: 0.2803 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.5981 - acc: 0.2739 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6127 - acc: 0.2696 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.5903 - acc: 0.2803 - val_loss: 0.4965 - val_acc: 0.2340\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.5964 - acc: 0.2739 - val_loss: 0.4983 - val_acc: 0.2199\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6004 - acc: 0.2696 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.5928 - acc: 0.2760 - val_loss: 0.5156 - val_acc: 0.2199\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6041 - acc: 0.2760 - val_loss: 0.5153 - val_acc: 0.2199\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6058 - acc: 0.2718 - val_loss: 0.5155 - val_acc: 0.2199\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.5989 - acc: 0.2739 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.5804 - acc: 0.2824 - val_loss: 0.5156 - val_acc: 0.2199\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.5982 - acc: 0.2760 - val_loss: 0.5152 - val_acc: 0.2199\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.5934 - acc: 0.2718 - val_loss: 0.5155 - val_acc: 0.2199\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.5935 - acc: 0.2760 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6419 - acc: 0.2654 - val_loss: 0.4901 - val_acc: 0.2411\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6975 - acc: 0.2781 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6001 - acc: 0.2654 - val_loss: 0.5157 - val_acc: 0.2057\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6112 - acc: 0.2633 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6210 - acc: 0.2611 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6169 - acc: 0.2633 - val_loss: 0.4804 - val_acc: 0.2482\n",
      "141/141 [==============================] - 0s 143us/step\n",
      "Test score: 0.4803989271745614\n",
      "Look! softmax softsign hard_sigmoid Test accuracy: 0.24822695141142986\n",
      "max there  0.6241134772909448 softmax softsign tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_198 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_743 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_548 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_744 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_549 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_745 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 20s 43ms/step - loss: 3.5669 - acc: 0.2378 - val_loss: 3.5652 - val_acc: 0.3262\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.6624 - acc: 0.2696 - val_loss: 1.5570 - val_acc: 0.2270\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 3.0463 - acc: 0.2930 - val_loss: 1.4802 - val_acc: 0.1135\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.4138 - acc: 0.2017 - val_loss: 0.7511 - val_acc: 0.0780\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.0534 - acc: 0.2442 - val_loss: 0.5457 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.7600 - acc: 0.2144 - val_loss: 0.5453 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 2.5304 - acc: 0.1868 - val_loss: 0.5416 - val_acc: 0.0426\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.9356 - acc: 0.2760 - val_loss: 0.5425 - val_acc: 0.0426\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.8252 - acc: 0.2102 - val_loss: 0.5454 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.2878 - acc: 0.1656 - val_loss: 0.5423 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 2.2502 - acc: 0.1699 - val_loss: 0.5392 - val_acc: 0.0355\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 2.4613 - acc: 0.1911 - val_loss: 0.5379 - val_acc: 0.0355\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.2012 - acc: 0.1762 - val_loss: 0.5363 - val_acc: 0.0496\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.5767 - acc: 0.2420 - val_loss: 0.5310 - val_acc: 0.3262\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.3133 - acc: 0.2845 - val_loss: 0.5149 - val_acc: 0.2695\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 2.3065 - acc: 0.2696 - val_loss: 0.5337 - val_acc: 0.0496\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.7431 - acc: 0.2144 - val_loss: 0.5337 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.6029 - acc: 0.1932 - val_loss: 0.5328 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.5022 - acc: 0.2123 - val_loss: 0.5322 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.3961 - acc: 0.1890 - val_loss: 0.5327 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.6576 - acc: 0.1486 - val_loss: 0.5331 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.3485 - acc: 0.1614 - val_loss: 0.5338 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.4153 - acc: 0.2123 - val_loss: 0.5313 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.3174 - acc: 0.1911 - val_loss: 0.5309 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.2723 - acc: 0.1911 - val_loss: 0.5309 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.1910 - acc: 0.2166 - val_loss: 0.5312 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.4819 - acc: 0.2102 - val_loss: 0.5310 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.5416 - acc: 0.1826 - val_loss: 0.5308 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.1826 - acc: 0.1911 - val_loss: 0.5304 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.4577 - acc: 0.2081 - val_loss: 0.6174 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.4651 - acc: 0.2038 - val_loss: 0.5301 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.2717 - acc: 0.1932 - val_loss: 0.5301 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.6292 - acc: 0.1953 - val_loss: 0.6319 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.7210 - acc: 0.2187 - val_loss: 0.5299 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.1788 - acc: 0.2017 - val_loss: 0.5297 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.9362 - acc: 0.2059 - val_loss: 0.5293 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.1643 - acc: 0.1805 - val_loss: 0.5289 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.0669 - acc: 0.1911 - val_loss: 0.5284 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 2.2020 - acc: 0.2038 - val_loss: 0.5280 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 2.2154 - acc: 0.1762 - val_loss: 0.5284 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.7493 - acc: 0.1975 - val_loss: 0.5302 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.9814 - acc: 0.2166 - val_loss: 0.5324 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 3.0656 - acc: 0.2017 - val_loss: 0.5338 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 2.9212 - acc: 0.2123 - val_loss: 0.5344 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.7793 - acc: 0.2335 - val_loss: 0.5347 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.6672 - acc: 0.2229 - val_loss: 0.5343 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.0237 - acc: 0.2123 - val_loss: 0.5329 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.2800 - acc: 0.1868 - val_loss: 0.5311 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.0259 - acc: 0.2038 - val_loss: 0.5297 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.9311 - acc: 0.1656 - val_loss: 0.5286 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.8568 - acc: 0.1783 - val_loss: 0.5278 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.8626 - acc: 0.1614 - val_loss: 0.5272 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7226 - acc: 0.1529 - val_loss: 0.5269 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.7103 - acc: 0.1762 - val_loss: 0.5265 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7697 - acc: 0.1783 - val_loss: 0.5261 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6744 - acc: 0.1720 - val_loss: 0.5257 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7319 - acc: 0.2038 - val_loss: 0.5253 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7282 - acc: 0.1932 - val_loss: 0.5250 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7064 - acc: 0.1826 - val_loss: 0.5247 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7069 - acc: 0.2038 - val_loss: 0.5244 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.7821 - acc: 0.2038 - val_loss: 0.5245 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.7089 - acc: 0.1805 - val_loss: 0.5247 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7188 - acc: 0.1571 - val_loss: 0.5247 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7128 - acc: 0.1975 - val_loss: 0.6378 - val_acc: 0.0993\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.8197 - acc: 0.1911 - val_loss: 0.5243 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.7656 - acc: 0.1592 - val_loss: 0.5244 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6742 - acc: 0.2102 - val_loss: 0.5257 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6879 - acc: 0.2272 - val_loss: 0.5267 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7224 - acc: 0.2994 - val_loss: 0.5274 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.7676 - acc: 0.2887 - val_loss: 0.5279 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7648 - acc: 0.2887 - val_loss: 0.5283 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7039 - acc: 0.2696 - val_loss: 0.5284 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7147 - acc: 0.3036 - val_loss: 0.5284 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.7019 - acc: 0.2654 - val_loss: 0.5282 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7617 - acc: 0.2442 - val_loss: 0.5279 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6906 - acc: 0.2208 - val_loss: 0.5275 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6708 - acc: 0.2463 - val_loss: 0.5271 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6821 - acc: 0.2251 - val_loss: 0.5266 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6959 - acc: 0.2081 - val_loss: 0.5261 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6854 - acc: 0.2229 - val_loss: 0.5256 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7159 - acc: 0.2420 - val_loss: 0.5252 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6900 - acc: 0.2611 - val_loss: 0.5249 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7729 - acc: 0.2208 - val_loss: 0.5248 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.7775 - acc: 0.2378 - val_loss: 0.5397 - val_acc: 0.1844\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.9393 - acc: 0.2696 - val_loss: 0.5245 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7817 - acc: 0.2059 - val_loss: 0.5242 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6739 - acc: 0.2081 - val_loss: 0.5239 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.7349 - acc: 0.1996 - val_loss: 0.5236 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7472 - acc: 0.2272 - val_loss: 0.5233 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7400 - acc: 0.2038 - val_loss: 0.5230 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6966 - acc: 0.2251 - val_loss: 0.5226 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7153 - acc: 0.2357 - val_loss: 0.5223 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6798 - acc: 0.2378 - val_loss: 0.5221 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6790 - acc: 0.2187 - val_loss: 0.5218 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7791 - acc: 0.2357 - val_loss: 0.5216 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6987 - acc: 0.2166 - val_loss: 0.5214 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6707 - acc: 0.2442 - val_loss: 0.5211 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6795 - acc: 0.2081 - val_loss: 0.5209 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6741 - acc: 0.2144 - val_loss: 0.5207 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6725 - acc: 0.1975 - val_loss: 0.5205 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6663 - acc: 0.1847 - val_loss: 0.5203 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6688 - acc: 0.1996 - val_loss: 0.5201 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6736 - acc: 0.2548 - val_loss: 0.5199 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.7229 - acc: 0.2059 - val_loss: 0.5200 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6955 - acc: 0.2038 - val_loss: 0.5199 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6855 - acc: 0.2123 - val_loss: 0.5200 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7005 - acc: 0.1847 - val_loss: 0.5203 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6538 - acc: 0.2272 - val_loss: 0.5204 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7239 - acc: 0.2102 - val_loss: 0.5204 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6790 - acc: 0.2272 - val_loss: 0.5204 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7538 - acc: 0.2357 - val_loss: 0.5202 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6866 - acc: 0.2144 - val_loss: 0.5201 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7189 - acc: 0.2463 - val_loss: 0.5201 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6635 - acc: 0.2208 - val_loss: 0.5201 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7156 - acc: 0.2144 - val_loss: 0.5202 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.7327 - acc: 0.2102 - val_loss: 0.5203 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6853 - acc: 0.1911 - val_loss: 0.5205 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6803 - acc: 0.2229 - val_loss: 0.5205 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.7014 - acc: 0.2166 - val_loss: 0.5205 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6440 - acc: 0.1911 - val_loss: 0.5205 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 152us/step\n",
      "Test score: 0.5204735875975156\n",
      "Look! softmax softsign linear Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax softsign tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_199 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_746 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_550 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_747 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_551 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_748 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 44ms/step - loss: 0.7130 - acc: 0.2484 - val_loss: 0.5803 - val_acc: 0.1489\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.7038 - acc: 0.2229 - val_loss: 0.5656 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6916 - acc: 0.2357 - val_loss: 0.5591 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6852 - acc: 0.2357 - val_loss: 0.5536 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6837 - acc: 0.2484 - val_loss: 0.5456 - val_acc: 0.2199\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6731 - acc: 0.2633 - val_loss: 0.5492 - val_acc: 0.1773\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.7036 - acc: 0.1996 - val_loss: 0.5696 - val_acc: 0.0851\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6810 - acc: 0.2335 - val_loss: 0.5316 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6648 - acc: 0.2633 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6572 - acc: 0.2569 - val_loss: 0.5355 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6534 - acc: 0.2569 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6583 - acc: 0.2548 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6554 - acc: 0.2611 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6568 - acc: 0.2548 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6419 - acc: 0.2654 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6579 - acc: 0.2527 - val_loss: 0.5441 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6510 - acc: 0.2633 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6384 - acc: 0.2569 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6627 - acc: 0.2569 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6472 - acc: 0.2569 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6644 - acc: 0.2569 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6290 - acc: 0.2569 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6370 - acc: 0.2590 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6403 - acc: 0.2527 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6268 - acc: 0.2569 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6306 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6414 - acc: 0.2548 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6266 - acc: 0.2527 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6366 - acc: 0.2569 - val_loss: 0.5127 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6413 - acc: 0.2548 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6415 - acc: 0.2505 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6348 - acc: 0.2484 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6325 - acc: 0.2569 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6445 - acc: 0.2569 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6236 - acc: 0.2569 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6265 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6379 - acc: 0.2548 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6303 - acc: 0.2633 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6286 - acc: 0.2569 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6270 - acc: 0.2611 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6331 - acc: 0.2548 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6218 - acc: 0.2654 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6200 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6261 - acc: 0.2654 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6260 - acc: 0.2590 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6232 - acc: 0.2611 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6163 - acc: 0.2633 - val_loss: 0.5491 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6540 - acc: 0.2357 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6235 - acc: 0.2675 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6236 - acc: 0.2611 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6230 - acc: 0.2654 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6368 - acc: 0.2527 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6002 - acc: 0.2675 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6210 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6175 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6204 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6244 - acc: 0.2633 - val_loss: 0.5030 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.5971 - acc: 0.2696 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6290 - acc: 0.2442 - val_loss: 0.5021 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6140 - acc: 0.2633 - val_loss: 0.5104 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6184 - acc: 0.2633 - val_loss: 0.5104 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6115 - acc: 0.2633 - val_loss: 0.4993 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6089 - acc: 0.2760 - val_loss: 0.5011 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.5999 - acc: 0.2696 - val_loss: 0.4989 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6121 - acc: 0.2654 - val_loss: 0.4995 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6209 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6183 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6219 - acc: 0.2590 - val_loss: 0.5087 - val_acc: 0.2270\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.5927 - acc: 0.2718 - val_loss: 0.5008 - val_acc: 0.2411\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6146 - acc: 0.2824 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6251 - acc: 0.2569 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6333 - acc: 0.2548 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6435 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6339 - acc: 0.2569 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6349 - acc: 0.2548 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6395 - acc: 0.2569 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6380 - acc: 0.2569 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: 0.6283 - acc: 0.2548 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6223 - acc: 0.2569 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6320 - acc: 0.2675 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6363 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6308 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6368 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6300 - acc: 0.2569 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6367 - acc: 0.2569 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6253 - acc: 0.2611 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6262 - acc: 0.2611 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6365 - acc: 0.2611 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6274 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6286 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6295 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6278 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6214 - acc: 0.2633 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6297 - acc: 0.2633 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6332 - acc: 0.2611 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6312 - acc: 0.2611 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6368 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6240 - acc: 0.2611 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6224 - acc: 0.2675 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6289 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6205 - acc: 0.2654 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6084 - acc: 0.2696 - val_loss: 0.5153 - val_acc: 0.2340\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6080 - acc: 0.2739 - val_loss: 0.5068 - val_acc: 0.2411\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6167 - acc: 0.2590 - val_loss: 0.4981 - val_acc: 0.2553\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6027 - acc: 0.2654 - val_loss: 0.4988 - val_acc: 0.2553\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6009 - acc: 0.2718 - val_loss: 0.5023 - val_acc: 0.2553\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.5931 - acc: 0.2781 - val_loss: 0.5014 - val_acc: 0.2553\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6323 - acc: 0.2505 - val_loss: 0.5048 - val_acc: 0.2766\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6015 - acc: 0.2739 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6212 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6249 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6319 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6278 - acc: 0.2590 - val_loss: 0.5083 - val_acc: 0.2411\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6145 - acc: 0.2760 - val_loss: 0.5017 - val_acc: 0.2624\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6231 - acc: 0.2696 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6098 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6353 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 163us/step\n",
      "Test score: 0.5114630021102039\n",
      "Look! softmax relu softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax softsign tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_200 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_749 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_552 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_750 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_553 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_751 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 44ms/step - loss: nan - acc: 0.4777 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 154us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 149us/step\n",
      "Test score: nan\n",
      "Look! softmax relu elu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax relu elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_201 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_752 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_554 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_753 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_555 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_754 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 44ms/step - loss: nan - acc: 0.4926 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 156us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 146us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 156us/step\n",
      "Test score: nan\n",
      "Look! softmax relu selu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax relu selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_202 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_755 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_556 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_756 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_557 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_757 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 44ms/step - loss: 0.7271 - acc: 0.2272 - val_loss: 0.5849 - val_acc: 0.2057\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7188 - acc: 0.2314 - val_loss: 0.5769 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7014 - acc: 0.2590 - val_loss: 0.5695 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7000 - acc: 0.2505 - val_loss: 0.5634 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6887 - acc: 0.2505 - val_loss: 0.5579 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6827 - acc: 0.2633 - val_loss: 0.5525 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6792 - acc: 0.2569 - val_loss: 0.5480 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6808 - acc: 0.2633 - val_loss: 0.5431 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6837 - acc: 0.2633 - val_loss: 0.5397 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6567 - acc: 0.2590 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6644 - acc: 0.2633 - val_loss: 0.5331 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6647 - acc: 0.2611 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6448 - acc: 0.2548 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6581 - acc: 0.2611 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6513 - acc: 0.2590 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6485 - acc: 0.2633 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6554 - acc: 0.2590 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6658 - acc: 0.2590 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6322 - acc: 0.2611 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6420 - acc: 0.2590 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6343 - acc: 0.2633 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6416 - acc: 0.2611 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6520 - acc: 0.2590 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6463 - acc: 0.2590 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6462 - acc: 0.2590 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6392 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6495 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6477 - acc: 0.2569 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6571 - acc: 0.2569 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6313 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6420 - acc: 0.2590 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6450 - acc: 0.2590 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6433 - acc: 0.2569 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6336 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6358 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6343 - acc: 0.2569 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6313 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6276 - acc: 0.2569 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6286 - acc: 0.2590 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6282 - acc: 0.2569 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6404 - acc: 0.2569 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6402 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6168 - acc: 0.2569 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6369 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6271 - acc: 0.2590 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6227 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6294 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6373 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6403 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6356 - acc: 0.2569 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6366 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6325 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6355 - acc: 0.2569 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6375 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6369 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6290 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6380 - acc: 0.2569 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6362 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6310 - acc: 0.2569 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6334 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6286 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6369 - acc: 0.2590 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6303 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6302 - acc: 0.2611 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6278 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6320 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6315 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6304 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6289 - acc: 0.2590 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6308 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6283 - acc: 0.2505 - val_loss: 0.5323 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6712 - acc: 0.2314 - val_loss: 0.5279 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6440 - acc: 0.2611 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6412 - acc: 0.2611 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6287 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6378 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6400 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6331 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6259 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6280 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6372 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6313 - acc: 0.2633 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6363 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6408 - acc: 0.2611 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6375 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6371 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6389 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6312 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6261 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6376 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6375 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6300 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6386 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6362 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6361 - acc: 0.2590 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6311 - acc: 0.2569 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6334 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6386 - acc: 0.2590 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6413 - acc: 0.2569 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6293 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6311 - acc: 0.2611 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6309 - acc: 0.2590 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6350 - acc: 0.2590 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6361 - acc: 0.2569 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6345 - acc: 0.2590 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6396 - acc: 0.2590 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 144us/step\n",
      "Test score: 0.5143342026582001\n",
      "Look! softmax relu softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax relu selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_203 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_758 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_558 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_759 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_559 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_760 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 44ms/step - loss: nan - acc: 0.4565 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 146us/step\n",
      "Test score: nan\n",
      "Look! softmax relu softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax relu softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_204 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_761 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_560 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_762 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_561 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_763 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 45ms/step - loss: nan - acc: 0.5011 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 144us/step\n",
      "Test score: nan\n",
      "Look! softmax relu relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax relu relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_205 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_764 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_562 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_765 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_563 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_766 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 45ms/step - loss: nan - acc: 0.4692 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 159us/step\n",
      "Test score: nan\n",
      "Look! softmax relu tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax relu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_206 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_767 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_564 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_768 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_565 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_769 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 45ms/step - loss: 0.7234 - acc: 0.2251 - val_loss: 0.5850 - val_acc: 0.2270\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.7199 - acc: 0.2484 - val_loss: 0.5807 - val_acc: 0.2553\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7171 - acc: 0.2463 - val_loss: 0.5775 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7155 - acc: 0.2378 - val_loss: 0.5725 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7052 - acc: 0.2590 - val_loss: 0.5686 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7024 - acc: 0.2569 - val_loss: 0.5648 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6989 - acc: 0.2633 - val_loss: 0.5611 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6957 - acc: 0.2548 - val_loss: 0.5575 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6832 - acc: 0.2590 - val_loss: 0.5538 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6789 - acc: 0.2611 - val_loss: 0.5500 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6738 - acc: 0.2611 - val_loss: 0.5465 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6813 - acc: 0.2590 - val_loss: 0.5588 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6867 - acc: 0.2611 - val_loss: 0.5621 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6889 - acc: 0.2399 - val_loss: 0.5575 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6824 - acc: 0.2527 - val_loss: 0.5522 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6748 - acc: 0.2590 - val_loss: 0.5472 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6652 - acc: 0.2633 - val_loss: 0.5427 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6639 - acc: 0.2611 - val_loss: 0.5386 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6517 - acc: 0.2611 - val_loss: 0.5346 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6592 - acc: 0.2590 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6521 - acc: 0.2590 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6488 - acc: 0.2590 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6541 - acc: 0.2590 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6455 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6542 - acc: 0.2590 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6470 - acc: 0.2590 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6434 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6501 - acc: 0.2590 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6478 - acc: 0.2590 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6497 - acc: 0.2590 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6490 - acc: 0.2590 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6402 - acc: 0.2590 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6421 - acc: 0.2590 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6400 - acc: 0.2590 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6226 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6353 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6311 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6312 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6425 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6407 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6419 - acc: 0.2590 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6402 - acc: 0.2590 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6366 - acc: 0.2590 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6388 - acc: 0.2590 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6345 - acc: 0.2590 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6395 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6382 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6262 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6315 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6322 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6338 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6322 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6275 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6420 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6325 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6267 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6292 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6263 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6372 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6341 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6307 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6306 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6306 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6399 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6341 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6339 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6291 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6272 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6290 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6280 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6252 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6329 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6359 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6339 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6368 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6300 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6277 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6269 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6322 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6317 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6285 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6245 - acc: 0.2611 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6297 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6314 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6255 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6282 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6346 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6299 - acc: 0.2611 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6226 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6253 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6274 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6341 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6350 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6243 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6320 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6315 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6229 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6292 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6342 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6276 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6295 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6222 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6259 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 150us/step\n",
      "Test score: 0.511503610205143\n",
      "Look! softmax relu sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax relu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_207 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_770 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_566 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_771 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_567 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_772 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 45ms/step - loss: 0.7308 - acc: 0.2527 - val_loss: 0.5908 - val_acc: 0.1844\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.7220 - acc: 0.2463 - val_loss: 0.5850 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7126 - acc: 0.2611 - val_loss: 0.5810 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.7105 - acc: 0.2654 - val_loss: 0.5771 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.7071 - acc: 0.2505 - val_loss: 0.5733 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7010 - acc: 0.2569 - val_loss: 0.5695 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6966 - acc: 0.2569 - val_loss: 0.5658 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6994 - acc: 0.2590 - val_loss: 0.5622 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6815 - acc: 0.2590 - val_loss: 0.5585 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6880 - acc: 0.2590 - val_loss: 0.5551 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6900 - acc: 0.2569 - val_loss: 0.5520 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6760 - acc: 0.2569 - val_loss: 0.5486 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6709 - acc: 0.2590 - val_loss: 0.5464 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6657 - acc: 0.2590 - val_loss: 0.5432 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6600 - acc: 0.2590 - val_loss: 0.5392 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6506 - acc: 0.2590 - val_loss: 0.5365 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6530 - acc: 0.2590 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6622 - acc: 0.2611 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6565 - acc: 0.2611 - val_loss: 0.5305 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6389 - acc: 0.2590 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6430 - acc: 0.2590 - val_loss: 0.5271 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6587 - acc: 0.2590 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6686 - acc: 0.2590 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6579 - acc: 0.2590 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6622 - acc: 0.2590 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6849 - acc: 0.2590 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6391 - acc: 0.2590 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6298 - acc: 0.2590 - val_loss: 0.5241 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6627 - acc: 0.2590 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6304 - acc: 0.2611 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6491 - acc: 0.2590 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6305 - acc: 0.2611 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6422 - acc: 0.2590 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6406 - acc: 0.2590 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6313 - acc: 0.2654 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6223 - acc: 0.2633 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6401 - acc: 0.2611 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6444 - acc: 0.2611 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6647 - acc: 0.2633 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6395 - acc: 0.2633 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6288 - acc: 0.2633 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6268 - acc: 0.2611 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6241 - acc: 0.2590 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6278 - acc: 0.2633 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6267 - acc: 0.2633 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6241 - acc: 0.2654 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6342 - acc: 0.2633 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6469 - acc: 0.2654 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6313 - acc: 0.2675 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 180us/step - loss: 0.6342 - acc: 0.2633 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6274 - acc: 0.2654 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6249 - acc: 0.2654 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6350 - acc: 0.2527 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: 0.6297 - acc: 0.2654 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6611 - acc: 0.2590 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6263 - acc: 0.2590 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6368 - acc: 0.2590 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6378 - acc: 0.2590 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6690 - acc: 0.2590 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6289 - acc: 0.2590 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6391 - acc: 0.2590 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6370 - acc: 0.2590 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6277 - acc: 0.2590 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6421 - acc: 0.2590 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6243 - acc: 0.2590 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6277 - acc: 0.2590 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6238 - acc: 0.2611 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6231 - acc: 0.2590 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6249 - acc: 0.2590 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 155us/step - loss: 0.6280 - acc: 0.2590 - val_loss: 0.5201 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: 0.6276 - acc: 0.2590 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6190 - acc: 0.2611 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6202 - acc: 0.2611 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6214 - acc: 0.2590 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6285 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6226 - acc: 0.2590 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6266 - acc: 0.2611 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6493 - acc: 0.2675 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6255 - acc: 0.2633 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6236 - acc: 0.2633 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6337 - acc: 0.2696 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6242 - acc: 0.2654 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6236 - acc: 0.2654 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6201 - acc: 0.2675 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6356 - acc: 0.2611 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6166 - acc: 0.2696 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6162 - acc: 0.2718 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6302 - acc: 0.2633 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6288 - acc: 0.2633 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6165 - acc: 0.2718 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6207 - acc: 0.2675 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6241 - acc: 0.2654 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6226 - acc: 0.2696 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6247 - acc: 0.2675 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6204 - acc: 0.2675 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6198 - acc: 0.2718 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6232 - acc: 0.2633 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6187 - acc: 0.2654 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6096 - acc: 0.2696 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6066 - acc: 0.2739 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6258 - acc: 0.2633 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6244 - acc: 0.2675 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6302 - acc: 0.2611 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6243 - acc: 0.2611 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6348 - acc: 0.2611 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6696 - acc: 0.2590 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6604 - acc: 0.2611 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6412 - acc: 0.2611 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6326 - acc: 0.2590 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6280 - acc: 0.2611 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6389 - acc: 0.2611 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 159us/step - loss: 0.6278 - acc: 0.2633 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 159us/step\n",
      "Test score: 0.5209792412764637\n",
      "Look! softmax relu hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax relu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_208 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_773 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_568 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_774 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_569 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_775 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 46ms/step - loss: nan - acc: 0.4352 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 153us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 169us/step\n",
      "Test score: nan\n",
      "Look! softmax relu linear Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax relu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_209 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_776 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_570 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_777 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_571 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_778 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 45ms/step - loss: 0.7491 - acc: 0.2484 - val_loss: 0.5864 - val_acc: 0.0993\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7166 - acc: 0.2123 - val_loss: 0.5691 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6986 - acc: 0.2208 - val_loss: 0.5560 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6829 - acc: 0.2272 - val_loss: 0.5446 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6756 - acc: 0.2548 - val_loss: 0.5358 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6536 - acc: 0.2654 - val_loss: 0.5292 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6522 - acc: 0.2569 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6649 - acc: 0.2505 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6593 - acc: 0.2569 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6510 - acc: 0.2569 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6564 - acc: 0.2654 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6512 - acc: 0.2569 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6380 - acc: 0.2484 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6558 - acc: 0.2527 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6514 - acc: 0.2527 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6619 - acc: 0.2696 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6493 - acc: 0.2569 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6576 - acc: 0.2548 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6426 - acc: 0.2569 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6563 - acc: 0.2527 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 157us/step - loss: 0.6441 - acc: 0.2654 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6374 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6329 - acc: 0.2527 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6471 - acc: 0.2548 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6453 - acc: 0.2569 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6396 - acc: 0.2569 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6358 - acc: 0.2633 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6498 - acc: 0.2527 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6356 - acc: 0.2505 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6400 - acc: 0.2569 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6548 - acc: 0.2420 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6406 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6333 - acc: 0.2527 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6379 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6394 - acc: 0.2505 - val_loss: 0.5112 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6377 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6271 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6387 - acc: 0.2633 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6367 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6426 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6318 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6347 - acc: 0.2505 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6364 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6278 - acc: 0.2463 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6352 - acc: 0.2548 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6430 - acc: 0.2505 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6295 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6365 - acc: 0.2548 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6383 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6354 - acc: 0.2505 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6404 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6260 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6295 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6339 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6423 - acc: 0.2484 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 0.6410 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6327 - acc: 0.2505 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6391 - acc: 0.2527 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6401 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6299 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6402 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6269 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6315 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6208 - acc: 0.2675 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6340 - acc: 0.2633 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6463 - acc: 0.2442 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6256 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6263 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6304 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6347 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6219 - acc: 0.2633 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6377 - acc: 0.2548 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6199 - acc: 0.2696 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6357 - acc: 0.2484 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6148 - acc: 0.2675 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6220 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6172 - acc: 0.2696 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6324 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6203 - acc: 0.2633 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6191 - acc: 0.2654 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6267 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6150 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6274 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6166 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6233 - acc: 0.2633 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6147 - acc: 0.2633 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6398 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6211 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6354 - acc: 0.2654 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6199 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6233 - acc: 0.2611 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6288 - acc: 0.2569 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6090 - acc: 0.2654 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6182 - acc: 0.2633 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6257 - acc: 0.2611 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6206 - acc: 0.2633 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6316 - acc: 0.2611 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6197 - acc: 0.2654 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6217 - acc: 0.2654 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6127 - acc: 0.2654 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6204 - acc: 0.2654 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6197 - acc: 0.2675 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6248 - acc: 0.2633 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6255 - acc: 0.2611 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6200 - acc: 0.2675 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6115 - acc: 0.2654 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6256 - acc: 0.2633 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6209 - acc: 0.2654 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6299 - acc: 0.2569 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6169 - acc: 0.2633 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6192 - acc: 0.2654 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6361 - acc: 0.2569 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6233 - acc: 0.2633 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6125 - acc: 0.2654 - val_loss: 0.5213 - val_acc: 0.2057\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6178 - acc: 0.2675 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6178 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6301 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 158us/step\n",
      "Test score: 0.5113002146389467\n",
      "Look! softmax tanh softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax relu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_210 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_779 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_572 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_780 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_573 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_781 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 46ms/step - loss: nan - acc: 0.4692 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 170us/step\n",
      "Test score: nan\n",
      "Look! softmax tanh elu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax tanh elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_211 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_782 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_574 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_783 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_575 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_784 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 21s 46ms/step - loss: nan - acc: 0.4416 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 154us/step\n",
      "Test score: nan\n",
      "Look! softmax tanh selu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax tanh selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_212 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_785 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_576 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_786 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_577 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_787 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 46ms/step - loss: 0.7201 - acc: 0.2930 - val_loss: 0.5728 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.7006 - acc: 0.2696 - val_loss: 0.5625 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6970 - acc: 0.2548 - val_loss: 0.5534 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6811 - acc: 0.2611 - val_loss: 0.5454 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6953 - acc: 0.2548 - val_loss: 0.5393 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6772 - acc: 0.2590 - val_loss: 0.5343 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6704 - acc: 0.2611 - val_loss: 0.5303 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6682 - acc: 0.2548 - val_loss: 0.5612 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6954 - acc: 0.2548 - val_loss: 0.5537 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6845 - acc: 0.2569 - val_loss: 0.5450 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6771 - acc: 0.2569 - val_loss: 0.5366 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6743 - acc: 0.2569 - val_loss: 0.5302 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6581 - acc: 0.2590 - val_loss: 0.5254 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6609 - acc: 0.2611 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6514 - acc: 0.2548 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6453 - acc: 0.2590 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 17/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 198us/step - loss: 0.6423 - acc: 0.2611 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6403 - acc: 0.2590 - val_loss: 0.5147 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6399 - acc: 0.2611 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6419 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6473 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6557 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6377 - acc: 0.2569 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6353 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6438 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6446 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6386 - acc: 0.2611 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6362 - acc: 0.2569 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6414 - acc: 0.2611 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6417 - acc: 0.2611 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6330 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6400 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6255 - acc: 0.2654 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6355 - acc: 0.2569 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6306 - acc: 0.2633 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6297 - acc: 0.2675 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6233 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6377 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6323 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6333 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6344 - acc: 0.2611 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6406 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6322 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6362 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6285 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6283 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6289 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6243 - acc: 0.2633 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6328 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6138 - acc: 0.2696 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6081 - acc: 0.2718 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6206 - acc: 0.2654 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6179 - acc: 0.2633 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6184 - acc: 0.2654 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6337 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6193 - acc: 0.2675 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6296 - acc: 0.2654 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6232 - acc: 0.2633 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6317 - acc: 0.2633 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6168 - acc: 0.2675 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6234 - acc: 0.2633 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6277 - acc: 0.2633 - val_loss: 0.5223 - val_acc: 0.2057\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6202 - acc: 0.2675 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6260 - acc: 0.2633 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6197 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6127 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6300 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6408 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6190 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6213 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6152 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6303 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6193 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6160 - acc: 0.2675 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6157 - acc: 0.2696 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6182 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6199 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6163 - acc: 0.2654 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6112 - acc: 0.2718 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6218 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6262 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6120 - acc: 0.2696 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6181 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6216 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6330 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6289 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6233 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6079 - acc: 0.2718 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6173 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6108 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6269 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6181 - acc: 0.2675 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6185 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6195 - acc: 0.2654 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6237 - acc: 0.2654 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6157 - acc: 0.2654 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6252 - acc: 0.2654 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6137 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6175 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6090 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6163 - acc: 0.2675 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6238 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6213 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6219 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6124 - acc: 0.2696 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6272 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6157 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6078 - acc: 0.2696 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6171 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6171 - acc: 0.2654 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6244 - acc: 0.2675 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6126 - acc: 0.2675 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6139 - acc: 0.2675 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6312 - acc: 0.2611 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6026 - acc: 0.2696 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6096 - acc: 0.2675 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6129 - acc: 0.2675 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6290 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6173 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 172us/step\n",
      "Test score: 0.5118506943925898\n",
      "Look! softmax tanh softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax tanh selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_213 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_788 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_578 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_789 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_579 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_790 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 46ms/step - loss: nan - acc: 0.4501 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 161us/step\n",
      "Test score: nan\n",
      "Look! softmax tanh softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax tanh softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_214 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_791 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_580 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_792 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_581 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_793 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 47ms/step - loss: nan - acc: 0.4841 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 152us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 162us/step\n",
      "Test score: nan\n",
      "Look! softmax tanh relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax tanh relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_215 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_794 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_582 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_795 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_583 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_796 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 47ms/step - loss: nan - acc: 0.4777 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 164us/step\n",
      "Test score: nan\n",
      "Look! softmax tanh tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax tanh tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_216 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_797 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_584 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_798 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_585 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_799 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 47ms/step - loss: 0.7440 - acc: 0.2760 - val_loss: 0.5954 - val_acc: 0.4965\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7305 - acc: 0.3015 - val_loss: 0.5883 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.7233 - acc: 0.2909 - val_loss: 0.5800 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.7070 - acc: 0.2696 - val_loss: 0.5720 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7047 - acc: 0.2378 - val_loss: 0.5646 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6962 - acc: 0.2654 - val_loss: 0.5579 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6928 - acc: 0.2569 - val_loss: 0.5519 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6846 - acc: 0.2611 - val_loss: 0.5466 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6802 - acc: 0.2633 - val_loss: 0.5421 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6787 - acc: 0.2590 - val_loss: 0.5382 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6616 - acc: 0.2611 - val_loss: 0.5342 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6816 - acc: 0.2590 - val_loss: 0.5310 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6635 - acc: 0.2548 - val_loss: 0.5479 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6722 - acc: 0.2590 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6572 - acc: 0.2569 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6572 - acc: 0.2611 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6462 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6630 - acc: 0.2590 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6560 - acc: 0.2590 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6643 - acc: 0.2611 - val_loss: 0.5373 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6781 - acc: 0.2505 - val_loss: 0.5468 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6742 - acc: 0.2484 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6715 - acc: 0.2442 - val_loss: 0.5323 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6552 - acc: 0.2463 - val_loss: 0.5263 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6457 - acc: 0.2611 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6482 - acc: 0.2569 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6468 - acc: 0.2611 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6433 - acc: 0.2590 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6460 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6341 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6390 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6523 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6326 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6470 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: 0.6373 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6423 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6388 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6377 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6303 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6380 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6293 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6448 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6436 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6296 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6378 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6284 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6333 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6307 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6374 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6339 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6370 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6259 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6386 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6312 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6351 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6361 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6290 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6342 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6280 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6294 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6350 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6361 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6297 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6347 - acc: 0.2590 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6363 - acc: 0.2590 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6326 - acc: 0.2590 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6329 - acc: 0.2590 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6288 - acc: 0.2590 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6393 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6277 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6372 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6294 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6258 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6379 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6303 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6276 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6322 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6340 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6274 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6308 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6287 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6375 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6274 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6334 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6290 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6359 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6324 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6273 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6333 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6299 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6291 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 141us/step\n",
      "Test score: 0.5108698268308707\n",
      "Look! softmax tanh sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax tanh tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_217 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_800 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_586 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_801 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_587 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_802 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 47ms/step - loss: 0.7242 - acc: 0.2951 - val_loss: 0.5838 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.7202 - acc: 0.2569 - val_loss: 0.5765 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7026 - acc: 0.2611 - val_loss: 0.5696 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6958 - acc: 0.2611 - val_loss: 0.5629 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6941 - acc: 0.2590 - val_loss: 0.5599 - val_acc: 0.2057\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6850 - acc: 0.2611 - val_loss: 0.5556 - val_acc: 0.1986\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6748 - acc: 0.2611 - val_loss: 0.5452 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6722 - acc: 0.2611 - val_loss: 0.5403 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6593 - acc: 0.2611 - val_loss: 0.5353 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6703 - acc: 0.2611 - val_loss: 0.5365 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6506 - acc: 0.2611 - val_loss: 0.5320 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6620 - acc: 0.2611 - val_loss: 0.5283 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6941 - acc: 0.2611 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6626 - acc: 0.2633 - val_loss: 0.5286 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6406 - acc: 0.2633 - val_loss: 0.5350 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6620 - acc: 0.2654 - val_loss: 0.5286 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6487 - acc: 0.2633 - val_loss: 0.5271 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6806 - acc: 0.2611 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6450 - acc: 0.2633 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6517 - acc: 0.2611 - val_loss: 0.5314 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6545 - acc: 0.2611 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6480 - acc: 0.2675 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6458 - acc: 0.2654 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6535 - acc: 0.2611 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6973 - acc: 0.2633 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6446 - acc: 0.2633 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6442 - acc: 0.2654 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6673 - acc: 0.2633 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6720 - acc: 0.2696 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6410 - acc: 0.2654 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6771 - acc: 0.2611 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6519 - acc: 0.2654 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6664 - acc: 0.2633 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6387 - acc: 0.2633 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6287 - acc: 0.2718 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6222 - acc: 0.2718 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6608 - acc: 0.2675 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6384 - acc: 0.2739 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6488 - acc: 0.2654 - val_loss: 0.5245 - val_acc: 0.2057\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6320 - acc: 0.2696 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6282 - acc: 0.2696 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6348 - acc: 0.2654 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6171 - acc: 0.2696 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6316 - acc: 0.2654 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6217 - acc: 0.2696 - val_loss: 0.5264 - val_acc: 0.2057\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6344 - acc: 0.2611 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6336 - acc: 0.2654 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6324 - acc: 0.2696 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6339 - acc: 0.2654 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6207 - acc: 0.2675 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 191us/step - loss: 0.6428 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6180 - acc: 0.2718 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6248 - acc: 0.2654 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6375 - acc: 0.2654 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6496 - acc: 0.2611 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6428 - acc: 0.2654 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6197 - acc: 0.2675 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6227 - acc: 0.2654 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6235 - acc: 0.2696 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6406 - acc: 0.2548 - val_loss: 0.5382 - val_acc: 0.1773\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6898 - acc: 0.2527 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6292 - acc: 0.2696 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6389 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6325 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6419 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6326 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6364 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6412 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6436 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6417 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6368 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6267 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6367 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6341 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6432 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6345 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6279 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6342 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6289 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6331 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6398 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6342 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6316 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6301 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6217 - acc: 0.2633 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6202 - acc: 0.2654 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6209 - acc: 0.2675 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6141 - acc: 0.2696 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6347 - acc: 0.2548 - val_loss: 0.5474 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.7034 - acc: 0.2038 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6100 - acc: 0.2696 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6128 - acc: 0.2654 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6305 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6226 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6295 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6316 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6219 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6246 - acc: 0.2654 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6165 - acc: 0.2675 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6246 - acc: 0.2654 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6138 - acc: 0.2696 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6290 - acc: 0.2611 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6237 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 0.6219 - acc: 0.2633 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6145 - acc: 0.2696 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6108 - acc: 0.2696 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6194 - acc: 0.2654 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6182 - acc: 0.2696 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6044 - acc: 0.2739 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 0.6190 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 161us/step\n",
      "Test score: 0.5114653558595806\n",
      "Look! softmax tanh hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax tanh tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_218 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_803 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_588 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_804 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_589 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_805 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 47ms/step - loss: nan - acc: 0.4820 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 158us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 162us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 160us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 131us/step\n",
      "Test score: nan\n",
      "Look! softmax tanh linear Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax tanh linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_219 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_806 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_590 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_807 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_591 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_808 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 22s 48ms/step - loss: 1.1201 - acc: 0.1083 - val_loss: 0.7390 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9291 - acc: 0.1486 - val_loss: 0.6468 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.8660 - acc: 0.1614 - val_loss: 0.5861 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.7794 - acc: 0.1996 - val_loss: 0.5488 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.7696 - acc: 0.1826 - val_loss: 0.5283 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.7356 - acc: 0.2123 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.7373 - acc: 0.2251 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.7321 - acc: 0.2420 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.7101 - acc: 0.2272 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7054 - acc: 0.2293 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6996 - acc: 0.2484 - val_loss: 0.5147 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.7222 - acc: 0.2569 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.7062 - acc: 0.2484 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.7115 - acc: 0.2399 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6868 - acc: 0.2739 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6770 - acc: 0.2696 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6932 - acc: 0.2378 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6551 - acc: 0.2718 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6836 - acc: 0.2442 - val_loss: 0.5074 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6999 - acc: 0.2505 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.7022 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6996 - acc: 0.2293 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6786 - acc: 0.2696 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.7182 - acc: 0.2208 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6611 - acc: 0.2803 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7063 - acc: 0.2760 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7143 - acc: 0.2633 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.6596 - acc: 0.2866 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 161us/step - loss: 0.6791 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6927 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.7158 - acc: 0.2208 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6756 - acc: 0.2442 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6720 - acc: 0.2845 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6583 - acc: 0.2739 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6889 - acc: 0.2378 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6798 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6697 - acc: 0.2463 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7164 - acc: 0.2357 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6790 - acc: 0.2463 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6916 - acc: 0.2335 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.7038 - acc: 0.2144 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6889 - acc: 0.2399 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6883 - acc: 0.2739 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6813 - acc: 0.2378 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6960 - acc: 0.2314 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.7061 - acc: 0.2208 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6886 - acc: 0.2484 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6833 - acc: 0.2357 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6966 - acc: 0.2251 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6755 - acc: 0.2357 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6840 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6787 - acc: 0.2442 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6925 - acc: 0.2442 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6921 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6653 - acc: 0.2314 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6824 - acc: 0.2335 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6753 - acc: 0.2293 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6905 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6811 - acc: 0.2463 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6763 - acc: 0.2442 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6920 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6860 - acc: 0.2399 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6658 - acc: 0.2569 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6980 - acc: 0.2335 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6637 - acc: 0.2251 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6819 - acc: 0.2420 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6742 - acc: 0.2527 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6918 - acc: 0.2463 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6723 - acc: 0.2399 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6487 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6789 - acc: 0.2335 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6645 - acc: 0.2378 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6693 - acc: 0.2548 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6873 - acc: 0.2484 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6654 - acc: 0.2442 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6664 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6638 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6701 - acc: 0.2187 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6597 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6617 - acc: 0.2399 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6853 - acc: 0.2272 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6651 - acc: 0.2484 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6656 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6911 - acc: 0.2293 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6863 - acc: 0.2442 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6688 - acc: 0.2378 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6865 - acc: 0.2251 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6711 - acc: 0.2442 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6822 - acc: 0.2378 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6776 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6861 - acc: 0.2335 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6742 - acc: 0.2420 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6668 - acc: 0.2357 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6722 - acc: 0.2569 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6515 - acc: 0.2505 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6550 - acc: 0.2442 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6689 - acc: 0.2314 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6680 - acc: 0.2420 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6512 - acc: 0.2442 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6828 - acc: 0.2272 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6649 - acc: 0.2527 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6671 - acc: 0.2378 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6544 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6555 - acc: 0.2527 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6794 - acc: 0.2187 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6741 - acc: 0.2335 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6821 - acc: 0.2399 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6636 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6478 - acc: 0.2505 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6526 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6628 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6545 - acc: 0.2293 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6609 - acc: 0.2378 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6760 - acc: 0.2548 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6586 - acc: 0.2229 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6830 - acc: 0.2187 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6565 - acc: 0.2463 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6783 - acc: 0.2378 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6411 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6644 - acc: 0.2399 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 165us/step\n",
      "Test score: 0.511486624995022\n",
      "Look! softmax sigmoid softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax tanh linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_220 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_809 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_592 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_810 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_593 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_811 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 23s 48ms/step - loss: 3.0614 - acc: 0.4650 - val_loss: 2.7465 - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.7927 - acc: 0.4055 - val_loss: 2.7310 - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.9375 - acc: 0.4225 - val_loss: 2.7278 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.5349 - acc: 0.3652 - val_loss: 2.7283 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.4899 - acc: 0.3397 - val_loss: 2.7364 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.1495 - acc: 0.3355 - val_loss: 1.1233 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 2.3463 - acc: 0.3270 - val_loss: 1.0302 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.2216 - acc: 0.2824 - val_loss: 1.0080 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 2.0291 - acc: 0.2972 - val_loss: 0.9989 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.6808 - acc: 0.3079 - val_loss: 0.9952 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.4548 - acc: 0.2930 - val_loss: 0.9922 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.7531 - acc: 0.2548 - val_loss: 0.9871 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.7294 - acc: 0.2930 - val_loss: 0.9846 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.4448 - acc: 0.3015 - val_loss: 0.9837 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.5444 - acc: 0.2718 - val_loss: 0.9817 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.0568 - acc: 0.2718 - val_loss: 0.9785 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.3510 - acc: 0.2824 - val_loss: 0.9786 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.1063 - acc: 0.2824 - val_loss: 0.9794 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.2083 - acc: 0.2909 - val_loss: 0.9804 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.0726 - acc: 0.2590 - val_loss: 0.9804 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.9497 - acc: 0.2548 - val_loss: 0.9799 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.9563 - acc: 0.2420 - val_loss: 0.6688 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.0718 - acc: 0.2824 - val_loss: 0.6270 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.1684 - acc: 0.2696 - val_loss: 0.6165 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.9620 - acc: 0.2824 - val_loss: 0.6170 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.0089 - acc: 0.2739 - val_loss: 0.5914 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.9792 - acc: 0.2675 - val_loss: 0.5782 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.0024 - acc: 0.2972 - val_loss: 0.5697 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.9798 - acc: 0.2527 - val_loss: 0.5605 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.9045 - acc: 0.2845 - val_loss: 0.5547 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.9858 - acc: 0.2781 - val_loss: 0.5487 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.9301 - acc: 0.2399 - val_loss: 0.5422 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.9992 - acc: 0.2866 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.8848 - acc: 0.2463 - val_loss: 0.5370 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.9335 - acc: 0.2527 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.8853 - acc: 0.2357 - val_loss: 0.5349 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.9638 - acc: 0.2654 - val_loss: 0.5345 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.9501 - acc: 0.2633 - val_loss: 0.5315 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.8327 - acc: 0.2569 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7832 - acc: 0.2760 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.8176 - acc: 0.2675 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7894 - acc: 0.2399 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.9079 - acc: 0.2548 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.8366 - acc: 0.2675 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.8279 - acc: 0.2335 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.9003 - acc: 0.2654 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.8128 - acc: 0.2399 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7889 - acc: 0.2442 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7976 - acc: 0.2314 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.8240 - acc: 0.2505 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.8406 - acc: 0.2378 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.8143 - acc: 0.2293 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.9493 - acc: 0.2293 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7154 - acc: 0.2611 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.8830 - acc: 0.2442 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.8107 - acc: 0.2611 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.8392 - acc: 0.2548 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.7904 - acc: 0.2420 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.8384 - acc: 0.2484 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.9248 - acc: 0.2420 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.8088 - acc: 0.2696 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7503 - acc: 0.2463 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6709 - acc: 0.2590 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7485 - acc: 0.2739 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7549 - acc: 0.2590 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.7945 - acc: 0.2335 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.8006 - acc: 0.2420 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7133 - acc: 0.2654 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7776 - acc: 0.2357 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.8790 - acc: 0.2590 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.7227 - acc: 0.2335 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.7191 - acc: 0.2569 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7179 - acc: 0.2590 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6818 - acc: 0.2463 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6879 - acc: 0.2548 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 0.7206 - acc: 0.2548 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6474 - acc: 0.2633 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6997 - acc: 0.2696 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6632 - acc: 0.2590 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.7371 - acc: 0.2569 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.7095 - acc: 0.2420 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7168 - acc: 0.2505 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7350 - acc: 0.2463 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6666 - acc: 0.2590 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6799 - acc: 0.2442 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7686 - acc: 0.2548 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6730 - acc: 0.2569 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.7520 - acc: 0.2548 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6572 - acc: 0.2378 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7013 - acc: 0.2548 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6572 - acc: 0.2654 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7000 - acc: 0.2527 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.7178 - acc: 0.2569 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7539 - acc: 0.2463 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7293 - acc: 0.2548 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.7115 - acc: 0.2633 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7369 - acc: 0.2484 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7491 - acc: 0.2548 - val_loss: 0.5262 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.7172 - acc: 0.2696 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7291 - acc: 0.2463 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.7773 - acc: 0.2633 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.7094 - acc: 0.2548 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6848 - acc: 0.2590 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6880 - acc: 0.2569 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6993 - acc: 0.2548 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6585 - acc: 0.2633 - val_loss: 0.5271 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6934 - acc: 0.2590 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6601 - acc: 0.2611 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6601 - acc: 0.2548 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6961 - acc: 0.2590 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6881 - acc: 0.2527 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7088 - acc: 0.2505 - val_loss: 0.5254 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.7391 - acc: 0.2527 - val_loss: 0.5251 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6715 - acc: 0.2548 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.7177 - acc: 0.2569 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 0.6782 - acc: 0.2739 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7051 - acc: 0.2505 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.7104 - acc: 0.2675 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6358 - acc: 0.2633 - val_loss: 0.5233 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6877 - acc: 0.2590 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 156us/step\n",
      "Test score: 0.5230159598884853\n",
      "Look! softmax sigmoid elu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax tanh linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_221 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_812 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_594 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_813 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_595 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_814 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 23s 48ms/step - loss: 1.9493 - acc: 0.3546 - val_loss: 0.7243 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.5149 - acc: 0.2781 - val_loss: 0.6695 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 2.3552 - acc: 0.2463 - val_loss: 0.6410 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.6951 - acc: 0.2420 - val_loss: 0.6222 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.0700 - acc: 0.2548 - val_loss: 0.6450 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.0099 - acc: 0.2718 - val_loss: 0.7780 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 3.3554 - acc: 0.2484 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 4.2528 - acc: 0.2272 - val_loss: 5.5189 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 3.9959 - acc: 0.2463 - val_loss: 5.5328 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 4.1646 - acc: 0.2335 - val_loss: 5.5335 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.2352 - acc: 0.2166 - val_loss: 5.5363 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 4.4011 - acc: 0.2187 - val_loss: 5.5481 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.7226 - acc: 0.2527 - val_loss: 5.5587 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 4.6163 - acc: 0.2739 - val_loss: 5.5646 - val_acc: 0.1277\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.0747 - acc: 0.2866 - val_loss: 5.5682 - val_acc: 0.1277\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.1293 - acc: 0.2654 - val_loss: 3.1522 - val_acc: 0.1277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.8226 - acc: 0.2654 - val_loss: 2.7128 - val_acc: 0.1277\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.8869 - acc: 0.2293 - val_loss: 2.6243 - val_acc: 0.1277\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.4789 - acc: 0.2611 - val_loss: 2.5802 - val_acc: 0.1277\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.9290 - acc: 0.2442 - val_loss: 1.0397 - val_acc: 0.1277\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.2184 - acc: 0.2335 - val_loss: 0.8790 - val_acc: 0.1277\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.9277 - acc: 0.2229 - val_loss: 0.7964 - val_acc: 0.1277\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.8526 - acc: 0.2505 - val_loss: 0.7503 - val_acc: 0.1277\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.4192 - acc: 0.2293 - val_loss: 0.7125 - val_acc: 0.1277\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.3463 - acc: 0.2229 - val_loss: 0.6791 - val_acc: 0.1277\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.2541 - acc: 0.1975 - val_loss: 0.6571 - val_acc: 0.1277\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.0972 - acc: 0.2293 - val_loss: 0.6319 - val_acc: 0.1277\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.9351 - acc: 0.1635 - val_loss: 0.6128 - val_acc: 0.1277\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.7839 - acc: 0.1847 - val_loss: 0.5831 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.8928 - acc: 0.1550 - val_loss: 1.0182 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.0854 - acc: 0.1040 - val_loss: 0.9642 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.7813 - acc: 0.0998 - val_loss: 0.9139 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.8849 - acc: 0.0913 - val_loss: 0.8897 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.3245 - acc: 0.0764 - val_loss: 0.8606 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.0535 - acc: 0.0743 - val_loss: 0.8213 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.2046 - acc: 0.0616 - val_loss: 0.7963 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.1123 - acc: 0.0637 - val_loss: 0.7754 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.2365 - acc: 0.0552 - val_loss: 0.7438 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.5003 - acc: 0.0552 - val_loss: 0.7106 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.8447 - acc: 0.0616 - val_loss: 0.6685 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.2314 - acc: 0.0488 - val_loss: 0.6321 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.2079 - acc: 0.0510 - val_loss: 0.6070 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 2.6620 - acc: 0.0531 - val_loss: 0.5881 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.4568 - acc: 0.0488 - val_loss: 0.5720 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 3.0675 - acc: 0.0446 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 3.4673 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.6196 - acc: 0.0467 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 3.9173 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.0839 - acc: 0.0446 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.9976 - acc: 0.0446 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 4.3086 - acc: 0.0488 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 4.5112 - acc: 0.0446 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 4.4900 - acc: 0.0446 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 4.1684 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 4.7839 - acc: 0.0467 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 4.8169 - acc: 0.0446 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 5.0517 - acc: 0.0446 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.9359 - acc: 0.0446 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 4.3960 - acc: 0.0446 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 5.0474 - acc: 0.0446 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 5.3140 - acc: 0.0488 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 5.3931 - acc: 0.0446 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 4.5701 - acc: 0.0467 - val_loss: 3.9780 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.5928 - acc: 0.0531 - val_loss: 3.5888 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 3.9956 - acc: 0.0488 - val_loss: 2.8005 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 3.7591 - acc: 0.0594 - val_loss: 2.6903 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.8828 - acc: 0.0616 - val_loss: 2.6324 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.7182 - acc: 0.0573 - val_loss: 2.5865 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.4832 - acc: 0.0722 - val_loss: 2.5749 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.4601 - acc: 0.0722 - val_loss: 3.2767 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.1914 - acc: 0.0934 - val_loss: 3.2492 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.8459 - acc: 0.0849 - val_loss: 1.8063 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 2.8658 - acc: 0.1083 - val_loss: 1.5188 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 2.8820 - acc: 0.1274 - val_loss: 1.3996 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.8284 - acc: 0.1656 - val_loss: 1.2869 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.0659 - acc: 0.1486 - val_loss: 1.2067 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 2.6310 - acc: 0.1868 - val_loss: 1.1613 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.8106 - acc: 0.1614 - val_loss: 1.1395 - val_acc: 0.1277\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 2.4769 - acc: 0.1868 - val_loss: 1.1378 - val_acc: 0.1277\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 2.5425 - acc: 0.2038 - val_loss: 1.1432 - val_acc: 0.1277\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.3993 - acc: 0.1826 - val_loss: 1.6040 - val_acc: 0.1277\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.5138 - acc: 0.2102 - val_loss: 1.5518 - val_acc: 0.1277\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 2.2995 - acc: 0.2059 - val_loss: 1.4966 - val_acc: 0.1277\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.8628 - acc: 0.2038 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.7886 - acc: 0.1826 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.8196 - acc: 0.1868 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 3.0329 - acc: 0.2208 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.3496 - acc: 0.2229 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.4215 - acc: 0.2081 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.2257 - acc: 0.1996 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.6702 - acc: 0.2017 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.7574 - acc: 0.2166 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.9352 - acc: 0.2144 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.4039 - acc: 0.2102 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 3.2523 - acc: 0.2081 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.4733 - acc: 0.2314 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.5865 - acc: 0.2420 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 3.5035 - acc: 0.2038 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 3.6083 - acc: 0.1996 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.4607 - acc: 0.2251 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 4.0863 - acc: 0.2335 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.7243 - acc: 0.2166 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 3.6605 - acc: 0.1890 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.7324 - acc: 0.1847 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.2059 - acc: 0.2059 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 3.7996 - acc: 0.2166 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.4866 - acc: 0.2123 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 4.0621 - acc: 0.1868 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.2305 - acc: 0.2208 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.9301 - acc: 0.2187 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 4.3861 - acc: 0.2144 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.8660 - acc: 0.2144 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.1123 - acc: 0.1911 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.3455 - acc: 0.2102 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.8954 - acc: 0.2123 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 3.2066 - acc: 0.2251 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.7671 - acc: 0.1911 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 4.2076 - acc: 0.2038 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.6962 - acc: 0.2335 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.8799 - acc: 0.2081 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "141/141 [==============================] - 0s 171us/step\n",
      "Test score: 5.487010921992309\n",
      "Look! softmax sigmoid selu Test accuracy: 0.1276595744680851\n",
      "max there  0.6241134772909448 softmax tanh linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_222 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_815 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_596 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_816 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_597 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_817 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 23s 49ms/step - loss: 0.9081 - acc: 0.2293 - val_loss: 0.6558 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.8412 - acc: 0.2718 - val_loss: 0.5999 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.7449 - acc: 0.2760 - val_loss: 0.5600 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6866 - acc: 0.2739 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6873 - acc: 0.2696 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6867 - acc: 0.2293 - val_loss: 0.5141 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6759 - acc: 0.2420 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6775 - acc: 0.2420 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6620 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6882 - acc: 0.2229 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6789 - acc: 0.2399 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6806 - acc: 0.2293 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6748 - acc: 0.2420 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6709 - acc: 0.2420 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6617 - acc: 0.2399 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6623 - acc: 0.2335 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6597 - acc: 0.2527 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6658 - acc: 0.2293 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6476 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6508 - acc: 0.2357 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6610 - acc: 0.2527 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6717 - acc: 0.2272 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6429 - acc: 0.2399 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6526 - acc: 0.2505 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6561 - acc: 0.2505 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6681 - acc: 0.2378 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6735 - acc: 0.2229 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6467 - acc: 0.2420 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6399 - acc: 0.2505 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6427 - acc: 0.2463 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6529 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6571 - acc: 0.2293 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6523 - acc: 0.2527 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6641 - acc: 0.2378 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6432 - acc: 0.2484 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6501 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 0.6554 - acc: 0.2484 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6534 - acc: 0.2442 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6555 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6616 - acc: 0.2399 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6546 - acc: 0.2569 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6556 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6439 - acc: 0.2484 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6633 - acc: 0.2335 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6429 - acc: 0.2463 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6545 - acc: 0.2357 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6554 - acc: 0.2378 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6624 - acc: 0.2251 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6445 - acc: 0.2442 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6444 - acc: 0.2484 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6543 - acc: 0.2463 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6439 - acc: 0.2442 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6349 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6464 - acc: 0.2463 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6447 - acc: 0.2251 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6552 - acc: 0.2420 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 0.6403 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6486 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6521 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 0.6506 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6522 - acc: 0.2420 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6756 - acc: 0.2548 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6535 - acc: 0.2463 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6356 - acc: 0.2675 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6388 - acc: 0.2463 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6437 - acc: 0.2484 - val_loss: 0.5097 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6535 - acc: 0.2548 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6464 - acc: 0.2378 - val_loss: 0.5101 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6399 - acc: 0.2442 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 0.6467 - acc: 0.2442 - val_loss: 0.5081 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6340 - acc: 0.2569 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6323 - acc: 0.2569 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6341 - acc: 0.2527 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6414 - acc: 0.2335 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6601 - acc: 0.2357 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6534 - acc: 0.2484 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6515 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6442 - acc: 0.2420 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6383 - acc: 0.2505 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6401 - acc: 0.2527 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6493 - acc: 0.2505 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6645 - acc: 0.2420 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6467 - acc: 0.2548 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6437 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 0.6500 - acc: 0.2484 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6501 - acc: 0.2527 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6403 - acc: 0.2527 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6511 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6400 - acc: 0.2505 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6366 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6433 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6413 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6289 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6392 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6393 - acc: 0.2505 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6568 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6374 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6483 - acc: 0.2463 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6403 - acc: 0.2548 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6425 - acc: 0.2420 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6535 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6354 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6359 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6385 - acc: 0.2505 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6466 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6437 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6457 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6449 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6401 - acc: 0.2548 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6487 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 0.6325 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6470 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6332 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6370 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6396 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6394 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6475 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6337 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 164us/step\n",
      "Test score: 0.5111008679613154\n",
      "Look! softmax sigmoid softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax tanh linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_223 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_818 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_598 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_819 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_599 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_820 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 23s 49ms/step - loss: 3.9028 - acc: 0.2378 - val_loss: 2.1791 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.5995 - acc: 0.2590 - val_loss: 2.9721 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.8437 - acc: 0.2654 - val_loss: 4.0009 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.8863 - acc: 0.2314 - val_loss: 4.0343 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 4.4474 - acc: 0.2463 - val_loss: 3.5894 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 3.6925 - acc: 0.2569 - val_loss: 3.6205 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.7931 - acc: 0.2994 - val_loss: 4.3967 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.8797 - acc: 0.2654 - val_loss: 4.4231 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 3.7060 - acc: 0.2824 - val_loss: 4.4104 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 4.3597 - acc: 0.2675 - val_loss: 3.8767 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 4.0900 - acc: 0.2803 - val_loss: 4.0962 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.8285 - acc: 0.2654 - val_loss: 4.0825 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.5052 - acc: 0.2696 - val_loss: 4.0757 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.5309 - acc: 0.2484 - val_loss: 4.0744 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.1134 - acc: 0.2399 - val_loss: 4.0756 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.3081 - acc: 0.2590 - val_loss: 4.0828 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 2.9956 - acc: 0.2399 - val_loss: 1.1385 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 2.3827 - acc: 0.1996 - val_loss: 1.0402 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 2.3987 - acc: 0.2166 - val_loss: 0.9768 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.5933 - acc: 0.1847 - val_loss: 0.9283 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 2.8223 - acc: 0.1699 - val_loss: 0.8815 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 164us/step - loss: 2.4792 - acc: 0.1741 - val_loss: 0.8548 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 2.1562 - acc: 0.1465 - val_loss: 0.8379 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.4820 - acc: 0.1423 - val_loss: 0.8214 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.8189 - acc: 0.1274 - val_loss: 0.8085 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.6270 - acc: 0.1189 - val_loss: 0.7825 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 2.7938 - acc: 0.1253 - val_loss: 0.7535 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.8553 - acc: 0.1146 - val_loss: 0.7293 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.5150 - acc: 0.1189 - val_loss: 0.7057 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.1635 - acc: 0.0870 - val_loss: 0.6813 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 2.5884 - acc: 0.0531 - val_loss: 0.6450 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.5527 - acc: 0.0828 - val_loss: 0.6164 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.7320 - acc: 0.0786 - val_loss: 0.6154 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 2.7583 - acc: 0.0786 - val_loss: 0.6130 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.0566 - acc: 0.0531 - val_loss: 0.6135 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.9265 - acc: 0.0722 - val_loss: 0.6196 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 3.1196 - acc: 0.0701 - val_loss: 0.6073 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.0590 - acc: 0.0573 - val_loss: 0.5962 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.9370 - acc: 0.0510 - val_loss: 0.5880 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 2.6671 - acc: 0.0552 - val_loss: 0.5825 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.2074 - acc: 0.0679 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.7150 - acc: 0.0573 - val_loss: 5.5503 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.4312 - acc: 0.0594 - val_loss: 5.5502 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.9200 - acc: 0.0594 - val_loss: 5.5542 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 4.2502 - acc: 0.0637 - val_loss: 3.8151 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 3.8694 - acc: 0.0616 - val_loss: 3.6786 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.6251 - acc: 0.0658 - val_loss: 3.6450 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.2047 - acc: 0.0616 - val_loss: 3.6353 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 4.1033 - acc: 0.0531 - val_loss: 3.6333 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.7656 - acc: 0.0786 - val_loss: 3.6338 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 3.9376 - acc: 0.0870 - val_loss: 3.6365 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.9902 - acc: 0.0743 - val_loss: 3.6402 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.6085 - acc: 0.0743 - val_loss: 3.6518 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 3.3455 - acc: 0.0913 - val_loss: 3.6615 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 3.2686 - acc: 0.0849 - val_loss: 3.6701 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.2223 - acc: 0.0807 - val_loss: 3.6793 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 2.8275 - acc: 0.1125 - val_loss: 1.0142 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.8526 - acc: 0.1104 - val_loss: 0.8817 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.8167 - acc: 0.1486 - val_loss: 0.8195 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.9978 - acc: 0.1295 - val_loss: 0.7895 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 2.3120 - acc: 0.1359 - val_loss: 0.7690 - val_acc: 0.1277\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.2528 - acc: 0.1783 - val_loss: 0.7525 - val_acc: 0.1277\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 2.5768 - acc: 0.1890 - val_loss: 0.7377 - val_acc: 0.1277\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 2.4204 - acc: 0.1529 - val_loss: 0.7156 - val_acc: 0.1277\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.2324 - acc: 0.2059 - val_loss: 0.6949 - val_acc: 0.1277\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.3358 - acc: 0.2017 - val_loss: 0.6788 - val_acc: 0.1277\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.1863 - acc: 0.2038 - val_loss: 0.6647 - val_acc: 0.1277\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.1542 - acc: 0.2102 - val_loss: 0.6504 - val_acc: 0.1277\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.2078 - acc: 0.1996 - val_loss: 0.6331 - val_acc: 0.1277\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.1141 - acc: 0.2293 - val_loss: 0.6150 - val_acc: 0.1277\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.6171 - acc: 0.2357 - val_loss: 0.6004 - val_acc: 0.1277\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.8248 - acc: 0.2059 - val_loss: 1.0399 - val_acc: 0.1277\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.8009 - acc: 0.1932 - val_loss: 0.9962 - val_acc: 0.1277\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.7430 - acc: 0.2187 - val_loss: 0.9577 - val_acc: 0.1277\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 1.9238 - acc: 0.2166 - val_loss: 0.9247 - val_acc: 0.1277\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.6437 - acc: 0.2081 - val_loss: 0.9004 - val_acc: 0.1277\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.5556 - acc: 0.2229 - val_loss: 0.8777 - val_acc: 0.1277\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.8558 - acc: 0.2017 - val_loss: 0.8603 - val_acc: 0.1277\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.4361 - acc: 0.2144 - val_loss: 0.8455 - val_acc: 0.1277\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.4640 - acc: 0.2335 - val_loss: 0.8321 - val_acc: 0.1277\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.5968 - acc: 0.2166 - val_loss: 0.8204 - val_acc: 0.1277\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.5863 - acc: 0.2314 - val_loss: 0.8109 - val_acc: 0.1277\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.7006 - acc: 0.2208 - val_loss: 0.8025 - val_acc: 0.1277\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.2093 - acc: 0.2251 - val_loss: 0.7985 - val_acc: 0.1277\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 165us/step - loss: 1.5158 - acc: 0.2081 - val_loss: 0.7942 - val_acc: 0.1277\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.6147 - acc: 0.2144 - val_loss: 0.7894 - val_acc: 0.1277\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.5238 - acc: 0.2059 - val_loss: 0.7847 - val_acc: 0.1277\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.4444 - acc: 0.2357 - val_loss: 0.7816 - val_acc: 0.1277\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.5799 - acc: 0.1975 - val_loss: 0.7817 - val_acc: 0.1277\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.2650 - acc: 0.2378 - val_loss: 0.7813 - val_acc: 0.1277\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.3654 - acc: 0.2123 - val_loss: 0.7800 - val_acc: 0.1277\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 1.1228 - acc: 0.2399 - val_loss: 0.7779 - val_acc: 0.1277\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.3353 - acc: 0.2144 - val_loss: 0.7753 - val_acc: 0.1277\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: 1.1214 - acc: 0.2123 - val_loss: 0.7719 - val_acc: 0.1277\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.2243 - acc: 0.2293 - val_loss: 0.7674 - val_acc: 0.1277\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.3775 - acc: 0.2399 - val_loss: 0.7635 - val_acc: 0.1277\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.4537 - acc: 0.2527 - val_loss: 0.7620 - val_acc: 0.1277\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.2450 - acc: 0.2357 - val_loss: 0.7606 - val_acc: 0.1277\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.2728 - acc: 0.2420 - val_loss: 0.7586 - val_acc: 0.1277\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 169us/step - loss: 1.0936 - acc: 0.2824 - val_loss: 0.7560 - val_acc: 0.1277\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.2632 - acc: 0.2293 - val_loss: 0.7526 - val_acc: 0.1277\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 166us/step - loss: 1.2135 - acc: 0.2611 - val_loss: 0.7485 - val_acc: 0.1277\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 168us/step - loss: 1.3156 - acc: 0.2654 - val_loss: 0.7440 - val_acc: 0.1277\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.4040 - acc: 0.2484 - val_loss: 0.7385 - val_acc: 0.1277\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.4680 - acc: 0.2229 - val_loss: 0.7335 - val_acc: 0.1277\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: 1.5690 - acc: 0.2548 - val_loss: 0.7283 - val_acc: 0.1277\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.5491 - acc: 0.2378 - val_loss: 0.7228 - val_acc: 0.1277\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.4455 - acc: 0.1996 - val_loss: 0.7195 - val_acc: 0.1277\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.4509 - acc: 0.2038 - val_loss: 0.7178 - val_acc: 0.1277\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.4588 - acc: 0.2314 - val_loss: 0.7148 - val_acc: 0.1277\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 163us/step - loss: 1.6725 - acc: 0.2208 - val_loss: 0.7112 - val_acc: 0.1277\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 167us/step - loss: 1.5295 - acc: 0.2505 - val_loss: 0.7076 - val_acc: 0.1277\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 170us/step - loss: 1.4274 - acc: 0.2357 - val_loss: 0.7113 - val_acc: 0.1277\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.6261 - acc: 0.2378 - val_loss: 0.7150 - val_acc: 0.1277\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.3707 - acc: 0.2208 - val_loss: 0.7167 - val_acc: 0.1277\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.3848 - acc: 0.2611 - val_loss: 0.7145 - val_acc: 0.1277\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.5005 - acc: 0.2569 - val_loss: 0.7204 - val_acc: 0.1277\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.2790 - acc: 0.2017 - val_loss: 0.7299 - val_acc: 0.1277\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.2307 - acc: 0.2845 - val_loss: 0.7338 - val_acc: 0.1277\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.1675 - acc: 0.2718 - val_loss: 0.7347 - val_acc: 0.1277\n",
      "141/141 [==============================] - 0s 160us/step\n",
      "Test score: 0.7347301341963153\n",
      "Look! softmax sigmoid softsign Test accuracy: 0.1276595744680851\n",
      "max there  0.6241134772909448 softmax tanh linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_224 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_821 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_600 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_822 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_601 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_823 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 23s 49ms/step - loss: 3.6598 - acc: 0.1401 - val_loss: 0.7163 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.4395 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 172us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 173us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 167us/step\n",
      "Test score: nan\n",
      "Look! softmax sigmoid relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_225 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_824 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_602 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_825 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_603 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_826 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 23s 49ms/step - loss: 4.7889 - acc: 0.2569 - val_loss: 3.6862 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3456 - acc: 0.2463 - val_loss: 3.6418 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.5356 - acc: 0.2633 - val_loss: 3.6236 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.9757 - acc: 0.2442 - val_loss: 3.6159 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 3.8823 - acc: 0.2548 - val_loss: 3.6158 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 3.8528 - acc: 0.2357 - val_loss: 3.6234 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.4024 - acc: 0.2527 - val_loss: 3.6349 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 3.5292 - acc: 0.2569 - val_loss: 3.6437 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.7900 - acc: 0.2378 - val_loss: 3.6532 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.1619 - acc: 0.2696 - val_loss: 1.0511 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.6240 - acc: 0.2335 - val_loss: 0.8030 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.3432 - acc: 0.2611 - val_loss: 0.7083 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.0976 - acc: 0.2335 - val_loss: 0.6491 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.6899 - acc: 0.2654 - val_loss: 0.6134 - val_acc: 0.0355\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.8261 - acc: 0.2293 - val_loss: 0.5887 - val_acc: 0.0355\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.5357 - acc: 0.2335 - val_loss: 0.5725 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.3558 - acc: 0.2527 - val_loss: 0.5609 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2468 - acc: 0.2378 - val_loss: 0.5510 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.1112 - acc: 0.2357 - val_loss: 0.5472 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.1860 - acc: 0.2357 - val_loss: 0.5419 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.3418 - acc: 0.2081 - val_loss: 0.5435 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.9634 - acc: 0.2038 - val_loss: 0.5438 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.3554 - acc: 0.1805 - val_loss: 0.5466 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.0429 - acc: 0.1507 - val_loss: 0.5494 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.8195 - acc: 0.1677 - val_loss: 0.5514 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.9179 - acc: 0.1316 - val_loss: 0.5530 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.0508 - acc: 0.1401 - val_loss: 0.5503 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.0130 - acc: 0.1295 - val_loss: 0.5511 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.8772 - acc: 0.1805 - val_loss: 0.5544 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.0544 - acc: 0.1826 - val_loss: 0.5562 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.9910 - acc: 0.1529 - val_loss: 0.5563 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.9424 - acc: 0.1507 - val_loss: 0.5558 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.9620 - acc: 0.1529 - val_loss: 0.5554 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8678 - acc: 0.1592 - val_loss: 0.5551 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.9239 - acc: 0.1699 - val_loss: 0.5612 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8187 - acc: 0.1295 - val_loss: 0.5629 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.8442 - acc: 0.1486 - val_loss: 0.5640 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.9521 - acc: 0.1359 - val_loss: 0.5650 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.8811 - acc: 0.1614 - val_loss: 0.5653 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.9189 - acc: 0.1338 - val_loss: 0.5652 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.8935 - acc: 0.1359 - val_loss: 0.5649 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.8672 - acc: 0.1656 - val_loss: 0.5675 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8222 - acc: 0.1486 - val_loss: 0.5688 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.8016 - acc: 0.1592 - val_loss: 0.5697 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.8035 - acc: 0.1465 - val_loss: 0.5710 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8400 - acc: 0.1444 - val_loss: 0.5717 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8442 - acc: 0.1826 - val_loss: 0.5722 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.8519 - acc: 0.1762 - val_loss: 0.5724 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8342 - acc: 0.1550 - val_loss: 0.5729 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7454 - acc: 0.1423 - val_loss: 0.5729 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7979 - acc: 0.1423 - val_loss: 0.5729 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8173 - acc: 0.1338 - val_loss: 0.5730 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.8350 - acc: 0.1359 - val_loss: 0.5726 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7791 - acc: 0.1380 - val_loss: 0.5723 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8287 - acc: 0.1338 - val_loss: 0.5722 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7764 - acc: 0.1316 - val_loss: 0.5719 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7276 - acc: 0.1465 - val_loss: 0.5714 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.8394 - acc: 0.1295 - val_loss: 0.5708 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6862 - acc: 0.1359 - val_loss: 0.5703 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7879 - acc: 0.1274 - val_loss: 0.5700 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7950 - acc: 0.1189 - val_loss: 0.5696 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7992 - acc: 0.1295 - val_loss: 0.5694 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6915 - acc: 0.1507 - val_loss: 0.5691 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7590 - acc: 0.1274 - val_loss: 0.5686 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.8007 - acc: 0.1529 - val_loss: 0.5681 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.8408 - acc: 0.1529 - val_loss: 0.5675 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7761 - acc: 0.1316 - val_loss: 0.5669 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7668 - acc: 0.1550 - val_loss: 0.5664 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.8917 - acc: 0.1359 - val_loss: 0.5657 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.8319 - acc: 0.1614 - val_loss: 0.5650 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.7702 - acc: 0.1444 - val_loss: 0.5644 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.8365 - acc: 0.1231 - val_loss: 0.5637 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.8600 - acc: 0.1401 - val_loss: 0.5634 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.8134 - acc: 0.1401 - val_loss: 0.5638 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7714 - acc: 0.1359 - val_loss: 0.5647 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7813 - acc: 0.1380 - val_loss: 0.5653 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7877 - acc: 0.0977 - val_loss: 0.5661 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7333 - acc: 0.1168 - val_loss: 0.5663 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7373 - acc: 0.1295 - val_loss: 0.5662 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7322 - acc: 0.1062 - val_loss: 0.5659 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.8159 - acc: 0.1189 - val_loss: 0.5655 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7991 - acc: 0.1507 - val_loss: 0.5650 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9047 - acc: 0.1253 - val_loss: 0.5642 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7928 - acc: 0.1062 - val_loss: 0.5635 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.8387 - acc: 0.1231 - val_loss: 0.5626 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6868 - acc: 0.1146 - val_loss: 0.5617 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.8091 - acc: 0.1125 - val_loss: 0.5606 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.8379 - acc: 0.1062 - val_loss: 0.5595 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.9572 - acc: 0.1380 - val_loss: 0.5599 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7950 - acc: 0.1040 - val_loss: 0.5603 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7727 - acc: 0.1231 - val_loss: 0.5607 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8661 - acc: 0.1486 - val_loss: 0.5607 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.7577 - acc: 0.1316 - val_loss: 0.5604 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.8035 - acc: 0.1380 - val_loss: 0.5599 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7166 - acc: 0.1019 - val_loss: 0.5592 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.8015 - acc: 0.1359 - val_loss: 0.5584 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.7327 - acc: 0.1253 - val_loss: 0.5575 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.8965 - acc: 0.1168 - val_loss: 0.5581 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.7583 - acc: 0.1444 - val_loss: 0.5592 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.9037 - acc: 0.1295 - val_loss: 0.5600 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9107 - acc: 0.1210 - val_loss: 0.5611 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.7288 - acc: 0.1189 - val_loss: 0.5617 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7607 - acc: 0.1189 - val_loss: 0.5621 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6928 - acc: 0.1210 - val_loss: 0.5624 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.8532 - acc: 0.1338 - val_loss: 0.5624 - val_acc: 0.0355\n",
      "Epoch 106/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 186us/step - loss: 0.8637 - acc: 0.1529 - val_loss: 0.5626 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.8454 - acc: 0.1231 - val_loss: 0.5626 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.8626 - acc: 0.1401 - val_loss: 0.5626 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.8193 - acc: 0.1253 - val_loss: 0.5624 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.7051 - acc: 0.1316 - val_loss: 0.5621 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7902 - acc: 0.1401 - val_loss: 0.5617 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.8106 - acc: 0.1699 - val_loss: 0.5611 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.8139 - acc: 0.1699 - val_loss: 0.5603 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7334 - acc: 0.1656 - val_loss: 0.5602 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.8230 - acc: 0.1423 - val_loss: 0.5610 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.8490 - acc: 0.1677 - val_loss: 0.5621 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.8741 - acc: 0.1868 - val_loss: 0.5624 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.8767 - acc: 0.1380 - val_loss: 0.5620 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.8601 - acc: 0.1571 - val_loss: 0.5617 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.7968 - acc: 0.1507 - val_loss: 0.5622 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 154us/step\n",
      "Test score: 0.5621863806501348\n",
      "Look! softmax sigmoid tanh Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_226 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_827 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_604 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_828 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_605 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_829 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 23s 50ms/step - loss: 0.7365 - acc: 0.2930 - val_loss: 0.5557 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.7009 - acc: 0.1996 - val_loss: 0.5369 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6771 - acc: 0.2229 - val_loss: 0.5255 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6553 - acc: 0.2675 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6618 - acc: 0.2229 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6609 - acc: 0.2272 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6563 - acc: 0.2378 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6654 - acc: 0.2484 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6482 - acc: 0.2357 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6598 - acc: 0.2484 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6377 - acc: 0.2569 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6455 - acc: 0.2399 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6679 - acc: 0.2378 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6644 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6733 - acc: 0.2378 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6340 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6482 - acc: 0.2378 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6306 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6577 - acc: 0.2569 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6628 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6452 - acc: 0.2569 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6565 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6522 - acc: 0.2611 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6467 - acc: 0.2505 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6265 - acc: 0.2611 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6627 - acc: 0.2633 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6360 - acc: 0.2569 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6448 - acc: 0.2505 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6532 - acc: 0.2569 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6603 - acc: 0.2527 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6438 - acc: 0.2569 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6613 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6490 - acc: 0.2548 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6451 - acc: 0.2527 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 36/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 196us/step - loss: 0.6498 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6374 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6426 - acc: 0.2527 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6468 - acc: 0.2633 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6300 - acc: 0.2569 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6494 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6440 - acc: 0.2548 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6427 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6506 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6483 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6388 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6396 - acc: 0.2527 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6579 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6411 - acc: 0.2527 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6483 - acc: 0.2633 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6421 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6287 - acc: 0.2569 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6502 - acc: 0.2611 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6493 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6483 - acc: 0.2569 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6369 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6468 - acc: 0.2548 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6425 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6373 - acc: 0.2611 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6431 - acc: 0.2569 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6438 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6312 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6413 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6480 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6278 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6420 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6448 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6449 - acc: 0.2548 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6367 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6385 - acc: 0.2590 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6457 - acc: 0.2569 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6409 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6196 - acc: 0.2569 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6419 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6448 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6484 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6317 - acc: 0.2569 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6375 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6296 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6324 - acc: 0.2569 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6376 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6398 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6562 - acc: 0.2611 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6362 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6290 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6248 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6431 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6391 - acc: 0.2569 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6274 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6405 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6491 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6277 - acc: 0.2611 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6333 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6425 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6484 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6410 - acc: 0.2569 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6388 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6448 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6307 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6287 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6390 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6370 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6345 - acc: 0.2590 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6296 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6431 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6301 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6359 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6268 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6340 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6304 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6273 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6255 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6345 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6302 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 191us/step\n",
      "Test score: 0.5129947231170979\n",
      "Look! softmax sigmoid sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_227 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_830 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_606 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_831 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_607 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_832 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 23s 50ms/step - loss: 0.7399 - acc: 0.3079 - val_loss: 0.5691 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.7477 - acc: 0.2994 - val_loss: 0.5542 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6921 - acc: 0.2739 - val_loss: 0.5421 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.7004 - acc: 0.2760 - val_loss: 0.5333 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.7262 - acc: 0.2548 - val_loss: 0.5294 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6636 - acc: 0.2357 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6934 - acc: 0.2420 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6640 - acc: 0.2442 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7066 - acc: 0.2505 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6982 - acc: 0.2463 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6773 - acc: 0.2505 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6644 - acc: 0.2527 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6539 - acc: 0.2548 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6479 - acc: 0.2505 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6833 - acc: 0.2569 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6455 - acc: 0.2527 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6512 - acc: 0.2718 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6670 - acc: 0.2569 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6574 - acc: 0.2378 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6572 - acc: 0.2548 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6539 - acc: 0.2484 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6574 - acc: 0.2420 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6897 - acc: 0.2527 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6859 - acc: 0.2548 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6441 - acc: 0.2590 - val_loss: 0.5200 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6447 - acc: 0.2505 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6932 - acc: 0.2590 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6534 - acc: 0.2590 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6378 - acc: 0.2654 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6468 - acc: 0.2569 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6895 - acc: 0.2548 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6658 - acc: 0.2569 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6516 - acc: 0.2590 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 0.6373 - acc: 0.2569 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6508 - acc: 0.2527 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6780 - acc: 0.2569 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6914 - acc: 0.2569 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6508 - acc: 0.2569 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6368 - acc: 0.2590 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6440 - acc: 0.2569 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6574 - acc: 0.2505 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6437 - acc: 0.2590 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6543 - acc: 0.2590 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6443 - acc: 0.2633 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6477 - acc: 0.2590 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6446 - acc: 0.2590 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6542 - acc: 0.2590 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6551 - acc: 0.2590 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6365 - acc: 0.2590 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6439 - acc: 0.2590 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6328 - acc: 0.2569 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6374 - acc: 0.2590 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6763 - acc: 0.2590 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6779 - acc: 0.2548 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6453 - acc: 0.2569 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6591 - acc: 0.2590 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7028 - acc: 0.2590 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6710 - acc: 0.2590 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6660 - acc: 0.2590 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6377 - acc: 0.2590 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6744 - acc: 0.2590 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6500 - acc: 0.2590 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6736 - acc: 0.2569 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6477 - acc: 0.2590 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6521 - acc: 0.2590 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6546 - acc: 0.2590 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6473 - acc: 0.2569 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6599 - acc: 0.2590 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6637 - acc: 0.2611 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6499 - acc: 0.2590 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6504 - acc: 0.2611 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6627 - acc: 0.2611 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6500 - acc: 0.2590 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6524 - acc: 0.2569 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6376 - acc: 0.2611 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6602 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6479 - acc: 0.2590 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6499 - acc: 0.2590 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6423 - acc: 0.2590 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6456 - acc: 0.2590 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6480 - acc: 0.2590 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6764 - acc: 0.2590 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6604 - acc: 0.2590 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6490 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6483 - acc: 0.2611 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6400 - acc: 0.2590 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6567 - acc: 0.2590 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6436 - acc: 0.2611 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6545 - acc: 0.2590 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6485 - acc: 0.2611 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6482 - acc: 0.2590 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6432 - acc: 0.2611 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7114 - acc: 0.2611 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6389 - acc: 0.2590 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6747 - acc: 0.2569 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6762 - acc: 0.2590 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6579 - acc: 0.2590 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6467 - acc: 0.2590 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6391 - acc: 0.2590 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 0.6488 - acc: 0.2590 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6423 - acc: 0.2590 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6476 - acc: 0.2590 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6477 - acc: 0.2590 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6593 - acc: 0.2590 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6451 - acc: 0.2590 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6419 - acc: 0.2611 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6380 - acc: 0.2590 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6500 - acc: 0.2590 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6567 - acc: 0.2590 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6415 - acc: 0.2590 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6392 - acc: 0.2590 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6519 - acc: 0.2590 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6548 - acc: 0.2548 - val_loss: 0.5233 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6543 - acc: 0.2590 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6537 - acc: 0.2590 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6638 - acc: 0.2590 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6439 - acc: 0.2590 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6372 - acc: 0.2590 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 165us/step\n",
      "Test score: 0.5227383036985465\n",
      "Look! softmax sigmoid hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_228 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_833 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_608 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_834 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_609 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_835 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 23s 49ms/step - loss: 3.4394 - acc: 0.3206 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.1078 - acc: 0.3439 - val_loss: 4.3459 - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.1671 - acc: 0.3673 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 3.2122 - acc: 0.3631 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 3.3555 - acc: 0.3715 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.0084 - acc: 0.4268 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.9050 - acc: 0.4331 - val_loss: 4.3473 - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.2629 - acc: 0.3928 - val_loss: 4.3460 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.5689 - acc: 0.4246 - val_loss: 4.3463 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 3.3065 - acc: 0.4268 - val_loss: 4.3462 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.6034 - acc: 0.4459 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.3380 - acc: 0.3970 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.6922 - acc: 0.4268 - val_loss: 1.5058 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.3738 - acc: 0.4459 - val_loss: 1.5150 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.2128 - acc: 0.3928 - val_loss: 1.4499 - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.1834 - acc: 0.4480 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 3.2132 - acc: 0.4331 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.0447 - acc: 0.4692 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 3.3470 - acc: 0.4183 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.8173 - acc: 0.4607 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 3.3626 - acc: 0.4671 - val_loss: 6.0586 - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.3884 - acc: 0.4607 - val_loss: 3.1969 - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.4115 - acc: 0.4522 - val_loss: 3.1495 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.8106 - acc: 0.4628 - val_loss: 3.0962 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 3.8893 - acc: 0.4501 - val_loss: 3.0080 - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.6007 - acc: 0.4459 - val_loss: 2.8686 - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.9750 - acc: 0.4650 - val_loss: 2.8373 - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 3.4563 - acc: 0.4183 - val_loss: 2.8695 - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.3105 - acc: 0.4671 - val_loss: 2.9297 - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.8227 - acc: 0.4183 - val_loss: 3.0138 - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.2953 - acc: 0.4756 - val_loss: 3.1486 - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.0155 - acc: 0.4374 - val_loss: 3.2250 - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.6892 - acc: 0.4331 - val_loss: 1.5105 - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.2333 - acc: 0.4225 - val_loss: 1.4129 - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.5245 - acc: 0.4331 - val_loss: 1.3836 - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.3126 - acc: 0.4395 - val_loss: 1.3184 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.8597 - acc: 0.3928 - val_loss: 1.2300 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.4588 - acc: 0.4119 - val_loss: 1.1598 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.3026 - acc: 0.4459 - val_loss: 0.9954 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.4428 - acc: 0.3694 - val_loss: 0.9032 - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.4812 - acc: 0.3524 - val_loss: 0.8549 - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.2946 - acc: 0.3524 - val_loss: 0.7939 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.5994 - acc: 0.3546 - val_loss: 0.7335 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.8678 - acc: 0.3567 - val_loss: 0.6791 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.4803 - acc: 0.3715 - val_loss: 0.6342 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.8057 - acc: 0.3291 - val_loss: 0.6583 - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.8833 - acc: 0.3270 - val_loss: 0.6808 - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.0430 - acc: 0.3079 - val_loss: 0.6864 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.0862 - acc: 0.3355 - val_loss: 0.6908 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.3617 - acc: 0.3355 - val_loss: 0.6953 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.6272 - acc: 0.2972 - val_loss: 0.6888 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.5382 - acc: 0.3567 - val_loss: 0.6975 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.7179 - acc: 0.2803 - val_loss: 0.6953 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.7888 - acc: 0.3333 - val_loss: 0.6963 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.9043 - acc: 0.3079 - val_loss: 0.6905 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.2317 - acc: 0.3376 - val_loss: 0.6691 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.3914 - acc: 0.3057 - val_loss: 0.6470 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.4103 - acc: 0.2675 - val_loss: 0.6296 - val_acc: 0.1277\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.4510 - acc: 0.2718 - val_loss: 0.6108 - val_acc: 0.1277\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.6848 - acc: 0.3227 - val_loss: 0.5978 - val_acc: 0.1277\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.1051 - acc: 0.2781 - val_loss: 0.5835 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.7880 - acc: 0.2527 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.1153 - acc: 0.2590 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.2958 - acc: 0.2803 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.1429 - acc: 0.3036 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.6021 - acc: 0.3142 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.1654 - acc: 0.3100 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.4829 - acc: 0.3227 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.6843 - acc: 0.3652 - val_loss: 6.4015 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.0467 - acc: 0.3291 - val_loss: 6.4015 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.1500 - acc: 0.3503 - val_loss: 6.4015 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.1477 - acc: 0.3715 - val_loss: 4.8051 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.7941 - acc: 0.3588 - val_loss: 4.5783 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.8118 - acc: 0.3992 - val_loss: 4.5145 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.0042 - acc: 0.3949 - val_loss: 4.4911 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.5801 - acc: 0.4076 - val_loss: 4.4866 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.3110 - acc: 0.4013 - val_loss: 1.8754 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.4290 - acc: 0.4055 - val_loss: 1.6614 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.2758 - acc: 0.4522 - val_loss: 1.5808 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.5347 - acc: 0.3800 - val_loss: 1.5208 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.4372 - acc: 0.4140 - val_loss: 1.4656 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.0643 - acc: 0.4076 - val_loss: 1.1272 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.3453 - acc: 0.4459 - val_loss: 0.7378 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.9215 - acc: 0.4225 - val_loss: 0.6841 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.7537 - acc: 0.3949 - val_loss: 0.6403 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.9030 - acc: 0.4459 - val_loss: 0.6140 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.2943 - acc: 0.4183 - val_loss: 0.5930 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.4785 - acc: 0.3949 - val_loss: 0.5723 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.2652 - acc: 0.3949 - val_loss: 0.5556 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.2675 - acc: 0.3609 - val_loss: 0.5471 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.1242 - acc: 0.3609 - val_loss: 0.5429 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.1597 - acc: 0.3524 - val_loss: 0.5384 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9730 - acc: 0.3163 - val_loss: 0.5349 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.0473 - acc: 0.3355 - val_loss: 0.5327 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.0158 - acc: 0.2909 - val_loss: 0.5310 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.0985 - acc: 0.3418 - val_loss: 0.5294 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.9458 - acc: 0.3015 - val_loss: 0.5279 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.0475 - acc: 0.2866 - val_loss: 0.5277 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.9596 - acc: 0.2675 - val_loss: 0.5279 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.7950 - acc: 0.2654 - val_loss: 0.5283 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.9069 - acc: 0.2484 - val_loss: 0.5284 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.9564 - acc: 0.2675 - val_loss: 0.5284 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.9633 - acc: 0.2144 - val_loss: 0.5282 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.0406 - acc: 0.2293 - val_loss: 0.5278 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.9511 - acc: 0.2208 - val_loss: 0.5277 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.8452 - acc: 0.2059 - val_loss: 0.5274 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.8512 - acc: 0.2272 - val_loss: 0.5322 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.9514 - acc: 0.2484 - val_loss: 0.5359 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.8351 - acc: 0.2548 - val_loss: 0.5387 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.7567 - acc: 0.2251 - val_loss: 0.5405 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7947 - acc: 0.2314 - val_loss: 0.5419 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8756 - acc: 0.2633 - val_loss: 0.5425 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.8637 - acc: 0.2590 - val_loss: 0.5426 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7748 - acc: 0.2696 - val_loss: 0.5425 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7988 - acc: 0.2293 - val_loss: 0.5423 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.8264 - acc: 0.2590 - val_loss: 0.5420 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.8000 - acc: 0.2569 - val_loss: 0.5416 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.7748 - acc: 0.1996 - val_loss: 0.5415 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7588 - acc: 0.2484 - val_loss: 0.5418 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7735 - acc: 0.2038 - val_loss: 0.5417 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 172us/step\n",
      "Test score: 0.541707307734388\n",
      "Look! softmax sigmoid linear Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_229 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_836 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_610 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_837 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_611 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_838 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 24s 50ms/step - loss: 1.0627 - acc: 0.1210 - val_loss: 0.7394 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.9347 - acc: 0.1529 - val_loss: 0.6635 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.8709 - acc: 0.1550 - val_loss: 0.6035 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7924 - acc: 0.1868 - val_loss: 0.5613 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7688 - acc: 0.1720 - val_loss: 0.5374 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7422 - acc: 0.2272 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7154 - acc: 0.2314 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7162 - acc: 0.2208 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7003 - acc: 0.2654 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7105 - acc: 0.2484 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6791 - acc: 0.2505 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6558 - acc: 0.2675 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6736 - acc: 0.2548 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6928 - acc: 0.2335 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7108 - acc: 0.2272 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6891 - acc: 0.2420 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7063 - acc: 0.2463 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7034 - acc: 0.2803 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6940 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7016 - acc: 0.2463 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6726 - acc: 0.2420 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6984 - acc: 0.2378 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7121 - acc: 0.2399 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7019 - acc: 0.2378 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.7227 - acc: 0.2654 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6845 - acc: 0.2378 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6914 - acc: 0.2527 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7172 - acc: 0.2314 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6948 - acc: 0.2335 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6804 - acc: 0.2505 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6727 - acc: 0.2781 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6955 - acc: 0.2357 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6665 - acc: 0.2569 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7074 - acc: 0.2484 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6808 - acc: 0.2399 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6856 - acc: 0.2675 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7343 - acc: 0.2081 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6883 - acc: 0.2314 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6835 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6395 - acc: 0.2760 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6543 - acc: 0.2314 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6837 - acc: 0.2527 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6757 - acc: 0.2314 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6661 - acc: 0.2420 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6684 - acc: 0.2781 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6960 - acc: 0.2335 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6709 - acc: 0.2378 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6649 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6696 - acc: 0.2484 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6661 - acc: 0.2293 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6736 - acc: 0.2505 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6843 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6756 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6779 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6851 - acc: 0.2272 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6816 - acc: 0.2378 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6805 - acc: 0.2293 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6905 - acc: 0.2442 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6752 - acc: 0.2399 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6887 - acc: 0.2399 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6652 - acc: 0.2548 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6864 - acc: 0.2187 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6615 - acc: 0.2569 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6459 - acc: 0.2718 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6607 - acc: 0.2675 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6665 - acc: 0.2505 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6645 - acc: 0.2420 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6728 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6746 - acc: 0.2335 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6641 - acc: 0.2548 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6795 - acc: 0.2505 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6505 - acc: 0.2718 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6741 - acc: 0.2399 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6798 - acc: 0.2420 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6686 - acc: 0.2420 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6500 - acc: 0.2505 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6710 - acc: 0.2378 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6724 - acc: 0.2378 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6598 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6832 - acc: 0.2442 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6655 - acc: 0.2378 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6697 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6615 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6816 - acc: 0.2420 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6655 - acc: 0.2463 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6479 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6627 - acc: 0.2378 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6686 - acc: 0.2399 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6714 - acc: 0.2357 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6814 - acc: 0.2442 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6515 - acc: 0.2527 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6589 - acc: 0.2293 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6382 - acc: 0.2654 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6515 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6433 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6749 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6622 - acc: 0.2442 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6856 - acc: 0.2399 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6649 - acc: 0.2442 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6465 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6638 - acc: 0.2357 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6669 - acc: 0.2527 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6570 - acc: 0.2484 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6389 - acc: 0.2569 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6531 - acc: 0.2505 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6604 - acc: 0.2505 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6496 - acc: 0.2548 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6592 - acc: 0.2548 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6590 - acc: 0.2442 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6494 - acc: 0.2442 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6508 - acc: 0.2505 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6608 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6636 - acc: 0.2527 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6591 - acc: 0.2484 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6629 - acc: 0.2378 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6492 - acc: 0.2378 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6501 - acc: 0.2463 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6578 - acc: 0.2442 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6583 - acc: 0.2378 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6595 - acc: 0.2463 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 166us/step\n",
      "Test score: 0.5114559433984418\n",
      "Look! softmax hard_sigmoid softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_230 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_839 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_612 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_840 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_613 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_841 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 24s 51ms/step - loss: 3.7324 - acc: 0.1571 - val_loss: 1.4410 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.1877 - acc: 0.1805 - val_loss: 1.4016 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.2018 - acc: 0.2187 - val_loss: 0.6402 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.8953 - acc: 0.2335 - val_loss: 0.6204 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.6660 - acc: 0.2442 - val_loss: 1.0578 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.6645 - acc: 0.2505 - val_loss: 1.0230 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.5170 - acc: 0.2930 - val_loss: 0.9858 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.3599 - acc: 0.2590 - val_loss: 0.9398 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.3913 - acc: 0.2463 - val_loss: 0.9020 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.2947 - acc: 0.2548 - val_loss: 0.8766 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.8275 - acc: 0.2866 - val_loss: 0.8585 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.4307 - acc: 0.2803 - val_loss: 0.8422 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.3721 - acc: 0.2569 - val_loss: 0.8298 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.4979 - acc: 0.2781 - val_loss: 0.8254 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.8339 - acc: 0.3142 - val_loss: 0.8276 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.0166 - acc: 0.2633 - val_loss: 0.8314 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.0387 - acc: 0.2887 - val_loss: 0.8344 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.9408 - acc: 0.2739 - val_loss: 0.8360 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.8874 - acc: 0.2548 - val_loss: 0.8356 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.9272 - acc: 0.2505 - val_loss: 0.8345 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.9559 - acc: 0.2781 - val_loss: 0.8331 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.9082 - acc: 0.2442 - val_loss: 0.8324 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.5437 - acc: 0.2505 - val_loss: 0.8299 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.5188 - acc: 0.2951 - val_loss: 0.8274 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.7093 - acc: 0.2718 - val_loss: 0.8246 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.9627 - acc: 0.3057 - val_loss: 0.8219 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.5269 - acc: 0.2484 - val_loss: 0.8252 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.8884 - acc: 0.2505 - val_loss: 0.8287 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.5793 - acc: 0.2463 - val_loss: 0.8309 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.5734 - acc: 0.2866 - val_loss: 0.8383 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.3856 - acc: 0.2314 - val_loss: 0.8428 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.7088 - acc: 0.2569 - val_loss: 0.8452 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.5291 - acc: 0.2675 - val_loss: 0.8480 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.4736 - acc: 0.2484 - val_loss: 0.8499 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.3689 - acc: 0.2951 - val_loss: 0.8510 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.3515 - acc: 0.2696 - val_loss: 0.8516 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.4793 - acc: 0.2633 - val_loss: 0.8516 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.1963 - acc: 0.2909 - val_loss: 0.8518 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.4133 - acc: 0.2781 - val_loss: 0.8516 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.4114 - acc: 0.2781 - val_loss: 0.8511 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.4511 - acc: 0.2357 - val_loss: 0.8516 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.5178 - acc: 0.2527 - val_loss: 0.8529 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.5753 - acc: 0.2654 - val_loss: 0.8547 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.5799 - acc: 0.2930 - val_loss: 0.8557 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.3907 - acc: 0.2590 - val_loss: 0.8561 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.4903 - acc: 0.2548 - val_loss: 0.8562 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.3567 - acc: 0.2463 - val_loss: 0.8569 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.4457 - acc: 0.2442 - val_loss: 0.8573 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.3372 - acc: 0.2399 - val_loss: 0.8586 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.3848 - acc: 0.2739 - val_loss: 0.8628 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.3729 - acc: 0.2675 - val_loss: 0.8679 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.3459 - acc: 0.2845 - val_loss: 0.8715 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.0859 - acc: 0.2951 - val_loss: 0.8736 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.2996 - acc: 0.2378 - val_loss: 0.8745 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.3126 - acc: 0.2675 - val_loss: 0.8745 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 1.3326 - acc: 0.2803 - val_loss: 0.8744 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.2894 - acc: 0.2484 - val_loss: 0.8774 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.2164 - acc: 0.2781 - val_loss: 0.8797 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.2520 - acc: 0.2505 - val_loss: 0.8812 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.1717 - acc: 0.2696 - val_loss: 0.8817 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.2976 - acc: 0.2760 - val_loss: 0.8821 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.1843 - acc: 0.2781 - val_loss: 0.8817 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.2991 - acc: 0.2718 - val_loss: 0.8809 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.1816 - acc: 0.2760 - val_loss: 0.8799 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.2374 - acc: 0.2675 - val_loss: 0.8786 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.1886 - acc: 0.2484 - val_loss: 0.8778 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.1670 - acc: 0.2718 - val_loss: 0.8784 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.2753 - acc: 0.2569 - val_loss: 0.8782 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.2285 - acc: 0.2484 - val_loss: 0.8777 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.2187 - acc: 0.2633 - val_loss: 0.8787 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.3609 - acc: 0.2420 - val_loss: 0.8839 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.1995 - acc: 0.2824 - val_loss: 0.8871 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.2355 - acc: 0.2887 - val_loss: 0.8896 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.3487 - acc: 0.2739 - val_loss: 0.8916 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.2532 - acc: 0.3142 - val_loss: 0.8946 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.1812 - acc: 0.2866 - val_loss: 0.8969 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.2140 - acc: 0.3100 - val_loss: 0.8979 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.2084 - acc: 0.2972 - val_loss: 0.8981 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.1677 - acc: 0.2611 - val_loss: 0.8980 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.2645 - acc: 0.2633 - val_loss: 0.8976 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.1861 - acc: 0.3142 - val_loss: 0.8968 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.2259 - acc: 0.2611 - val_loss: 0.8957 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.3056 - acc: 0.2994 - val_loss: 0.8946 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.1911 - acc: 0.3057 - val_loss: 0.8934 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.2312 - acc: 0.2781 - val_loss: 0.8922 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.1402 - acc: 0.2972 - val_loss: 0.8910 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.1533 - acc: 0.2527 - val_loss: 0.8900 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.0952 - acc: 0.2866 - val_loss: 0.8890 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.1640 - acc: 0.2633 - val_loss: 0.8885 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.2727 - acc: 0.2739 - val_loss: 0.8882 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.2584 - acc: 0.2866 - val_loss: 0.8879 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.2352 - acc: 0.2378 - val_loss: 0.8875 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.1890 - acc: 0.2505 - val_loss: 0.8869 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.2122 - acc: 0.2463 - val_loss: 0.8862 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.1761 - acc: 0.2548 - val_loss: 0.8861 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.3062 - acc: 0.2569 - val_loss: 0.8859 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.1244 - acc: 0.2675 - val_loss: 0.8854 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.2345 - acc: 0.2505 - val_loss: 0.8851 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.2891 - acc: 0.2442 - val_loss: 0.8846 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.1491 - acc: 0.2420 - val_loss: 0.8842 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.1340 - acc: 0.2548 - val_loss: 0.8846 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.1625 - acc: 0.2548 - val_loss: 0.8876 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.2213 - acc: 0.2505 - val_loss: 0.8900 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.1740 - acc: 0.2505 - val_loss: 0.8916 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.1772 - acc: 0.2824 - val_loss: 0.8927 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.1121 - acc: 0.2187 - val_loss: 0.8930 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.1094 - acc: 0.2803 - val_loss: 0.8928 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.2011 - acc: 0.2548 - val_loss: 0.8922 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.0857 - acc: 0.2951 - val_loss: 0.8916 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.2092 - acc: 0.2718 - val_loss: 0.8925 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.0763 - acc: 0.3100 - val_loss: 0.8931 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.1398 - acc: 0.2569 - val_loss: 0.8929 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.1821 - acc: 0.2654 - val_loss: 0.8924 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.1525 - acc: 0.2548 - val_loss: 0.8914 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.3333 - acc: 0.2590 - val_loss: 0.8904 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.1842 - acc: 0.2611 - val_loss: 0.8892 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.1427 - acc: 0.2420 - val_loss: 0.8881 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.3581 - acc: 0.2442 - val_loss: 0.8869 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.1515 - acc: 0.2760 - val_loss: 0.8860 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.0764 - acc: 0.2463 - val_loss: 0.8848 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 178us/step\n",
      "Test score: 0.8848362070448855\n",
      "Look! softmax hard_sigmoid elu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_231 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_842 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_614 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_843 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_615 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_844 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 24s 51ms/step - loss: 2.4694 - acc: 0.1444 - val_loss: 1.3234 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.5196 - acc: 0.1762 - val_loss: 1.2085 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 2.3149 - acc: 0.1720 - val_loss: 1.1177 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.4400 - acc: 0.1932 - val_loss: 1.0771 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.5057 - acc: 0.1911 - val_loss: 1.4898 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.3930 - acc: 0.1890 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 2.2633 - acc: 0.1783 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 3.1546 - acc: 0.2251 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.3196 - acc: 0.1996 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 3.3473 - acc: 0.1868 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.5215 - acc: 0.2357 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.3381 - acc: 0.2017 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.7930 - acc: 0.2038 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.5263 - acc: 0.2335 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.1201 - acc: 0.2399 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.9601 - acc: 0.2442 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.9701 - acc: 0.2272 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 4.3470 - acc: 0.2527 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.0138 - acc: 0.2208 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 4.2928 - acc: 0.2144 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 4.2003 - acc: 0.2314 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 4.1272 - acc: 0.2144 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 4.1844 - acc: 0.2187 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 4.1648 - acc: 0.2293 - val_loss: 5.4892 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 4.1864 - acc: 0.2293 - val_loss: 5.4940 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.9653 - acc: 0.2144 - val_loss: 5.5015 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.2962 - acc: 0.2420 - val_loss: 4.0942 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 3.9064 - acc: 0.2654 - val_loss: 3.7447 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 4.0976 - acc: 0.2548 - val_loss: 3.6905 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.6159 - acc: 0.2527 - val_loss: 3.6640 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.6852 - acc: 0.2675 - val_loss: 3.6486 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 3.3532 - acc: 0.2760 - val_loss: 3.6368 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.8774 - acc: 0.2505 - val_loss: 3.6339 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.3142 - acc: 0.2442 - val_loss: 3.6344 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.8780 - acc: 0.1975 - val_loss: 3.6424 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.9057 - acc: 0.2187 - val_loss: 1.1103 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 3.2217 - acc: 0.2187 - val_loss: 1.0387 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.6888 - acc: 0.2420 - val_loss: 0.9994 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.9996 - acc: 0.2123 - val_loss: 0.9573 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.4115 - acc: 0.1932 - val_loss: 0.9364 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.7148 - acc: 0.1953 - val_loss: 0.9219 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.5034 - acc: 0.2038 - val_loss: 0.9074 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.1638 - acc: 0.1805 - val_loss: 0.8952 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.0797 - acc: 0.1677 - val_loss: 0.8860 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.8968 - acc: 0.1635 - val_loss: 0.8778 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.8861 - acc: 0.2038 - val_loss: 0.8696 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.3146 - acc: 0.1699 - val_loss: 0.8586 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.0035 - acc: 0.1656 - val_loss: 0.8467 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 2.3923 - acc: 0.1571 - val_loss: 0.8349 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.9369 - acc: 0.1338 - val_loss: 0.8308 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.7006 - acc: 0.1316 - val_loss: 0.8250 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.2020 - acc: 0.1231 - val_loss: 0.8190 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.0495 - acc: 0.1231 - val_loss: 0.8067 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.9771 - acc: 0.0934 - val_loss: 0.7910 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.0069 - acc: 0.1083 - val_loss: 0.7730 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.9193 - acc: 0.0743 - val_loss: 0.7534 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.1296 - acc: 0.0870 - val_loss: 0.7312 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.0422 - acc: 0.0807 - val_loss: 0.7061 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.2699 - acc: 0.0679 - val_loss: 0.6791 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.1011 - acc: 0.0616 - val_loss: 0.6521 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.0626 - acc: 0.0679 - val_loss: 0.6245 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.5645 - acc: 0.0594 - val_loss: 0.6102 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.4953 - acc: 0.0510 - val_loss: 0.6092 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.4735 - acc: 0.0531 - val_loss: 0.6074 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.4160 - acc: 0.0510 - val_loss: 0.6042 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.0464 - acc: 0.0425 - val_loss: 0.6005 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 2.6002 - acc: 0.0510 - val_loss: 0.5963 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 2.5310 - acc: 0.0510 - val_loss: 0.5916 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.0763 - acc: 0.0446 - val_loss: 0.5859 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.1986 - acc: 0.0467 - val_loss: 0.5787 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.8795 - acc: 0.0488 - val_loss: 0.5728 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.0701 - acc: 0.0510 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 3.3165 - acc: 0.0488 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.3372 - acc: 0.0488 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 3.3964 - acc: 0.0467 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.5837 - acc: 0.0488 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.4214 - acc: 0.0446 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.0944 - acc: 0.0467 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 3.2229 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 4.1051 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.8244 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.9955 - acc: 0.0446 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 4.0015 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.9170 - acc: 0.0446 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 4.3915 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.7186 - acc: 0.0446 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 4.3524 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.3814 - acc: 0.0446 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 5.1592 - acc: 0.0467 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 4.8462 - acc: 0.0403 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 5.1873 - acc: 0.0382 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.6543 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.7812 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 4.3353 - acc: 0.0510 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 4.6401 - acc: 0.0467 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.0497 - acc: 0.0446 - val_loss: 3.5488 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.3343 - acc: 0.0510 - val_loss: 3.3730 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.7487 - acc: 0.0510 - val_loss: 3.2599 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 4.1746 - acc: 0.0552 - val_loss: 3.1789 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.5290 - acc: 0.0679 - val_loss: 3.1376 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.4205 - acc: 0.0637 - val_loss: 3.1108 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.4390 - acc: 0.0828 - val_loss: 3.0939 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.1501 - acc: 0.1125 - val_loss: 3.0824 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.4905 - acc: 0.1295 - val_loss: 3.0738 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.3028 - acc: 0.1168 - val_loss: 3.0699 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.1043 - acc: 0.1359 - val_loss: 3.0679 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.1526 - acc: 0.1295 - val_loss: 3.0700 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.0114 - acc: 0.1316 - val_loss: 3.0728 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.6580 - acc: 0.1571 - val_loss: 3.0717 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.8707 - acc: 0.1592 - val_loss: 3.0710 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.8917 - acc: 0.1614 - val_loss: 3.0799 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.6734 - acc: 0.1741 - val_loss: 3.0929 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.4477 - acc: 0.1847 - val_loss: 3.1039 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.3483 - acc: 0.1932 - val_loss: 3.1142 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.2938 - acc: 0.2102 - val_loss: 1.5511 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.3742 - acc: 0.1932 - val_loss: 1.4330 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 2.1061 - acc: 0.1932 - val_loss: 1.3833 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.7471 - acc: 0.1911 - val_loss: 1.3577 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 2.0109 - acc: 0.1890 - val_loss: 1.3380 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: 1.7309 - acc: 0.2335 - val_loss: 1.3209 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 166us/step\n",
      "Test score: 1.320937325768437\n",
      "Look! softmax hard_sigmoid selu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_232 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_845 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_616 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_846 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_617 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_847 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 24s 51ms/step - loss: 0.7125 - acc: 0.2081 - val_loss: 0.5500 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7088 - acc: 0.2357 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6964 - acc: 0.2166 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6739 - acc: 0.2293 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6878 - acc: 0.2633 - val_loss: 0.5103 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6691 - acc: 0.2059 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6621 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6438 - acc: 0.2633 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6454 - acc: 0.2527 - val_loss: 0.5104 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6904 - acc: 0.2357 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6462 - acc: 0.2484 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6805 - acc: 0.2484 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6389 - acc: 0.2611 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6764 - acc: 0.2229 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6653 - acc: 0.2272 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6492 - acc: 0.2399 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6653 - acc: 0.2335 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6542 - acc: 0.2378 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6514 - acc: 0.2633 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6706 - acc: 0.2357 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6730 - acc: 0.2420 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6442 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6655 - acc: 0.2527 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6804 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6518 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6603 - acc: 0.2314 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6540 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6597 - acc: 0.2378 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6423 - acc: 0.2442 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6414 - acc: 0.2463 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6626 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6500 - acc: 0.2399 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6499 - acc: 0.2442 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6515 - acc: 0.2420 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6711 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6511 - acc: 0.2335 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6603 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6682 - acc: 0.2442 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6211 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6506 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 41/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 188us/step - loss: 0.6421 - acc: 0.2654 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6341 - acc: 0.2633 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6566 - acc: 0.2463 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6296 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6471 - acc: 0.2463 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6465 - acc: 0.2505 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6761 - acc: 0.2442 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6414 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6655 - acc: 0.2399 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6478 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6483 - acc: 0.2442 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6421 - acc: 0.2463 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6434 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6500 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6471 - acc: 0.2654 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6382 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6428 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6469 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6410 - acc: 0.2633 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6550 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6545 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6389 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6504 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6496 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6443 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6424 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6511 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6447 - acc: 0.2527 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6430 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6546 - acc: 0.2484 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6500 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6306 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6527 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6508 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6393 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6394 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6312 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6442 - acc: 0.2548 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6325 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6410 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6179 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6466 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6458 - acc: 0.2548 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6439 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6340 - acc: 0.2505 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6468 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6466 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6593 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6413 - acc: 0.2548 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6358 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6533 - acc: 0.2463 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6431 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6515 - acc: 0.2505 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6479 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6372 - acc: 0.2505 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6467 - acc: 0.2527 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6563 - acc: 0.2484 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6282 - acc: 0.2633 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6338 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6422 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6428 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6476 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6508 - acc: 0.2548 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6370 - acc: 0.2633 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6363 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6309 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6495 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6458 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6313 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6353 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6292 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6530 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6373 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6424 - acc: 0.2569 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6410 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6404 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6553 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6234 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6427 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 163us/step\n",
      "Test score: 0.5110894035785756\n",
      "Look! softmax hard_sigmoid softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_233 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_848 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_618 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_849 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_619 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_850 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 24s 51ms/step - loss: 2.8028 - acc: 0.2972 - val_loss: 2.0766 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 3.4384 - acc: 0.2675 - val_loss: 2.0909 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.2054 - acc: 0.2102 - val_loss: 2.1098 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.3676 - acc: 0.2272 - val_loss: 2.1205 - val_acc: 0.0355\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.9955 - acc: 0.1699 - val_loss: 2.1115 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.0840 - acc: 0.2293 - val_loss: 2.1198 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.4490 - acc: 0.2272 - val_loss: 2.1227 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.1149 - acc: 0.1975 - val_loss: 2.1313 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.1931 - acc: 0.1720 - val_loss: 2.1444 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.8906 - acc: 0.2144 - val_loss: 2.1573 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.1314 - acc: 0.2144 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.2197 - acc: 0.1699 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.4375 - acc: 0.1805 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.1070 - acc: 0.2038 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.6745 - acc: 0.2293 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.6534 - acc: 0.1932 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.1713 - acc: 0.1783 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.1499 - acc: 0.1699 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.2211 - acc: 0.1720 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.7116 - acc: 0.2187 - val_loss: 2.1868 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.7316 - acc: 0.1868 - val_loss: 2.1956 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.2876 - acc: 0.1635 - val_loss: 3.0256 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.9223 - acc: 0.1741 - val_loss: 2.9907 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.8293 - acc: 0.1146 - val_loss: 2.9874 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.0850 - acc: 0.1168 - val_loss: 2.9889 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.2020 - acc: 0.0722 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.1975 - acc: 0.0786 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.7331 - acc: 0.0594 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.1303 - acc: 0.0786 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.1171 - acc: 0.0701 - val_loss: 2.9721 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.9234 - acc: 0.0849 - val_loss: 2.9721 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.2184 - acc: 0.0807 - val_loss: 2.9755 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.0741 - acc: 0.0679 - val_loss: 3.0423 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.7589 - acc: 0.0679 - val_loss: 3.0968 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.2581 - acc: 0.0934 - val_loss: 1.3624 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.7165 - acc: 0.0786 - val_loss: 1.2928 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.6608 - acc: 0.0892 - val_loss: 1.2758 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.5114 - acc: 0.0892 - val_loss: 1.2662 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.5853 - acc: 0.0955 - val_loss: 1.2569 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.4964 - acc: 0.1168 - val_loss: 1.2391 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.0998 - acc: 0.1083 - val_loss: 1.2239 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.1574 - acc: 0.1274 - val_loss: 1.2091 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.3862 - acc: 0.1529 - val_loss: 1.1947 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.5059 - acc: 0.1656 - val_loss: 1.1665 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.1232 - acc: 0.1614 - val_loss: 1.1337 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.4579 - acc: 0.1720 - val_loss: 1.1186 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.3039 - acc: 0.1783 - val_loss: 1.1111 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.4037 - acc: 0.1635 - val_loss: 1.0978 - val_acc: 0.1277\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.8810 - acc: 0.2081 - val_loss: 1.0831 - val_acc: 0.1277\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.1568 - acc: 0.2017 - val_loss: 1.0943 - val_acc: 0.1277\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.3482 - acc: 0.2059 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.0007 - acc: 0.2017 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.3855 - acc: 0.1847 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.8800 - acc: 0.2144 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.8382 - acc: 0.2187 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 3.0877 - acc: 0.2527 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.9449 - acc: 0.2611 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.6571 - acc: 0.2569 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.1266 - acc: 0.2314 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.1838 - acc: 0.2102 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.4218 - acc: 0.2314 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.2489 - acc: 0.2314 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.3948 - acc: 0.2208 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.9004 - acc: 0.2017 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 3.4199 - acc: 0.2654 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.3231 - acc: 0.2357 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.3962 - acc: 0.1996 - val_loss: 5.4927 - val_acc: 0.1277\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.3277 - acc: 0.2527 - val_loss: 5.5030 - val_acc: 0.1277\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.3637 - acc: 0.2654 - val_loss: 5.5123 - val_acc: 0.1277\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.5647 - acc: 0.2505 - val_loss: 5.5193 - val_acc: 0.1277\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.4031 - acc: 0.2463 - val_loss: 5.5259 - val_acc: 0.1277\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.0908 - acc: 0.2569 - val_loss: 3.0224 - val_acc: 0.1277\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.2765 - acc: 0.2654 - val_loss: 2.6790 - val_acc: 0.1277\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 3.0952 - acc: 0.2208 - val_loss: 2.5215 - val_acc: 0.1277\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.2649 - acc: 0.2399 - val_loss: 2.4448 - val_acc: 0.1277\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.0855 - acc: 0.2017 - val_loss: 1.0682 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.4685 - acc: 0.1805 - val_loss: 0.8647 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.9327 - acc: 0.2017 - val_loss: 4.3439 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.8531 - acc: 0.1592 - val_loss: 4.3439 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.9861 - acc: 0.1486 - val_loss: 4.3439 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.1130 - acc: 0.1762 - val_loss: 4.3439 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.5725 - acc: 0.1635 - val_loss: 4.3439 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.4928 - acc: 0.1592 - val_loss: 4.3439 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.0643 - acc: 0.1847 - val_loss: 4.3439 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.8684 - acc: 0.1635 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.7011 - acc: 0.1762 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.1869 - acc: 0.2335 - val_loss: 2.6467 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.9604 - acc: 0.2038 - val_loss: 1.0773 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.9031 - acc: 0.1911 - val_loss: 0.8274 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.2042 - acc: 0.2251 - val_loss: 0.8267 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.9467 - acc: 0.2102 - val_loss: 0.8380 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.7121 - acc: 0.2229 - val_loss: 0.8615 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.2607 - acc: 0.2251 - val_loss: 0.8927 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.7760 - acc: 0.1762 - val_loss: 0.8894 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.5619 - acc: 0.1805 - val_loss: 0.8808 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.6737 - acc: 0.2463 - val_loss: 0.8938 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.0670 - acc: 0.1783 - val_loss: 0.9412 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.9679 - acc: 0.2505 - val_loss: 1.0698 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.9312 - acc: 0.2463 - val_loss: 2.6682 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.8695 - acc: 0.2166 - val_loss: 2.6506 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.8628 - acc: 0.1975 - val_loss: 2.6441 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.9840 - acc: 0.1762 - val_loss: 2.6349 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.7036 - acc: 0.1932 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.7244 - acc: 0.2229 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 3.0863 - acc: 0.1529 - val_loss: 4.3439 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.0072 - acc: 0.1359 - val_loss: 4.3585 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.0934 - acc: 0.1125 - val_loss: 4.3936 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.8068 - acc: 0.1125 - val_loss: 4.4089 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.1245 - acc: 0.0870 - val_loss: 4.4285 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.3826 - acc: 0.0934 - val_loss: 4.4462 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.9093 - acc: 0.0934 - val_loss: 4.4590 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.6499 - acc: 0.0764 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 3.0603 - acc: 0.0807 - val_loss: 1.3953 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.0152 - acc: 0.0849 - val_loss: 1.3735 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.0169 - acc: 0.0955 - val_loss: 1.3755 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.9350 - acc: 0.0977 - val_loss: 1.3818 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.1162 - acc: 0.0786 - val_loss: 1.3808 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.6583 - acc: 0.0934 - val_loss: 1.3709 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.8134 - acc: 0.1168 - val_loss: 1.3491 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.6206 - acc: 0.1062 - val_loss: 1.3306 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 169us/step\n",
      "Test score: 1.3306231126717643\n",
      "Look! softmax hard_sigmoid softsign Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_234 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_851 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_620 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_852 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_621 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_853 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 24s 51ms/step - loss: nan - acc: 0.2972 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 168us/step\n",
      "Test score: nan\n",
      "Look! softmax hard_sigmoid relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax hard_sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_235 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_854 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_622 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_855 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_623 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_856 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 24s 50ms/step - loss: 3.4140 - acc: 0.2930 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.3504 - acc: 0.2845 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.0728 - acc: 0.2590 - val_loss: 4.9154 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.1341 - acc: 0.2527 - val_loss: 2.2338 - val_acc: 0.0355\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.0080 - acc: 0.2633 - val_loss: 1.6894 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.4596 - acc: 0.2548 - val_loss: 1.6114 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.3259 - acc: 0.2590 - val_loss: 1.5740 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.9099 - acc: 0.2760 - val_loss: 1.5284 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.4070 - acc: 0.2611 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.5493 - acc: 0.2675 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.0733 - acc: 0.2187 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.9358 - acc: 0.2229 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 3.1953 - acc: 0.2017 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 3.4296 - acc: 0.2081 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.3801 - acc: 0.1996 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 3.0853 - acc: 0.1380 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 3.2323 - acc: 0.1911 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.7308 - acc: 0.1699 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.2601 - acc: 0.2251 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 3.6590 - acc: 0.1975 - val_loss: 5.4907 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.1034 - acc: 0.1699 - val_loss: 5.5096 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 3.0104 - acc: 0.2335 - val_loss: 5.5256 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 3.2963 - acc: 0.1635 - val_loss: 2.4912 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.8873 - acc: 0.1826 - val_loss: 2.3751 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.1396 - acc: 0.1720 - val_loss: 2.3480 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.9510 - acc: 0.1890 - val_loss: 2.3491 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.0546 - acc: 0.1741 - val_loss: 2.3338 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.0142 - acc: 0.1953 - val_loss: 2.3437 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.9461 - acc: 0.1762 - val_loss: 2.3513 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.8936 - acc: 0.1868 - val_loss: 2.3573 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.9242 - acc: 0.2251 - val_loss: 2.3622 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.4182 - acc: 0.2102 - val_loss: 2.3659 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.4708 - acc: 0.1805 - val_loss: 0.6918 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.7100 - acc: 0.2123 - val_loss: 0.6167 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.1717 - acc: 0.2144 - val_loss: 0.5962 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.4305 - acc: 0.2059 - val_loss: 0.5877 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.0069 - acc: 0.2293 - val_loss: 0.5545 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.7186 - acc: 0.2590 - val_loss: 0.5440 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.4842 - acc: 0.2548 - val_loss: 0.5378 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.6053 - acc: 0.2463 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.5865 - acc: 0.2548 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.8527 - acc: 0.2378 - val_loss: 0.5233 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.5888 - acc: 0.2527 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.3059 - acc: 0.2590 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.3127 - acc: 0.2505 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.1806 - acc: 0.2293 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.2869 - acc: 0.2611 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.3684 - acc: 0.2484 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.5512 - acc: 0.2229 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.4430 - acc: 0.2484 - val_loss: 0.5241 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.4074 - acc: 0.2633 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.2326 - acc: 0.2527 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.1675 - acc: 0.2463 - val_loss: 0.5292 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.2400 - acc: 0.2548 - val_loss: 0.5299 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.2956 - acc: 0.2442 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.9320 - acc: 0.2293 - val_loss: 0.5313 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.9802 - acc: 0.2335 - val_loss: 0.5353 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.1300 - acc: 0.2675 - val_loss: 0.5449 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.0813 - acc: 0.2335 - val_loss: 0.5689 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.9882 - acc: 0.2484 - val_loss: 0.9744 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.0104 - acc: 0.2548 - val_loss: 0.9756 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.3454 - acc: 0.2442 - val_loss: 0.9762 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.0045 - acc: 0.2484 - val_loss: 0.6019 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.9595 - acc: 0.2739 - val_loss: 0.5736 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.1617 - acc: 0.2229 - val_loss: 0.5709 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.1554 - acc: 0.2527 - val_loss: 0.5730 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.9456 - acc: 0.2293 - val_loss: 0.5762 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.0791 - acc: 0.2293 - val_loss: 0.8943 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.1012 - acc: 0.2314 - val_loss: 0.9691 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.9907 - acc: 0.1996 - val_loss: 0.9631 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.2526 - acc: 0.2505 - val_loss: 0.9618 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.9123 - acc: 0.2399 - val_loss: 0.9663 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.2009 - acc: 0.2548 - val_loss: 0.9681 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.2847 - acc: 0.2420 - val_loss: 0.9663 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.0374 - acc: 0.2378 - val_loss: 0.9647 - val_acc: 0.2128\n",
      "Epoch 76/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 198us/step - loss: 0.9095 - acc: 0.2335 - val_loss: 0.9632 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.9436 - acc: 0.2229 - val_loss: 0.9601 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.0772 - acc: 0.2335 - val_loss: 0.9596 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.0516 - acc: 0.2527 - val_loss: 0.9576 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.9671 - acc: 0.2527 - val_loss: 0.9582 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.0146 - acc: 0.2144 - val_loss: 0.9585 - val_acc: 0.1277\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.9738 - acc: 0.2102 - val_loss: 0.9582 - val_acc: 0.1277\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.0749 - acc: 0.2314 - val_loss: 0.9559 - val_acc: 0.1277\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.0135 - acc: 0.2357 - val_loss: 0.9536 - val_acc: 0.1277\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.9270 - acc: 0.2420 - val_loss: 0.9522 - val_acc: 0.1277\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.0932 - acc: 0.2293 - val_loss: 0.9521 - val_acc: 0.1277\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.9805 - acc: 0.2229 - val_loss: 0.9562 - val_acc: 0.1277\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.0175 - acc: 0.2527 - val_loss: 0.9592 - val_acc: 0.1277\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.8866 - acc: 0.2293 - val_loss: 0.9645 - val_acc: 0.1277\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.0477 - acc: 0.2229 - val_loss: 0.9714 - val_acc: 0.1277\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.9863 - acc: 0.2548 - val_loss: 0.9773 - val_acc: 0.1277\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.0157 - acc: 0.2760 - val_loss: 0.9796 - val_acc: 0.1277\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9006 - acc: 0.2505 - val_loss: 0.9794 - val_acc: 0.1277\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.9145 - acc: 0.2314 - val_loss: 0.9821 - val_acc: 0.1277\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.0514 - acc: 0.2272 - val_loss: 0.9828 - val_acc: 0.1277\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.0683 - acc: 0.2399 - val_loss: 0.9821 - val_acc: 0.1277\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.8782 - acc: 0.2335 - val_loss: 0.9800 - val_acc: 0.1277\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.8679 - acc: 0.2166 - val_loss: 0.9764 - val_acc: 0.1277\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.0543 - acc: 0.2378 - val_loss: 0.9723 - val_acc: 0.1277\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.9850 - acc: 0.2505 - val_loss: 0.9676 - val_acc: 0.1277\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.0084 - acc: 0.2399 - val_loss: 0.9632 - val_acc: 0.1277\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.0343 - acc: 0.2505 - val_loss: 0.9590 - val_acc: 0.1277\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.8635 - acc: 0.2081 - val_loss: 0.9550 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.1004 - acc: 0.2463 - val_loss: 0.9529 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.9753 - acc: 0.2208 - val_loss: 0.9503 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.1467 - acc: 0.2251 - val_loss: 0.9464 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.0716 - acc: 0.2484 - val_loss: 0.9421 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.1466 - acc: 0.2527 - val_loss: 0.9383 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.0165 - acc: 0.2187 - val_loss: 0.9343 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.9557 - acc: 0.2527 - val_loss: 0.9306 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 1.0842 - acc: 0.2038 - val_loss: 0.9301 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.1348 - acc: 0.2335 - val_loss: 0.9379 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.9879 - acc: 0.2378 - val_loss: 0.9412 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.0017 - acc: 0.2463 - val_loss: 0.9424 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.0251 - acc: 0.2208 - val_loss: 0.9433 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.0076 - acc: 0.2335 - val_loss: 0.9443 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.1274 - acc: 0.2824 - val_loss: 0.9450 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.9520 - acc: 0.2633 - val_loss: 0.9446 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.0008 - acc: 0.2166 - val_loss: 0.9434 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.0988 - acc: 0.2229 - val_loss: 0.9419 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 176us/step\n",
      "Test score: 0.9418635397938127\n",
      "Look! softmax hard_sigmoid tanh Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax hard_sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_236 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_857 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_624 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_858 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_625 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_859 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 24s 51ms/step - loss: 0.7194 - acc: 0.3567 - val_loss: 0.5492 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6944 - acc: 0.3142 - val_loss: 0.5348 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6794 - acc: 0.2781 - val_loss: 0.5249 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6736 - acc: 0.2505 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6512 - acc: 0.2590 - val_loss: 0.5147 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6587 - acc: 0.2611 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6583 - acc: 0.2527 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6683 - acc: 0.2442 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6621 - acc: 0.2463 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6559 - acc: 0.2654 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6552 - acc: 0.2548 - val_loss: 0.5103 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6394 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6486 - acc: 0.2484 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6532 - acc: 0.2463 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6464 - acc: 0.2505 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6601 - acc: 0.2505 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6535 - acc: 0.2527 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6466 - acc: 0.2654 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6493 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6559 - acc: 0.2654 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6509 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6451 - acc: 0.2569 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6630 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6497 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6419 - acc: 0.2548 - val_loss: 0.5101 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6366 - acc: 0.2590 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6465 - acc: 0.2633 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6511 - acc: 0.2590 - val_loss: 0.5107 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6342 - acc: 0.2527 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6478 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6416 - acc: 0.2505 - val_loss: 0.5103 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6506 - acc: 0.2590 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6476 - acc: 0.2611 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6424 - acc: 0.2548 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6411 - acc: 0.2633 - val_loss: 0.5103 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6335 - acc: 0.2569 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6440 - acc: 0.2569 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6293 - acc: 0.2633 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6459 - acc: 0.2611 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6390 - acc: 0.2633 - val_loss: 0.5088 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6415 - acc: 0.2590 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6403 - acc: 0.2590 - val_loss: 0.5080 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6507 - acc: 0.2590 - val_loss: 0.5081 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6423 - acc: 0.2548 - val_loss: 0.5076 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6520 - acc: 0.2590 - val_loss: 0.5078 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6366 - acc: 0.2569 - val_loss: 0.5077 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6397 - acc: 0.2569 - val_loss: 0.5074 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6512 - acc: 0.2590 - val_loss: 0.5070 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6270 - acc: 0.2611 - val_loss: 0.5072 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5065 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6413 - acc: 0.2611 - val_loss: 0.5070 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6319 - acc: 0.2611 - val_loss: 0.5071 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6412 - acc: 0.2569 - val_loss: 0.5065 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6418 - acc: 0.2569 - val_loss: 0.5064 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5054 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6358 - acc: 0.2590 - val_loss: 0.5052 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6328 - acc: 0.2611 - val_loss: 0.5057 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6309 - acc: 0.2590 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6354 - acc: 0.2590 - val_loss: 0.5055 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6410 - acc: 0.2569 - val_loss: 0.5072 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6349 - acc: 0.2569 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6401 - acc: 0.2590 - val_loss: 0.5104 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6351 - acc: 0.2548 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6454 - acc: 0.2569 - val_loss: 0.5104 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6411 - acc: 0.2633 - val_loss: 0.5104 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6320 - acc: 0.2569 - val_loss: 0.5074 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6393 - acc: 0.2611 - val_loss: 0.5046 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6365 - acc: 0.2590 - val_loss: 0.5055 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6347 - acc: 0.2590 - val_loss: 0.5038 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6331 - acc: 0.2590 - val_loss: 0.5058 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6341 - acc: 0.2590 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6243 - acc: 0.2590 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6327 - acc: 0.2611 - val_loss: 0.5051 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6394 - acc: 0.2590 - val_loss: 0.5030 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5031 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6377 - acc: 0.2590 - val_loss: 0.5096 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6498 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6455 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6399 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6557 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6401 - acc: 0.2611 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6404 - acc: 0.2569 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6585 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6446 - acc: 0.2590 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6375 - acc: 0.2611 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6248 - acc: 0.2569 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6404 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6435 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6396 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6365 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6353 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6442 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6398 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6518 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6327 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6440 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6495 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6366 - acc: 0.2548 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6435 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6317 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6313 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6435 - acc: 0.2569 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6456 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6457 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6423 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6254 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6359 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6430 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6379 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6288 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6458 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6419 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6236 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6392 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6445 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 170us/step\n",
      "Test score: 0.5115006265910804\n",
      "Look! softmax hard_sigmoid sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax hard_sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_237 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_860 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_626 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_861 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_627 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_862 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 52ms/step - loss: 0.7332 - acc: 0.3333 - val_loss: 0.5764 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7060 - acc: 0.2611 - val_loss: 0.5597 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7017 - acc: 0.2590 - val_loss: 0.5476 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6861 - acc: 0.2357 - val_loss: 0.5389 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6799 - acc: 0.2251 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6650 - acc: 0.2272 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7541 - acc: 0.2484 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7481 - acc: 0.2633 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6801 - acc: 0.2463 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6857 - acc: 0.2633 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6447 - acc: 0.2590 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6441 - acc: 0.2569 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6563 - acc: 0.2569 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6654 - acc: 0.2548 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6587 - acc: 0.2611 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6673 - acc: 0.2590 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6618 - acc: 0.2378 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6500 - acc: 0.2505 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6395 - acc: 0.2611 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6403 - acc: 0.2611 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6540 - acc: 0.2527 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6494 - acc: 0.2654 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6567 - acc: 0.2590 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6398 - acc: 0.2548 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6562 - acc: 0.2633 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6465 - acc: 0.2611 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6497 - acc: 0.2590 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6989 - acc: 0.2633 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6746 - acc: 0.2505 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6953 - acc: 0.2548 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6453 - acc: 0.2590 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6648 - acc: 0.2569 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6492 - acc: 0.2569 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6594 - acc: 0.2569 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6501 - acc: 0.2611 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6517 - acc: 0.2548 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6642 - acc: 0.2569 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6403 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6533 - acc: 0.2569 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6868 - acc: 0.2527 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6485 - acc: 0.2590 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6525 - acc: 0.2569 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6437 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6477 - acc: 0.2590 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6516 - acc: 0.2569 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6568 - acc: 0.2569 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6466 - acc: 0.2590 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6456 - acc: 0.2590 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6461 - acc: 0.2569 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6505 - acc: 0.2654 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6579 - acc: 0.2569 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6498 - acc: 0.2590 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6534 - acc: 0.2590 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6863 - acc: 0.2569 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6493 - acc: 0.2590 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6513 - acc: 0.2590 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6545 - acc: 0.2548 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6488 - acc: 0.2590 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6303 - acc: 0.2569 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6433 - acc: 0.2590 - val_loss: 0.5196 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6418 - acc: 0.2611 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6400 - acc: 0.2590 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6584 - acc: 0.2569 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6403 - acc: 0.2590 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6467 - acc: 0.2569 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6586 - acc: 0.2590 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6424 - acc: 0.2611 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6361 - acc: 0.2590 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6404 - acc: 0.2569 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6702 - acc: 0.2590 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6550 - acc: 0.2590 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6763 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6538 - acc: 0.2569 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6640 - acc: 0.2590 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6441 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7064 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6340 - acc: 0.2569 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6487 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7185 - acc: 0.2590 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6469 - acc: 0.2590 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6518 - acc: 0.2590 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6490 - acc: 0.2611 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6442 - acc: 0.2590 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6506 - acc: 0.2590 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6502 - acc: 0.2590 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6634 - acc: 0.2590 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.6788 - acc: 0.2590 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7104 - acc: 0.2590 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6836 - acc: 0.2590 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6450 - acc: 0.2590 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6518 - acc: 0.2590 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6750 - acc: 0.2590 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7078 - acc: 0.2590 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6444 - acc: 0.2590 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6741 - acc: 0.2590 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6500 - acc: 0.2590 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6761 - acc: 0.2611 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6326 - acc: 0.2590 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6407 - acc: 0.2590 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6449 - acc: 0.2590 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6650 - acc: 0.2590 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6721 - acc: 0.2590 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6460 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6436 - acc: 0.2569 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6568 - acc: 0.2590 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6403 - acc: 0.2590 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6392 - acc: 0.2590 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6794 - acc: 0.2590 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6708 - acc: 0.2590 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6374 - acc: 0.2590 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6328 - acc: 0.2569 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6781 - acc: 0.2590 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6540 - acc: 0.2590 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6501 - acc: 0.2590 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6471 - acc: 0.2590 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6691 - acc: 0.2590 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6828 - acc: 0.2590 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6602 - acc: 0.2590 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6570 - acc: 0.2590 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 164us/step\n",
      "Test score: 0.5252639849980673\n",
      "Look! softmax hard_sigmoid hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax hard_sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_238 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_863 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_628 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_864 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_629 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_865 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 24s 51ms/step - loss: 3.1746 - acc: 0.1614 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.4245 - acc: 0.1316 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.7413 - acc: 0.0955 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.9513 - acc: 0.0934 - val_loss: 5.5202 - val_acc: 0.0355\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.3691 - acc: 0.0913 - val_loss: 5.5608 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.9936 - acc: 0.1040 - val_loss: 5.5902 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.5259 - acc: 0.0870 - val_loss: 5.5882 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.5847 - acc: 0.1019 - val_loss: 3.9458 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.0886 - acc: 0.1125 - val_loss: 3.8201 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.1187 - acc: 0.1316 - val_loss: 3.7830 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.4185 - acc: 0.1210 - val_loss: 3.7465 - val_acc: 0.0355\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.0025 - acc: 0.1529 - val_loss: 3.6990 - val_acc: 0.0355\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.9423 - acc: 0.1380 - val_loss: 3.6839 - val_acc: 0.0355\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 3.3104 - acc: 0.1975 - val_loss: 3.6781 - val_acc: 0.0355\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 3.5736 - acc: 0.2038 - val_loss: 3.6799 - val_acc: 0.0355\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.3971 - acc: 0.2081 - val_loss: 0.8106 - val_acc: 0.1277\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.2858 - acc: 0.2102 - val_loss: 0.6216 - val_acc: 0.1277\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.8888 - acc: 0.2166 - val_loss: 0.5823 - val_acc: 0.1277\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.9747 - acc: 0.2357 - val_loss: 0.9539 - val_acc: 0.1277\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.9584 - acc: 0.2548 - val_loss: 0.9063 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 2.5356 - acc: 0.2718 - val_loss: 0.8696 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.1052 - acc: 0.2527 - val_loss: 0.8324 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 2.2767 - acc: 0.2590 - val_loss: 0.7963 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.3421 - acc: 0.2314 - val_loss: 0.7459 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.5676 - acc: 0.2654 - val_loss: 0.7113 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.6813 - acc: 0.2335 - val_loss: 0.6841 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.0817 - acc: 0.2590 - val_loss: 0.6527 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.4029 - acc: 0.2548 - val_loss: 0.6168 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.5777 - acc: 0.2675 - val_loss: 0.5923 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 3.0628 - acc: 0.2718 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 3.8217 - acc: 0.2781 - val_loss: 0.5716 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.9255 - acc: 0.2718 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 4.1415 - acc: 0.2675 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 4.7102 - acc: 0.2527 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.8375 - acc: 0.2909 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 5.0964 - acc: 0.2654 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 5.2984 - acc: 0.2357 - val_loss: 6.4015 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 5.0530 - acc: 0.2590 - val_loss: 5.7452 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 4.9981 - acc: 0.2590 - val_loss: 5.6356 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 5.2014 - acc: 0.2611 - val_loss: 5.6139 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 5.2684 - acc: 0.2760 - val_loss: 3.8491 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 5.4702 - acc: 0.2633 - val_loss: 3.7757 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 5.0225 - acc: 0.2760 - val_loss: 3.7358 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.9441 - acc: 0.2505 - val_loss: 3.7054 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 4.7654 - acc: 0.2739 - val_loss: 3.6818 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 4.5378 - acc: 0.2569 - val_loss: 3.6577 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 4.9934 - acc: 0.2781 - val_loss: 3.6374 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.4918 - acc: 0.2760 - val_loss: 3.6188 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.6490 - acc: 0.2654 - val_loss: 3.6010 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 4.4309 - acc: 0.2781 - val_loss: 3.5860 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.1707 - acc: 0.2675 - val_loss: 3.5684 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 4.2390 - acc: 0.2633 - val_loss: 3.5515 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 4.5493 - acc: 0.2739 - val_loss: 3.5519 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.9872 - acc: 0.2548 - val_loss: 3.5584 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.0140 - acc: 0.2548 - val_loss: 3.5624 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.3130 - acc: 0.2505 - val_loss: 3.5650 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.2948 - acc: 0.2781 - val_loss: 3.5727 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.2166 - acc: 0.2675 - val_loss: 3.5834 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.1714 - acc: 0.2463 - val_loss: 3.5882 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.2366 - acc: 0.2463 - val_loss: 3.5898 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 4.0566 - acc: 0.2590 - val_loss: 3.5911 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 3.9700 - acc: 0.2654 - val_loss: 3.6013 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 3.8040 - acc: 0.2484 - val_loss: 3.6111 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 3.5726 - acc: 0.2166 - val_loss: 3.6194 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.1718 - acc: 0.2399 - val_loss: 3.6253 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.4345 - acc: 0.2123 - val_loss: 3.6301 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.5688 - acc: 0.2527 - val_loss: 3.6333 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.8456 - acc: 0.2272 - val_loss: 3.6374 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.1385 - acc: 0.2378 - val_loss: 3.6420 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.0898 - acc: 0.2420 - val_loss: 3.6452 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.8955 - acc: 0.1975 - val_loss: 1.3428 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.4998 - acc: 0.2272 - val_loss: 1.0502 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.3610 - acc: 0.1783 - val_loss: 0.8373 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.5816 - acc: 0.2123 - val_loss: 0.7427 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.1414 - acc: 0.2081 - val_loss: 0.7062 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.9658 - acc: 0.2293 - val_loss: 0.6816 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.8333 - acc: 0.2654 - val_loss: 0.6531 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.5222 - acc: 0.2484 - val_loss: 0.6159 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.4152 - acc: 0.2357 - val_loss: 0.5964 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.2038 - acc: 0.2718 - val_loss: 0.5864 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.0160 - acc: 0.2590 - val_loss: 0.5802 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.1478 - acc: 0.2718 - val_loss: 0.5754 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.2912 - acc: 0.2760 - val_loss: 0.5727 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.0420 - acc: 0.2357 - val_loss: 0.5700 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.0486 - acc: 0.2505 - val_loss: 0.5676 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.9779 - acc: 0.2251 - val_loss: 0.5663 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.2550 - acc: 0.2463 - val_loss: 0.5663 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.9684 - acc: 0.2633 - val_loss: 0.5666 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.1050 - acc: 0.2059 - val_loss: 0.5664 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.1071 - acc: 0.2357 - val_loss: 0.5670 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.9505 - acc: 0.2123 - val_loss: 0.5673 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.9755 - acc: 0.1868 - val_loss: 0.5670 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.9766 - acc: 0.1932 - val_loss: 0.5658 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.9006 - acc: 0.2081 - val_loss: 0.5643 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.9201 - acc: 0.1486 - val_loss: 0.5625 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.0592 - acc: 0.1762 - val_loss: 0.5611 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.8203 - acc: 0.1614 - val_loss: 0.5602 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.9228 - acc: 0.1401 - val_loss: 0.5588 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.9039 - acc: 0.1571 - val_loss: 0.5579 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.0434 - acc: 0.1847 - val_loss: 0.5575 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.9573 - acc: 0.1677 - val_loss: 0.5567 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.7725 - acc: 0.1635 - val_loss: 0.5562 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.9193 - acc: 0.1741 - val_loss: 0.5570 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.7800 - acc: 0.1444 - val_loss: 0.5576 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.8871 - acc: 0.1677 - val_loss: 0.5578 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.8878 - acc: 0.1762 - val_loss: 0.5579 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.9535 - acc: 0.1529 - val_loss: 0.5576 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9575 - acc: 0.1529 - val_loss: 0.5579 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.8524 - acc: 0.1805 - val_loss: 0.5595 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.8563 - acc: 0.2038 - val_loss: 0.5621 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.9142 - acc: 0.2229 - val_loss: 0.5638 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.8724 - acc: 0.2166 - val_loss: 0.5647 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8154 - acc: 0.2144 - val_loss: 0.5646 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.8111 - acc: 0.2272 - val_loss: 0.5640 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.8372 - acc: 0.2059 - val_loss: 0.5652 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.8107 - acc: 0.2059 - val_loss: 0.5672 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.8133 - acc: 0.2081 - val_loss: 0.5682 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7530 - acc: 0.1953 - val_loss: 0.5683 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.8834 - acc: 0.2272 - val_loss: 0.5678 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7812 - acc: 0.1720 - val_loss: 0.5674 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 168us/step\n",
      "Test score: 0.5674114387931554\n",
      "Look! softmax hard_sigmoid linear Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 softmax hard_sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_239 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_866 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_630 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_867 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_631 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_868 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 52ms/step - loss: 0.7192 - acc: 0.2675 - val_loss: 0.5673 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7001 - acc: 0.2208 - val_loss: 0.5526 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6965 - acc: 0.2335 - val_loss: 0.5409 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6783 - acc: 0.2569 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6670 - acc: 0.2548 - val_loss: 0.5281 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6733 - acc: 0.2569 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6723 - acc: 0.2548 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6483 - acc: 0.2527 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6657 - acc: 0.2548 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6637 - acc: 0.2569 - val_loss: 0.5292 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6496 - acc: 0.2611 - val_loss: 0.5294 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6620 - acc: 0.2569 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6667 - acc: 0.2569 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6573 - acc: 0.2611 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6564 - acc: 0.2484 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6381 - acc: 0.2675 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6554 - acc: 0.2399 - val_loss: 0.5067 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6376 - acc: 0.2760 - val_loss: 0.5029 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6460 - acc: 0.2611 - val_loss: 0.5016 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6376 - acc: 0.2527 - val_loss: 0.4987 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6286 - acc: 0.2675 - val_loss: 0.5004 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6386 - acc: 0.2357 - val_loss: 0.5042 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6366 - acc: 0.2569 - val_loss: 0.4941 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6427 - acc: 0.2463 - val_loss: 0.4950 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6297 - acc: 0.2633 - val_loss: 0.4975 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6417 - acc: 0.2611 - val_loss: 0.4958 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6228 - acc: 0.2633 - val_loss: 0.4923 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6119 - acc: 0.2696 - val_loss: 0.4947 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6349 - acc: 0.2442 - val_loss: 0.4904 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6266 - acc: 0.2675 - val_loss: 0.4900 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6207 - acc: 0.2696 - val_loss: 0.4969 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6188 - acc: 0.2633 - val_loss: 0.4995 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6260 - acc: 0.2654 - val_loss: 0.4971 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6399 - acc: 0.2548 - val_loss: 0.4880 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6242 - acc: 0.2718 - val_loss: 0.4927 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6332 - acc: 0.2484 - val_loss: 0.4917 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6266 - acc: 0.2611 - val_loss: 0.4890 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6285 - acc: 0.2527 - val_loss: 0.4841 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6268 - acc: 0.2866 - val_loss: 0.4838 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6221 - acc: 0.2739 - val_loss: 0.4815 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6170 - acc: 0.2718 - val_loss: 0.4826 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6299 - acc: 0.2611 - val_loss: 0.4858 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6168 - acc: 0.2633 - val_loss: 0.4811 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6143 - acc: 0.2675 - val_loss: 0.4859 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6345 - acc: 0.2569 - val_loss: 0.4998 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6321 - acc: 0.2675 - val_loss: 0.5004 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6372 - acc: 0.2611 - val_loss: 0.5021 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6315 - acc: 0.2739 - val_loss: 0.5015 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5008 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6299 - acc: 0.2718 - val_loss: 0.4980 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6318 - acc: 0.2675 - val_loss: 0.4875 - val_acc: 0.2624\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6329 - acc: 0.2611 - val_loss: 0.4840 - val_acc: 0.2837\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6129 - acc: 0.2803 - val_loss: 0.4842 - val_acc: 0.2837\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6243 - acc: 0.2611 - val_loss: 0.4848 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6170 - acc: 0.2781 - val_loss: 0.4818 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6303 - acc: 0.2590 - val_loss: 0.4782 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6114 - acc: 0.2654 - val_loss: 0.4759 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6002 - acc: 0.2760 - val_loss: 0.4738 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6048 - acc: 0.2803 - val_loss: 0.4703 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6104 - acc: 0.2675 - val_loss: 0.4692 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6149 - acc: 0.2654 - val_loss: 0.4755 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6011 - acc: 0.2760 - val_loss: 0.4682 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6119 - acc: 0.2781 - val_loss: 0.4652 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6014 - acc: 0.2909 - val_loss: 0.4738 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6209 - acc: 0.2803 - val_loss: 0.4619 - val_acc: 0.2908\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.5990 - acc: 0.2845 - val_loss: 0.4617 - val_acc: 0.3050\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6090 - acc: 0.3079 - val_loss: 0.4592 - val_acc: 0.2908\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.5924 - acc: 0.2994 - val_loss: 0.4655 - val_acc: 0.2837\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6074 - acc: 0.2760 - val_loss: 0.4593 - val_acc: 0.2837\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6087 - acc: 0.2760 - val_loss: 0.4731 - val_acc: 0.2695\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6341 - acc: 0.2548 - val_loss: 0.4611 - val_acc: 0.2908\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6044 - acc: 0.2760 - val_loss: 0.4566 - val_acc: 0.2979\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.5990 - acc: 0.2824 - val_loss: 0.4664 - val_acc: 0.2837\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 0.6153 - acc: 0.2866 - val_loss: 0.4561 - val_acc: 0.2908\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6090 - acc: 0.2739 - val_loss: 0.4576 - val_acc: 0.2979\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.5977 - acc: 0.2781 - val_loss: 0.4628 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6079 - acc: 0.2760 - val_loss: 0.4685 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6190 - acc: 0.2803 - val_loss: 0.4590 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6049 - acc: 0.2803 - val_loss: 0.4618 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.5934 - acc: 0.2887 - val_loss: 0.4643 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6052 - acc: 0.2824 - val_loss: 0.4742 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6197 - acc: 0.2611 - val_loss: 0.4682 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.5994 - acc: 0.2739 - val_loss: 0.4543 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6264 - acc: 0.2739 - val_loss: 0.4892 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6210 - acc: 0.2739 - val_loss: 0.4824 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.5953 - acc: 0.2845 - val_loss: 0.4565 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6019 - acc: 0.2696 - val_loss: 0.4585 - val_acc: 0.2979\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6182 - acc: 0.2696 - val_loss: 0.5004 - val_acc: 0.2340\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6376 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2199\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6483 - acc: 0.2569 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6500 - acc: 0.2569 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6422 - acc: 0.2569 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6363 - acc: 0.2548 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6318 - acc: 0.2569 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6343 - acc: 0.2569 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6408 - acc: 0.2569 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6387 - acc: 0.2505 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6328 - acc: 0.2527 - val_loss: 0.5105 - val_acc: 0.2199\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6310 - acc: 0.2590 - val_loss: 0.5100 - val_acc: 0.2199\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6323 - acc: 0.2590 - val_loss: 0.5076 - val_acc: 0.2199\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6291 - acc: 0.2675 - val_loss: 0.5073 - val_acc: 0.2199\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6281 - acc: 0.2611 - val_loss: 0.5064 - val_acc: 0.2199\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6336 - acc: 0.2590 - val_loss: 0.5066 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6386 - acc: 0.2569 - val_loss: 0.5060 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6328 - acc: 0.2590 - val_loss: 0.5061 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6275 - acc: 0.2718 - val_loss: 0.5041 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6298 - acc: 0.2633 - val_loss: 0.5024 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6251 - acc: 0.2611 - val_loss: 0.5016 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6248 - acc: 0.2696 - val_loss: 0.4990 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6258 - acc: 0.2611 - val_loss: 0.4941 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6235 - acc: 0.2696 - val_loss: 0.4859 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6086 - acc: 0.2909 - val_loss: 0.4795 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.5926 - acc: 0.2994 - val_loss: 0.4699 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.5986 - acc: 0.2887 - val_loss: 0.4669 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.5917 - acc: 0.2951 - val_loss: 0.4761 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6075 - acc: 0.2718 - val_loss: 0.4536 - val_acc: 0.3050\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.5914 - acc: 0.2972 - val_loss: 0.4651 - val_acc: 0.2908\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6098 - acc: 0.2611 - val_loss: 0.4645 - val_acc: 0.2766\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.5971 - acc: 0.2739 - val_loss: 0.4654 - val_acc: 0.2766\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6022 - acc: 0.2696 - val_loss: 0.4616 - val_acc: 0.2979\n",
      "141/141 [==============================] - 0s 180us/step\n",
      "Test score: 0.46159820184640005\n",
      "Look! softmax linear softmax Test accuracy: 0.2978723410596239\n",
      "max there  0.6241134772909448 softmax hard_sigmoid relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_240 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_869 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_632 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_870 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_633 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_871 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 53ms/step - loss: nan - acc: 0.4459 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 174us/step\n",
      "Test score: nan\n",
      "Look! softmax linear elu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax linear elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_241 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_872 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_634 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_873 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_635 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_874 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 52ms/step - loss: nan - acc: 0.4607 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 189us/step\n",
      "Test score: nan\n",
      "Look! softmax linear selu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax linear selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_242 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_875 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_636 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_876 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_637 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_877 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 53ms/step - loss: 0.7187 - acc: 0.2293 - val_loss: 0.5736 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7108 - acc: 0.2527 - val_loss: 0.5633 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6854 - acc: 0.2505 - val_loss: 0.5538 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6877 - acc: 0.2527 - val_loss: 0.5449 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6810 - acc: 0.2548 - val_loss: 0.5415 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6542 - acc: 0.2675 - val_loss: 0.5316 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6623 - acc: 0.2611 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6552 - acc: 0.2590 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6417 - acc: 0.2569 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6731 - acc: 0.2611 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6732 - acc: 0.2569 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6513 - acc: 0.2590 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6448 - acc: 0.2590 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6535 - acc: 0.2611 - val_loss: 0.5147 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6359 - acc: 0.2633 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6374 - acc: 0.2633 - val_loss: 0.5071 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6397 - acc: 0.2527 - val_loss: 0.5473 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6686 - acc: 0.2272 - val_loss: 0.5003 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6478 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6310 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 21/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 201us/step - loss: 0.6320 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6423 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6347 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6645 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6290 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6468 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6514 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6299 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6477 - acc: 0.2611 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6416 - acc: 0.2611 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6396 - acc: 0.2611 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6434 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6386 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6436 - acc: 0.2611 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6438 - acc: 0.2611 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6428 - acc: 0.2569 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6284 - acc: 0.2590 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6251 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6379 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6378 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6364 - acc: 0.2548 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6280 - acc: 0.2611 - val_loss: 0.5101 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6396 - acc: 0.2527 - val_loss: 0.5101 - val_acc: 0.2199\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6263 - acc: 0.2675 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6430 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6431 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6371 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6347 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6331 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6408 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6355 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6291 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6352 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6398 - acc: 0.2569 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6329 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6341 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6336 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6362 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6274 - acc: 0.2633 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6310 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6299 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6325 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6280 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6309 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6325 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6337 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6322 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6228 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 0.6260 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6302 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6317 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6239 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6241 - acc: 0.2611 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6260 - acc: 0.2569 - val_loss: 0.5093 - val_acc: 0.2199\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6184 - acc: 0.2633 - val_loss: 0.5079 - val_acc: 0.2199\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6167 - acc: 0.2611 - val_loss: 0.5107 - val_acc: 0.2199\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6162 - acc: 0.2739 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6252 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2199\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6145 - acc: 0.2633 - val_loss: 0.5123 - val_acc: 0.2199\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6199 - acc: 0.2654 - val_loss: 0.5103 - val_acc: 0.2270\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6179 - acc: 0.2611 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6314 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6382 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6292 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6347 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6290 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6293 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6343 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6307 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6317 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6310 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6363 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6295 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6389 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6331 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6308 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6320 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6251 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6277 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6285 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6304 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6315 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6274 - acc: 0.2611 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6362 - acc: 0.2569 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6311 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6278 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6301 - acc: 0.2611 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6322 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6315 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6329 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 188us/step\n",
      "Test score: 0.5109847319041584\n",
      "Look! softmax linear softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax linear selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_243 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_878 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_638 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_879 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_639 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_880 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 53ms/step - loss: nan - acc: 0.4671 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 194us/step\n",
      "Test score: nan\n",
      "Look! softmax linear softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax linear softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_244 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_881 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_640 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_882 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_641 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_883 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 53ms/step - loss: nan - acc: 0.4756 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 179us/step\n",
      "Test score: nan\n",
      "Look! softmax linear relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax linear relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_245 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_884 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_642 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_885 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_643 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_886 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 25s 53ms/step - loss: nan - acc: 0.4607 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 167us/step\n",
      "Test score: nan\n",
      "Look! softmax linear tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax linear tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_246 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_887 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_644 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_888 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_645 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_889 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 54ms/step - loss: 0.7363 - acc: 0.2930 - val_loss: 0.5897 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7250 - acc: 0.2611 - val_loss: 0.5801 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7152 - acc: 0.2569 - val_loss: 0.5712 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7014 - acc: 0.2548 - val_loss: 0.5633 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6877 - acc: 0.2569 - val_loss: 0.5561 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6867 - acc: 0.2527 - val_loss: 0.5539 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6915 - acc: 0.2590 - val_loss: 0.5696 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6955 - acc: 0.2590 - val_loss: 0.5627 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6914 - acc: 0.2590 - val_loss: 0.5556 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6828 - acc: 0.2590 - val_loss: 0.5488 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6796 - acc: 0.2611 - val_loss: 0.5430 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6719 - acc: 0.2611 - val_loss: 0.5374 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6703 - acc: 0.2590 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6625 - acc: 0.2590 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6611 - acc: 0.2590 - val_loss: 0.5255 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6600 - acc: 0.2590 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6531 - acc: 0.2590 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6469 - acc: 0.2590 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6575 - acc: 0.2590 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6455 - acc: 0.2590 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6442 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6432 - acc: 0.2590 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6434 - acc: 0.2590 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6431 - acc: 0.2590 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6437 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6420 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6520 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6434 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6402 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6482 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6332 - acc: 0.2611 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6347 - acc: 0.2611 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6458 - acc: 0.2590 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6511 - acc: 0.2590 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6380 - acc: 0.2611 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6363 - acc: 0.2611 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6360 - acc: 0.2633 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6407 - acc: 0.2590 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6413 - acc: 0.2463 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6287 - acc: 0.2611 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6381 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6362 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6377 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6394 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6389 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6287 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6302 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6335 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6412 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6320 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6414 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6389 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6351 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6377 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6353 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6366 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6376 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6311 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6329 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6375 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6373 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6305 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6275 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6390 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6402 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6342 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6263 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6289 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6326 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6336 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6349 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6307 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6354 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6333 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6337 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6303 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6350 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6344 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6347 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6322 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6316 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6350 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6303 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6306 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6265 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6250 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6304 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6358 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6354 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6299 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6300 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6296 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6326 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6346 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6323 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6312 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6318 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6338 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6342 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6332 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6323 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 173us/step\n",
      "Test score: 0.5112345844295854\n",
      "Look! softmax linear sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax linear tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_247 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_890 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_646 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_891 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_647 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_892 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 54ms/step - loss: 0.7358 - acc: 0.3439 - val_loss: 0.5914 - val_acc: 0.2270\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7220 - acc: 0.2654 - val_loss: 0.5846 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7150 - acc: 0.2654 - val_loss: 0.5798 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.7074 - acc: 0.2463 - val_loss: 0.5725 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6994 - acc: 0.2611 - val_loss: 0.5656 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6957 - acc: 0.2590 - val_loss: 0.5608 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6855 - acc: 0.2527 - val_loss: 0.5587 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6938 - acc: 0.2548 - val_loss: 0.5538 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6710 - acc: 0.2654 - val_loss: 0.5430 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6783 - acc: 0.2590 - val_loss: 0.5386 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6647 - acc: 0.2548 - val_loss: 0.5338 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6688 - acc: 0.2611 - val_loss: 0.5400 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6633 - acc: 0.2696 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6600 - acc: 0.2569 - val_loss: 0.5331 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6620 - acc: 0.2590 - val_loss: 0.5307 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6847 - acc: 0.2569 - val_loss: 0.5300 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6595 - acc: 0.2569 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6676 - acc: 0.2548 - val_loss: 0.5426 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6508 - acc: 0.2590 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6636 - acc: 0.2590 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6442 - acc: 0.2611 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6532 - acc: 0.2611 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6574 - acc: 0.2590 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6756 - acc: 0.2611 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6406 - acc: 0.2590 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6485 - acc: 0.2611 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6558 - acc: 0.2611 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6500 - acc: 0.2590 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6522 - acc: 0.2590 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6324 - acc: 0.2590 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6364 - acc: 0.2590 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6392 - acc: 0.2590 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6400 - acc: 0.2611 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6393 - acc: 0.2569 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6408 - acc: 0.2611 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6771 - acc: 0.2590 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6356 - acc: 0.2611 - val_loss: 0.5305 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6367 - acc: 0.2590 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6428 - acc: 0.2590 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6387 - acc: 0.2633 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6365 - acc: 0.2590 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6344 - acc: 0.2633 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6325 - acc: 0.2633 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6289 - acc: 0.2590 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6383 - acc: 0.2611 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6361 - acc: 0.2633 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6195 - acc: 0.2675 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6297 - acc: 0.2633 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6284 - acc: 0.2654 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6197 - acc: 0.2696 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 214us/step - loss: 0.6259 - acc: 0.2654 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6356 - acc: 0.2611 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6223 - acc: 0.2633 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6309 - acc: 0.2611 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6298 - acc: 0.2633 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6211 - acc: 0.2654 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6249 - acc: 0.2696 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6146 - acc: 0.2696 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6274 - acc: 0.2590 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6164 - acc: 0.2675 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6420 - acc: 0.2718 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6105 - acc: 0.2739 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6313 - acc: 0.2696 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6194 - acc: 0.2633 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6406 - acc: 0.2739 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6161 - acc: 0.2696 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6117 - acc: 0.2718 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6147 - acc: 0.2675 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6145 - acc: 0.2696 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6131 - acc: 0.2718 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6169 - acc: 0.2675 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6067 - acc: 0.2760 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6218 - acc: 0.2633 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6127 - acc: 0.2760 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.5998 - acc: 0.2739 - val_loss: 0.5271 - val_acc: 0.2057\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.5783 - acc: 0.2803 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.5972 - acc: 0.2718 - val_loss: 0.5268 - val_acc: 0.1986\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6320 - acc: 0.2633 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6100 - acc: 0.2696 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6221 - acc: 0.2718 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 0.6162 - acc: 0.2675 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6083 - acc: 0.2654 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.5989 - acc: 0.2781 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6059 - acc: 0.2696 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6139 - acc: 0.2633 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6492 - acc: 0.2654 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6567 - acc: 0.2654 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6140 - acc: 0.2696 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6084 - acc: 0.2718 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6300 - acc: 0.2718 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.5956 - acc: 0.2760 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.5894 - acc: 0.2781 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6328 - acc: 0.2675 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.5897 - acc: 0.2739 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6017 - acc: 0.2739 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6143 - acc: 0.2675 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6040 - acc: 0.2781 - val_loss: 0.5251 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6532 - acc: 0.2633 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6261 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6308 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6416 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6326 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6356 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6297 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6277 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6354 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6283 - acc: 0.2611 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6298 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6306 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6363 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6223 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6286 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6354 - acc: 0.2611 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6425 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6358 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6318 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6343 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6337 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6300 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6226 - acc: 0.2611 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 186us/step\n",
      "Test score: 0.5114083839646468\n",
      "Look! softmax linear hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax linear tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_248 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_893 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_648 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_894 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_649 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_895 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 54ms/step - loss: nan - acc: 0.4883 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 180us/step\n",
      "Test score: nan\n",
      "Look! softmax linear linear Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 softmax linear linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_249 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_896 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_650 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_897 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_651 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_898 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 25s 54ms/step - loss: 0.7419 - acc: 0.2569 - val_loss: 0.5771 - val_acc: 0.2270\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7293 - acc: 0.2272 - val_loss: 0.5745 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7183 - acc: 0.2463 - val_loss: 0.5730 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7087 - acc: 0.2484 - val_loss: 0.5714 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7073 - acc: 0.2590 - val_loss: 0.5699 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6997 - acc: 0.2569 - val_loss: 0.5683 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7027 - acc: 0.2569 - val_loss: 0.5668 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7050 - acc: 0.2654 - val_loss: 0.5653 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6966 - acc: 0.2548 - val_loss: 0.5639 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7010 - acc: 0.2548 - val_loss: 0.5625 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6958 - acc: 0.2590 - val_loss: 0.5611 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7004 - acc: 0.2611 - val_loss: 0.5599 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6851 - acc: 0.2590 - val_loss: 0.5586 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6838 - acc: 0.2590 - val_loss: 0.5573 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6973 - acc: 0.2569 - val_loss: 0.5561 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6899 - acc: 0.2590 - val_loss: 0.5549 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6842 - acc: 0.2590 - val_loss: 0.5537 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6842 - acc: 0.2590 - val_loss: 0.5526 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6914 - acc: 0.2569 - val_loss: 0.5516 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6848 - acc: 0.2590 - val_loss: 0.5506 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6749 - acc: 0.2590 - val_loss: 0.5495 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6841 - acc: 0.2569 - val_loss: 0.5485 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6717 - acc: 0.2590 - val_loss: 0.5476 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6794 - acc: 0.2590 - val_loss: 0.5466 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6712 - acc: 0.2590 - val_loss: 0.5456 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6763 - acc: 0.2569 - val_loss: 0.5447 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6804 - acc: 0.2590 - val_loss: 0.5439 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6771 - acc: 0.2590 - val_loss: 0.5431 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6728 - acc: 0.2590 - val_loss: 0.5423 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6702 - acc: 0.2590 - val_loss: 0.5415 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6718 - acc: 0.2590 - val_loss: 0.5408 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6663 - acc: 0.2590 - val_loss: 0.5401 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6734 - acc: 0.2590 - val_loss: 0.5394 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6727 - acc: 0.2611 - val_loss: 0.5388 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6677 - acc: 0.2590 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6728 - acc: 0.2569 - val_loss: 0.5375 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6711 - acc: 0.2569 - val_loss: 0.5368 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6759 - acc: 0.2590 - val_loss: 0.5363 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6666 - acc: 0.2590 - val_loss: 0.5358 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6738 - acc: 0.2590 - val_loss: 0.5353 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6700 - acc: 0.2590 - val_loss: 0.5348 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6699 - acc: 0.2590 - val_loss: 0.5344 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6567 - acc: 0.2590 - val_loss: 0.5339 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6645 - acc: 0.2590 - val_loss: 0.5333 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6820 - acc: 0.2590 - val_loss: 0.5328 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6683 - acc: 0.2590 - val_loss: 0.5323 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6660 - acc: 0.2590 - val_loss: 0.5319 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6574 - acc: 0.2590 - val_loss: 0.5314 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6643 - acc: 0.2548 - val_loss: 0.5310 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6666 - acc: 0.2505 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6629 - acc: 0.2590 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6729 - acc: 0.2590 - val_loss: 0.5298 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6635 - acc: 0.2590 - val_loss: 0.5294 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6711 - acc: 0.2590 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6684 - acc: 0.2590 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6658 - acc: 0.2590 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6541 - acc: 0.2569 - val_loss: 0.5280 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6631 - acc: 0.2590 - val_loss: 0.5276 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6641 - acc: 0.2590 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6576 - acc: 0.2590 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6601 - acc: 0.2590 - val_loss: 0.5267 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6618 - acc: 0.2590 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6592 - acc: 0.2590 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6625 - acc: 0.2590 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6655 - acc: 0.2590 - val_loss: 0.5255 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6630 - acc: 0.2590 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6641 - acc: 0.2590 - val_loss: 0.5251 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6658 - acc: 0.2590 - val_loss: 0.5249 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6421 - acc: 0.2548 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6641 - acc: 0.2590 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6688 - acc: 0.2569 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6552 - acc: 0.2548 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6661 - acc: 0.2611 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6640 - acc: 0.2590 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6542 - acc: 0.2590 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6612 - acc: 0.2505 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6544 - acc: 0.2590 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6669 - acc: 0.2590 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6507 - acc: 0.2590 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6626 - acc: 0.2590 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6465 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6475 - acc: 0.2611 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6569 - acc: 0.2590 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6590 - acc: 0.2633 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6585 - acc: 0.2569 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6519 - acc: 0.2590 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6657 - acc: 0.2590 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6569 - acc: 0.2590 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6537 - acc: 0.2590 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6490 - acc: 0.2590 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6491 - acc: 0.2590 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6532 - acc: 0.2590 - val_loss: 0.5201 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6583 - acc: 0.2590 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6578 - acc: 0.2590 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6605 - acc: 0.2590 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 96/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 197us/step - loss: 0.6551 - acc: 0.2590 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6598 - acc: 0.2569 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6563 - acc: 0.2590 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6508 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6475 - acc: 0.2590 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6532 - acc: 0.2611 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6545 - acc: 0.2590 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6495 - acc: 0.2590 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6458 - acc: 0.2590 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6625 - acc: 0.2590 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6670 - acc: 0.2590 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6557 - acc: 0.2590 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6543 - acc: 0.2590 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6471 - acc: 0.2590 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6496 - acc: 0.2590 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6485 - acc: 0.2590 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6541 - acc: 0.2590 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6457 - acc: 0.2590 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6486 - acc: 0.2590 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6626 - acc: 0.2590 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6569 - acc: 0.2590 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6464 - acc: 0.2590 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6443 - acc: 0.2590 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6432 - acc: 0.2590 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6449 - acc: 0.2569 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 193us/step\n",
      "Test score: 0.5171501712596163\n",
      "Look! elu softmax softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 softmax linear linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_250 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_899 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_652 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_900 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_653 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_901 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 26s 55ms/step - loss: nan - acc: 0.4692 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 238us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 193us/step\n",
      "Test score: nan\n",
      "Look! elu softmax elu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softmax elu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_251 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_902 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_654 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_903 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_655 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_904 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 26s 55ms/step - loss: nan - acc: 0.4904 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 182us/step\n",
      "Test score: nan\n",
      "Look! elu softmax selu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softmax selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_252 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_905 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_656 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_906 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_657 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_907 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 26s 54ms/step - loss: 0.7372 - acc: 0.2187 - val_loss: 0.5784 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7303 - acc: 0.2909 - val_loss: 0.6063 - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7340 - acc: 0.3461 - val_loss: 0.6049 - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7322 - acc: 0.3524 - val_loss: 0.6034 - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7358 - acc: 0.3397 - val_loss: 0.6018 - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7247 - acc: 0.3248 - val_loss: 0.5732 - val_acc: 0.1277\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7162 - acc: 0.2272 - val_loss: 0.5722 - val_acc: 0.1277\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7036 - acc: 0.2017 - val_loss: 0.5712 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7060 - acc: 0.2335 - val_loss: 0.5702 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7086 - acc: 0.2611 - val_loss: 0.5692 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7007 - acc: 0.2569 - val_loss: 0.5682 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7052 - acc: 0.2569 - val_loss: 0.5672 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7068 - acc: 0.2590 - val_loss: 0.5663 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6914 - acc: 0.2569 - val_loss: 0.5653 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6986 - acc: 0.2590 - val_loss: 0.5644 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6950 - acc: 0.2569 - val_loss: 0.5635 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6954 - acc: 0.2590 - val_loss: 0.5626 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6900 - acc: 0.2569 - val_loss: 0.5616 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6971 - acc: 0.2590 - val_loss: 0.5607 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7003 - acc: 0.2590 - val_loss: 0.5598 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6907 - acc: 0.2590 - val_loss: 0.5590 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6920 - acc: 0.2590 - val_loss: 0.5582 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6908 - acc: 0.2590 - val_loss: 0.5574 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6926 - acc: 0.2590 - val_loss: 0.5567 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6885 - acc: 0.2590 - val_loss: 0.5559 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6965 - acc: 0.2590 - val_loss: 0.5552 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6840 - acc: 0.2590 - val_loss: 0.5545 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6911 - acc: 0.2590 - val_loss: 0.5538 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6825 - acc: 0.2569 - val_loss: 0.5531 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6839 - acc: 0.2590 - val_loss: 0.5524 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6854 - acc: 0.2569 - val_loss: 0.5517 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6793 - acc: 0.2590 - val_loss: 0.5510 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6903 - acc: 0.2590 - val_loss: 0.5503 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6859 - acc: 0.2590 - val_loss: 0.5497 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6751 - acc: 0.2590 - val_loss: 0.5491 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6688 - acc: 0.2611 - val_loss: 0.5484 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6812 - acc: 0.2590 - val_loss: 0.5477 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6878 - acc: 0.2590 - val_loss: 0.5471 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6861 - acc: 0.2590 - val_loss: 0.5465 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6750 - acc: 0.2590 - val_loss: 0.5459 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6761 - acc: 0.2590 - val_loss: 0.5453 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6726 - acc: 0.2590 - val_loss: 0.5448 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6824 - acc: 0.2590 - val_loss: 0.5442 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6899 - acc: 0.2569 - val_loss: 0.5437 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6757 - acc: 0.2590 - val_loss: 0.5433 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6777 - acc: 0.2590 - val_loss: 0.5428 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6824 - acc: 0.2611 - val_loss: 0.5423 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6790 - acc: 0.2590 - val_loss: 0.5419 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6737 - acc: 0.2590 - val_loss: 0.5414 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6738 - acc: 0.2590 - val_loss: 0.5409 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6743 - acc: 0.2590 - val_loss: 0.5405 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6671 - acc: 0.2590 - val_loss: 0.5400 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6606 - acc: 0.2590 - val_loss: 0.5395 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6793 - acc: 0.2590 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6696 - acc: 0.2569 - val_loss: 0.5386 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6690 - acc: 0.2590 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6730 - acc: 0.2590 - val_loss: 0.5376 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6671 - acc: 0.2590 - val_loss: 0.5372 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6802 - acc: 0.2569 - val_loss: 0.5368 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6646 - acc: 0.2590 - val_loss: 0.5364 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6727 - acc: 0.2590 - val_loss: 0.5360 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6671 - acc: 0.2590 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6591 - acc: 0.2590 - val_loss: 0.5353 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6793 - acc: 0.2590 - val_loss: 0.5349 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6683 - acc: 0.2590 - val_loss: 0.5346 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6630 - acc: 0.2590 - val_loss: 0.5342 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6744 - acc: 0.2590 - val_loss: 0.5339 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6720 - acc: 0.2590 - val_loss: 0.5336 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6627 - acc: 0.2590 - val_loss: 0.5333 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6580 - acc: 0.2590 - val_loss: 0.5329 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6698 - acc: 0.2590 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6557 - acc: 0.2590 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6580 - acc: 0.2590 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6772 - acc: 0.2590 - val_loss: 0.5315 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6541 - acc: 0.2590 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6696 - acc: 0.2590 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6571 - acc: 0.2590 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6639 - acc: 0.2590 - val_loss: 0.5303 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6674 - acc: 0.2590 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6569 - acc: 0.2590 - val_loss: 0.5298 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6595 - acc: 0.2590 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6547 - acc: 0.2590 - val_loss: 0.5293 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6605 - acc: 0.2590 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6562 - acc: 0.2590 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6684 - acc: 0.2590 - val_loss: 0.5285 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6616 - acc: 0.2590 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6585 - acc: 0.2590 - val_loss: 0.5280 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6652 - acc: 0.2590 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6576 - acc: 0.2611 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6602 - acc: 0.2590 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6709 - acc: 0.2590 - val_loss: 0.5271 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6593 - acc: 0.2590 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6736 - acc: 0.2590 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6591 - acc: 0.2590 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6589 - acc: 0.2590 - val_loss: 0.5262 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6568 - acc: 0.2590 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6586 - acc: 0.2590 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6547 - acc: 0.2590 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6534 - acc: 0.2590 - val_loss: 0.5254 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6541 - acc: 0.2590 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6575 - acc: 0.2590 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6531 - acc: 0.2590 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6712 - acc: 0.2590 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6666 - acc: 0.2590 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6524 - acc: 0.2590 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6447 - acc: 0.2590 - val_loss: 0.5241 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6541 - acc: 0.2590 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6429 - acc: 0.2590 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6611 - acc: 0.2590 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6562 - acc: 0.2590 - val_loss: 0.5233 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6513 - acc: 0.2590 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6668 - acc: 0.2590 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6484 - acc: 0.2590 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6546 - acc: 0.2590 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6563 - acc: 0.2590 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6505 - acc: 0.2590 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6657 - acc: 0.2590 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6673 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6544 - acc: 0.2590 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6586 - acc: 0.2590 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 180us/step\n",
      "Test score: 0.5219071029771304\n",
      "Look! elu softmax softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softmax selu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_253 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_908 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_658 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_909 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_659 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_910 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 26s 56ms/step - loss: nan - acc: 0.4565 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 190us/step\n",
      "Test score: nan\n",
      "Look! elu softmax softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softmax softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_254 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_911 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_660 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_912 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_661 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_913 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 26s 55ms/step - loss: nan - acc: 0.4607 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 189us/step\n",
      "Test score: nan\n",
      "Look! elu softmax relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softmax relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_255 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_914 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_662 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_915 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_663 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_916 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 26s 56ms/step - loss: nan - acc: 0.4480 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 182us/step\n",
      "Test score: nan\n",
      "Look! elu softmax tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softmax tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_256 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_917 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_664 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_918 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_665 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_919 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 26s 56ms/step - loss: 0.7328 - acc: 0.2208 - val_loss: 0.5842 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7168 - acc: 0.2611 - val_loss: 0.5834 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7164 - acc: 0.2569 - val_loss: 0.5826 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7150 - acc: 0.2590 - val_loss: 0.5818 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7154 - acc: 0.2611 - val_loss: 0.5810 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7165 - acc: 0.2590 - val_loss: 0.5802 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7118 - acc: 0.2590 - val_loss: 0.5793 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7129 - acc: 0.2590 - val_loss: 0.5785 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7114 - acc: 0.2590 - val_loss: 0.5778 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7134 - acc: 0.2569 - val_loss: 0.5770 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7098 - acc: 0.2590 - val_loss: 0.5763 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7118 - acc: 0.2590 - val_loss: 0.5755 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7063 - acc: 0.2590 - val_loss: 0.5748 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7060 - acc: 0.2590 - val_loss: 0.5741 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7080 - acc: 0.2590 - val_loss: 0.5733 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7044 - acc: 0.2569 - val_loss: 0.5726 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7042 - acc: 0.2590 - val_loss: 0.5719 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7000 - acc: 0.2590 - val_loss: 0.5712 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7092 - acc: 0.2590 - val_loss: 0.5705 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7005 - acc: 0.2590 - val_loss: 0.5699 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7030 - acc: 0.2590 - val_loss: 0.5692 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7050 - acc: 0.2590 - val_loss: 0.5685 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6975 - acc: 0.2590 - val_loss: 0.5679 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7007 - acc: 0.2590 - val_loss: 0.5672 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7032 - acc: 0.2590 - val_loss: 0.5666 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6983 - acc: 0.2590 - val_loss: 0.5660 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6957 - acc: 0.2590 - val_loss: 0.5654 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7002 - acc: 0.2590 - val_loss: 0.5648 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6955 - acc: 0.2590 - val_loss: 0.5642 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6981 - acc: 0.2590 - val_loss: 0.5636 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6928 - acc: 0.2590 - val_loss: 0.5630 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6940 - acc: 0.2590 - val_loss: 0.5624 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6926 - acc: 0.2590 - val_loss: 0.5618 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6956 - acc: 0.2590 - val_loss: 0.5612 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6936 - acc: 0.2590 - val_loss: 0.5606 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6918 - acc: 0.2590 - val_loss: 0.5601 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6898 - acc: 0.2590 - val_loss: 0.5595 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6900 - acc: 0.2590 - val_loss: 0.5589 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6873 - acc: 0.2590 - val_loss: 0.5584 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6944 - acc: 0.2590 - val_loss: 0.5579 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6908 - acc: 0.2590 - val_loss: 0.5574 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6910 - acc: 0.2590 - val_loss: 0.5569 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6915 - acc: 0.2590 - val_loss: 0.5564 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6897 - acc: 0.2590 - val_loss: 0.5559 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6803 - acc: 0.2590 - val_loss: 0.5554 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6894 - acc: 0.2590 - val_loss: 0.5549 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6907 - acc: 0.2590 - val_loss: 0.5544 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.6882 - acc: 0.2590 - val_loss: 0.5539 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6893 - acc: 0.2590 - val_loss: 0.5535 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6842 - acc: 0.2590 - val_loss: 0.5530 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6829 - acc: 0.2590 - val_loss: 0.5525 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6848 - acc: 0.2590 - val_loss: 0.5521 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6812 - acc: 0.2590 - val_loss: 0.5516 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6781 - acc: 0.2590 - val_loss: 0.5512 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6840 - acc: 0.2590 - val_loss: 0.5507 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6874 - acc: 0.2590 - val_loss: 0.5503 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6834 - acc: 0.2590 - val_loss: 0.5499 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6802 - acc: 0.2590 - val_loss: 0.5495 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6833 - acc: 0.2590 - val_loss: 0.5490 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6711 - acc: 0.2590 - val_loss: 0.5486 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6757 - acc: 0.2590 - val_loss: 0.5482 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6760 - acc: 0.2590 - val_loss: 0.5477 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6839 - acc: 0.2590 - val_loss: 0.5473 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6805 - acc: 0.2590 - val_loss: 0.5469 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6805 - acc: 0.2590 - val_loss: 0.5465 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6754 - acc: 0.2590 - val_loss: 0.5461 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6711 - acc: 0.2590 - val_loss: 0.5457 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6754 - acc: 0.2590 - val_loss: 0.5453 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6747 - acc: 0.2590 - val_loss: 0.5449 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6763 - acc: 0.2590 - val_loss: 0.5445 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6720 - acc: 0.2590 - val_loss: 0.5441 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6818 - acc: 0.2590 - val_loss: 0.5437 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6791 - acc: 0.2590 - val_loss: 0.5433 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6735 - acc: 0.2590 - val_loss: 0.5430 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6677 - acc: 0.2590 - val_loss: 0.5427 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6743 - acc: 0.2590 - val_loss: 0.5423 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6763 - acc: 0.2590 - val_loss: 0.5419 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6667 - acc: 0.2590 - val_loss: 0.5416 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6748 - acc: 0.2590 - val_loss: 0.5412 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6794 - acc: 0.2590 - val_loss: 0.5409 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6667 - acc: 0.2590 - val_loss: 0.5406 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6757 - acc: 0.2590 - val_loss: 0.5403 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6689 - acc: 0.2590 - val_loss: 0.5400 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6674 - acc: 0.2590 - val_loss: 0.5396 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6714 - acc: 0.2590 - val_loss: 0.5393 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6646 - acc: 0.2590 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6673 - acc: 0.2590 - val_loss: 0.5387 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6643 - acc: 0.2590 - val_loss: 0.5384 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6758 - acc: 0.2590 - val_loss: 0.5380 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6708 - acc: 0.2590 - val_loss: 0.5377 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6729 - acc: 0.2590 - val_loss: 0.5374 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6640 - acc: 0.2590 - val_loss: 0.5372 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6664 - acc: 0.2590 - val_loss: 0.5369 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6573 - acc: 0.2590 - val_loss: 0.5366 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6702 - acc: 0.2590 - val_loss: 0.5363 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6621 - acc: 0.2590 - val_loss: 0.5360 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6794 - acc: 0.2590 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6618 - acc: 0.2590 - val_loss: 0.5355 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6634 - acc: 0.2590 - val_loss: 0.5352 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6732 - acc: 0.2590 - val_loss: 0.5349 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6694 - acc: 0.2590 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6659 - acc: 0.2590 - val_loss: 0.5344 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6685 - acc: 0.2590 - val_loss: 0.5342 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6640 - acc: 0.2590 - val_loss: 0.5339 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6591 - acc: 0.2590 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6603 - acc: 0.2590 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6614 - acc: 0.2590 - val_loss: 0.5331 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6606 - acc: 0.2590 - val_loss: 0.5329 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6663 - acc: 0.2590 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6656 - acc: 0.2590 - val_loss: 0.5324 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6609 - acc: 0.2590 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6674 - acc: 0.2590 - val_loss: 0.5320 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6601 - acc: 0.2590 - val_loss: 0.5317 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6622 - acc: 0.2590 - val_loss: 0.5315 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6545 - acc: 0.2590 - val_loss: 0.5313 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6607 - acc: 0.2590 - val_loss: 0.5311 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6636 - acc: 0.2590 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6625 - acc: 0.2590 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6559 - acc: 0.2590 - val_loss: 0.5304 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6695 - acc: 0.2590 - val_loss: 0.5302 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 171us/step\n",
      "Test score: 0.530224250563493\n",
      "Look! elu softmax sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softmax tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_257 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_920 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_666 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_921 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_667 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_922 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 26s 56ms/step - loss: 0.7392 - acc: 0.2505 - val_loss: 0.5992 - val_acc: 0.3191\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7347 - acc: 0.2675 - val_loss: 0.5955 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7303 - acc: 0.2654 - val_loss: 0.5949 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7290 - acc: 0.2548 - val_loss: 0.5943 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7279 - acc: 0.2399 - val_loss: 0.5936 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7239 - acc: 0.2527 - val_loss: 0.5929 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7267 - acc: 0.2378 - val_loss: 0.5922 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7249 - acc: 0.2378 - val_loss: 0.5903 - val_acc: 0.1489\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7245 - acc: 0.2208 - val_loss: 0.5836 - val_acc: 0.2199\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7173 - acc: 0.2569 - val_loss: 0.5844 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7180 - acc: 0.2611 - val_loss: 0.5837 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7214 - acc: 0.2505 - val_loss: 0.5829 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7170 - acc: 0.2590 - val_loss: 0.5821 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7160 - acc: 0.2590 - val_loss: 0.5813 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7153 - acc: 0.2611 - val_loss: 0.5805 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7159 - acc: 0.2569 - val_loss: 0.5797 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7129 - acc: 0.2569 - val_loss: 0.5789 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7127 - acc: 0.2590 - val_loss: 0.5782 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7103 - acc: 0.2590 - val_loss: 0.5775 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7096 - acc: 0.2590 - val_loss: 0.5768 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7068 - acc: 0.2569 - val_loss: 0.5760 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7096 - acc: 0.2590 - val_loss: 0.5754 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7088 - acc: 0.2590 - val_loss: 0.5747 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7095 - acc: 0.2590 - val_loss: 0.5740 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7097 - acc: 0.2590 - val_loss: 0.5734 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7053 - acc: 0.2590 - val_loss: 0.5727 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7058 - acc: 0.2590 - val_loss: 0.5721 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6982 - acc: 0.2611 - val_loss: 0.5715 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7022 - acc: 0.2590 - val_loss: 0.5708 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7018 - acc: 0.2590 - val_loss: 0.5702 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6976 - acc: 0.2590 - val_loss: 0.5695 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7019 - acc: 0.2590 - val_loss: 0.5689 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7001 - acc: 0.2590 - val_loss: 0.5683 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7021 - acc: 0.2590 - val_loss: 0.5677 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7001 - acc: 0.2590 - val_loss: 0.5672 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7000 - acc: 0.2590 - val_loss: 0.5666 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7022 - acc: 0.2590 - val_loss: 0.5660 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6912 - acc: 0.2590 - val_loss: 0.5655 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6958 - acc: 0.2590 - val_loss: 0.5649 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6921 - acc: 0.2590 - val_loss: 0.5643 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6964 - acc: 0.2590 - val_loss: 0.5638 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6941 - acc: 0.2590 - val_loss: 0.5632 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6983 - acc: 0.2590 - val_loss: 0.5627 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6932 - acc: 0.2590 - val_loss: 0.5622 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6912 - acc: 0.2590 - val_loss: 0.5617 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6979 - acc: 0.2590 - val_loss: 0.5612 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6971 - acc: 0.2590 - val_loss: 0.5607 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6930 - acc: 0.2590 - val_loss: 0.5602 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6864 - acc: 0.2590 - val_loss: 0.5597 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6928 - acc: 0.2590 - val_loss: 0.5592 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 204us/step - loss: 0.6854 - acc: 0.2590 - val_loss: 0.5587 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6849 - acc: 0.2590 - val_loss: 0.5582 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6893 - acc: 0.2590 - val_loss: 0.5577 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6880 - acc: 0.2590 - val_loss: 0.5572 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6913 - acc: 0.2590 - val_loss: 0.5568 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6799 - acc: 0.2590 - val_loss: 0.5563 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6868 - acc: 0.2590 - val_loss: 0.5558 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6819 - acc: 0.2590 - val_loss: 0.5553 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6842 - acc: 0.2590 - val_loss: 0.5548 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6823 - acc: 0.2590 - val_loss: 0.5544 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6821 - acc: 0.2590 - val_loss: 0.5539 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6876 - acc: 0.2590 - val_loss: 0.5535 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6842 - acc: 0.2590 - val_loss: 0.5531 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6901 - acc: 0.2590 - val_loss: 0.5527 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6785 - acc: 0.2590 - val_loss: 0.5523 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6813 - acc: 0.2590 - val_loss: 0.5518 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6803 - acc: 0.2590 - val_loss: 0.5514 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6833 - acc: 0.2590 - val_loss: 0.5510 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6771 - acc: 0.2590 - val_loss: 0.5506 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6825 - acc: 0.2590 - val_loss: 0.5502 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6762 - acc: 0.2590 - val_loss: 0.5498 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6820 - acc: 0.2590 - val_loss: 0.5494 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6792 - acc: 0.2590 - val_loss: 0.5490 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6798 - acc: 0.2590 - val_loss: 0.5486 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6757 - acc: 0.2590 - val_loss: 0.5482 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6694 - acc: 0.2590 - val_loss: 0.5478 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6747 - acc: 0.2590 - val_loss: 0.5474 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6691 - acc: 0.2590 - val_loss: 0.5470 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6803 - acc: 0.2590 - val_loss: 0.5466 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6790 - acc: 0.2590 - val_loss: 0.5462 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6810 - acc: 0.2590 - val_loss: 0.5459 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6751 - acc: 0.2590 - val_loss: 0.5455 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6764 - acc: 0.2590 - val_loss: 0.5452 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6651 - acc: 0.2590 - val_loss: 0.5448 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6781 - acc: 0.2590 - val_loss: 0.5444 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6751 - acc: 0.2590 - val_loss: 0.5441 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6730 - acc: 0.2590 - val_loss: 0.5437 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6741 - acc: 0.2590 - val_loss: 0.5434 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6792 - acc: 0.2590 - val_loss: 0.5431 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6699 - acc: 0.2590 - val_loss: 0.5427 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6724 - acc: 0.2590 - val_loss: 0.5424 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6796 - acc: 0.2590 - val_loss: 0.5421 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6654 - acc: 0.2590 - val_loss: 0.5418 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6804 - acc: 0.2590 - val_loss: 0.5415 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6658 - acc: 0.2590 - val_loss: 0.5412 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6708 - acc: 0.2590 - val_loss: 0.5409 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6759 - acc: 0.2590 - val_loss: 0.5406 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6675 - acc: 0.2590 - val_loss: 0.5403 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6586 - acc: 0.2590 - val_loss: 0.5399 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6765 - acc: 0.2590 - val_loss: 0.5396 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6628 - acc: 0.2590 - val_loss: 0.5393 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6736 - acc: 0.2590 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6668 - acc: 0.2590 - val_loss: 0.5387 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6690 - acc: 0.2590 - val_loss: 0.5384 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6746 - acc: 0.2590 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6730 - acc: 0.2590 - val_loss: 0.5379 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6675 - acc: 0.2590 - val_loss: 0.5377 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6658 - acc: 0.2590 - val_loss: 0.5374 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6706 - acc: 0.2590 - val_loss: 0.5371 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6593 - acc: 0.2590 - val_loss: 0.5369 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6586 - acc: 0.2590 - val_loss: 0.5366 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6680 - acc: 0.2590 - val_loss: 0.5363 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6592 - acc: 0.2590 - val_loss: 0.5360 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6707 - acc: 0.2590 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6626 - acc: 0.2590 - val_loss: 0.5355 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6638 - acc: 0.2590 - val_loss: 0.5352 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6586 - acc: 0.2590 - val_loss: 0.5350 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6734 - acc: 0.2590 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6660 - acc: 0.2590 - val_loss: 0.5345 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6571 - acc: 0.2590 - val_loss: 0.5343 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 177us/step\n",
      "Test score: 0.5342780258638639\n",
      "Look! elu softmax hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softmax tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_258 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_923 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_668 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_924 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_669 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_925 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 26s 56ms/step - loss: nan - acc: 0.4501 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 188us/step\n",
      "Test score: nan\n",
      "Look! elu softmax linear Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softmax linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_259 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_926 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_670 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_927 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_671 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_928 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 58ms/step - loss: 4.2217 - acc: 0.2654 - val_loss: 3.4772 - val_acc: 0.1489\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 5.0387 - acc: 0.2144 - val_loss: 2.7931 - val_acc: 0.1560\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.8509 - acc: 0.2357 - val_loss: 2.7356 - val_acc: 0.2270\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.6281 - acc: 0.2463 - val_loss: 3.4670 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.5041 - acc: 0.2420 - val_loss: 3.5165 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.1687 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.2717 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3857 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.4184 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3464 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.4172 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3071 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3554 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.2813 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.3541 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.3759 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.2850 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3706 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3791 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 4.4468 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3814 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.4581 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3721 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.3131 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3461 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.3174 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.4005 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.4385 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.2971 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3342 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.4385 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.4687 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3727 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.2435 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3170 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.4042 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3407 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.4017 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3462 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3328 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3707 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3678 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.4064 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.2915 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.3461 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.2788 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 4.3702 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3593 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3853 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3461 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 4.4461 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.3803 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.3804 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.3471 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3453 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3949 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.3255 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.3134 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.3353 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 4.1946 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.2428 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 4.2564 - acc: 0.2718 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.3633 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.1663 - acc: 0.2675 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.3277 - acc: 0.2569 - val_loss: 3.0294 - val_acc: 0.2199\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.8108 - acc: 0.2102 - val_loss: 4.5615 - val_acc: 0.1418\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.8474 - acc: 0.2335 - val_loss: 3.6286 - val_acc: 0.1773\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.8464 - acc: 0.2293 - val_loss: 2.1670 - val_acc: 0.2624\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 4.2694 - acc: 0.2654 - val_loss: 3.4583 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.2002 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3478 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.4157 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.3446 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.2792 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 4.3597 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3248 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.3834 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3611 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3733 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.3562 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3549 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.3815 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3472 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3465 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.4403 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3473 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 176us/step\n",
      "Test score: 3.543694685536919\n",
      "Look! elu elu softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softmax linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_260 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_929 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_672 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_930 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_673 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_931 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 57ms/step - loss: 3.4394 - acc: 0.1975 - val_loss: 0.9940 - val_acc: 0.1631\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.3034 - acc: 0.2930 - val_loss: 0.9795 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.1347 - acc: 0.2994 - val_loss: 0.9729 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.2746 - acc: 0.2505 - val_loss: 0.9721 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.1294 - acc: 0.2569 - val_loss: 0.9703 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.0486 - acc: 0.2420 - val_loss: 0.5432 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.8828 - acc: 0.2335 - val_loss: 0.5262 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8688 - acc: 0.2505 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.8649 - acc: 0.2314 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7635 - acc: 0.2229 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7982 - acc: 0.2335 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7307 - acc: 0.2314 - val_loss: 0.5329 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6875 - acc: 0.2803 - val_loss: 0.5331 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7356 - acc: 0.2378 - val_loss: 0.5327 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7003 - acc: 0.2505 - val_loss: 0.5307 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7654 - acc: 0.2187 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7794 - acc: 0.2442 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7589 - acc: 0.2378 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6812 - acc: 0.2548 - val_loss: 0.5201 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6815 - acc: 0.2633 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7436 - acc: 0.2463 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6418 - acc: 0.2611 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7096 - acc: 0.2548 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6555 - acc: 0.2654 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.7111 - acc: 0.2633 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7154 - acc: 0.2633 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 27/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 204us/step - loss: 0.7214 - acc: 0.2569 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6726 - acc: 0.2654 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6554 - acc: 0.2675 - val_loss: 0.5305 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7593 - acc: 0.2505 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6511 - acc: 0.2887 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6650 - acc: 0.2548 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6863 - acc: 0.2654 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6782 - acc: 0.2633 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6832 - acc: 0.2611 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7110 - acc: 0.2611 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6486 - acc: 0.2569 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6605 - acc: 0.2739 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6760 - acc: 0.2675 - val_loss: 0.5169 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6617 - acc: 0.2569 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6889 - acc: 0.2548 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6787 - acc: 0.2420 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6503 - acc: 0.2484 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7276 - acc: 0.2654 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6839 - acc: 0.2484 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6735 - acc: 0.2548 - val_loss: 0.5106 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6760 - acc: 0.2611 - val_loss: 0.5091 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6938 - acc: 0.2633 - val_loss: 0.5080 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6189 - acc: 0.2654 - val_loss: 0.5072 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.7147 - acc: 0.2611 - val_loss: 0.5066 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7190 - acc: 0.2505 - val_loss: 0.5056 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6458 - acc: 0.2484 - val_loss: 0.5050 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6597 - acc: 0.2611 - val_loss: 0.5049 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6206 - acc: 0.2590 - val_loss: 0.5049 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6778 - acc: 0.2633 - val_loss: 0.5050 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6755 - acc: 0.2590 - val_loss: 0.5043 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6883 - acc: 0.2611 - val_loss: 0.5038 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6666 - acc: 0.2654 - val_loss: 0.5043 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6355 - acc: 0.2420 - val_loss: 0.5046 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6158 - acc: 0.2527 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6675 - acc: 0.2590 - val_loss: 0.5043 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6741 - acc: 0.2675 - val_loss: 0.5024 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6533 - acc: 0.2611 - val_loss: 0.5017 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6629 - acc: 0.2633 - val_loss: 0.5009 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7320 - acc: 0.2548 - val_loss: 0.4977 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6811 - acc: 0.2633 - val_loss: 0.4995 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7086 - acc: 0.2633 - val_loss: 0.5008 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7118 - acc: 0.2675 - val_loss: 0.5021 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6513 - acc: 0.2505 - val_loss: 0.5026 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6987 - acc: 0.2569 - val_loss: 0.5019 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6495 - acc: 0.2590 - val_loss: 0.5001 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6821 - acc: 0.2505 - val_loss: 0.4982 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6202 - acc: 0.2590 - val_loss: 0.4968 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6291 - acc: 0.2569 - val_loss: 0.4974 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6465 - acc: 0.2611 - val_loss: 0.4961 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6314 - acc: 0.2675 - val_loss: 0.4966 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6203 - acc: 0.2739 - val_loss: 0.4976 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6077 - acc: 0.2548 - val_loss: 0.4963 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6842 - acc: 0.2633 - val_loss: 0.4946 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6114 - acc: 0.2696 - val_loss: 0.4931 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6077 - acc: 0.2633 - val_loss: 0.4907 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6038 - acc: 0.2633 - val_loss: 0.4881 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.5940 - acc: 0.2675 - val_loss: 0.4856 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6086 - acc: 0.2675 - val_loss: 0.4835 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6023 - acc: 0.2611 - val_loss: 0.4828 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6166 - acc: 0.2675 - val_loss: 0.4826 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.6588 - acc: 0.2696 - val_loss: 0.4812 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.5928 - acc: 0.2611 - val_loss: 0.4815 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6235 - acc: 0.2590 - val_loss: 0.4805 - val_acc: 0.2199\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6597 - acc: 0.2654 - val_loss: 0.4797 - val_acc: 0.2199\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6150 - acc: 0.2675 - val_loss: 0.4792 - val_acc: 0.2270\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6526 - acc: 0.2633 - val_loss: 0.4781 - val_acc: 0.2270\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6264 - acc: 0.2633 - val_loss: 0.4775 - val_acc: 0.2270\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6904 - acc: 0.2633 - val_loss: 0.4770 - val_acc: 0.2270\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6255 - acc: 0.2675 - val_loss: 0.4777 - val_acc: 0.2270\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6309 - acc: 0.2611 - val_loss: 0.4802 - val_acc: 0.2340\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6170 - acc: 0.2718 - val_loss: 0.4794 - val_acc: 0.2270\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.5928 - acc: 0.2760 - val_loss: 0.4764 - val_acc: 0.2270\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6312 - acc: 0.2718 - val_loss: 0.4737 - val_acc: 0.2270\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6347 - acc: 0.2654 - val_loss: 0.4737 - val_acc: 0.2270\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.5973 - acc: 0.2569 - val_loss: 0.4740 - val_acc: 0.2340\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6180 - acc: 0.2760 - val_loss: 0.4730 - val_acc: 0.2340\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6079 - acc: 0.2654 - val_loss: 0.4709 - val_acc: 0.2340\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6072 - acc: 0.2781 - val_loss: 0.4690 - val_acc: 0.2340\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.6452 - acc: 0.2803 - val_loss: 0.4691 - val_acc: 0.2340\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6603 - acc: 0.2696 - val_loss: 0.4874 - val_acc: 0.2340\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6008 - acc: 0.2696 - val_loss: 0.4706 - val_acc: 0.2340\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6085 - acc: 0.2803 - val_loss: 0.4687 - val_acc: 0.2340\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6109 - acc: 0.2824 - val_loss: 0.4698 - val_acc: 0.2482\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.6386 - acc: 0.2866 - val_loss: 0.4680 - val_acc: 0.2482\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6212 - acc: 0.2781 - val_loss: 0.4733 - val_acc: 0.2482\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.5797 - acc: 0.2803 - val_loss: 0.4756 - val_acc: 0.2340\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6249 - acc: 0.2718 - val_loss: 0.4755 - val_acc: 0.2340\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6041 - acc: 0.2866 - val_loss: 0.4740 - val_acc: 0.2340\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.5676 - acc: 0.3057 - val_loss: 0.4741 - val_acc: 0.2482\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.5742 - acc: 0.2760 - val_loss: 0.4747 - val_acc: 0.2482\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6144 - acc: 0.2675 - val_loss: 0.4732 - val_acc: 0.2482\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.5746 - acc: 0.2887 - val_loss: 0.4698 - val_acc: 0.2411\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.5706 - acc: 0.2972 - val_loss: 0.4663 - val_acc: 0.2411\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.5700 - acc: 0.2739 - val_loss: 0.4624 - val_acc: 0.2411\n",
      "141/141 [==============================] - 0s 178us/step\n",
      "Test score: 0.4624341354302481\n",
      "Look! elu elu elu Test accuracy: 0.2411347524071416\n",
      "max there  0.6241134772909448 elu softmax linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_261 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_932 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_674 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_933 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_675 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_934 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 57ms/step - loss: 4.5655 - acc: 0.2654 - val_loss: 3.0816 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.5421 - acc: 0.2293 - val_loss: 1.1538 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.7721 - acc: 0.2654 - val_loss: 0.5755 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.5465 - acc: 0.2633 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.6012 - acc: 0.2569 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.1706 - acc: 0.2420 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.1125 - acc: 0.2718 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.0918 - acc: 0.2144 - val_loss: 0.5205 - val_acc: 0.2270\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.9660 - acc: 0.2739 - val_loss: 0.5218 - val_acc: 0.2340\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7794 - acc: 0.2718 - val_loss: 0.5242 - val_acc: 0.2199\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.8062 - acc: 0.2251 - val_loss: 0.5274 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7886 - acc: 0.3057 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7011 - acc: 0.2654 - val_loss: 0.5271 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.8308 - acc: 0.2781 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7352 - acc: 0.2760 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7505 - acc: 0.2590 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 17/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 191us/step - loss: 0.7103 - acc: 0.2909 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7243 - acc: 0.2718 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7249 - acc: 0.2484 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.7091 - acc: 0.2527 - val_loss: 0.5201 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7180 - acc: 0.2611 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6884 - acc: 0.2675 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7299 - acc: 0.2527 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6841 - acc: 0.2548 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7136 - acc: 0.2654 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6800 - acc: 0.2887 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6453 - acc: 0.2611 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6912 - acc: 0.2633 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.8165 - acc: 0.2590 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6584 - acc: 0.2718 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7665 - acc: 0.2845 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6877 - acc: 0.2781 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6639 - acc: 0.2611 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6517 - acc: 0.2803 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6937 - acc: 0.2781 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6839 - acc: 0.2845 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6535 - acc: 0.2675 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6510 - acc: 0.2739 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6810 - acc: 0.2675 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6610 - acc: 0.2505 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6341 - acc: 0.2484 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7116 - acc: 0.2505 - val_loss: 0.5097 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6836 - acc: 0.2463 - val_loss: 0.5090 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6321 - acc: 0.2569 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6648 - acc: 0.2527 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6207 - acc: 0.2803 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6585 - acc: 0.2760 - val_loss: 0.5096 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6501 - acc: 0.2590 - val_loss: 0.5068 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.6810 - acc: 0.2569 - val_loss: 0.5054 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6206 - acc: 0.2675 - val_loss: 0.5036 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6636 - acc: 0.2675 - val_loss: 0.5033 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6531 - acc: 0.2718 - val_loss: 0.5020 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6461 - acc: 0.2484 - val_loss: 0.5002 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6947 - acc: 0.2633 - val_loss: 0.5000 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7414 - acc: 0.2569 - val_loss: 0.5018 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6896 - acc: 0.2484 - val_loss: 0.5020 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6859 - acc: 0.2654 - val_loss: 0.5016 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7342 - acc: 0.2675 - val_loss: 0.4999 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.7184 - acc: 0.2590 - val_loss: 0.4983 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7285 - acc: 0.2611 - val_loss: 0.4988 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.7721 - acc: 0.2590 - val_loss: 0.5006 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6517 - acc: 0.2739 - val_loss: 0.5019 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6100 - acc: 0.2675 - val_loss: 0.5021 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6378 - acc: 0.2633 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6548 - acc: 0.2548 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6391 - acc: 0.2527 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6485 - acc: 0.2590 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6447 - acc: 0.2505 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6334 - acc: 0.2590 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6898 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6993 - acc: 0.2611 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7274 - acc: 0.2633 - val_loss: 0.5054 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6592 - acc: 0.2569 - val_loss: 0.5043 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7257 - acc: 0.2611 - val_loss: 0.5040 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6589 - acc: 0.2505 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6071 - acc: 0.2633 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6624 - acc: 0.2611 - val_loss: 0.5034 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6400 - acc: 0.2696 - val_loss: 0.5079 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6461 - acc: 0.2569 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6564 - acc: 0.2569 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6787 - acc: 0.2548 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6314 - acc: 0.2569 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6408 - acc: 0.2675 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6472 - acc: 0.2654 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6878 - acc: 0.2463 - val_loss: 0.5085 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6286 - acc: 0.2654 - val_loss: 0.5060 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6394 - acc: 0.2484 - val_loss: 0.5055 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6504 - acc: 0.2633 - val_loss: 0.5047 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6676 - acc: 0.2675 - val_loss: 0.5055 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6193 - acc: 0.2654 - val_loss: 0.5067 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6289 - acc: 0.2654 - val_loss: 0.5064 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6159 - acc: 0.2611 - val_loss: 0.5054 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6656 - acc: 0.2590 - val_loss: 0.5041 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6183 - acc: 0.2611 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6194 - acc: 0.2633 - val_loss: 0.5005 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6358 - acc: 0.2590 - val_loss: 0.4985 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6215 - acc: 0.2484 - val_loss: 0.4978 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6958 - acc: 0.2611 - val_loss: 0.4984 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6861 - acc: 0.2611 - val_loss: 0.5000 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6319 - acc: 0.2527 - val_loss: 0.5087 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6354 - acc: 0.2633 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6303 - acc: 0.2611 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6320 - acc: 0.2569 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6404 - acc: 0.2611 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6397 - acc: 0.2527 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6623 - acc: 0.2527 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6397 - acc: 0.2569 - val_loss: 0.5092 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6228 - acc: 0.2675 - val_loss: 0.5067 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6411 - acc: 0.2611 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6255 - acc: 0.2675 - val_loss: 0.5027 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6280 - acc: 0.2569 - val_loss: 0.5006 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6260 - acc: 0.2633 - val_loss: 0.4984 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6012 - acc: 0.2675 - val_loss: 0.4962 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6461 - acc: 0.2548 - val_loss: 0.4945 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6055 - acc: 0.2633 - val_loss: 0.4938 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6226 - acc: 0.2654 - val_loss: 0.4929 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6309 - acc: 0.2569 - val_loss: 0.4920 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6251 - acc: 0.2611 - val_loss: 0.4917 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6850 - acc: 0.2611 - val_loss: 0.4919 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6122 - acc: 0.2611 - val_loss: 0.4927 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 190us/step\n",
      "Test score: 0.4927447450921891\n",
      "Look! elu elu selu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softmax linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_262 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_935 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_676 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_936 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_677 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_937 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 57ms/step - loss: nan - acc: 0.4650 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 165us/step\n",
      "Test score: nan\n",
      "Look! elu elu softplus Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu elu softplus\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_263 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_938 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_678 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_939 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_679 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_940 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 57ms/step - loss: 2.7038 - acc: 0.3907 - val_loss: 2.7927 - val_acc: 0.6241\n",
      "Epoch 2/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 191us/step - loss: 2.5417 - acc: 0.3800 - val_loss: 0.6993 - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 2.8697 - acc: 0.3652 - val_loss: 0.8469 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.3351 - acc: 0.3418 - val_loss: 0.8427 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.1979 - acc: 0.3121 - val_loss: 0.8314 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.3233 - acc: 0.2654 - val_loss: 0.7813 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.2458 - acc: 0.2696 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.6598 - acc: 0.2548 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.6006 - acc: 0.2208 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.1086 - acc: 0.2611 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.9988 - acc: 0.2463 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.1058 - acc: 0.2357 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 3.1211 - acc: 0.2357 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 3.8392 - acc: 0.2251 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.2753 - acc: 0.2484 - val_loss: 5.4870 - val_acc: 0.2199\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 4.3707 - acc: 0.2081 - val_loss: 5.4870 - val_acc: 0.2340\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.5327 - acc: 0.2123 - val_loss: 5.4870 - val_acc: 0.2411\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 5.6231 - acc: 0.2293 - val_loss: 5.4870 - val_acc: 0.2411\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 4.9505 - acc: 0.2229 - val_loss: 5.4870 - val_acc: 0.2766\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 5.3566 - acc: 0.2505 - val_loss: 5.4870 - val_acc: 0.2624\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.9209 - acc: 0.2144 - val_loss: 5.4870 - val_acc: 0.2553\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 5.3898 - acc: 0.2293 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 5.0815 - acc: 0.2314 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.8732 - acc: 0.2272 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 5.2395 - acc: 0.2420 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.9388 - acc: 0.2420 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.8589 - acc: 0.2272 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.8754 - acc: 0.2484 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 5.2719 - acc: 0.2357 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.5382 - acc: 0.2293 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.9319 - acc: 0.2208 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.6389 - acc: 0.2335 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.8456 - acc: 0.2123 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.7815 - acc: 0.2463 - val_loss: 5.4870 - val_acc: 0.2340\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.5449 - acc: 0.2378 - val_loss: 2.4060 - val_acc: 0.1277\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.6370 - acc: 0.2017 - val_loss: 2.2963 - val_acc: 0.1277\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.9672 - acc: 0.2335 - val_loss: 2.2805 - val_acc: 0.1277\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.3472 - acc: 0.2378 - val_loss: 2.2769 - val_acc: 0.1277\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.2005 - acc: 0.2293 - val_loss: 2.2768 - val_acc: 0.1277\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 175us/step - loss: 2.1560 - acc: 0.2548 - val_loss: 2.2758 - val_acc: 0.1277\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 174us/step - loss: 2.2704 - acc: 0.2484 - val_loss: 2.2768 - val_acc: 0.1277\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.5516 - acc: 0.2335 - val_loss: 2.2791 - val_acc: 0.1277\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.1356 - acc: 0.2314 - val_loss: 2.2820 - val_acc: 0.1277\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 2.0833 - acc: 0.2442 - val_loss: 2.2772 - val_acc: 0.1277\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.0502 - acc: 0.2335 - val_loss: 2.2748 - val_acc: 0.1277\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.8133 - acc: 0.2399 - val_loss: 2.2734 - val_acc: 0.1277\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.8236 - acc: 0.2017 - val_loss: 2.2735 - val_acc: 0.1277\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.8634 - acc: 0.2314 - val_loss: 0.7137 - val_acc: 0.1277\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.0724 - acc: 0.3206 - val_loss: 0.6007 - val_acc: 0.1277\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.5263 - acc: 0.2803 - val_loss: 0.6000 - val_acc: 0.1277\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.7726 - acc: 0.3397 - val_loss: 0.5997 - val_acc: 0.1277\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 1.7007 - acc: 0.3737 - val_loss: 0.5995 - val_acc: 0.6312\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.6865 - acc: 0.3355 - val_loss: 0.5990 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.7684 - acc: 0.4055 - val_loss: 0.5973 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.8585 - acc: 0.4204 - val_loss: 1.2076 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.7658 - acc: 0.4713 - val_loss: 1.1803 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.8241 - acc: 0.4544 - val_loss: 1.1783 - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.8866 - acc: 0.4650 - val_loss: 1.1782 - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.0514 - acc: 0.4416 - val_loss: 1.1785 - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.8661 - acc: 0.4650 - val_loss: 1.1776 - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.0988 - acc: 0.4459 - val_loss: 1.1768 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.8626 - acc: 0.4713 - val_loss: 1.1763 - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.8006 - acc: 0.4607 - val_loss: 1.1760 - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.9306 - acc: 0.4841 - val_loss: 1.1758 - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.0299 - acc: 0.4586 - val_loss: 1.1756 - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: 2.5469 - acc: 0.4756 - val_loss: 1.1754 - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.2156 - acc: 0.4713 - val_loss: 1.1750 - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.2334 - acc: 0.4862 - val_loss: 1.1740 - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 2.3362 - acc: 0.4841 - val_loss: 1.2714 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.2878 - acc: 0.4820 - val_loss: 1.1734 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.3919 - acc: 0.4841 - val_loss: 1.2718 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.8195 - acc: 0.4904 - val_loss: 2.2321 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5032 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 176us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 182us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 179us/step\n",
      "Test score: nan\n",
      "Look! elu elu softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu elu softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_264 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_941 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_680 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_942 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_681 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_943 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 57ms/step - loss: nan - acc: 0.4671 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 199us/step\n",
      "Test score: nan\n",
      "Look! elu elu relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu elu relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_265 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_944 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_682 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_945 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_683 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_946 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 58ms/step - loss: nan - acc: 0.4883 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 190us/step\n",
      "Test score: nan\n",
      "Look! elu elu tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu elu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_266 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_947 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_684 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_948 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_685 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_949 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 58ms/step - loss: 1.7261 - acc: 0.4310 - val_loss: 0.5987 - val_acc: 0.5957\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.2253 - acc: 0.4713 - val_loss: 0.5961 - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.0389 - acc: 0.4904 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.8346 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.8136 - acc: 0.5308 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7732 - acc: 0.5202 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.9785 - acc: 0.5202 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.9061 - acc: 0.5138 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7366 - acc: 0.5138 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7487 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.8155 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7608 - acc: 0.5032 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7364 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8291 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7295 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7267 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7286 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7316 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7542 - acc: 0.5096 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7440 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7613 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7315 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7503 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7268 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7568 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7464 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7308 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.8205 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7344 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7610 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7600 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7334 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7312 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7295 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.7322 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7437 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7334 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7624 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7454 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7502 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7339 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7329 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7353 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.7367 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7346 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7334 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7328 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7334 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.7352 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7634 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7647 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7659 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7355 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7649 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7433 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7786 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7424 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7327 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7947 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7671 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7953 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7559 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.7912 - acc: 0.5287 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7581 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.8820 - acc: 0.5074 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8271 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7592 - acc: 0.5287 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7305 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7365 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.7339 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7345 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7340 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7343 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7339 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7346 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7362 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7332 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7649 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7659 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7346 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7334 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7342 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7340 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7322 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7327 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7652 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.8018 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7660 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.7334 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7334 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7665 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7671 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7359 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7644 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7358 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7352 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7346 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7358 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7358 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7352 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7568 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7346 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7369 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7352 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7671 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7352 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7352 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7353 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7353 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7352 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7352 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 176us/step\n",
      "Test score: 0.5997443816340562\n",
      "Look! elu elu sigmoid Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu elu sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_267 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_950 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_686 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_951 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_687 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_952 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 58ms/step - loss: nan - acc: 0.3376 - val_loss: 1.7222 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.3715 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.5122 - acc: 0.3418 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.3052 - acc: 0.3588 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.1641 - acc: 0.3248 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.1844 - acc: 0.3291 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.2433 - acc: 0.3121 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.9893 - acc: 0.2994 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.2090 - acc: 0.2951 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.0667 - acc: 0.3100 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.1142 - acc: 0.3163 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 2.0903 - acc: 0.2845 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.0826 - acc: 0.2887 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.8602 - acc: 0.2994 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.0111 - acc: 0.2909 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.9274 - acc: 0.2930 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.9930 - acc: 0.3121 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 2.1437 - acc: 0.2845 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.1478 - acc: 0.2972 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.0601 - acc: 0.3057 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 171us/step - loss: 1.9035 - acc: 0.3291 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 1.8731 - acc: 0.3758 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.9461 - acc: 0.3567 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.7541 - acc: 0.3503 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.8676 - acc: 0.3758 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.7388 - acc: 0.3482 - val_loss: 1.7253 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 1.6400 - acc: 0.4352 - val_loss: 0.9917 - val_acc: 0.5390\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.6624 - acc: 0.4034 - val_loss: 1.0053 - val_acc: 0.5957\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.6335 - acc: 0.3970 - val_loss: 1.0071 - val_acc: 0.6028\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.6522 - acc: 0.4268 - val_loss: 1.0012 - val_acc: 0.5816\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.6944 - acc: 0.4374 - val_loss: 1.0013 - val_acc: 0.5674\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.7301 - acc: 0.3800 - val_loss: 1.0076 - val_acc: 0.6028\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.5335 - acc: 0.4013 - val_loss: 1.0046 - val_acc: 0.5603\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.6599 - acc: 0.4098 - val_loss: 0.9767 - val_acc: 0.4184\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 1.5846 - acc: 0.4034 - val_loss: 1.0072 - val_acc: 0.5957\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.7526 - acc: 0.3588 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.7161 - acc: 0.4076 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.3717 - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.4092 - acc: 0.4862 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.2091 - acc: 0.5329 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.3251 - acc: 0.4989 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 1.0574 - acc: 0.5350 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 1.2759 - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.3036 - acc: 0.5456 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.0342 - acc: 0.5244 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 179us/step - loss: 1.2829 - acc: 0.5117 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.3540 - acc: 0.5223 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 1.3239 - acc: 0.5117 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.1922 - acc: 0.5308 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.2324 - acc: 0.5308 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 198us/step - loss: 1.2080 - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.2313 - acc: 0.5350 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.0940 - acc: 0.5456 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2538 - acc: 0.5265 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.1274 - acc: 0.5478 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.0962 - acc: 0.5350 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.3708 - acc: 0.5180 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 1.1939 - acc: 0.5265 - val_loss: 1.0084 - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.1616 - acc: 0.5499 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.0887 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.9273 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.1297 - acc: 0.5138 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.0390 - acc: 0.5011 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.0110 - acc: 0.5287 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.8852 - acc: 0.5308 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.9783 - acc: 0.5520 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.0113 - acc: 0.5244 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.9745 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.9780 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.0177 - acc: 0.5074 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.0524 - acc: 0.5202 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8517 - acc: 0.5244 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.8036 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.8755 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.9157 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.9161 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.9474 - acc: 0.5202 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.9928 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.9514 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.9524 - acc: 0.5180 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.9177 - acc: 0.5138 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.0173 - acc: 0.5223 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9449 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.9711 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.0078 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.9806 - acc: 0.5223 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.9755 - acc: 0.5180 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.8455 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.9017 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.9338 - acc: 0.5223 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.9498 - acc: 0.4947 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.0610 - acc: 0.5202 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.9402 - acc: 0.5202 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8644 - acc: 0.5202 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.2121 - acc: 0.5265 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.9938 - acc: 0.5032 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.1866 - acc: 0.5223 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8265 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.0826 - acc: 0.5202 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 1.0894 - acc: 0.5138 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.9644 - acc: 0.4968 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 1.1282 - acc: 0.5138 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.9375 - acc: 0.4968 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.0009 - acc: 0.5032 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8110 - acc: 0.5223 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9040 - acc: 0.5096 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.0342 - acc: 0.4820 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.8146 - acc: 0.5265 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.2173 - acc: 0.5308 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.1219 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 1.1853 - acc: 0.4947 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.8735 - acc: 0.5053 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.0210 - acc: 0.4989 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.9173 - acc: 0.5223 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.9612 - acc: 0.4926 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.9495 - acc: 0.5011 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8832 - acc: 0.5180 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 1.2147 - acc: 0.5159 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.1379 - acc: 0.4756 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.2456 - acc: 0.4989 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 168us/step\n",
      "Test score: 0.5997443816340562\n",
      "Look! elu elu hard_sigmoid Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu elu hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_268 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_953 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_688 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_954 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_689 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_955 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 27s 58ms/step - loss: 3.2726 - acc: 0.1677 - val_loss: 0.9315 - val_acc: 0.0638\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.1096 - acc: 0.1975 - val_loss: 0.9895 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.0178 - acc: 0.1699 - val_loss: 0.9237 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.6490 - acc: 0.1253 - val_loss: 0.8059 - val_acc: 0.0355\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.5032 - acc: 0.0892 - val_loss: 0.7181 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.7924 - acc: 0.0998 - val_loss: 0.6743 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.6933 - acc: 0.0786 - val_loss: 0.6558 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.7114 - acc: 0.0701 - val_loss: 0.6397 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.1513 - acc: 0.0722 - val_loss: 0.6284 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 3.2084 - acc: 0.0743 - val_loss: 0.6013 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.4264 - acc: 0.0594 - val_loss: 0.5729 - val_acc: 0.0355\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.5842 - acc: 0.0743 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.8861 - acc: 0.0679 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 3.8738 - acc: 0.0743 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 3.9219 - acc: 0.0764 - val_loss: 3.1892 - val_acc: 0.0355\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.7174 - acc: 0.0849 - val_loss: 2.2610 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.5477 - acc: 0.1210 - val_loss: 2.1719 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.5331 - acc: 0.1146 - val_loss: 2.1534 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.3142 - acc: 0.1571 - val_loss: 2.1362 - val_acc: 0.1631\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.7846 - acc: 0.1953 - val_loss: 2.1145 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.6805 - acc: 0.1826 - val_loss: 2.0902 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 3.6813 - acc: 0.2314 - val_loss: 2.0602 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.3983 - acc: 0.2399 - val_loss: 2.0576 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.8649 - acc: 0.2463 - val_loss: 2.5149 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.1458 - acc: 0.2357 - val_loss: 4.3439 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.0421 - acc: 0.2166 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.9854 - acc: 0.2335 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.9321 - acc: 0.2357 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.1915 - acc: 0.2739 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.1526 - acc: 0.2760 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.2776 - acc: 0.2463 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.6082 - acc: 0.2378 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.6489 - acc: 0.2569 - val_loss: 4.9154 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.5138 - acc: 0.2611 - val_loss: 4.7724 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.4386 - acc: 0.2569 - val_loss: 3.8200 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.3326 - acc: 0.2527 - val_loss: 3.6522 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.6662 - acc: 0.2633 - val_loss: 3.6294 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.1878 - acc: 0.2293 - val_loss: 3.6251 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.7508 - acc: 0.2229 - val_loss: 3.6060 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.6372 - acc: 0.2144 - val_loss: 3.6147 - val_acc: 0.2128\n",
      "Epoch 41/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 196us/step - loss: 3.2773 - acc: 0.2505 - val_loss: 3.6322 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.9086 - acc: 0.2314 - val_loss: 0.9846 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 2.5493 - acc: 0.2335 - val_loss: 0.7745 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.1987 - acc: 0.2590 - val_loss: 0.6843 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.5462 - acc: 0.2314 - val_loss: 0.6351 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.5851 - acc: 0.2251 - val_loss: 0.6070 - val_acc: 0.1986\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.1406 - acc: 0.2399 - val_loss: 0.5901 - val_acc: 0.0496\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.1775 - acc: 0.2442 - val_loss: 0.5768 - val_acc: 0.0567\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.0233 - acc: 0.2208 - val_loss: 0.5655 - val_acc: 0.0426\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.0112 - acc: 0.2357 - val_loss: 0.5556 - val_acc: 0.0426\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.0496 - acc: 0.2357 - val_loss: 0.5486 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.8253 - acc: 0.2144 - val_loss: 0.5427 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.9474 - acc: 0.2102 - val_loss: 0.5382 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8484 - acc: 0.2335 - val_loss: 0.5350 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.9763 - acc: 0.1847 - val_loss: 0.5331 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9506 - acc: 0.1996 - val_loss: 0.5308 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7390 - acc: 0.1911 - val_loss: 0.5284 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.9999 - acc: 0.1868 - val_loss: 0.5266 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7146 - acc: 0.1953 - val_loss: 0.5257 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.8642 - acc: 0.1571 - val_loss: 0.5282 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.8403 - acc: 0.2059 - val_loss: 0.5299 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.8340 - acc: 0.1677 - val_loss: 0.5303 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8555 - acc: 0.1783 - val_loss: 0.5302 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.8052 - acc: 0.1699 - val_loss: 0.5303 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7658 - acc: 0.1699 - val_loss: 0.5301 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7323 - acc: 0.1550 - val_loss: 0.5295 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.8200 - acc: 0.1805 - val_loss: 0.5293 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.8219 - acc: 0.1805 - val_loss: 0.5286 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7725 - acc: 0.1868 - val_loss: 0.5323 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7858 - acc: 0.2293 - val_loss: 0.5348 - val_acc: 0.0638\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.8018 - acc: 0.2463 - val_loss: 0.5359 - val_acc: 0.1135\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: 0.7244 - acc: 0.2548 - val_loss: 0.5361 - val_acc: 0.2624\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9085 - acc: 0.2866 - val_loss: 0.5359 - val_acc: 0.5532\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8406 - acc: 0.2887 - val_loss: 0.5361 - val_acc: 0.3333\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7840 - acc: 0.2760 - val_loss: 0.5363 - val_acc: 0.1277\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7213 - acc: 0.2590 - val_loss: 0.5360 - val_acc: 0.0993\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7770 - acc: 0.2017 - val_loss: 0.5353 - val_acc: 0.0851\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7441 - acc: 0.2718 - val_loss: 0.5353 - val_acc: 0.0567\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7342 - acc: 0.2144 - val_loss: 0.5351 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6722 - acc: 0.2166 - val_loss: 0.5346 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7667 - acc: 0.1996 - val_loss: 0.5344 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7160 - acc: 0.2251 - val_loss: 0.5342 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7473 - acc: 0.2229 - val_loss: 0.5340 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7074 - acc: 0.1868 - val_loss: 0.5337 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7211 - acc: 0.2251 - val_loss: 0.5331 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7497 - acc: 0.1783 - val_loss: 0.5325 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6776 - acc: 0.1635 - val_loss: 0.5322 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6791 - acc: 0.2187 - val_loss: 0.5316 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7863 - acc: 0.2059 - val_loss: 0.5308 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7639 - acc: 0.1932 - val_loss: 0.5313 - val_acc: 0.0426\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6500 - acc: 0.2293 - val_loss: 0.5326 - val_acc: 0.0780\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7386 - acc: 0.2633 - val_loss: 0.5333 - val_acc: 0.0780\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7165 - acc: 0.2463 - val_loss: 0.5337 - val_acc: 0.0851\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6673 - acc: 0.2420 - val_loss: 0.5369 - val_acc: 0.5674\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7776 - acc: 0.2845 - val_loss: 0.5416 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7619 - acc: 0.2994 - val_loss: 0.5438 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7126 - acc: 0.3333 - val_loss: 0.5445 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 0.7777 - acc: 0.3227 - val_loss: 0.5448 - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7137 - acc: 0.3418 - val_loss: 0.5444 - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7102 - acc: 0.2972 - val_loss: 0.5439 - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7386 - acc: 0.3461 - val_loss: 0.5435 - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7336 - acc: 0.3036 - val_loss: 0.5437 - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7361 - acc: 0.2845 - val_loss: 0.5438 - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7376 - acc: 0.2420 - val_loss: 0.5433 - val_acc: 0.4823\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6609 - acc: 0.2505 - val_loss: 0.5426 - val_acc: 0.1206\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7615 - acc: 0.2548 - val_loss: 0.5420 - val_acc: 0.0780\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6917 - acc: 0.2293 - val_loss: 0.5417 - val_acc: 0.0567\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6830 - acc: 0.2102 - val_loss: 0.5411 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6860 - acc: 0.2123 - val_loss: 0.5402 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6877 - acc: 0.1826 - val_loss: 0.5390 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7128 - acc: 0.1932 - val_loss: 0.5377 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7418 - acc: 0.2081 - val_loss: 0.5368 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6967 - acc: 0.1868 - val_loss: 0.5361 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7061 - acc: 0.1720 - val_loss: 0.5353 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6615 - acc: 0.1783 - val_loss: 0.5343 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7097 - acc: 0.1656 - val_loss: 0.5333 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7417 - acc: 0.1847 - val_loss: 0.5324 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6669 - acc: 0.1720 - val_loss: 0.5316 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7437 - acc: 0.1932 - val_loss: 0.5322 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6675 - acc: 0.1677 - val_loss: 0.5325 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 190us/step\n",
      "Test score: 0.5324795533579292\n",
      "Look! elu elu linear Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 elu elu hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_269 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_956 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_690 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_957 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_691 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_958 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 28s 59ms/step - loss: 5.7378 - acc: 0.2357 - val_loss: 3.4847 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.7577 - acc: 0.2293 - val_loss: 3.5261 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.6155 - acc: 0.2357 - val_loss: 3.4716 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.5847 - acc: 0.2399 - val_loss: 3.4720 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.6559 - acc: 0.2378 - val_loss: 3.5435 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.6234 - acc: 0.2399 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 4.5301 - acc: 0.2484 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.4126 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3211 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.5654 - acc: 0.2463 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.2428 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.1964 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 4.5268 - acc: 0.2463 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.6034 - acc: 0.2420 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.4648 - acc: 0.2463 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.3798 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 4.4724 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.3614 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.3774 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.4039 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.4053 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.3384 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.4497 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.4847 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.2525 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 4.4312 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.4224 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.3461 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 31/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 196us/step - loss: 4.3881 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.3412 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 183us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.3883 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 4.4111 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3606 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3661 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.3902 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3984 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.4056 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.4041 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3462 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 4.4091 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.4000 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3929 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3945 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3118 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.3628 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.3517 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.3844 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3806 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3787 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.3552 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.3572 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.3549 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.3803 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.3791 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3829 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.2996 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3118 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.3885 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.4145 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.4345 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3779 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.4113 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3702 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.3813 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.4104 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3703 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3803 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.3960 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 194us/step\n",
      "Test score: 3.543694685536919\n",
      "Look! elu selu softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu elu hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_270 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_959 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_692 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_960 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_693 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_961 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 28s 60ms/step - loss: 2.9798 - acc: 0.2845 - val_loss: 1.4511 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.2050 - acc: 0.2378 - val_loss: 0.8067 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.5460 - acc: 0.2463 - val_loss: 0.6279 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.3243 - acc: 0.2166 - val_loss: 0.5461 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.0518 - acc: 0.2527 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.1351 - acc: 0.2548 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8942 - acc: 0.2569 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.9856 - acc: 0.2569 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7422 - acc: 0.2930 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7327 - acc: 0.2442 - val_loss: 0.5300 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6983 - acc: 0.2548 - val_loss: 0.5321 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8081 - acc: 0.2463 - val_loss: 0.5368 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6756 - acc: 0.2590 - val_loss: 0.5382 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7964 - acc: 0.2463 - val_loss: 0.5383 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8171 - acc: 0.2569 - val_loss: 0.5375 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7312 - acc: 0.2633 - val_loss: 0.5362 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7644 - acc: 0.2760 - val_loss: 0.5348 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6991 - acc: 0.2611 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6997 - acc: 0.2611 - val_loss: 0.5320 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7088 - acc: 0.2442 - val_loss: 0.5303 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6938 - acc: 0.2611 - val_loss: 0.5294 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7123 - acc: 0.2399 - val_loss: 0.5285 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6653 - acc: 0.2633 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6631 - acc: 0.2675 - val_loss: 0.5263 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6790 - acc: 0.2505 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7241 - acc: 0.2611 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6499 - acc: 0.2527 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6728 - acc: 0.2505 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7665 - acc: 0.2484 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6755 - acc: 0.2611 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6479 - acc: 0.2463 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6441 - acc: 0.2696 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6753 - acc: 0.2548 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6556 - acc: 0.2484 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6788 - acc: 0.2633 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6653 - acc: 0.2590 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6422 - acc: 0.2527 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6383 - acc: 0.2633 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6559 - acc: 0.2590 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6538 - acc: 0.2675 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6490 - acc: 0.2633 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6553 - acc: 0.2633 - val_loss: 0.5241 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6583 - acc: 0.2590 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6562 - acc: 0.2527 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6472 - acc: 0.2696 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6571 - acc: 0.2505 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6356 - acc: 0.2590 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6456 - acc: 0.2569 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6461 - acc: 0.2548 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7474 - acc: 0.2633 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7026 - acc: 0.2569 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6483 - acc: 0.2611 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6425 - acc: 0.2505 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6777 - acc: 0.2611 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6585 - acc: 0.2590 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6531 - acc: 0.2633 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6428 - acc: 0.2505 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6366 - acc: 0.2463 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6532 - acc: 0.2569 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6354 - acc: 0.2590 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6812 - acc: 0.2505 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6461 - acc: 0.2527 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6771 - acc: 0.2527 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6391 - acc: 0.2548 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6621 - acc: 0.2590 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6725 - acc: 0.2590 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6458 - acc: 0.2548 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6480 - acc: 0.2611 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6426 - acc: 0.2611 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6296 - acc: 0.2633 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6694 - acc: 0.2611 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6552 - acc: 0.2548 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6472 - acc: 0.2548 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6345 - acc: 0.2633 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6403 - acc: 0.2611 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6431 - acc: 0.2611 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6618 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6697 - acc: 0.2590 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6410 - acc: 0.2611 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6302 - acc: 0.2590 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6336 - acc: 0.2633 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6468 - acc: 0.2590 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6392 - acc: 0.2590 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6399 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6717 - acc: 0.2611 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6666 - acc: 0.2590 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6330 - acc: 0.2590 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6267 - acc: 0.2590 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6622 - acc: 0.2569 - val_loss: 0.5092 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6346 - acc: 0.2633 - val_loss: 0.5089 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6374 - acc: 0.2569 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6213 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6408 - acc: 0.2633 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6191 - acc: 0.2611 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6338 - acc: 0.2590 - val_loss: 0.5106 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6312 - acc: 0.2548 - val_loss: 0.5096 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6568 - acc: 0.2590 - val_loss: 0.5086 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5082 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6363 - acc: 0.2590 - val_loss: 0.5082 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6416 - acc: 0.2611 - val_loss: 0.5096 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6604 - acc: 0.2569 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6312 - acc: 0.2590 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6389 - acc: 0.2548 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5106 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6642 - acc: 0.2569 - val_loss: 0.5097 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6376 - acc: 0.2548 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6330 - acc: 0.2548 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5089 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6272 - acc: 0.2675 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6246 - acc: 0.2590 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6326 - acc: 0.2633 - val_loss: 0.5101 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6386 - acc: 0.2590 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6344 - acc: 0.2569 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6264 - acc: 0.2590 - val_loss: 0.5089 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6597 - acc: 0.2569 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6314 - acc: 0.2590 - val_loss: 0.5076 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6221 - acc: 0.2633 - val_loss: 0.5068 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6249 - acc: 0.2569 - val_loss: 0.5058 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6279 - acc: 0.2569 - val_loss: 0.5051 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6325 - acc: 0.2611 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 201us/step\n",
      "Test score: 0.5043519456335839\n",
      "Look! elu selu elu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu elu hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_271 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_962 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_694 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_963 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_695 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_964 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 28s 59ms/step - loss: 3.6029 - acc: 0.2102 - val_loss: 2.0259 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.2193 - acc: 0.2102 - val_loss: 1.7087 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.8459 - acc: 0.2590 - val_loss: 1.6973 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.4441 - acc: 0.2357 - val_loss: 1.6982 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.0717 - acc: 0.2357 - val_loss: 1.7000 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.9527 - acc: 0.2251 - val_loss: 1.7012 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.0089 - acc: 0.2038 - val_loss: 1.4718 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.6218 - acc: 0.2314 - val_loss: 0.8947 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.6833 - acc: 0.2357 - val_loss: 0.5379 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.5069 - acc: 0.2102 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 11/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 206us/step - loss: 1.3652 - acc: 0.2357 - val_loss: 0.5450 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.9631 - acc: 0.2527 - val_loss: 0.5428 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.1734 - acc: 0.2569 - val_loss: 0.5429 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.0950 - acc: 0.2484 - val_loss: 0.5354 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.9480 - acc: 0.2781 - val_loss: 0.5338 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.9767 - acc: 0.2569 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.0360 - acc: 0.2654 - val_loss: 0.5360 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8158 - acc: 0.2527 - val_loss: 0.5383 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6966 - acc: 0.2824 - val_loss: 0.5395 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.9020 - acc: 0.2420 - val_loss: 0.5400 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7847 - acc: 0.2611 - val_loss: 0.5400 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.8525 - acc: 0.2675 - val_loss: 0.5401 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.7329 - acc: 0.2420 - val_loss: 0.5399 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.8558 - acc: 0.2166 - val_loss: 0.5394 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6957 - acc: 0.2187 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7563 - acc: 0.2527 - val_loss: 0.5363 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7599 - acc: 0.2527 - val_loss: 0.5335 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7539 - acc: 0.2633 - val_loss: 0.5330 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 0.7336 - acc: 0.2463 - val_loss: 0.5328 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: 0.7960 - acc: 0.2399 - val_loss: 0.5328 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7344 - acc: 0.2251 - val_loss: 0.5360 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7276 - acc: 0.2229 - val_loss: 0.5409 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6840 - acc: 0.2718 - val_loss: 0.5432 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6604 - acc: 0.2633 - val_loss: 0.5433 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6805 - acc: 0.2569 - val_loss: 0.5426 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7182 - acc: 0.2527 - val_loss: 0.5414 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6618 - acc: 0.2463 - val_loss: 0.5399 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.7257 - acc: 0.2781 - val_loss: 0.5382 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6602 - acc: 0.2675 - val_loss: 0.5365 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 177us/step - loss: 0.6694 - acc: 0.2378 - val_loss: 0.5353 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6825 - acc: 0.2569 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.7398 - acc: 0.2590 - val_loss: 0.5321 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 180us/step - loss: 0.7147 - acc: 0.2718 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6759 - acc: 0.2399 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7066 - acc: 0.2569 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7139 - acc: 0.2569 - val_loss: 0.5340 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7222 - acc: 0.2463 - val_loss: 0.5338 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.7256 - acc: 0.2611 - val_loss: 0.5335 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6465 - acc: 0.2675 - val_loss: 0.5329 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6993 - acc: 0.2357 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7944 - acc: 0.2548 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7060 - acc: 0.2484 - val_loss: 0.5300 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6880 - acc: 0.2484 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7044 - acc: 0.2314 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7389 - acc: 0.2569 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6315 - acc: 0.2633 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7466 - acc: 0.2569 - val_loss: 0.5279 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7610 - acc: 0.2527 - val_loss: 0.5274 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6828 - acc: 0.2527 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6917 - acc: 0.2611 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7186 - acc: 0.2527 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: 0.6730 - acc: 0.2569 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6642 - acc: 0.2378 - val_loss: 0.5280 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6578 - acc: 0.2548 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6848 - acc: 0.2484 - val_loss: 0.5283 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6500 - acc: 0.2611 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6515 - acc: 0.2442 - val_loss: 0.5278 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6769 - acc: 0.2611 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6487 - acc: 0.2633 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6433 - acc: 0.2463 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6552 - acc: 0.2378 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6799 - acc: 0.2463 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6288 - acc: 0.2590 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.6464 - acc: 0.2611 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6698 - acc: 0.2484 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7141 - acc: 0.2654 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6763 - acc: 0.2548 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6500 - acc: 0.2548 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6772 - acc: 0.2399 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6742 - acc: 0.2590 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6811 - acc: 0.2548 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7302 - acc: 0.2569 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6458 - acc: 0.2569 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6769 - acc: 0.2420 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6685 - acc: 0.2611 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6399 - acc: 0.2696 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6763 - acc: 0.2484 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6365 - acc: 0.2527 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6756 - acc: 0.2569 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6703 - acc: 0.2569 - val_loss: 0.5169 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6328 - acc: 0.2611 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6430 - acc: 0.2633 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6308 - acc: 0.2611 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6862 - acc: 0.2633 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6978 - acc: 0.2484 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6641 - acc: 0.2654 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6552 - acc: 0.2654 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6261 - acc: 0.2611 - val_loss: 0.5147 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6662 - acc: 0.2569 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6404 - acc: 0.2548 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6625 - acc: 0.2633 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6755 - acc: 0.2569 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6399 - acc: 0.2548 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6698 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6434 - acc: 0.2527 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6437 - acc: 0.2527 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6404 - acc: 0.2590 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6414 - acc: 0.2654 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6371 - acc: 0.2548 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6618 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6868 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6590 - acc: 0.2633 - val_loss: 0.5103 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6611 - acc: 0.2505 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6625 - acc: 0.2505 - val_loss: 0.5089 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6949 - acc: 0.2654 - val_loss: 0.5097 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6320 - acc: 0.2590 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6277 - acc: 0.2633 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6763 - acc: 0.2527 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7126 - acc: 0.2611 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6368 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 187us/step\n",
      "Test score: 0.5125970121816541\n",
      "Look! elu selu selu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu elu hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_272 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_965 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_696 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_966 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_697 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_967 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 28s 59ms/step - loss: 2.1974 - acc: 0.2378 - val_loss: 0.5634 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.0832 - acc: 0.3015 - val_loss: 0.5353 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.9454 - acc: 0.2335 - val_loss: 0.5387 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.0101 - acc: 0.2293 - val_loss: 0.5424 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7844 - acc: 0.2463 - val_loss: 0.5459 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.7420 - acc: 0.2166 - val_loss: 0.5521 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.7151 - acc: 0.2272 - val_loss: 0.5545 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6969 - acc: 0.2611 - val_loss: 0.5539 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6912 - acc: 0.2059 - val_loss: 0.5508 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7466 - acc: 0.2251 - val_loss: 0.5473 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6837 - acc: 0.2293 - val_loss: 0.5443 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6998 - acc: 0.2484 - val_loss: 0.5435 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7156 - acc: 0.1911 - val_loss: 0.5434 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7287 - acc: 0.2335 - val_loss: 0.5417 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7346 - acc: 0.2527 - val_loss: 0.5404 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6605 - acc: 0.2420 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7064 - acc: 0.2357 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7055 - acc: 0.2293 - val_loss: 0.5336 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7496 - acc: 0.2208 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6891 - acc: 0.2420 - val_loss: 0.5330 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6814 - acc: 0.2527 - val_loss: 0.5316 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6600 - acc: 0.2463 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7251 - acc: 0.2251 - val_loss: 0.5285 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7335 - acc: 0.2484 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6760 - acc: 0.2420 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6407 - acc: 0.2611 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.7792 - acc: 0.2654 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7041 - acc: 0.2442 - val_loss: 0.5249 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6570 - acc: 0.2548 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7179 - acc: 0.2505 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6587 - acc: 0.2548 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6491 - acc: 0.2463 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6377 - acc: 0.2611 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6796 - acc: 0.2527 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6718 - acc: 0.2590 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6542 - acc: 0.2442 - val_loss: 0.5249 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6442 - acc: 0.2569 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6537 - acc: 0.2442 - val_loss: 0.5233 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6936 - acc: 0.2505 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6731 - acc: 0.2442 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6438 - acc: 0.2548 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6896 - acc: 0.2633 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6819 - acc: 0.2590 - val_loss: 0.5254 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6431 - acc: 0.2442 - val_loss: 0.5259 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6503 - acc: 0.2654 - val_loss: 0.5255 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7184 - acc: 0.2675 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6518 - acc: 0.2548 - val_loss: 0.5241 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6568 - acc: 0.2399 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6374 - acc: 0.2654 - val_loss: 0.5208 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6723 - acc: 0.2548 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6473 - acc: 0.2442 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6236 - acc: 0.2633 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6651 - acc: 0.2357 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 0.6456 - acc: 0.2548 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6893 - acc: 0.2484 - val_loss: 0.5201 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6352 - acc: 0.2569 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6444 - acc: 0.2505 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6455 - acc: 0.2611 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6420 - acc: 0.2611 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6413 - acc: 0.2654 - val_loss: 0.5255 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6419 - acc: 0.2590 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6572 - acc: 0.2463 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6407 - acc: 0.2484 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6340 - acc: 0.2633 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6463 - acc: 0.2505 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6940 - acc: 0.2548 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6386 - acc: 0.2590 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7273 - acc: 0.2484 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6408 - acc: 0.2569 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6397 - acc: 0.2654 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6427 - acc: 0.2633 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6601 - acc: 0.2633 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6304 - acc: 0.2633 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6301 - acc: 0.2675 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6409 - acc: 0.2675 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6418 - acc: 0.2590 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6371 - acc: 0.2569 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6363 - acc: 0.2611 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6521 - acc: 0.2611 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6269 - acc: 0.2633 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6630 - acc: 0.2505 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6270 - acc: 0.2611 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6973 - acc: 0.2569 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6246 - acc: 0.2611 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.6587 - acc: 0.2590 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6637 - acc: 0.2548 - val_loss: 0.5106 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6509 - acc: 0.2505 - val_loss: 0.5104 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7203 - acc: 0.2611 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6208 - acc: 0.2590 - val_loss: 0.5092 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6390 - acc: 0.2675 - val_loss: 0.5088 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7042 - acc: 0.2633 - val_loss: 0.5084 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6195 - acc: 0.2654 - val_loss: 0.5081 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6124 - acc: 0.2654 - val_loss: 0.5078 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6486 - acc: 0.2696 - val_loss: 0.5073 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6614 - acc: 0.2696 - val_loss: 0.5074 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6156 - acc: 0.2611 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6447 - acc: 0.2548 - val_loss: 0.5062 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6542 - acc: 0.2569 - val_loss: 0.5040 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6155 - acc: 0.2696 - val_loss: 0.5027 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6772 - acc: 0.2463 - val_loss: 0.5013 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6367 - acc: 0.2527 - val_loss: 0.5019 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6368 - acc: 0.2569 - val_loss: 0.5032 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6662 - acc: 0.2590 - val_loss: 0.5040 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6122 - acc: 0.2654 - val_loss: 0.5042 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6252 - acc: 0.2654 - val_loss: 0.5040 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6195 - acc: 0.2611 - val_loss: 0.5036 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6114 - acc: 0.2611 - val_loss: 0.5031 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6224 - acc: 0.2569 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6242 - acc: 0.2675 - val_loss: 0.5020 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6177 - acc: 0.2569 - val_loss: 0.5016 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6446 - acc: 0.2654 - val_loss: 0.5032 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6280 - acc: 0.2548 - val_loss: 0.5051 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6259 - acc: 0.2675 - val_loss: 0.5061 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6190 - acc: 0.2569 - val_loss: 0.5058 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6212 - acc: 0.2633 - val_loss: 0.5049 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6506 - acc: 0.2633 - val_loss: 0.5042 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6491 - acc: 0.2739 - val_loss: 0.5036 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6201 - acc: 0.2654 - val_loss: 0.5031 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6184 - acc: 0.2611 - val_loss: 0.5026 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6025 - acc: 0.2675 - val_loss: 0.5017 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 185us/step\n",
      "Test score: 0.5017418278024551\n",
      "Look! elu selu softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu elu hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_273 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_968 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_698 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_969 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_699 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_970 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 28s 60ms/step - loss: 2.8372 - acc: 0.1826 - val_loss: 0.8501 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.3155 - acc: 0.1019 - val_loss: 0.8467 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.1851 - acc: 0.1040 - val_loss: 0.8446 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.4495 - acc: 0.0934 - val_loss: 0.8339 - val_acc: 0.0355\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.1314 - acc: 0.1083 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.0207 - acc: 0.1465 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.6623 - acc: 0.1592 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.9352 - acc: 0.1550 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.3906 - acc: 0.2017 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.7090 - acc: 0.2272 - val_loss: 2.0576 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.5284 - acc: 0.2442 - val_loss: 4.2296 - val_acc: 0.0355\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.2509 - acc: 0.2548 - val_loss: 5.4870 - val_acc: 0.0355\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3915 - acc: 0.2442 - val_loss: 5.4870 - val_acc: 0.3759\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.7541 - acc: 0.2887 - val_loss: 5.4870 - val_acc: 0.5887\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.6479 - acc: 0.3291 - val_loss: 5.4870 - val_acc: 0.5957\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.4389 - acc: 0.3142 - val_loss: 3.1435 - val_acc: 0.5957\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.7332 - acc: 0.3227 - val_loss: 2.2715 - val_acc: 0.6170\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.3746 - acc: 0.3439 - val_loss: 2.2706 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.2531 - acc: 0.3142 - val_loss: 2.2702 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.8236 - acc: 0.3057 - val_loss: 2.2697 - val_acc: 0.6099\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.7007 - acc: 0.3270 - val_loss: 2.2694 - val_acc: 0.3546\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.9190 - acc: 0.3015 - val_loss: 2.2692 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.7563 - acc: 0.3376 - val_loss: 2.2690 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.9101 - acc: 0.3036 - val_loss: 2.2689 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.9789 - acc: 0.3142 - val_loss: 2.2688 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.8758 - acc: 0.3631 - val_loss: 2.2686 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.8873 - acc: 0.3100 - val_loss: 2.2685 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.9168 - acc: 0.3270 - val_loss: 2.2685 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.0787 - acc: 0.3312 - val_loss: 2.2686 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.9991 - acc: 0.3100 - val_loss: 2.2686 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.8752 - acc: 0.2760 - val_loss: 2.2686 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 3.0185 - acc: 0.2951 - val_loss: 2.2689 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.8297 - acc: 0.2569 - val_loss: 2.2689 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.0098 - acc: 0.2675 - val_loss: 2.2689 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.2594 - acc: 0.2484 - val_loss: 2.2689 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.8264 - acc: 0.2845 - val_loss: 2.2690 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.9997 - acc: 0.2484 - val_loss: 2.2692 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.7282 - acc: 0.2548 - val_loss: 2.2692 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.7031 - acc: 0.2611 - val_loss: 2.2691 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.9577 - acc: 0.2590 - val_loss: 2.2690 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.2213 - acc: 0.2866 - val_loss: 2.2690 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.9017 - acc: 0.2675 - val_loss: 2.2689 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.1718 - acc: 0.2633 - val_loss: 2.2687 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.8129 - acc: 0.2696 - val_loss: 2.2686 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.9324 - acc: 0.2781 - val_loss: 2.2682 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.9131 - acc: 0.2548 - val_loss: 2.2677 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.1103 - acc: 0.2548 - val_loss: 2.2668 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.3185 - acc: 0.2527 - val_loss: 2.2648 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 3.4440 - acc: 0.2718 - val_loss: 2.5485 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.3057 - acc: 0.2505 - val_loss: 2.9948 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 199us/step - loss: 3.4251 - acc: 0.2675 - val_loss: 2.8697 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.6983 - acc: 0.2442 - val_loss: 2.8732 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.4561 - acc: 0.2442 - val_loss: 2.1765 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.9181 - acc: 0.2633 - val_loss: 2.2714 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.8583 - acc: 0.2675 - val_loss: 2.2699 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.6145 - acc: 0.2760 - val_loss: 2.2680 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.0147 - acc: 0.2972 - val_loss: 2.2622 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.8576 - acc: 0.2718 - val_loss: 2.2914 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.1873 - acc: 0.3079 - val_loss: 2.6302 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.5412 - acc: 0.3142 - val_loss: 2.6292 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.7994 - acc: 0.3142 - val_loss: 2.6292 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.3940 - acc: 0.2972 - val_loss: 2.6292 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.3124 - acc: 0.2972 - val_loss: 2.6292 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.8043 - acc: 0.3418 - val_loss: 2.6292 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.4027 - acc: 0.3461 - val_loss: 2.6292 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.0997 - acc: 0.3482 - val_loss: 3.4294 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.8682 - acc: 0.3928 - val_loss: 4.2296 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.1770 - acc: 0.3567 - val_loss: 4.3439 - val_acc: 0.5319\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.9623 - acc: 0.3715 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.4809 - acc: 0.4161 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.3982 - acc: 0.4289 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.8642 - acc: 0.4459 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 3.2815 - acc: 0.4607 - val_loss: 1.4143 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.8381 - acc: 0.4841 - val_loss: 1.1764 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.5663 - acc: 0.4628 - val_loss: 1.1755 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.1123 - acc: 0.5117 - val_loss: 1.1753 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.7281 - acc: 0.4735 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.6001 - acc: 0.4798 - val_loss: 1.1749 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.4069 - acc: 0.4777 - val_loss: 1.1748 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.1993 - acc: 0.4607 - val_loss: 1.1747 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 2.0377 - acc: 0.4713 - val_loss: 1.1746 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.0051 - acc: 0.4862 - val_loss: 1.1746 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.4525 - acc: 0.4947 - val_loss: 1.1746 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.2777 - acc: 0.5117 - val_loss: 1.1746 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.9573 - acc: 0.5074 - val_loss: 1.1746 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.3951 - acc: 0.5032 - val_loss: 1.1744 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.9060 - acc: 0.5032 - val_loss: 1.1743 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.1273 - acc: 0.5265 - val_loss: 1.1741 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.1314 - acc: 0.5265 - val_loss: 1.1742 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.1389 - acc: 0.5053 - val_loss: 1.1742 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.3702 - acc: 0.5096 - val_loss: 1.1742 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.4086 - acc: 0.4820 - val_loss: 1.1743 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.2450 - acc: 0.5138 - val_loss: 1.1742 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.4499 - acc: 0.5265 - val_loss: 1.1742 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.0530 - acc: 0.5032 - val_loss: 1.1740 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.2546 - acc: 0.5074 - val_loss: 1.1739 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.0038 - acc: 0.5011 - val_loss: 1.1737 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.3027 - acc: 0.5138 - val_loss: 1.1736 - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.2316 - acc: 0.5096 - val_loss: 1.1734 - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.3634 - acc: 0.5265 - val_loss: 1.1732 - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.0913 - acc: 0.4904 - val_loss: 1.1730 - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.9963 - acc: 0.4904 - val_loss: 1.1725 - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.1041 - acc: 0.5096 - val_loss: 1.1733 - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.2069 - acc: 0.4926 - val_loss: 1.1741 - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.1506 - acc: 0.5096 - val_loss: 1.1744 - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.0185 - acc: 0.5011 - val_loss: 1.1745 - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.3021 - acc: 0.5202 - val_loss: 1.1749 - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.4320 - acc: 0.5223 - val_loss: 1.1750 - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.2752 - acc: 0.5180 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.9647 - acc: 0.5032 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.2138 - acc: 0.5159 - val_loss: 1.1752 - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.2943 - acc: 0.5159 - val_loss: 1.1752 - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.2823 - acc: 0.5287 - val_loss: 1.1752 - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.1931 - acc: 0.5202 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.9490 - acc: 0.5138 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.9524 - acc: 0.5223 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.1010 - acc: 0.5138 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.1551 - acc: 0.5096 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.1518 - acc: 0.5159 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.9482 - acc: 0.5202 - val_loss: 1.1751 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 200us/step\n",
      "Test score: 1.175110194699984\n",
      "Look! elu selu softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu selu softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_274 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_971 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_700 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_972 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_701 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_973 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 61ms/step - loss: nan - acc: 0.4650 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 242us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 201us/step\n",
      "Test score: nan\n",
      "Look! elu selu relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu selu relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_275 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_974 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_702 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_975 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_703 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_976 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 28s 60ms/step - loss: nan - acc: 0.5414 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 181us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 204us/step\n",
      "Test score: nan\n",
      "Look! elu selu tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu selu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_276 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_977 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_704 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_978 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_705 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_979 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 61ms/step - loss: nan - acc: 0.3928 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 224us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 178us/step\n",
      "Test score: nan\n",
      "Look! elu selu sigmoid Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu selu sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_277 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_980 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_706 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_981 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_707 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_982 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 61ms/step - loss: nan - acc: 0.3333 - val_loss: 1.2829 - val_acc: 0.3688\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.4183 - val_loss: 1.0050 - val_acc: 0.5887\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.4395 - val_loss: 1.0066 - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.4756 - val_loss: 1.0070 - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.4204 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.4607 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.4416 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.4565 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.4735 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.4841 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.5788 - acc: 0.5074 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.4544 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.4671 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.6727 - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.6453 - acc: 0.4374 - val_loss: 1.0005 - val_acc: 0.4965\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.4140 - val_loss: 1.1737 - val_acc: 0.3617\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.3673 - val_loss: 1.2638 - val_acc: 0.3050\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.3928 - val_loss: 1.4333 - val_acc: 0.2695\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.3885 - val_loss: 1.5310 - val_acc: 0.2199\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.4034 - val_loss: 1.6280 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.3715 - val_loss: 1.7241 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.3567 - val_loss: 1.7236 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 237us/step - loss: nan - acc: 0.3800 - val_loss: 1.7243 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.3800 - val_loss: 1.7238 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.3694 - val_loss: 1.6311 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.3694 - val_loss: 1.6279 - val_acc: 0.2199\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.3885 - val_loss: 1.6282 - val_acc: 0.2199\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.3992 - val_loss: 1.4403 - val_acc: 0.2199\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.9287 - acc: 0.3482 - val_loss: 1.2832 - val_acc: 0.3262\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.4034 - val_loss: 0.9892 - val_acc: 0.4894\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: nan - acc: 0.3928 - val_loss: 1.0001 - val_acc: 0.5816\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.8102 - acc: 0.3822 - val_loss: 0.9959 - val_acc: 0.5745\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.8253 - acc: 0.3524 - val_loss: 0.9882 - val_acc: 0.4752\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.7405 - acc: 0.3992 - val_loss: 1.2576 - val_acc: 0.3121\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.7484 - acc: 0.3907 - val_loss: 1.5355 - val_acc: 0.2199\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.3631 - val_loss: 1.6303 - val_acc: 0.2199\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.8243 - acc: 0.3715 - val_loss: 1.6333 - val_acc: 0.2199\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.7652 - acc: 0.3694 - val_loss: 1.6317 - val_acc: 0.2199\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.8323 - acc: 0.3843 - val_loss: 1.4372 - val_acc: 0.2411\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.9936 - acc: 0.3737 - val_loss: 1.4352 - val_acc: 0.2411\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.7059 - acc: 0.4055 - val_loss: 1.4351 - val_acc: 0.2482\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.7733 - acc: 0.3524 - val_loss: 1.6313 - val_acc: 0.2199\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.7963 - acc: 0.3482 - val_loss: 1.7226 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.7622 - acc: 0.3609 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.8145 - acc: 0.3588 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.7594 - acc: 0.3694 - val_loss: 1.7239 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 1.9587 - acc: 0.3439 - val_loss: 1.4385 - val_acc: 0.2411\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.6669 - acc: 0.3631 - val_loss: 1.2522 - val_acc: 0.3121\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.4204 - val_loss: 1.2540 - val_acc: 0.3121\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.7507 - acc: 0.3928 - val_loss: 1.0019 - val_acc: 0.5532\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.6273 - acc: 0.4055 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.5837 - acc: 0.4310 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.5510 - acc: 0.4628 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.3710 - acc: 0.4735 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.4027 - acc: 0.4947 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.4086 - acc: 0.4947 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.2537 - acc: 0.4628 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.3623 - acc: 0.4437 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2974 - acc: 0.4883 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.3627 - acc: 0.4692 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.3588 - acc: 0.5032 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.4490 - acc: 0.4989 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.3070 - acc: 0.4904 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.2942 - acc: 0.5138 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.2350 - acc: 0.5329 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.2389 - acc: 0.5074 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.3051 - acc: 0.5053 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.2390 - acc: 0.5117 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.2754 - acc: 0.5032 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.3310 - acc: 0.5265 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.2748 - acc: 0.5138 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.3941 - acc: 0.5117 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.2334 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.2730 - acc: 0.4862 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.2961 - acc: 0.5244 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.3907 - acc: 0.5117 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.2957 - acc: 0.5053 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.2955 - acc: 0.5032 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.2452 - acc: 0.4883 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.2956 - acc: 0.4989 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.2629 - acc: 0.5180 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.2555 - acc: 0.5223 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.2922 - acc: 0.5096 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.2944 - acc: 0.5032 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.5163 - acc: 0.4841 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.2956 - acc: 0.4968 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.4149 - acc: 0.4968 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.3481 - acc: 0.4713 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.3817 - acc: 0.4841 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.3687 - acc: 0.4628 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.5933 - acc: 0.4586 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.4255 - acc: 0.4416 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.5605 - acc: 0.4310 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.4878 - acc: 0.4713 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.3285 - acc: 0.4628 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.6170 - acc: 0.4480 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.6044 - acc: 0.4501 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.5130 - acc: 0.4268 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.5865 - acc: 0.4119 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.6725 - acc: 0.4225 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.4684 - acc: 0.4289 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.5247 - acc: 0.4395 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.6089 - acc: 0.4268 - val_loss: 1.0050 - val_acc: 0.5957\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.6479 - acc: 0.3928 - val_loss: 0.9836 - val_acc: 0.5106\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.7186 - acc: 0.4076 - val_loss: 1.6361 - val_acc: 0.2199\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.9459 - acc: 0.3822 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.8075 - acc: 0.3376 - val_loss: 1.7221 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.7849 - acc: 0.3694 - val_loss: 1.0701 - val_acc: 0.4539\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.7413 - acc: 0.3949 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.7381 - acc: 0.4437 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.4680 - acc: 0.4225 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.7242 - acc: 0.3949 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.6325 - acc: 0.3949 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.6552 - acc: 0.3992 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.4715 - acc: 0.4246 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.5752 - acc: 0.4501 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.4023 - acc: 0.4735 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.3822 - acc: 0.4798 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 193us/step\n",
      "Test score: 1.0078918815504574\n",
      "Look! elu selu hard_sigmoid Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu selu hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_278 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_983 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_708 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_984 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_709 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_985 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 61ms/step - loss: 3.1245 - acc: 0.2569 - val_loss: 0.5934 - val_acc: 0.0851\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.2066 - acc: 0.1996 - val_loss: 0.7687 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.3871 - acc: 0.2123 - val_loss: 0.9320 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.0280 - acc: 0.1911 - val_loss: 0.8824 - val_acc: 0.0355\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.2227 - acc: 0.1932 - val_loss: 0.7901 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.0712 - acc: 0.1592 - val_loss: 0.8105 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.2649 - acc: 0.1762 - val_loss: 0.9362 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.3234 - acc: 0.1423 - val_loss: 0.9292 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.0431 - acc: 0.1316 - val_loss: 0.9170 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.2945 - acc: 0.1401 - val_loss: 0.9104 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.0346 - acc: 0.1338 - val_loss: 0.9003 - val_acc: 0.0355\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.0538 - acc: 0.1083 - val_loss: 0.8925 - val_acc: 0.0355\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.1823 - acc: 0.0786 - val_loss: 0.8829 - val_acc: 0.0355\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.3232 - acc: 0.0616 - val_loss: 0.8710 - val_acc: 0.0355\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.1502 - acc: 0.0701 - val_loss: 0.8513 - val_acc: 0.0355\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.0988 - acc: 0.0488 - val_loss: 0.8183 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.1629 - acc: 0.0488 - val_loss: 0.7696 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.1496 - acc: 0.0467 - val_loss: 0.7109 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.3790 - acc: 0.0425 - val_loss: 0.6688 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.4251 - acc: 0.0425 - val_loss: 0.6172 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.8074 - acc: 0.0425 - val_loss: 0.5724 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.4191 - acc: 0.0425 - val_loss: 0.5716 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.1174 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.4471 - acc: 0.0425 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 5.0544 - acc: 0.0425 - val_loss: 3.4519 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 4.6027 - acc: 0.0425 - val_loss: 3.2175 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.4703 - acc: 0.0446 - val_loss: 3.1648 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.8445 - acc: 0.0446 - val_loss: 1.4198 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.2903 - acc: 0.0743 - val_loss: 1.3340 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.9043 - acc: 0.0934 - val_loss: 1.2926 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.8504 - acc: 0.1316 - val_loss: 1.2632 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.7228 - acc: 0.1720 - val_loss: 1.2410 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.6846 - acc: 0.1762 - val_loss: 1.2188 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.6106 - acc: 0.2059 - val_loss: 1.1937 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.6094 - acc: 0.2399 - val_loss: 1.1683 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.6827 - acc: 0.2293 - val_loss: 1.1454 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.6652 - acc: 0.2357 - val_loss: 1.1221 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.5471 - acc: 0.2357 - val_loss: 1.0932 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.7266 - acc: 0.2335 - val_loss: 1.0578 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.7793 - acc: 0.2357 - val_loss: 1.0528 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.7002 - acc: 0.2335 - val_loss: 1.0373 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.8398 - acc: 0.2399 - val_loss: 1.0165 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.2371 - acc: 0.2357 - val_loss: 1.0044 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.2947 - acc: 0.2357 - val_loss: 0.9893 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.6494 - acc: 0.2229 - val_loss: 0.9706 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.1971 - acc: 0.2314 - val_loss: 0.9521 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.7891 - acc: 0.2166 - val_loss: 0.9363 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.9334 - acc: 0.2187 - val_loss: 0.9227 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.9381 - acc: 0.2144 - val_loss: 0.9170 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.6136 - acc: 0.2187 - val_loss: 0.9146 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.7061 - acc: 0.2144 - val_loss: 0.9145 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.1633 - acc: 0.2399 - val_loss: 0.9145 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.8989 - acc: 0.2123 - val_loss: 0.9145 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.8074 - acc: 0.2059 - val_loss: 0.9145 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 4.5417 - acc: 0.2081 - val_loss: 0.9145 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 5.2035 - acc: 0.2314 - val_loss: 0.9145 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.6168 - acc: 0.2314 - val_loss: 0.9145 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 4.8820 - acc: 0.2357 - val_loss: 3.0864 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 5.0285 - acc: 0.2208 - val_loss: 5.9443 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 5.1051 - acc: 0.2335 - val_loss: 6.0586 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 5.2584 - acc: 0.2272 - val_loss: 5.5713 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 5.7566 - acc: 0.2357 - val_loss: 5.5381 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 5.7514 - acc: 0.2144 - val_loss: 5.5293 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 5.8678 - acc: 0.2378 - val_loss: 5.5257 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 5.9821 - acc: 0.2357 - val_loss: 5.5245 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 6.3473 - acc: 0.2314 - val_loss: 5.5233 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 6.3121 - acc: 0.2357 - val_loss: 5.5232 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 6.4246 - acc: 0.2208 - val_loss: 5.5227 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 6.4647 - acc: 0.2038 - val_loss: 5.5235 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 5.5920 - acc: 0.2251 - val_loss: 5.5254 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 6.2580 - acc: 0.2017 - val_loss: 5.5270 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 5.8657 - acc: 0.2038 - val_loss: 5.5267 - val_acc: 0.1348\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 5.5768 - acc: 0.1996 - val_loss: 5.5277 - val_acc: 0.1277\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.8625 - acc: 0.1762 - val_loss: 5.5346 - val_acc: 0.1277\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3141 - acc: 0.1592 - val_loss: 2.8583 - val_acc: 0.1277\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.6529 - acc: 0.1677 - val_loss: 2.5729 - val_acc: 0.1277\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.6104 - acc: 0.1465 - val_loss: 2.4879 - val_acc: 0.1277\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.2897 - acc: 0.1529 - val_loss: 0.8679 - val_acc: 0.1277\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.6281 - acc: 0.1529 - val_loss: 0.7219 - val_acc: 0.1277\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.3094 - acc: 0.1571 - val_loss: 0.6572 - val_acc: 0.1277\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.9457 - acc: 0.1635 - val_loss: 0.6196 - val_acc: 0.1277\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.9167 - acc: 0.1529 - val_loss: 0.5975 - val_acc: 0.1277\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8979 - acc: 0.1592 - val_loss: 0.5829 - val_acc: 0.1277\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7905 - acc: 0.1847 - val_loss: 0.5729 - val_acc: 0.1277\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7485 - acc: 0.1741 - val_loss: 0.5649 - val_acc: 0.0284\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7904 - acc: 0.1890 - val_loss: 0.5585 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7786 - acc: 0.1911 - val_loss: 0.5528 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7140 - acc: 0.2017 - val_loss: 0.5480 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7311 - acc: 0.1953 - val_loss: 0.5445 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7521 - acc: 0.2038 - val_loss: 0.5413 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7312 - acc: 0.2144 - val_loss: 0.5384 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6968 - acc: 0.2399 - val_loss: 0.5375 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7451 - acc: 0.1847 - val_loss: 0.5374 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6958 - acc: 0.2420 - val_loss: 0.5370 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6466 - acc: 0.2123 - val_loss: 0.5361 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7761 - acc: 0.2166 - val_loss: 0.5353 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7315 - acc: 0.2442 - val_loss: 0.5346 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.8334 - acc: 0.2909 - val_loss: 0.5336 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7149 - acc: 0.2442 - val_loss: 0.5323 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7004 - acc: 0.2696 - val_loss: 0.5309 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6755 - acc: 0.2123 - val_loss: 0.5298 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7583 - acc: 0.2527 - val_loss: 0.5286 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7222 - acc: 0.2420 - val_loss: 0.5274 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6989 - acc: 0.2781 - val_loss: 0.5265 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7375 - acc: 0.2739 - val_loss: 0.5259 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7163 - acc: 0.2144 - val_loss: 0.5255 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7186 - acc: 0.2654 - val_loss: 0.5248 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6634 - acc: 0.2420 - val_loss: 0.5239 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7020 - acc: 0.2463 - val_loss: 0.5231 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6958 - acc: 0.2442 - val_loss: 0.5225 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7279 - acc: 0.2378 - val_loss: 0.5221 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7130 - acc: 0.2569 - val_loss: 0.5218 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6637 - acc: 0.2569 - val_loss: 0.5217 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7285 - acc: 0.2187 - val_loss: 0.5217 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6840 - acc: 0.2590 - val_loss: 0.5216 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6662 - acc: 0.2527 - val_loss: 0.5213 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6824 - acc: 0.2314 - val_loss: 0.5221 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6720 - acc: 0.2484 - val_loss: 0.5235 - val_acc: 0.0922\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7112 - acc: 0.3206 - val_loss: 0.5243 - val_acc: 0.5532\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7138 - acc: 0.2994 - val_loss: 0.5243 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 195us/step\n",
      "Test score: 0.5243004645016176\n",
      "Look! elu selu linear Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_279 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_986 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_710 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_987 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_711 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_988 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 62ms/step - loss: 6.6378 - acc: 0.1274 - val_loss: 2.5689 - val_acc: 0.0851\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 5.1362 - acc: 0.2335 - val_loss: 3.3846 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.6978 - acc: 0.2166 - val_loss: 3.5241 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3055 - acc: 0.2696 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.6297 - acc: 0.2357 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.2564 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 4.1035 - acc: 0.2739 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 8/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 209us/step - loss: 4.4689 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3385 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.2738 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3699 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3802 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.3859 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.4214 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3321 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3564 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.4628 - acc: 0.2420 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.6241 - acc: 0.2357 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 4.4409 - acc: 0.2420 - val_loss: 3.5397 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3934 - acc: 0.2590 - val_loss: 3.5340 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.3877 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.3795 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.4699 - acc: 0.2463 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.6083 - acc: 0.2420 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3980 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.5577 - acc: 0.2463 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.6082 - acc: 0.2378 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.1119 - acc: 0.2696 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.4889 - acc: 0.2463 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.3644 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 4.4830 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.3215 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 4.2211 - acc: 0.2675 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.2776 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.4463 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.3201 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 4.4288 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.4997 - acc: 0.2463 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 4.3817 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 4.3897 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3499 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 4.4150 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.3250 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 4.3598 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 4.3559 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 4.4437 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3763 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.3344 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3270 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.4056 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.3822 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3656 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.3738 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3290 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3870 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.4235 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3022 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3802 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.3869 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 4.3897 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3693 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3647 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3586 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.3655 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.4483 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.3461 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 4.4487 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 4.4205 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3849 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.2776 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.3807 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3803 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3441 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.4012 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3495 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 4.3144 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3456 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3140 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3803 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3613 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3461 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.4080 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3810 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 4.3667 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3621 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.3383 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3361 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3805 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 4.4691 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.4116 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.4575 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.3634 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.3725 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.4145 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 4.4375 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.2162 - acc: 0.2675 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 200us/step\n",
      "Test score: 3.543694685536919\n",
      "Look! elu softplus softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_280 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_989 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_712 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_990 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_713 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_991 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 61ms/step - loss: 3.1790 - acc: 0.1953 - val_loss: 1.3641 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.1985 - acc: 0.2059 - val_loss: 1.7030 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.8003 - acc: 0.2081 - val_loss: 1.7027 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.5650 - acc: 0.2229 - val_loss: 1.5418 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.3994 - acc: 0.2144 - val_loss: 0.8322 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.6428 - acc: 0.2357 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.1435 - acc: 0.2548 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.0714 - acc: 0.2378 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.9802 - acc: 0.2229 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8809 - acc: 0.2505 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.0482 - acc: 0.2590 - val_loss: 0.5332 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.9125 - acc: 0.2442 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.9157 - acc: 0.2484 - val_loss: 0.5321 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8037 - acc: 0.2187 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7373 - acc: 0.2505 - val_loss: 0.5285 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6650 - acc: 0.2399 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7323 - acc: 0.2718 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7589 - acc: 0.2718 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7263 - acc: 0.2590 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7232 - acc: 0.2739 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7228 - acc: 0.2527 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6943 - acc: 0.2505 - val_loss: 0.5241 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7566 - acc: 0.2675 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7510 - acc: 0.2293 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6563 - acc: 0.2590 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6424 - acc: 0.2548 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7157 - acc: 0.2611 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7376 - acc: 0.2569 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.8032 - acc: 0.2654 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6605 - acc: 0.2590 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7431 - acc: 0.2442 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6757 - acc: 0.2463 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7223 - acc: 0.2229 - val_loss: 0.5263 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7082 - acc: 0.2675 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6545 - acc: 0.2527 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 0.7291 - acc: 0.2654 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6876 - acc: 0.2527 - val_loss: 0.5254 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7010 - acc: 0.2399 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6914 - acc: 0.2420 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6491 - acc: 0.2548 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6461 - acc: 0.2527 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6937 - acc: 0.2548 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6550 - acc: 0.2527 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7157 - acc: 0.2484 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6848 - acc: 0.2548 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7062 - acc: 0.2463 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6664 - acc: 0.2548 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6423 - acc: 0.2484 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7286 - acc: 0.2484 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6527 - acc: 0.2399 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6374 - acc: 0.2527 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6418 - acc: 0.2527 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6443 - acc: 0.2590 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6684 - acc: 0.2633 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6462 - acc: 0.2590 - val_loss: 0.5168 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7533 - acc: 0.2569 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6730 - acc: 0.2654 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7072 - acc: 0.2590 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6993 - acc: 0.2590 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6290 - acc: 0.2696 - val_loss: 0.5157 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6636 - acc: 0.2505 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6420 - acc: 0.2569 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6453 - acc: 0.2633 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6585 - acc: 0.2527 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6711 - acc: 0.2654 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6279 - acc: 0.2611 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6386 - acc: 0.2590 - val_loss: 0.5087 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6433 - acc: 0.2548 - val_loss: 0.5081 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6633 - acc: 0.2463 - val_loss: 0.5076 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6683 - acc: 0.2611 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6617 - acc: 0.2611 - val_loss: 0.5082 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6613 - acc: 0.2633 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6880 - acc: 0.2654 - val_loss: 0.5077 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6943 - acc: 0.2505 - val_loss: 0.5072 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6271 - acc: 0.2633 - val_loss: 0.5066 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6716 - acc: 0.2633 - val_loss: 0.5063 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6609 - acc: 0.2590 - val_loss: 0.5062 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6683 - acc: 0.2654 - val_loss: 0.5060 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6531 - acc: 0.2633 - val_loss: 0.5056 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6292 - acc: 0.2548 - val_loss: 0.5051 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6207 - acc: 0.2654 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6544 - acc: 0.2696 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6305 - acc: 0.2611 - val_loss: 0.5038 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6473 - acc: 0.2675 - val_loss: 0.5061 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6273 - acc: 0.2569 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6348 - acc: 0.2654 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6378 - acc: 0.2569 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6240 - acc: 0.2633 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6220 - acc: 0.2590 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6158 - acc: 0.2569 - val_loss: 0.5096 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6224 - acc: 0.2696 - val_loss: 0.5081 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6326 - acc: 0.2611 - val_loss: 0.5071 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6215 - acc: 0.2696 - val_loss: 0.5060 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6301 - acc: 0.2654 - val_loss: 0.5048 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6231 - acc: 0.2611 - val_loss: 0.5039 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6590 - acc: 0.2590 - val_loss: 0.5031 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6478 - acc: 0.2654 - val_loss: 0.5023 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6190 - acc: 0.2718 - val_loss: 0.5012 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6245 - acc: 0.2569 - val_loss: 0.5004 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6146 - acc: 0.2696 - val_loss: 0.4997 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6178 - acc: 0.2718 - val_loss: 0.5002 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6520 - acc: 0.2527 - val_loss: 0.5002 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6554 - acc: 0.2633 - val_loss: 0.5034 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6161 - acc: 0.2696 - val_loss: 0.5052 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6044 - acc: 0.2739 - val_loss: 0.5055 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6861 - acc: 0.2633 - val_loss: 0.5045 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6238 - acc: 0.2611 - val_loss: 0.5030 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6704 - acc: 0.2569 - val_loss: 0.5010 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6636 - acc: 0.2675 - val_loss: 0.4993 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6271 - acc: 0.2590 - val_loss: 0.4988 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6271 - acc: 0.2633 - val_loss: 0.4992 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6443 - acc: 0.2590 - val_loss: 0.4992 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6360 - acc: 0.2548 - val_loss: 0.4990 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6053 - acc: 0.2739 - val_loss: 0.4986 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6399 - acc: 0.2611 - val_loss: 0.4974 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6450 - acc: 0.2739 - val_loss: 0.4965 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6190 - acc: 0.2590 - val_loss: 0.4951 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6084 - acc: 0.2569 - val_loss: 0.4940 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6209 - acc: 0.2569 - val_loss: 0.4933 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.5941 - acc: 0.2739 - val_loss: 0.4930 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 189us/step\n",
      "Test score: 0.49302145352600313\n",
      "Look! elu softplus elu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_281 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_992 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_714 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_993 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_715 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_994 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 61ms/step - loss: 3.6295 - acc: 0.2123 - val_loss: 1.3005 - val_acc: 0.1489\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.5428 - acc: 0.1847 - val_loss: 1.2768 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.0903 - acc: 0.2314 - val_loss: 1.2706 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.1267 - acc: 0.2187 - val_loss: 1.2599 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.5998 - acc: 0.2463 - val_loss: 1.2551 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.8201 - acc: 0.2314 - val_loss: 1.2611 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.6982 - acc: 0.2463 - val_loss: 0.7770 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.4823 - acc: 0.2229 - val_loss: 0.5437 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.4323 - acc: 0.2357 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.1387 - acc: 0.2229 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.0169 - acc: 0.2442 - val_loss: 0.5300 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.9879 - acc: 0.2272 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.1121 - acc: 0.2781 - val_loss: 0.5343 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.0465 - acc: 0.2590 - val_loss: 0.5364 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.9142 - acc: 0.2845 - val_loss: 0.5372 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7834 - acc: 0.2803 - val_loss: 0.5413 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.9471 - acc: 0.2420 - val_loss: 0.5369 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8684 - acc: 0.2803 - val_loss: 0.5333 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.8313 - acc: 0.2654 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7683 - acc: 0.2357 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.8467 - acc: 0.2420 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6811 - acc: 0.2442 - val_loss: 0.5294 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7957 - acc: 0.2611 - val_loss: 0.5333 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7532 - acc: 0.2251 - val_loss: 0.5374 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7086 - acc: 0.2590 - val_loss: 0.5404 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6739 - acc: 0.2399 - val_loss: 0.5417 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6731 - acc: 0.2378 - val_loss: 0.5411 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6809 - acc: 0.2760 - val_loss: 0.5394 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6861 - acc: 0.2611 - val_loss: 0.5370 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7245 - acc: 0.2654 - val_loss: 0.5346 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7223 - acc: 0.2803 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6679 - acc: 0.2675 - val_loss: 0.5308 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7163 - acc: 0.2760 - val_loss: 0.5294 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7386 - acc: 0.2548 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7456 - acc: 0.2569 - val_loss: 0.5292 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6848 - acc: 0.2548 - val_loss: 0.5281 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7564 - acc: 0.2633 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6910 - acc: 0.2611 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6662 - acc: 0.2590 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7094 - acc: 0.2590 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6821 - acc: 0.2611 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6503 - acc: 0.2527 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7138 - acc: 0.2548 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7379 - acc: 0.2463 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6843 - acc: 0.2590 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7180 - acc: 0.2718 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6991 - acc: 0.2527 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7252 - acc: 0.2633 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6569 - acc: 0.2569 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 0.6713 - acc: 0.2611 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 215us/step - loss: 0.7155 - acc: 0.2590 - val_loss: 0.5169 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6739 - acc: 0.2590 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7373 - acc: 0.2527 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6841 - acc: 0.2569 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6442 - acc: 0.2611 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7355 - acc: 0.2611 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6845 - acc: 0.2590 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6557 - acc: 0.2654 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6651 - acc: 0.2675 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6601 - acc: 0.2569 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6475 - acc: 0.2569 - val_loss: 0.5183 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6405 - acc: 0.2569 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6506 - acc: 0.2527 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6526 - acc: 0.2633 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6322 - acc: 0.2611 - val_loss: 0.5162 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6957 - acc: 0.2633 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6637 - acc: 0.2505 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6996 - acc: 0.2590 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6360 - acc: 0.2548 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7161 - acc: 0.2527 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6300 - acc: 0.2633 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6740 - acc: 0.2611 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6281 - acc: 0.2548 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6276 - acc: 0.2548 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6319 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6995 - acc: 0.2611 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6411 - acc: 0.2590 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6934 - acc: 0.2569 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6390 - acc: 0.2611 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6777 - acc: 0.2569 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6431 - acc: 0.2505 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7333 - acc: 0.2611 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6385 - acc: 0.2505 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6397 - acc: 0.2548 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6354 - acc: 0.2611 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6538 - acc: 0.2590 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6610 - acc: 0.2548 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6515 - acc: 0.2590 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6956 - acc: 0.2569 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6400 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6296 - acc: 0.2527 - val_loss: 0.5106 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6675 - acc: 0.2548 - val_loss: 0.5101 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6404 - acc: 0.2590 - val_loss: 0.5097 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6296 - acc: 0.2569 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6352 - acc: 0.2696 - val_loss: 0.5091 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6321 - acc: 0.2569 - val_loss: 0.5090 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6280 - acc: 0.2590 - val_loss: 0.5088 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6251 - acc: 0.2633 - val_loss: 0.5084 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6228 - acc: 0.2633 - val_loss: 0.5081 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6202 - acc: 0.2590 - val_loss: 0.5082 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6262 - acc: 0.2590 - val_loss: 0.5087 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6169 - acc: 0.2611 - val_loss: 0.5089 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6574 - acc: 0.2569 - val_loss: 0.5090 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6222 - acc: 0.2654 - val_loss: 0.5092 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6371 - acc: 0.2611 - val_loss: 0.5091 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6625 - acc: 0.2569 - val_loss: 0.5086 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6156 - acc: 0.2611 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6253 - acc: 0.2611 - val_loss: 0.5066 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6382 - acc: 0.2569 - val_loss: 0.5066 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6518 - acc: 0.2675 - val_loss: 0.5069 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6155 - acc: 0.2590 - val_loss: 0.5069 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6786 - acc: 0.2590 - val_loss: 0.5067 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6235 - acc: 0.2590 - val_loss: 0.5064 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6779 - acc: 0.2590 - val_loss: 0.5058 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6216 - acc: 0.2569 - val_loss: 0.5051 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6275 - acc: 0.2633 - val_loss: 0.5045 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6253 - acc: 0.2590 - val_loss: 0.5040 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6339 - acc: 0.2611 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6197 - acc: 0.2654 - val_loss: 0.5046 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6476 - acc: 0.2590 - val_loss: 0.5049 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 205us/step\n",
      "Test score: 0.5048664436272695\n",
      "Look! elu softplus selu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_282 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_995 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_716 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_996 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_717 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_997 (Dense)            (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 62ms/step - loss: 2.5174 - acc: 0.3248 - val_loss: 0.9551 - val_acc: 0.2270\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.4730 - acc: 0.2505 - val_loss: 0.8863 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.1527 - acc: 0.2505 - val_loss: 0.5483 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8898 - acc: 0.2505 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7878 - acc: 0.2463 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7585 - acc: 0.2633 - val_loss: 0.5335 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7879 - acc: 0.2484 - val_loss: 0.5344 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7348 - acc: 0.2335 - val_loss: 0.5328 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7106 - acc: 0.2654 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7622 - acc: 0.2633 - val_loss: 0.5320 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7087 - acc: 0.2463 - val_loss: 0.5350 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7275 - acc: 0.2548 - val_loss: 0.5374 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7102 - acc: 0.2527 - val_loss: 0.5392 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6848 - acc: 0.2824 - val_loss: 0.5395 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7113 - acc: 0.2611 - val_loss: 0.5389 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6942 - acc: 0.2463 - val_loss: 0.5382 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6644 - acc: 0.2760 - val_loss: 0.5368 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6672 - acc: 0.2739 - val_loss: 0.5349 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6999 - acc: 0.2357 - val_loss: 0.5328 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6750 - acc: 0.2718 - val_loss: 0.5321 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7159 - acc: 0.2378 - val_loss: 0.5323 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7079 - acc: 0.2527 - val_loss: 0.5331 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7106 - acc: 0.2484 - val_loss: 0.5340 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6704 - acc: 0.2505 - val_loss: 0.5340 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6749 - acc: 0.2484 - val_loss: 0.5336 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6609 - acc: 0.2611 - val_loss: 0.5330 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6766 - acc: 0.2484 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6553 - acc: 0.2569 - val_loss: 0.5305 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6707 - acc: 0.2442 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7153 - acc: 0.2569 - val_loss: 0.5293 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7352 - acc: 0.2399 - val_loss: 0.5297 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6806 - acc: 0.2548 - val_loss: 0.5321 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7045 - acc: 0.2611 - val_loss: 0.5344 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7165 - acc: 0.2548 - val_loss: 0.5353 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6489 - acc: 0.2590 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6673 - acc: 0.2442 - val_loss: 0.5350 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6548 - acc: 0.2781 - val_loss: 0.5340 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7025 - acc: 0.2505 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6689 - acc: 0.2505 - val_loss: 0.5310 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7072 - acc: 0.2611 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 41/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 207us/step - loss: 0.6578 - acc: 0.2399 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6530 - acc: 0.2696 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6561 - acc: 0.2442 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6726 - acc: 0.2484 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6916 - acc: 0.2378 - val_loss: 0.5255 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6685 - acc: 0.2569 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6512 - acc: 0.2548 - val_loss: 0.5241 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6380 - acc: 0.2569 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6488 - acc: 0.2527 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6761 - acc: 0.2505 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6449 - acc: 0.2633 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6718 - acc: 0.2633 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6518 - acc: 0.2569 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6439 - acc: 0.2654 - val_loss: 0.5233 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6571 - acc: 0.2569 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6734 - acc: 0.2548 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6457 - acc: 0.2569 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7177 - acc: 0.2675 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6479 - acc: 0.2484 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6538 - acc: 0.2611 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6426 - acc: 0.2675 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6398 - acc: 0.2654 - val_loss: 0.5198 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6388 - acc: 0.2675 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6484 - acc: 0.2611 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7255 - acc: 0.2675 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6870 - acc: 0.2611 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6894 - acc: 0.2548 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6306 - acc: 0.2654 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6539 - acc: 0.2654 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6458 - acc: 0.2548 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6634 - acc: 0.2611 - val_loss: 0.5157 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6335 - acc: 0.2569 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6280 - acc: 0.2718 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6415 - acc: 0.2569 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6517 - acc: 0.2548 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6694 - acc: 0.2484 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6725 - acc: 0.2590 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6534 - acc: 0.2569 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6384 - acc: 0.2633 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6520 - acc: 0.2633 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6411 - acc: 0.2590 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6782 - acc: 0.2569 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6482 - acc: 0.2548 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6637 - acc: 0.2548 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6374 - acc: 0.2569 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6378 - acc: 0.2611 - val_loss: 0.5165 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6337 - acc: 0.2633 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6385 - acc: 0.2569 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6682 - acc: 0.2611 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6334 - acc: 0.2633 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6476 - acc: 0.2548 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6580 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6418 - acc: 0.2569 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6454 - acc: 0.2569 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6343 - acc: 0.2590 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6491 - acc: 0.2611 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6500 - acc: 0.2548 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6325 - acc: 0.2675 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6593 - acc: 0.2590 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6633 - acc: 0.2569 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6384 - acc: 0.2633 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6392 - acc: 0.2590 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6307 - acc: 0.2611 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6384 - acc: 0.2590 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6269 - acc: 0.2590 - val_loss: 0.5107 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6389 - acc: 0.2633 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6321 - acc: 0.2590 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6465 - acc: 0.2654 - val_loss: 0.5091 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6156 - acc: 0.2590 - val_loss: 0.5088 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6360 - acc: 0.2654 - val_loss: 0.5086 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6269 - acc: 0.2654 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6333 - acc: 0.2590 - val_loss: 0.5080 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6736 - acc: 0.2611 - val_loss: 0.5079 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6222 - acc: 0.2590 - val_loss: 0.5077 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6293 - acc: 0.2590 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6361 - acc: 0.2611 - val_loss: 0.5073 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6631 - acc: 0.2611 - val_loss: 0.5070 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5068 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6422 - acc: 0.2611 - val_loss: 0.5078 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 200us/step\n",
      "Test score: 0.5078437167701991\n",
      "Look! elu softplus softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu selu linear\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_283 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_998 (Dense)            (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_718 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_999 (Dense)            (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_719 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1000 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 62ms/step - loss: 2.6306 - acc: 0.2081 - val_loss: 3.3861 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.2165 - acc: 0.1507 - val_loss: 3.7389 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.3469 - acc: 0.1253 - val_loss: 3.2876 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.1732 - acc: 0.1104 - val_loss: 3.0067 - val_acc: 0.0355\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 2.8241 - acc: 0.1146 - val_loss: 2.4070 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.9688 - acc: 0.1316 - val_loss: 3.2922 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 3.1555 - acc: 0.1571 - val_loss: 3.5899 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.5105 - acc: 0.1656 - val_loss: 3.5875 - val_acc: 0.0426\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.0755 - acc: 0.1444 - val_loss: 3.5861 - val_acc: 0.0426\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.7571 - acc: 0.1231 - val_loss: 3.5862 - val_acc: 0.0638\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 3.1963 - acc: 0.1380 - val_loss: 2.8225 - val_acc: 0.1064\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.7608 - acc: 0.1444 - val_loss: 0.6044 - val_acc: 0.1277\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.4570 - acc: 0.1720 - val_loss: 0.6006 - val_acc: 0.1277\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.5151 - acc: 0.1529 - val_loss: 0.5992 - val_acc: 0.1277\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.7679 - acc: 0.1571 - val_loss: 0.5981 - val_acc: 0.1277\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.5553 - acc: 0.1932 - val_loss: 0.5970 - val_acc: 0.1277\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.0407 - acc: 0.1592 - val_loss: 0.6070 - val_acc: 0.1277\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.8215 - acc: 0.2059 - val_loss: 0.6932 - val_acc: 0.1277\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.0676 - acc: 0.1932 - val_loss: 1.1873 - val_acc: 0.1277\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.1058 - acc: 0.1847 - val_loss: 1.1676 - val_acc: 0.1277\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.1082 - acc: 0.1890 - val_loss: 1.2407 - val_acc: 0.1277\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.8724 - acc: 0.1529 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.3799 - acc: 0.1932 - val_loss: 1.4861 - val_acc: 0.1277\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.9055 - acc: 0.2081 - val_loss: 1.4861 - val_acc: 0.1418\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 244us/step - loss: 3.2795 - acc: 0.2102 - val_loss: 1.4861 - val_acc: 0.2057\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.9765 - acc: 0.1677 - val_loss: 1.4861 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.8728 - acc: 0.2166 - val_loss: 1.6004 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.6782 - acc: 0.2123 - val_loss: 1.9433 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.9061 - acc: 0.2293 - val_loss: 1.9433 - val_acc: 0.2270\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.7354 - acc: 0.2017 - val_loss: 2.4006 - val_acc: 0.1702\n",
      "Epoch 31/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 219us/step - loss: 3.7938 - acc: 0.1868 - val_loss: 5.0298 - val_acc: 0.1277\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 3.3452 - acc: 0.2144 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.6465 - acc: 0.2081 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 4.0045 - acc: 0.1953 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 4.0898 - acc: 0.2059 - val_loss: 5.4870 - val_acc: 0.1277\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 3.5581 - acc: 0.1868 - val_loss: 4.6652 - val_acc: 0.1277\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.1517 - acc: 0.1720 - val_loss: 2.2709 - val_acc: 0.1277\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.0711 - acc: 0.1699 - val_loss: 2.2711 - val_acc: 0.1277\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.7703 - acc: 0.1720 - val_loss: 2.2761 - val_acc: 0.1277\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 2.3650 - acc: 0.1656 - val_loss: 0.6089 - val_acc: 0.1277\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.9444 - acc: 0.1571 - val_loss: 0.6008 - val_acc: 0.1277\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 2.0853 - acc: 0.1656 - val_loss: 0.6003 - val_acc: 0.1277\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.7235 - acc: 0.1486 - val_loss: 0.6001 - val_acc: 0.1277\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.0655 - acc: 0.1529 - val_loss: 0.5999 - val_acc: 0.1277\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.8173 - acc: 0.1465 - val_loss: 0.5998 - val_acc: 0.1277\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.7215 - acc: 0.1614 - val_loss: 0.5997 - val_acc: 0.1277\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.7274 - acc: 0.1592 - val_loss: 0.5997 - val_acc: 0.1277\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.9237 - acc: 0.1444 - val_loss: 0.5996 - val_acc: 0.1277\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.7773 - acc: 0.1316 - val_loss: 0.5996 - val_acc: 0.1277\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.8023 - acc: 0.1486 - val_loss: 0.5996 - val_acc: 0.1277\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.9769 - acc: 0.1359 - val_loss: 0.5998 - val_acc: 0.1277\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.1731 - acc: 0.1401 - val_loss: 0.6003 - val_acc: 0.1277\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.9346 - acc: 0.1529 - val_loss: 0.6006 - val_acc: 0.1277\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.2124 - acc: 0.1295 - val_loss: 0.6009 - val_acc: 0.1277\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.0619 - acc: 0.1083 - val_loss: 0.6039 - val_acc: 0.1348\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.8843 - acc: 0.1486 - val_loss: 0.8042 - val_acc: 0.1277\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.9824 - acc: 0.1189 - val_loss: 1.6686 - val_acc: 0.0993\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.4577 - acc: 0.1295 - val_loss: 2.6336 - val_acc: 0.0922\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.9356 - acc: 0.0892 - val_loss: 2.6292 - val_acc: 0.0567\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.2771 - acc: 0.1189 - val_loss: 2.6292 - val_acc: 0.0426\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.3123 - acc: 0.1062 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.6212 - acc: 0.1125 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 2.4679 - acc: 0.0955 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 2.3394 - acc: 0.0870 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.8865 - acc: 0.0955 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.7432 - acc: 0.0807 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.8153 - acc: 0.0743 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.6378 - acc: 0.0786 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.7892 - acc: 0.0701 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.8405 - acc: 0.0828 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 3.0143 - acc: 0.0913 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 3.0954 - acc: 0.0977 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 3.1710 - acc: 0.0870 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.5946 - acc: 0.1083 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 2.8915 - acc: 0.0743 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 3.2272 - acc: 0.0977 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.4951 - acc: 0.0934 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 3.5573 - acc: 0.0913 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 3.9740 - acc: 0.0870 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 3.6185 - acc: 0.0764 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 3.1201 - acc: 0.0828 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 3.4786 - acc: 0.0786 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 3.2767 - acc: 0.0679 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 3.6740 - acc: 0.0870 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 3.4204 - acc: 0.0977 - val_loss: 2.6292 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.6609 - acc: 0.1019 - val_loss: 2.6292 - val_acc: 0.0780\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.3586 - acc: 0.1189 - val_loss: 2.7435 - val_acc: 0.1135\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 3.3515 - acc: 0.1189 - val_loss: 3.7723 - val_acc: 0.1348\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 239us/step - loss: nan - acc: 0.4183 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 238us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 207us/step\n",
      "Test score: nan\n",
      "Look! elu softplus softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softplus softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_284 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1001 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_720 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1002 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_721 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1003 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 29s 63ms/step - loss: nan - acc: 0.4607 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 184us/step\n",
      "Test score: nan\n",
      "Look! elu softplus relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softplus relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_285 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1004 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_722 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1005 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_723 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1006 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 30s 63ms/step - loss: nan - acc: 0.4692 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 205us/step\n",
      "Test score: nan\n",
      "Look! elu softplus tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softplus tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_286 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1007 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_724 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1008 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_725 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1009 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 30s 63ms/step - loss: 4.3942 - acc: 0.2866 - val_loss: 0.9514 - val_acc: 0.2340\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.3685 - acc: 0.3694 - val_loss: 0.9508 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.3976 - acc: 0.3312 - val_loss: 0.8585 - val_acc: 0.2340\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.4895 - acc: 0.3843 - val_loss: 0.7498 - val_acc: 0.4894\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.5897 - acc: 0.3546 - val_loss: 0.5969 - val_acc: 0.5319\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.1189 - acc: 0.4183 - val_loss: 0.5997 - val_acc: 0.5816\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.0913 - acc: 0.4459 - val_loss: 0.5997 - val_acc: 0.6099\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.0606 - acc: 0.4756 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8035 - acc: 0.5138 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8043 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8742 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.8078 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.9224 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7791 - acc: 0.5308 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7828 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8248 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8114 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8133 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7818 - acc: 0.5244 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7364 - acc: 0.5308 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7376 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.8251 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7578 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7603 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7658 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7256 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7522 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7444 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7303 - acc: 0.5287 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7293 - acc: 0.5265 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7597 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7353 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7602 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7564 - acc: 0.5499 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7628 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7309 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7281 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7339 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7376 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7321 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7632 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7683 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7565 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7381 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7818 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7327 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7479 - acc: 0.5308 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7328 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7336 - acc: 0.5244 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7658 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7309 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7344 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.7658 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7629 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7345 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7331 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7326 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7641 - acc: 0.5265 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7342 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7646 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7976 - acc: 0.5244 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7334 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7647 - acc: 0.5287 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7489 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7645 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7324 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7465 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7836 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7347 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7657 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7347 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7330 - acc: 0.5265 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7343 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7352 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7352 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7337 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7328 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7323 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7352 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7639 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7342 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7788 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7335 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7329 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7382 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8219 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7337 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7346 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7605 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7346 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7352 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7346 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7304 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7358 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7346 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7351 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7352 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7340 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7359 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7351 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7336 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7345 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7334 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7438 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7330 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7337 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7327 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7671 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7622 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7342 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7653 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7358 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7350 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7353 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7352 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7340 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7358 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7352 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7358 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7386 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 188us/step\n",
      "Test score: 0.5997443816340562\n",
      "Look! elu softplus sigmoid Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softplus sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_287 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1010 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_726 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1011 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_727 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1012 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 30s 63ms/step - loss: nan - acc: 0.4331 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.4331 - val_loss: 3.0173 - val_acc: 0.2624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.3928 - val_loss: 1.7270 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.3907 - val_loss: 1.7299 - val_acc: 0.2057\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.4013 - val_loss: 1.1115 - val_acc: 0.5319\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.4289 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.4650 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.7021 - acc: 0.4565 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.5793 - acc: 0.4968 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.4947 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.4560 - acc: 0.5074 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.5263 - acc: 0.5096 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.4968 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.4876 - acc: 0.5096 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.5218 - acc: 0.4841 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.5500 - acc: 0.4904 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.6382 - acc: 0.4862 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.5313 - acc: 0.4650 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.4903 - acc: 0.4246 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.7338 - acc: 0.4140 - val_loss: 1.0093 - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.5735 - acc: 0.4076 - val_loss: 1.0086 - val_acc: 0.6170\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.7031 - acc: 0.4013 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.7222 - acc: 0.3992 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.4395 - acc: 0.4692 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.6115 - acc: 0.4926 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.5015 - acc: 0.5117 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.2641 - acc: 0.4947 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.3747 - acc: 0.4968 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.5357 - acc: 0.5032 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.3589 - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.4862 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.3399 - acc: 0.4989 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.5642 - acc: 0.4650 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.6012 - acc: 0.4735 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.2186 - acc: 0.5032 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.5332 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.4798 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.5749 - acc: 0.5138 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.5585 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5011 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.4692 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5329 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.8039 - acc: 0.5265 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5096 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.7439 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.3893 - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.4905 - acc: 0.4947 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.3288 - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.4862 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.6020 - acc: 0.4756 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.3213 - acc: 0.4904 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.5472 - acc: 0.5074 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.7395 - acc: 0.4947 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.6164 - acc: 0.5053 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5096 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.5843 - acc: 0.5011 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.4257 - acc: 0.5053 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.4520 - acc: 0.4862 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.6658 - acc: 0.4883 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.4454 - acc: 0.4989 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.4749 - acc: 0.4756 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 1.5812 - acc: 0.4268 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.4585 - acc: 0.4098 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.5741 - acc: 0.4395 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 1.6763 - acc: 0.4268 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.6645 - acc: 0.4416 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.4904 - acc: 0.4544 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.6085 - acc: 0.4119 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.4067 - acc: 0.5032 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.3197 - acc: 0.4862 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.3913 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.5009 - acc: 0.4926 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.5067 - acc: 0.4947 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.2390 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5350 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.2830 - acc: 0.5074 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.4050 - acc: 0.4989 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.2198 - acc: 0.5032 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.2698 - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.2589 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.3801 - acc: 0.4926 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.1930 - acc: 0.5138 - val_loss: 1.0088 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.0632 - acc: 0.5244 - val_loss: 1.0117 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.1405 - acc: 0.5308 - val_loss: 1.0102 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.1482 - acc: 0.5180 - val_loss: 1.0088 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.1400 - acc: 0.5265 - val_loss: 1.0081 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.0085 - acc: 0.5329 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.2276 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.1330 - acc: 0.5244 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.1934 - acc: 0.5308 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.1291 - acc: 0.5308 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.1538 - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.0834 - acc: 0.5223 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.2695 - acc: 0.5265 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.2358 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.1966 - acc: 0.5372 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.2037 - acc: 0.5350 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.3087 - acc: 0.5074 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.1058 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.3199 - acc: 0.5159 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.2033 - acc: 0.5287 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.1317 - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.2963 - acc: 0.5244 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.3216 - acc: 0.5244 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.2658 - acc: 0.5308 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.2361 - acc: 0.5372 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.3312 - acc: 0.5350 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2261 - acc: 0.5265 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.2020 - acc: 0.5096 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.3907 - acc: 0.5372 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2023 - acc: 0.5393 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.2905 - acc: 0.5435 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.2250 - acc: 0.5350 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.2898 - acc: 0.5244 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2649 - acc: 0.5287 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.4171 - acc: 0.5244 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.2274 - acc: 0.5287 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 218us/step\n",
      "Test score: 1.0078918815504574\n",
      "Look! elu softplus hard_sigmoid Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softplus hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_288 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1013 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_728 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1014 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_729 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1015 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 30s 63ms/step - loss: 3.2557 - acc: 0.2017 - val_loss: 2.3623 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.3712 - acc: 0.2229 - val_loss: 2.8112 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.9569 - acc: 0.2081 - val_loss: 1.7273 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.0533 - acc: 0.1975 - val_loss: 1.2222 - val_acc: 0.2199\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.5997 - acc: 0.2208 - val_loss: 1.2115 - val_acc: 0.1489\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.8163 - acc: 0.2293 - val_loss: 1.2143 - val_acc: 0.1277\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.5596 - acc: 0.2081 - val_loss: 1.2069 - val_acc: 0.1277\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.8770 - acc: 0.1783 - val_loss: 1.4161 - val_acc: 0.1277\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.9030 - acc: 0.1762 - val_loss: 1.7656 - val_acc: 0.1277\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.1375 - acc: 0.1975 - val_loss: 1.6415 - val_acc: 0.1277\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 3.1287 - acc: 0.2038 - val_loss: 2.7976 - val_acc: 0.1277\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.8277 - acc: 0.2314 - val_loss: 2.3312 - val_acc: 0.1277\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.7903 - acc: 0.2399 - val_loss: 2.3264 - val_acc: 0.1277\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.8451 - acc: 0.2463 - val_loss: 2.3236 - val_acc: 0.1277\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.5384 - acc: 0.2824 - val_loss: 0.5986 - val_acc: 0.6312\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.1360 - acc: 0.3121 - val_loss: 1.0309 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.6748 - acc: 0.3142 - val_loss: 0.8690 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.5947 - acc: 0.2675 - val_loss: 0.6048 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.5706 - acc: 0.3121 - val_loss: 0.5799 - val_acc: 0.6170\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.3518 - acc: 0.3015 - val_loss: 0.5942 - val_acc: 0.4752\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.5046 - acc: 0.2866 - val_loss: 0.6156 - val_acc: 0.6312\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.3096 - acc: 0.2972 - val_loss: 0.7438 - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.3121 - acc: 0.2930 - val_loss: 0.9655 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.3690 - acc: 0.3291 - val_loss: 1.2646 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.4955 - acc: 0.3439 - val_loss: 0.7026 - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2706 - acc: 0.3546 - val_loss: 0.5571 - val_acc: 0.6312\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2085 - acc: 0.2994 - val_loss: 0.5344 - val_acc: 0.5461\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.1706 - acc: 0.3079 - val_loss: 0.5250 - val_acc: 0.0426\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.1023 - acc: 0.2718 - val_loss: 0.5239 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.2437 - acc: 0.2357 - val_loss: 0.5256 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.2663 - acc: 0.2420 - val_loss: 0.5310 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.0651 - acc: 0.2187 - val_loss: 0.5421 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.9831 - acc: 0.1996 - val_loss: 0.6790 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.1017 - acc: 0.1911 - val_loss: 0.9582 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.1362 - acc: 0.1571 - val_loss: 0.9571 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.2554 - acc: 0.1677 - val_loss: 0.9556 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.0284 - acc: 0.1677 - val_loss: 0.9541 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.1363 - acc: 0.1295 - val_loss: 0.9517 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.8814 - acc: 0.1380 - val_loss: 0.9515 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.0061 - acc: 0.1529 - val_loss: 0.9540 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.9823 - acc: 0.1614 - val_loss: 0.9580 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 1.0542 - acc: 0.1699 - val_loss: 0.8265 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.9511 - acc: 0.1720 - val_loss: 0.7503 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.8974 - acc: 0.1550 - val_loss: 0.7522 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.0044 - acc: 0.1720 - val_loss: 0.7533 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.0028 - acc: 0.1380 - val_loss: 0.8259 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.9248 - acc: 0.1338 - val_loss: 0.8988 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.9276 - acc: 0.1146 - val_loss: 0.8138 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.8630 - acc: 0.0955 - val_loss: 0.7327 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.9359 - acc: 0.1040 - val_loss: 0.6369 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8639 - acc: 0.1380 - val_loss: 0.5429 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.8315 - acc: 0.1359 - val_loss: 0.5316 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8623 - acc: 0.1316 - val_loss: 0.5281 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.9362 - acc: 0.1720 - val_loss: 0.5230 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8466 - acc: 0.1699 - val_loss: 0.5200 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7948 - acc: 0.1592 - val_loss: 0.5187 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.8754 - acc: 0.1996 - val_loss: 0.5187 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.8230 - acc: 0.2017 - val_loss: 0.5193 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8924 - acc: 0.1932 - val_loss: 0.5204 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7257 - acc: 0.2038 - val_loss: 0.5209 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8322 - acc: 0.1614 - val_loss: 0.5213 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7594 - acc: 0.1975 - val_loss: 0.5216 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.8096 - acc: 0.1783 - val_loss: 0.5217 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8284 - acc: 0.1890 - val_loss: 0.5218 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7447 - acc: 0.1656 - val_loss: 0.5217 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6921 - acc: 0.1847 - val_loss: 0.5214 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7308 - acc: 0.2059 - val_loss: 0.5211 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7205 - acc: 0.1911 - val_loss: 0.5209 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7389 - acc: 0.1911 - val_loss: 0.5212 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.7527 - acc: 0.1571 - val_loss: 0.5216 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7319 - acc: 0.1614 - val_loss: 0.5219 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6875 - acc: 0.1614 - val_loss: 0.5220 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6940 - acc: 0.1635 - val_loss: 0.5219 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6959 - acc: 0.1720 - val_loss: 0.5218 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7327 - acc: 0.1423 - val_loss: 0.5216 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6973 - acc: 0.1465 - val_loss: 0.5214 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6559 - acc: 0.1295 - val_loss: 0.5212 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6894 - acc: 0.1571 - val_loss: 0.5209 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7406 - acc: 0.1380 - val_loss: 0.5206 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7174 - acc: 0.1316 - val_loss: 0.5204 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7356 - acc: 0.1486 - val_loss: 0.5200 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7729 - acc: 0.1805 - val_loss: 0.5216 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7343 - acc: 0.1826 - val_loss: 0.5241 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6430 - acc: 0.1720 - val_loss: 0.5257 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7519 - acc: 0.1911 - val_loss: 0.5264 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6598 - acc: 0.1677 - val_loss: 0.5265 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7353 - acc: 0.1953 - val_loss: 0.5261 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7176 - acc: 0.1975 - val_loss: 0.5250 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6675 - acc: 0.1762 - val_loss: 0.5241 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6929 - acc: 0.1975 - val_loss: 0.5231 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6951 - acc: 0.1783 - val_loss: 0.5225 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7074 - acc: 0.1805 - val_loss: 0.5220 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7047 - acc: 0.1720 - val_loss: 0.5214 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6981 - acc: 0.2017 - val_loss: 0.5209 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6511 - acc: 0.1529 - val_loss: 0.5204 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6733 - acc: 0.1614 - val_loss: 0.5199 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6929 - acc: 0.1762 - val_loss: 0.5194 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6696 - acc: 0.1592 - val_loss: 0.5191 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6575 - acc: 0.1677 - val_loss: 0.5188 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7124 - acc: 0.1762 - val_loss: 0.5191 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6569 - acc: 0.1741 - val_loss: 0.5192 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6631 - acc: 0.1911 - val_loss: 0.5198 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.7089 - acc: 0.2505 - val_loss: 0.5200 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6812 - acc: 0.2272 - val_loss: 0.5201 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7563 - acc: 0.2442 - val_loss: 0.5200 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6679 - acc: 0.2378 - val_loss: 0.5197 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6984 - acc: 0.2208 - val_loss: 0.5194 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7027 - acc: 0.2102 - val_loss: 0.5191 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7272 - acc: 0.2166 - val_loss: 0.5188 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6634 - acc: 0.2038 - val_loss: 0.5185 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6849 - acc: 0.1868 - val_loss: 0.5182 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6596 - acc: 0.2059 - val_loss: 0.5180 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7393 - acc: 0.1677 - val_loss: 0.5177 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7238 - acc: 0.1677 - val_loss: 0.5175 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6654 - acc: 0.1656 - val_loss: 0.5175 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6393 - acc: 0.1486 - val_loss: 0.5173 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6782 - acc: 0.1507 - val_loss: 0.5170 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7505 - acc: 0.1677 - val_loss: 0.5169 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7403 - acc: 0.1656 - val_loss: 0.5168 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6450 - acc: 0.1529 - val_loss: 0.5167 - val_acc: 0.0355\n",
      "141/141 [==============================] - 0s 207us/step\n",
      "Test score: 0.5166848213114636\n",
      "Look! elu softplus linear Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 elu softplus hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_289 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1016 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_730 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1017 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_731 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1018 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 30s 64ms/step - loss: 1.0212 - acc: 0.2654 - val_loss: 0.5268 - val_acc: 0.2199\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.9960 - acc: 0.2654 - val_loss: 0.6530 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.9157 - acc: 0.2442 - val_loss: 0.6172 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.9554 - acc: 0.2314 - val_loss: 0.6382 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.9287 - acc: 0.2569 - val_loss: 0.5931 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.9504 - acc: 0.2166 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.8814 - acc: 0.2420 - val_loss: 0.5415 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.8916 - acc: 0.2484 - val_loss: 0.5544 - val_acc: 0.2199\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.8939 - acc: 0.2781 - val_loss: 0.5750 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.9984 - acc: 0.2463 - val_loss: 0.5535 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.9104 - acc: 0.2505 - val_loss: 0.5457 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.8640 - acc: 0.2845 - val_loss: 0.5304 - val_acc: 0.2199\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.9491 - acc: 0.2378 - val_loss: 0.5202 - val_acc: 0.2340\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.9282 - acc: 0.2293 - val_loss: 0.5326 - val_acc: 0.2199\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8129 - acc: 0.2548 - val_loss: 0.5346 - val_acc: 0.2411\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.8332 - acc: 0.2866 - val_loss: 0.5231 - val_acc: 0.2411\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.9259 - acc: 0.2569 - val_loss: 0.5177 - val_acc: 0.2411\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8552 - acc: 0.2654 - val_loss: 0.5049 - val_acc: 0.2553\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8283 - acc: 0.2654 - val_loss: 0.4920 - val_acc: 0.2766\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8131 - acc: 0.2590 - val_loss: 0.4888 - val_acc: 0.2624\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.8908 - acc: 0.2335 - val_loss: 0.5456 - val_acc: 0.2199\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8368 - acc: 0.2590 - val_loss: 0.6134 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.8498 - acc: 0.2548 - val_loss: 0.6000 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.8126 - acc: 0.2293 - val_loss: 0.5595 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.8549 - acc: 0.2229 - val_loss: 0.5589 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8258 - acc: 0.2739 - val_loss: 0.5460 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7981 - acc: 0.2718 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.8532 - acc: 0.2548 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7931 - acc: 0.2696 - val_loss: 0.5009 - val_acc: 0.2199\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.8788 - acc: 0.2399 - val_loss: 0.4871 - val_acc: 0.2340\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.8304 - acc: 0.2420 - val_loss: 0.4850 - val_acc: 0.2482\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8245 - acc: 0.2166 - val_loss: 0.4866 - val_acc: 0.2340\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8346 - acc: 0.2293 - val_loss: 0.5066 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.8051 - acc: 0.2484 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.8242 - acc: 0.2420 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7574 - acc: 0.2654 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7664 - acc: 0.2781 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7598 - acc: 0.2272 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7675 - acc: 0.2527 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.8049 - acc: 0.2272 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7842 - acc: 0.2590 - val_loss: 0.5080 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7475 - acc: 0.2399 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7632 - acc: 0.2590 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7769 - acc: 0.2293 - val_loss: 0.5160 - val_acc: 0.2199\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7459 - acc: 0.2739 - val_loss: 0.5145 - val_acc: 0.2199\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7256 - acc: 0.2208 - val_loss: 0.5045 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7567 - acc: 0.2760 - val_loss: 0.5067 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7224 - acc: 0.2696 - val_loss: 0.5122 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7677 - acc: 0.2505 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7662 - acc: 0.2272 - val_loss: 0.5224 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7398 - acc: 0.2569 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7377 - acc: 0.2505 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7528 - acc: 0.2442 - val_loss: 0.5130 - val_acc: 0.2482\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7217 - acc: 0.2420 - val_loss: 0.5178 - val_acc: 0.2482\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7407 - acc: 0.2696 - val_loss: 0.5168 - val_acc: 0.2057\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7648 - acc: 0.2378 - val_loss: 0.5169 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7533 - acc: 0.2378 - val_loss: 0.5143 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7545 - acc: 0.2229 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7112 - acc: 0.2442 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7111 - acc: 0.2442 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7427 - acc: 0.2399 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6845 - acc: 0.2739 - val_loss: 0.5051 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6776 - acc: 0.2548 - val_loss: 0.5011 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7090 - acc: 0.2335 - val_loss: 0.4978 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7076 - acc: 0.2505 - val_loss: 0.4971 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7028 - acc: 0.2484 - val_loss: 0.4990 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7285 - acc: 0.2463 - val_loss: 0.5042 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7647 - acc: 0.2357 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7367 - acc: 0.2527 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6815 - acc: 0.2803 - val_loss: 0.5251 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6874 - acc: 0.2781 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7071 - acc: 0.2696 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6801 - acc: 0.2590 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6921 - acc: 0.2378 - val_loss: 0.5101 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7047 - acc: 0.2781 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6798 - acc: 0.2590 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6688 - acc: 0.2781 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7006 - acc: 0.2548 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6938 - acc: 0.2463 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6667 - acc: 0.2633 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6620 - acc: 0.2590 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6777 - acc: 0.2527 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6733 - acc: 0.2548 - val_loss: 0.5077 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6939 - acc: 0.2696 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6566 - acc: 0.2739 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6697 - acc: 0.2675 - val_loss: 0.5101 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6779 - acc: 0.2675 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6824 - acc: 0.2420 - val_loss: 0.5090 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6524 - acc: 0.2505 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6550 - acc: 0.2633 - val_loss: 0.5079 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6428 - acc: 0.2781 - val_loss: 0.5089 - val_acc: 0.2199\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6284 - acc: 0.2569 - val_loss: 0.5100 - val_acc: 0.2340\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6692 - acc: 0.2590 - val_loss: 0.5123 - val_acc: 0.2270\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6767 - acc: 0.2484 - val_loss: 0.5175 - val_acc: 0.2199\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6489 - acc: 0.2484 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6803 - acc: 0.2611 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6278 - acc: 0.2633 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6311 - acc: 0.2654 - val_loss: 0.5113 - val_acc: 0.2199\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6907 - acc: 0.2399 - val_loss: 0.5078 - val_acc: 0.2199\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6525 - acc: 0.2696 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6565 - acc: 0.2420 - val_loss: 0.5013 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6650 - acc: 0.2548 - val_loss: 0.5008 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6455 - acc: 0.2548 - val_loss: 0.4928 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6626 - acc: 0.2569 - val_loss: 0.4846 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6577 - acc: 0.2696 - val_loss: 0.4874 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6733 - acc: 0.2442 - val_loss: 0.4927 - val_acc: 0.2270\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6498 - acc: 0.2930 - val_loss: 0.4929 - val_acc: 0.2270\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6301 - acc: 0.2696 - val_loss: 0.4991 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6551 - acc: 0.2484 - val_loss: 0.5088 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6439 - acc: 0.2505 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6795 - acc: 0.2399 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6326 - acc: 0.2633 - val_loss: 0.5087 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6468 - acc: 0.2760 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6393 - acc: 0.2739 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6538 - acc: 0.2654 - val_loss: 0.5047 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6301 - acc: 0.2611 - val_loss: 0.5066 - val_acc: 0.2199\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6739 - acc: 0.2463 - val_loss: 0.5083 - val_acc: 0.2199\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6584 - acc: 0.2463 - val_loss: 0.5092 - val_acc: 0.2199\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6104 - acc: 0.2654 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6367 - acc: 0.2696 - val_loss: 0.5058 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 197us/step\n",
      "Test score: 0.5058041007806223\n",
      "Look! elu softsign softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softplus hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_290 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1019 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_732 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1020 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_733 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1021 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 30s 65ms/step - loss: 2.9180 - acc: 0.2357 - val_loss: 3.2933 - val_acc: 0.3050\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.0028 - acc: 0.2527 - val_loss: 3.8754 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 3.7563 - acc: 0.2399 - val_loss: 3.3680 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 3.2382 - acc: 0.2633 - val_loss: 4.4675 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 3.2227 - acc: 0.2378 - val_loss: 4.6965 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.1725 - acc: 0.2590 - val_loss: 3.7997 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.4896 - acc: 0.2505 - val_loss: 3.4463 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.1068 - acc: 0.2803 - val_loss: 3.4537 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.3352 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.7011 - acc: 0.2824 - val_loss: 3.0747 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.5585 - acc: 0.2633 - val_loss: 2.7522 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.3490 - acc: 0.2548 - val_loss: 1.7105 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.0247 - acc: 0.2739 - val_loss: 1.6930 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.9280 - acc: 0.2399 - val_loss: 1.7015 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.0083 - acc: 0.2463 - val_loss: 1.5321 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.6518 - acc: 0.2569 - val_loss: 1.5248 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.7209 - acc: 0.2229 - val_loss: 1.4340 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.5944 - acc: 0.2357 - val_loss: 0.9760 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.6323 - acc: 0.2718 - val_loss: 0.9509 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.5028 - acc: 0.2208 - val_loss: 0.9440 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.3876 - acc: 0.2017 - val_loss: 0.9411 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.6283 - acc: 0.2166 - val_loss: 0.9386 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.5310 - acc: 0.2293 - val_loss: 0.9366 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.3357 - acc: 0.2357 - val_loss: 0.9305 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.3576 - acc: 0.2611 - val_loss: 0.9267 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.3183 - acc: 0.2335 - val_loss: 0.9318 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.3605 - acc: 0.2505 - val_loss: 0.9442 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.4553 - acc: 0.2399 - val_loss: 0.9416 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.3760 - acc: 0.2314 - val_loss: 0.9412 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.2497 - acc: 0.2187 - val_loss: 0.9414 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.3106 - acc: 0.2420 - val_loss: 0.9417 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.1765 - acc: 0.2314 - val_loss: 0.9426 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.1510 - acc: 0.2548 - val_loss: 0.9480 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.4479 - acc: 0.2399 - val_loss: 0.9502 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.0822 - acc: 0.2442 - val_loss: 0.9494 - val_acc: 0.2199\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.3218 - acc: 0.2399 - val_loss: 0.9484 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.1410 - acc: 0.2335 - val_loss: 0.9502 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.1560 - acc: 0.2548 - val_loss: 0.9548 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.1819 - acc: 0.2251 - val_loss: 0.9576 - val_acc: 0.2411\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.1609 - acc: 0.2463 - val_loss: 0.9579 - val_acc: 0.2411\n",
      "Epoch 41/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 205us/step - loss: 1.2138 - acc: 0.1996 - val_loss: 0.9608 - val_acc: 0.1915\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.9790 - acc: 0.2251 - val_loss: 0.9687 - val_acc: 0.1206\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.0158 - acc: 0.2272 - val_loss: 0.9705 - val_acc: 0.0780\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.1416 - acc: 0.2357 - val_loss: 0.9682 - val_acc: 0.1489\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2001 - acc: 0.2251 - val_loss: 0.9651 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.1102 - acc: 0.2187 - val_loss: 0.9610 - val_acc: 0.1986\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.1057 - acc: 0.2420 - val_loss: 0.9552 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.9661 - acc: 0.2527 - val_loss: 0.9569 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.0748 - acc: 0.2378 - val_loss: 0.8873 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.0090 - acc: 0.2314 - val_loss: 0.7117 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.9710 - acc: 0.2633 - val_loss: 0.6230 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.9155 - acc: 0.2781 - val_loss: 0.5555 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.0749 - acc: 0.2781 - val_loss: 0.5480 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.9026 - acc: 0.2208 - val_loss: 0.5489 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.9600 - acc: 0.2442 - val_loss: 0.5365 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.9692 - acc: 0.2569 - val_loss: 0.5320 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.9823 - acc: 0.2144 - val_loss: 0.5319 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.8412 - acc: 0.2399 - val_loss: 0.5329 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.0202 - acc: 0.2463 - val_loss: 0.5302 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.0027 - acc: 0.2590 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.9941 - acc: 0.2611 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8400 - acc: 0.2442 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.9590 - acc: 0.2633 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.9411 - acc: 0.2527 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.0405 - acc: 0.2314 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.8561 - acc: 0.2654 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.9004 - acc: 0.2590 - val_loss: 0.5317 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7826 - acc: 0.2335 - val_loss: 0.5307 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8468 - acc: 0.2314 - val_loss: 0.5313 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7109 - acc: 0.2442 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8192 - acc: 0.2654 - val_loss: 0.5361 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.9394 - acc: 0.2505 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7597 - acc: 0.2527 - val_loss: 0.5338 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.8547 - acc: 0.2357 - val_loss: 0.5320 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.9648 - acc: 0.2569 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.8278 - acc: 0.2378 - val_loss: 0.5287 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.8464 - acc: 0.2675 - val_loss: 0.5267 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8719 - acc: 0.2420 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7643 - acc: 0.2335 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.8108 - acc: 0.2314 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8537 - acc: 0.2229 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.8020 - acc: 0.2420 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.8805 - acc: 0.2378 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7856 - acc: 0.2272 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7265 - acc: 0.2314 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7404 - acc: 0.2505 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7539 - acc: 0.2335 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7314 - acc: 0.2187 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7716 - acc: 0.2484 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8064 - acc: 0.2420 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7967 - acc: 0.2527 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7210 - acc: 0.2357 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7442 - acc: 0.2378 - val_loss: 0.5300 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7932 - acc: 0.2569 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6885 - acc: 0.2442 - val_loss: 0.5303 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7890 - acc: 0.2442 - val_loss: 0.5314 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.7562 - acc: 0.2293 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6820 - acc: 0.2463 - val_loss: 0.5316 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6937 - acc: 0.2442 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6890 - acc: 0.2463 - val_loss: 0.5298 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7283 - acc: 0.2654 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6993 - acc: 0.2357 - val_loss: 0.5281 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7044 - acc: 0.2675 - val_loss: 0.5281 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6938 - acc: 0.2442 - val_loss: 0.5289 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6510 - acc: 0.2484 - val_loss: 0.5293 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7035 - acc: 0.2527 - val_loss: 0.5289 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7145 - acc: 0.2378 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7667 - acc: 0.2399 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6523 - acc: 0.2463 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7979 - acc: 0.2548 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.7972 - acc: 0.2293 - val_loss: 0.5280 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6671 - acc: 0.2420 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.6522 - acc: 0.2633 - val_loss: 0.5274 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6774 - acc: 0.2442 - val_loss: 0.5271 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6499 - acc: 0.2590 - val_loss: 0.5270 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7437 - acc: 0.2611 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6634 - acc: 0.2357 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7475 - acc: 0.2590 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7267 - acc: 0.2527 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7449 - acc: 0.2548 - val_loss: 0.5233 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 201us/step\n",
      "Test score: 0.523268850137156\n",
      "Look! elu softsign elu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softplus hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_291 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1022 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_734 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1023 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_735 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1024 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 30s 64ms/step - loss: 2.3172 - acc: 0.2187 - val_loss: 1.2457 - val_acc: 0.1631\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 2.4153 - acc: 0.1720 - val_loss: 1.1564 - val_acc: 0.1773\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 2.7737 - acc: 0.1486 - val_loss: 1.3396 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.4115 - acc: 0.1656 - val_loss: 1.2739 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.5923 - acc: 0.1444 - val_loss: 1.3672 - val_acc: 0.1277\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 2.3381 - acc: 0.1911 - val_loss: 1.3203 - val_acc: 0.1489\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.3699 - acc: 0.1911 - val_loss: 1.2943 - val_acc: 0.1489\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.8894 - acc: 0.1890 - val_loss: 1.2858 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 2.0378 - acc: 0.1996 - val_loss: 1.3845 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 2.1707 - acc: 0.1868 - val_loss: 1.4784 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.8376 - acc: 0.1953 - val_loss: 1.5610 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.9322 - acc: 0.2229 - val_loss: 1.6347 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.9216 - acc: 0.2144 - val_loss: 1.6238 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.7643 - acc: 0.2272 - val_loss: 1.6074 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.6905 - acc: 0.1911 - val_loss: 1.6036 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.8082 - acc: 0.2017 - val_loss: 1.5907 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.1507 - acc: 0.1868 - val_loss: 1.5840 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.8045 - acc: 0.2272 - val_loss: 1.5817 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.9683 - acc: 0.2123 - val_loss: 1.5788 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.8217 - acc: 0.2038 - val_loss: 1.5746 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.5841 - acc: 0.2123 - val_loss: 1.5674 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.8905 - acc: 0.2293 - val_loss: 1.5668 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.8106 - acc: 0.2017 - val_loss: 1.5773 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.8283 - acc: 0.2187 - val_loss: 1.5935 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.9537 - acc: 0.1953 - val_loss: 1.6019 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.9769 - acc: 0.1805 - val_loss: 1.6105 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 238us/step - loss: 1.6661 - acc: 0.2208 - val_loss: 1.6265 - val_acc: 0.2057\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.6573 - acc: 0.2293 - val_loss: 1.6400 - val_acc: 0.1277\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.7754 - acc: 0.2229 - val_loss: 1.3338 - val_acc: 0.1277\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.7016 - acc: 0.1975 - val_loss: 0.9331 - val_acc: 0.1277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 1.7241 - acc: 0.2144 - val_loss: 0.9190 - val_acc: 0.1348\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.5545 - acc: 0.2229 - val_loss: 0.9078 - val_acc: 0.2057\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.5682 - acc: 0.2144 - val_loss: 0.9139 - val_acc: 0.0922\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.3875 - acc: 0.2293 - val_loss: 0.9229 - val_acc: 0.1064\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.6458 - acc: 0.2251 - val_loss: 0.9291 - val_acc: 0.1206\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.4173 - acc: 0.2463 - val_loss: 0.9294 - val_acc: 0.1277\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.4758 - acc: 0.2123 - val_loss: 0.9278 - val_acc: 0.1348\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.4205 - acc: 0.2166 - val_loss: 0.9280 - val_acc: 0.1844\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.5252 - acc: 0.2420 - val_loss: 0.9253 - val_acc: 0.1915\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.3620 - acc: 0.1975 - val_loss: 0.9265 - val_acc: 0.0993\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.5486 - acc: 0.2527 - val_loss: 0.9260 - val_acc: 0.0993\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.3502 - acc: 0.2420 - val_loss: 0.9206 - val_acc: 0.1348\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.3922 - acc: 0.2251 - val_loss: 0.9169 - val_acc: 0.1348\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.3606 - acc: 0.2378 - val_loss: 0.9167 - val_acc: 0.1277\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.2290 - acc: 0.2293 - val_loss: 0.9190 - val_acc: 0.1277\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.3282 - acc: 0.2229 - val_loss: 0.9209 - val_acc: 0.0922\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.1507 - acc: 0.2314 - val_loss: 0.9218 - val_acc: 0.1631\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.3625 - acc: 0.2335 - val_loss: 0.9226 - val_acc: 0.2057\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.0823 - acc: 0.2399 - val_loss: 0.9233 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.2752 - acc: 0.2824 - val_loss: 0.9226 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.2196 - acc: 0.2548 - val_loss: 0.9233 - val_acc: 0.2199\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.3550 - acc: 0.2569 - val_loss: 0.9233 - val_acc: 0.2199\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.1749 - acc: 0.2229 - val_loss: 0.9226 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.1607 - acc: 0.2654 - val_loss: 0.9214 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.2634 - acc: 0.2378 - val_loss: 0.9205 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.1974 - acc: 0.2335 - val_loss: 0.9200 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.2758 - acc: 0.2675 - val_loss: 0.9186 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.2260 - acc: 0.2590 - val_loss: 0.9172 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.1255 - acc: 0.2272 - val_loss: 0.9164 - val_acc: 0.2199\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.1908 - acc: 0.2569 - val_loss: 0.9182 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2728 - acc: 0.2505 - val_loss: 0.9191 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.1135 - acc: 0.2548 - val_loss: 0.9207 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.9775 - acc: 0.2569 - val_loss: 0.9220 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.0193 - acc: 0.2378 - val_loss: 0.9237 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.1605 - acc: 0.2442 - val_loss: 0.9277 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.0378 - acc: 0.2229 - val_loss: 0.9329 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.9499 - acc: 0.2739 - val_loss: 0.9355 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.9428 - acc: 0.2718 - val_loss: 0.9475 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.0918 - acc: 0.2357 - val_loss: 0.8851 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.8620 - acc: 0.2845 - val_loss: 0.6408 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.0647 - acc: 0.2505 - val_loss: 0.5422 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.0373 - acc: 0.2187 - val_loss: 0.5432 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.0218 - acc: 0.2718 - val_loss: 0.5442 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.1157 - acc: 0.2293 - val_loss: 0.5493 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.1319 - acc: 0.2463 - val_loss: 0.5433 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.8950 - acc: 0.2463 - val_loss: 0.5302 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.0230 - acc: 0.2760 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.8865 - acc: 0.2442 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7863 - acc: 0.2654 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.8485 - acc: 0.2781 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.9175 - acc: 0.2123 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.8335 - acc: 0.2357 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7711 - acc: 0.2378 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.9108 - acc: 0.2378 - val_loss: 0.5293 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8374 - acc: 0.2569 - val_loss: 0.5292 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.9530 - acc: 0.2718 - val_loss: 0.5302 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.9799 - acc: 0.2718 - val_loss: 0.5297 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8032 - acc: 0.2420 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.9009 - acc: 0.2463 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8669 - acc: 0.2548 - val_loss: 0.5171 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8741 - acc: 0.2718 - val_loss: 0.5153 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.8448 - acc: 0.2548 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.9174 - acc: 0.2442 - val_loss: 0.5174 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.9332 - acc: 0.2484 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7509 - acc: 0.2399 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6892 - acc: 0.2251 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.8586 - acc: 0.2335 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7635 - acc: 0.2399 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7717 - acc: 0.2420 - val_loss: 0.5188 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8348 - acc: 0.2527 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7417 - acc: 0.2505 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7618 - acc: 0.2675 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7287 - acc: 0.2378 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7216 - acc: 0.2590 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7672 - acc: 0.2357 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7278 - acc: 0.2781 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7408 - acc: 0.2251 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7346 - acc: 0.2527 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7648 - acc: 0.2463 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7154 - acc: 0.2272 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7493 - acc: 0.2463 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7179 - acc: 0.2399 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7239 - acc: 0.2378 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7265 - acc: 0.2314 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7805 - acc: 0.2357 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7332 - acc: 0.2272 - val_loss: 0.5293 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7281 - acc: 0.2548 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7288 - acc: 0.2633 - val_loss: 0.5304 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7393 - acc: 0.2505 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6832 - acc: 0.2420 - val_loss: 0.5315 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 188us/step\n",
      "Test score: 0.531498815996427\n",
      "Look! elu softsign selu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softplus hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_292 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1025 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_736 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1026 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_737 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1027 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 30s 64ms/step - loss: 0.8538 - acc: 0.2166 - val_loss: 0.5681 - val_acc: 0.1489\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8518 - acc: 0.2208 - val_loss: 0.5287 - val_acc: 0.2199\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7135 - acc: 0.2314 - val_loss: 0.5093 - val_acc: 0.2340\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7298 - acc: 0.2357 - val_loss: 0.5169 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7120 - acc: 0.2314 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7440 - acc: 0.2293 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7190 - acc: 0.2505 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6670 - acc: 0.2590 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6888 - acc: 0.2335 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: 0.6975 - acc: 0.2611 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6684 - acc: 0.2675 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6736 - acc: 0.2272 - val_loss: 0.5179 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6963 - acc: 0.2420 - val_loss: 0.5073 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6865 - acc: 0.2696 - val_loss: 0.4988 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6713 - acc: 0.2590 - val_loss: 0.4954 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6555 - acc: 0.2442 - val_loss: 0.5040 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6522 - acc: 0.2675 - val_loss: 0.5057 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6920 - acc: 0.2590 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6831 - acc: 0.2739 - val_loss: 0.4982 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6705 - acc: 0.2654 - val_loss: 0.4976 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6602 - acc: 0.2611 - val_loss: 0.5001 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6708 - acc: 0.2442 - val_loss: 0.5022 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6799 - acc: 0.2696 - val_loss: 0.5074 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6625 - acc: 0.2590 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6965 - acc: 0.2251 - val_loss: 0.5085 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6414 - acc: 0.2611 - val_loss: 0.5090 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6387 - acc: 0.2527 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6653 - acc: 0.2420 - val_loss: 0.5077 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6581 - acc: 0.2420 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6731 - acc: 0.2442 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6472 - acc: 0.2527 - val_loss: 0.5086 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6514 - acc: 0.2548 - val_loss: 0.5045 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6662 - acc: 0.2548 - val_loss: 0.5032 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6585 - acc: 0.2378 - val_loss: 0.5011 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6604 - acc: 0.2548 - val_loss: 0.4980 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6285 - acc: 0.2590 - val_loss: 0.5002 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6458 - acc: 0.2484 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6507 - acc: 0.2569 - val_loss: 0.5029 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6600 - acc: 0.2548 - val_loss: 0.5032 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6353 - acc: 0.2611 - val_loss: 0.5052 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6480 - acc: 0.2633 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6458 - acc: 0.2654 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6423 - acc: 0.2378 - val_loss: 0.5086 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6513 - acc: 0.2527 - val_loss: 0.5086 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6340 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6449 - acc: 0.2484 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6413 - acc: 0.2484 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6436 - acc: 0.2484 - val_loss: 0.5076 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6718 - acc: 0.2463 - val_loss: 0.5069 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6485 - acc: 0.2378 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6468 - acc: 0.2633 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6462 - acc: 0.2378 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6394 - acc: 0.2463 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6351 - acc: 0.2611 - val_loss: 0.5085 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6489 - acc: 0.2548 - val_loss: 0.5098 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6500 - acc: 0.2569 - val_loss: 0.5066 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6532 - acc: 0.2378 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6436 - acc: 0.2484 - val_loss: 0.5042 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6432 - acc: 0.2527 - val_loss: 0.5037 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6316 - acc: 0.2569 - val_loss: 0.5027 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6397 - acc: 0.2675 - val_loss: 0.5029 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6409 - acc: 0.2569 - val_loss: 0.5033 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6346 - acc: 0.2527 - val_loss: 0.5040 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6460 - acc: 0.2611 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6353 - acc: 0.2569 - val_loss: 0.5059 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6509 - acc: 0.2527 - val_loss: 0.5074 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6180 - acc: 0.2718 - val_loss: 0.5069 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6319 - acc: 0.2548 - val_loss: 0.5042 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6343 - acc: 0.2569 - val_loss: 0.5043 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6438 - acc: 0.2611 - val_loss: 0.5052 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6330 - acc: 0.2569 - val_loss: 0.5045 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6297 - acc: 0.2548 - val_loss: 0.5028 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6187 - acc: 0.2590 - val_loss: 0.5004 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6426 - acc: 0.2420 - val_loss: 0.5002 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6182 - acc: 0.2527 - val_loss: 0.5007 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6215 - acc: 0.2590 - val_loss: 0.5011 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6369 - acc: 0.2548 - val_loss: 0.5015 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6223 - acc: 0.2633 - val_loss: 0.5018 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6282 - acc: 0.2569 - val_loss: 0.5019 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6486 - acc: 0.2696 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6498 - acc: 0.2611 - val_loss: 0.5031 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6446 - acc: 0.2611 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6276 - acc: 0.2654 - val_loss: 0.5046 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6232 - acc: 0.2633 - val_loss: 0.5031 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6415 - acc: 0.2611 - val_loss: 0.5005 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6231 - acc: 0.2505 - val_loss: 0.5008 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6415 - acc: 0.2548 - val_loss: 0.5022 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6243 - acc: 0.2569 - val_loss: 0.5042 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6242 - acc: 0.2654 - val_loss: 0.5045 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6177 - acc: 0.2463 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6377 - acc: 0.2654 - val_loss: 0.5038 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6347 - acc: 0.2569 - val_loss: 0.5032 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6376 - acc: 0.2548 - val_loss: 0.5030 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6331 - acc: 0.2590 - val_loss: 0.5034 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6277 - acc: 0.2569 - val_loss: 0.5064 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6485 - acc: 0.2527 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5062 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6361 - acc: 0.2718 - val_loss: 0.5052 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6343 - acc: 0.2696 - val_loss: 0.5030 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6242 - acc: 0.2527 - val_loss: 0.5007 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6270 - acc: 0.2590 - val_loss: 0.5009 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6192 - acc: 0.2505 - val_loss: 0.5013 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6360 - acc: 0.2739 - val_loss: 0.5031 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6252 - acc: 0.2569 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6251 - acc: 0.2675 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6333 - acc: 0.2548 - val_loss: 0.5011 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6301 - acc: 0.2611 - val_loss: 0.5008 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6327 - acc: 0.2527 - val_loss: 0.5028 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6354 - acc: 0.2675 - val_loss: 0.5027 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6271 - acc: 0.2611 - val_loss: 0.5018 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6383 - acc: 0.2484 - val_loss: 0.5029 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6276 - acc: 0.2611 - val_loss: 0.5019 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6375 - acc: 0.2590 - val_loss: 0.4965 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6342 - acc: 0.2548 - val_loss: 0.4946 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6262 - acc: 0.2527 - val_loss: 0.4952 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6335 - acc: 0.2484 - val_loss: 0.4926 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6217 - acc: 0.2569 - val_loss: 0.4923 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6289 - acc: 0.2633 - val_loss: 0.4959 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6334 - acc: 0.2505 - val_loss: 0.4937 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6119 - acc: 0.2548 - val_loss: 0.4926 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 184us/step\n",
      "Test score: 0.49259542742519513\n",
      "Look! elu softsign softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softplus hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_293 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1028 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_738 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1029 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_739 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1030 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 31s 65ms/step - loss: 3.2175 - acc: 0.1423 - val_loss: 3.5456 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.3534 - acc: 0.1295 - val_loss: 2.7731 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.7666 - acc: 0.1699 - val_loss: 3.6580 - val_acc: 0.0709\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.9088 - acc: 0.1826 - val_loss: 5.1441 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.8220 - acc: 0.1762 - val_loss: 4.6868 - val_acc: 0.0426\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 3.1318 - acc: 0.2144 - val_loss: 3.0504 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.0171 - acc: 0.1699 - val_loss: 1.7461 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.1516 - acc: 0.1699 - val_loss: 0.8415 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.0617 - acc: 0.1486 - val_loss: 0.7927 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.2569 - acc: 0.1783 - val_loss: 1.1784 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.9234 - acc: 0.1847 - val_loss: 2.2075 - val_acc: 0.0993\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 3.1070 - acc: 0.1953 - val_loss: 2.0086 - val_acc: 0.0851\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.1491 - acc: 0.2017 - val_loss: 2.3657 - val_acc: 0.0851\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.7053 - acc: 0.2208 - val_loss: 3.7052 - val_acc: 0.0709\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.0336 - acc: 0.2335 - val_loss: 3.1138 - val_acc: 0.0567\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.0867 - acc: 0.1996 - val_loss: 2.8834 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.6645 - acc: 0.1762 - val_loss: 2.2249 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.3607 - acc: 0.2166 - val_loss: 2.7453 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.9776 - acc: 0.2378 - val_loss: 3.2512 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.9344 - acc: 0.2166 - val_loss: 4.0034 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.3638 - acc: 0.2357 - val_loss: 4.1086 - val_acc: 0.0426\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.9338 - acc: 0.2059 - val_loss: 4.0328 - val_acc: 0.0426\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.9030 - acc: 0.2378 - val_loss: 3.0800 - val_acc: 0.0426\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.3142 - acc: 0.2548 - val_loss: 1.6855 - val_acc: 0.0426\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.7565 - acc: 0.2548 - val_loss: 1.4142 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.1239 - acc: 0.2463 - val_loss: 1.2764 - val_acc: 0.0567\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.1008 - acc: 0.2399 - val_loss: 1.2726 - val_acc: 0.1277\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.7655 - acc: 0.2548 - val_loss: 1.1545 - val_acc: 0.1348\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.9518 - acc: 0.2803 - val_loss: 0.9936 - val_acc: 0.1277\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.9636 - acc: 0.2909 - val_loss: 1.1366 - val_acc: 0.1277\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.0328 - acc: 0.2590 - val_loss: 1.6781 - val_acc: 0.1277\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.1059 - acc: 0.2357 - val_loss: 1.6396 - val_acc: 0.1277\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.4157 - acc: 0.2357 - val_loss: 1.2004 - val_acc: 0.1277\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 3.1880 - acc: 0.2357 - val_loss: 1.0510 - val_acc: 0.1277\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 3.3006 - acc: 0.2548 - val_loss: 1.0766 - val_acc: 0.1206\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.6624 - acc: 0.2718 - val_loss: 1.1066 - val_acc: 0.1135\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.0928 - acc: 0.2675 - val_loss: 0.8929 - val_acc: 0.0922\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.0951 - acc: 0.2633 - val_loss: 0.9180 - val_acc: 0.1135\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 2.6663 - acc: 0.2442 - val_loss: 0.8922 - val_acc: 0.1277\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.9070 - acc: 0.2675 - val_loss: 1.1643 - val_acc: 0.1277\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.8700 - acc: 0.2718 - val_loss: 2.9077 - val_acc: 0.1277\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.3757 - acc: 0.2718 - val_loss: 5.0612 - val_acc: 0.1277\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 2.7714 - acc: 0.2527 - val_loss: 5.1441 - val_acc: 0.1277\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.3155 - acc: 0.2611 - val_loss: 4.7162 - val_acc: 0.1277\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.9945 - acc: 0.2845 - val_loss: 2.4352 - val_acc: 0.1277\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.7856 - acc: 0.2590 - val_loss: 2.8323 - val_acc: 0.1277\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.5978 - acc: 0.2718 - val_loss: 0.8702 - val_acc: 0.1277\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.4215 - acc: 0.2293 - val_loss: 0.7696 - val_acc: 0.1277\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.7864 - acc: 0.2484 - val_loss: 0.8718 - val_acc: 0.1277\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.5380 - acc: 0.2378 - val_loss: 0.8730 - val_acc: 0.1277\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.5625 - acc: 0.2803 - val_loss: 1.0967 - val_acc: 0.1277\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.6999 - acc: 0.2442 - val_loss: 1.4915 - val_acc: 0.1277\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.6808 - acc: 0.2803 - val_loss: 1.5249 - val_acc: 0.1135\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.9155 - acc: 0.2484 - val_loss: 1.5189 - val_acc: 0.1418\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.5411 - acc: 0.2378 - val_loss: 1.0913 - val_acc: 0.1135\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.5410 - acc: 0.2420 - val_loss: 1.0965 - val_acc: 0.1135\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.5273 - acc: 0.2059 - val_loss: 1.0449 - val_acc: 0.1135\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.6876 - acc: 0.2718 - val_loss: 0.7053 - val_acc: 0.1135\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.3213 - acc: 0.2378 - val_loss: 0.8755 - val_acc: 0.1206\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.4668 - acc: 0.2335 - val_loss: 0.7755 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.2558 - acc: 0.2611 - val_loss: 1.1079 - val_acc: 0.2057\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 1.9516 - acc: 0.2696 - val_loss: 1.1148 - val_acc: 0.2057\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.5119 - acc: 0.2335 - val_loss: 0.8543 - val_acc: 0.1986\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.2489 - acc: 0.2548 - val_loss: 0.7997 - val_acc: 0.2057\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.1722 - acc: 0.2378 - val_loss: 0.8020 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.3597 - acc: 0.2569 - val_loss: 0.7953 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.7640 - acc: 0.2611 - val_loss: 0.7812 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.3358 - acc: 0.2399 - val_loss: 0.8633 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.3229 - acc: 0.2845 - val_loss: 0.8106 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 2.3474 - acc: 0.2781 - val_loss: 0.8247 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.9656 - acc: 0.2972 - val_loss: 0.8452 - val_acc: 0.2553\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.5851 - acc: 0.3461 - val_loss: 0.8482 - val_acc: 0.5957\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.0858 - acc: 0.3588 - val_loss: 0.8462 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.4057 - acc: 0.3248 - val_loss: 0.8449 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.2670 - acc: 0.3503 - val_loss: 0.8437 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.5486 - acc: 0.3503 - val_loss: 0.8350 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.4623 - acc: 0.3206 - val_loss: 0.8259 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.4444 - acc: 0.3715 - val_loss: 0.8259 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.3577 - acc: 0.3333 - val_loss: 0.8264 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.4351 - acc: 0.3057 - val_loss: 0.8245 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.2903 - acc: 0.3907 - val_loss: 0.8197 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.9307 - acc: 0.3546 - val_loss: 0.8172 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.3881 - acc: 0.3631 - val_loss: 0.8162 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.0366 - acc: 0.3503 - val_loss: 0.8127 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 2.4021 - acc: 0.3864 - val_loss: 0.8205 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.4669 - acc: 0.3673 - val_loss: 0.8274 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.5928 - acc: 0.3737 - val_loss: 0.8316 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 2.3970 - acc: 0.3503 - val_loss: 0.8353 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.2522 - acc: 0.3609 - val_loss: 0.8351 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.6223 - acc: 0.3397 - val_loss: 0.8355 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.4848 - acc: 0.3567 - val_loss: 0.8335 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.4097 - acc: 0.3333 - val_loss: 0.8299 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.6512 - acc: 0.3567 - val_loss: 0.8257 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.1612 - acc: 0.3673 - val_loss: 0.8180 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 2.3622 - acc: 0.3333 - val_loss: 0.8025 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.2851 - acc: 0.3546 - val_loss: 0.7933 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.3611 - acc: 0.3461 - val_loss: 0.7897 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.3050 - acc: 0.3333 - val_loss: 0.7922 - val_acc: 0.6170\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.6586 - acc: 0.3333 - val_loss: 0.7852 - val_acc: 0.4113\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.9856 - acc: 0.3864 - val_loss: 0.7810 - val_acc: 0.3404\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.3021 - acc: 0.3503 - val_loss: 0.7851 - val_acc: 0.2553\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.9827 - acc: 0.3673 - val_loss: 0.7783 - val_acc: 0.5106\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 2.3455 - acc: 0.3609 - val_loss: 0.7811 - val_acc: 0.3688\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.3689 - acc: 0.3418 - val_loss: 0.7852 - val_acc: 0.3404\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.4474 - acc: 0.3227 - val_loss: 0.7870 - val_acc: 0.2837\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.9132 - acc: 0.3673 - val_loss: 0.7869 - val_acc: 0.2695\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.4862 - acc: 0.3461 - val_loss: 0.7880 - val_acc: 0.2695\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.2252 - acc: 0.3270 - val_loss: 0.7885 - val_acc: 0.2624\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.1184 - acc: 0.2803 - val_loss: 0.7868 - val_acc: 0.2199\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.0154 - acc: 0.3100 - val_loss: 0.7861 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.5933 - acc: 0.3015 - val_loss: 0.7863 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.4798 - acc: 0.3163 - val_loss: 0.7872 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.1057 - acc: 0.3163 - val_loss: 0.7879 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.5534 - acc: 0.2951 - val_loss: 0.7890 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.2799 - acc: 0.3503 - val_loss: 0.7889 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.2085 - acc: 0.2972 - val_loss: 0.7880 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 2.2798 - acc: 0.3036 - val_loss: 0.7864 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.0344 - acc: 0.3312 - val_loss: 0.7853 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: 2.3262 - acc: 0.2866 - val_loss: 0.7746 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.2592 - acc: 0.3079 - val_loss: 0.7731 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 197us/step\n",
      "Test score: 0.7731299983694199\n",
      "Look! elu softsign softsign Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softplus hard_sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_294 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1031 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_740 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1032 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_741 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1033 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 31s 65ms/step - loss: nan - acc: 0.4395 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 185us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 188us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 184us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 187us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 208us/step\n",
      "Test score: nan\n",
      "Look! elu softsign relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_295 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1034 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_742 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1035 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_743 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1036 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 30s 65ms/step - loss: 2.5682 - acc: 0.2696 - val_loss: 2.0649 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.9436 - acc: 0.2293 - val_loss: 4.2872 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.0453 - acc: 0.1911 - val_loss: 4.0595 - val_acc: 0.2057\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.2163 - acc: 0.2081 - val_loss: 3.3299 - val_acc: 0.1560\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.2983 - acc: 0.2590 - val_loss: 2.2197 - val_acc: 0.0780\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.9201 - acc: 0.1890 - val_loss: 1.5015 - val_acc: 0.0496\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.7646 - acc: 0.1911 - val_loss: 1.1610 - val_acc: 0.0355\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.5270 - acc: 0.2187 - val_loss: 0.9352 - val_acc: 0.0355\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.5833 - acc: 0.1783 - val_loss: 0.8952 - val_acc: 0.0355\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.7946 - acc: 0.2272 - val_loss: 0.8186 - val_acc: 0.0355\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.6840 - acc: 0.1847 - val_loss: 0.7779 - val_acc: 0.0355\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.1569 - acc: 0.2272 - val_loss: 0.7567 - val_acc: 0.0355\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.0580 - acc: 0.1635 - val_loss: 1.0254 - val_acc: 0.0355\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.3097 - acc: 0.1975 - val_loss: 1.2136 - val_acc: 0.0355\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.5083 - acc: 0.2399 - val_loss: 1.2125 - val_acc: 0.0355\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.2964 - acc: 0.2102 - val_loss: 1.2188 - val_acc: 0.0355\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.4883 - acc: 0.1953 - val_loss: 1.2993 - val_acc: 0.0355\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.0212 - acc: 0.1550 - val_loss: 1.2102 - val_acc: 0.0355\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.5573 - acc: 0.1571 - val_loss: 1.0064 - val_acc: 0.0355\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.5810 - acc: 0.1550 - val_loss: 1.3030 - val_acc: 0.0355\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.6539 - acc: 0.1720 - val_loss: 1.4878 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.1651 - acc: 0.1847 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.2543 - acc: 0.1380 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.3216 - acc: 0.1571 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.9188 - acc: 0.1996 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.0224 - acc: 0.1826 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.7738 - acc: 0.2123 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.7453 - acc: 0.2038 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.2351 - acc: 0.2081 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.2711 - acc: 0.2463 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.1835 - acc: 0.1783 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.9359 - acc: 0.2038 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.0690 - acc: 0.2081 - val_loss: 1.4861 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.3886 - acc: 0.1677 - val_loss: 1.4864 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.4161 - acc: 0.1677 - val_loss: 1.4868 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.0798 - acc: 0.1614 - val_loss: 1.4870 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.0507 - acc: 0.1316 - val_loss: 1.0215 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.5995 - acc: 0.1125 - val_loss: 0.8191 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.8143 - acc: 0.1295 - val_loss: 0.7324 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.1116 - acc: 0.1338 - val_loss: 1.4370 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.5420 - acc: 0.1316 - val_loss: 2.1228 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 3.7782 - acc: 0.1231 - val_loss: 2.6987 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 3.4101 - acc: 0.1592 - val_loss: 3.6401 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.4603 - acc: 0.1401 - val_loss: 4.4536 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.8712 - acc: 0.1571 - val_loss: 3.9196 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.4938 - acc: 0.1975 - val_loss: 4.1858 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.3023 - acc: 0.1699 - val_loss: 3.7746 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 3.5871 - acc: 0.1762 - val_loss: 3.6583 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.0957 - acc: 0.1996 - val_loss: 3.7732 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 3.6973 - acc: 0.1996 - val_loss: 3.6953 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 3.2851 - acc: 0.2166 - val_loss: 3.6401 - val_acc: 0.0426\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.1266 - acc: 0.2399 - val_loss: 3.6631 - val_acc: 0.1631\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.1612 - acc: 0.2739 - val_loss: 0.9442 - val_acc: 0.5957\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 2.4758 - acc: 0.2144 - val_loss: 0.6841 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.9674 - acc: 0.2059 - val_loss: 0.6341 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.5825 - acc: 0.2378 - val_loss: 0.6173 - val_acc: 0.6170\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.6266 - acc: 0.2654 - val_loss: 0.6086 - val_acc: 0.5674\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.3153 - acc: 0.2569 - val_loss: 0.6018 - val_acc: 0.5177\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.5379 - acc: 0.2548 - val_loss: 0.6142 - val_acc: 0.4752\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.2850 - acc: 0.2633 - val_loss: 0.6271 - val_acc: 0.3262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.0265 - acc: 0.2548 - val_loss: 0.6350 - val_acc: 0.2553\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.1761 - acc: 0.2590 - val_loss: 0.6271 - val_acc: 0.2057\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.2924 - acc: 0.2590 - val_loss: 0.6189 - val_acc: 0.2199\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.0381 - acc: 0.2335 - val_loss: 0.6161 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.2111 - acc: 0.2272 - val_loss: 0.6136 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.0130 - acc: 0.2442 - val_loss: 0.6068 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.5760 - acc: 0.2335 - val_loss: 0.6032 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.9423 - acc: 0.2760 - val_loss: 0.5999 - val_acc: 0.2199\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.1889 - acc: 0.2590 - val_loss: 0.5946 - val_acc: 0.2340\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.8103 - acc: 0.2102 - val_loss: 0.5946 - val_acc: 0.2199\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.6717 - acc: 0.2887 - val_loss: 0.5939 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.6582 - acc: 0.2569 - val_loss: 0.5939 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.5428 - acc: 0.2845 - val_loss: 0.5929 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.4500 - acc: 0.2824 - val_loss: 0.5902 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.4024 - acc: 0.3206 - val_loss: 0.5881 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.5393 - acc: 0.2696 - val_loss: 0.5851 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.1765 - acc: 0.2696 - val_loss: 0.5828 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.4685 - acc: 0.2569 - val_loss: 0.5750 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.3682 - acc: 0.2739 - val_loss: 0.5726 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.3965 - acc: 0.2527 - val_loss: 0.5681 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.4316 - acc: 0.2505 - val_loss: 0.5627 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.6591 - acc: 0.2399 - val_loss: 0.5511 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.2497 - acc: 0.2208 - val_loss: 0.5417 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.2631 - acc: 0.2463 - val_loss: 0.5443 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.3733 - acc: 0.2633 - val_loss: 0.5458 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.6362 - acc: 0.2718 - val_loss: 0.5608 - val_acc: 0.1631\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.3254 - acc: 0.2527 - val_loss: 0.5588 - val_acc: 0.1277\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.2492 - acc: 0.2611 - val_loss: 0.5387 - val_acc: 0.1277\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 1.5145 - acc: 0.2505 - val_loss: 0.7467 - val_acc: 0.1277\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.2660 - acc: 0.2293 - val_loss: 0.8662 - val_acc: 0.1277\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.2828 - acc: 0.2123 - val_loss: 0.8294 - val_acc: 0.1277\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.5571 - acc: 0.2187 - val_loss: 0.8230 - val_acc: 0.1277\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.2814 - acc: 0.2527 - val_loss: 0.8131 - val_acc: 0.1277\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.3593 - acc: 0.2335 - val_loss: 0.8091 - val_acc: 0.1277\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2959 - acc: 0.1868 - val_loss: 0.8052 - val_acc: 0.1277\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.2114 - acc: 0.2166 - val_loss: 0.8105 - val_acc: 0.1277\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.4680 - acc: 0.2144 - val_loss: 0.8230 - val_acc: 0.1277\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.4270 - acc: 0.2335 - val_loss: 0.8247 - val_acc: 0.1277\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.4426 - acc: 0.2378 - val_loss: 0.8220 - val_acc: 0.1277\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.4155 - acc: 0.2187 - val_loss: 0.8194 - val_acc: 0.1277\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.2406 - acc: 0.2038 - val_loss: 0.8143 - val_acc: 0.1277\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.3743 - acc: 0.2314 - val_loss: 0.8109 - val_acc: 0.1277\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.4369 - acc: 0.2314 - val_loss: 0.8065 - val_acc: 0.1277\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.1459 - acc: 0.2548 - val_loss: 0.8033 - val_acc: 0.1277\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 1.3605 - acc: 0.2272 - val_loss: 0.8129 - val_acc: 0.1348\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.2242 - acc: 0.2251 - val_loss: 0.8191 - val_acc: 0.1277\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.4467 - acc: 0.2081 - val_loss: 0.8115 - val_acc: 0.1277\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.3073 - acc: 0.2442 - val_loss: 0.8064 - val_acc: 0.1277\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.2511 - acc: 0.2272 - val_loss: 0.8025 - val_acc: 0.1277\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 1.5058 - acc: 0.2251 - val_loss: 0.8024 - val_acc: 0.1277\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.5858 - acc: 0.2399 - val_loss: 0.8029 - val_acc: 0.1277\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.3126 - acc: 0.2102 - val_loss: 0.8149 - val_acc: 0.1206\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.3538 - acc: 0.1868 - val_loss: 0.8212 - val_acc: 0.1206\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.3530 - acc: 0.2208 - val_loss: 0.8226 - val_acc: 0.1064\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.2219 - acc: 0.2229 - val_loss: 0.8217 - val_acc: 0.1135\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.3102 - acc: 0.2335 - val_loss: 0.8181 - val_acc: 0.0922\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.4241 - acc: 0.2293 - val_loss: 0.8149 - val_acc: 0.0993\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.2721 - acc: 0.2548 - val_loss: 0.8107 - val_acc: 0.0851\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.2323 - acc: 0.2781 - val_loss: 0.8059 - val_acc: 0.0993\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2302 - acc: 0.2059 - val_loss: 0.8108 - val_acc: 0.1064\n",
      "141/141 [==============================] - 0s 189us/step\n",
      "Test score: 0.8107575841829286\n",
      "Look! elu softsign tanh Test accuracy: 0.10638297898760925\n",
      "max there  0.6241134772909448 elu softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_296 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1037 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_744 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1038 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_745 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1039 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 31s 66ms/step - loss: 0.8263 - acc: 0.2930 - val_loss: 0.5144 - val_acc: 0.2057\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6919 - acc: 0.2314 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7325 - acc: 0.2505 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7014 - acc: 0.2335 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6850 - acc: 0.2399 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6940 - acc: 0.2314 - val_loss: 0.5371 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6993 - acc: 0.2527 - val_loss: 0.5387 - val_acc: 0.1773\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6936 - acc: 0.2442 - val_loss: 0.5364 - val_acc: 0.2270\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6605 - acc: 0.2590 - val_loss: 0.5303 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6642 - acc: 0.2420 - val_loss: 0.5336 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6926 - acc: 0.2420 - val_loss: 0.5367 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6664 - acc: 0.2102 - val_loss: 0.5333 - val_acc: 0.2270\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6915 - acc: 0.2527 - val_loss: 0.5354 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6662 - acc: 0.2569 - val_loss: 0.5420 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7015 - acc: 0.2505 - val_loss: 0.5365 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6815 - acc: 0.2335 - val_loss: 0.5352 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7045 - acc: 0.2463 - val_loss: 0.5413 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6882 - acc: 0.2399 - val_loss: 0.5389 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6816 - acc: 0.2229 - val_loss: 0.5410 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6724 - acc: 0.2229 - val_loss: 0.5432 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6620 - acc: 0.2611 - val_loss: 0.5417 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6591 - acc: 0.2314 - val_loss: 0.5356 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6555 - acc: 0.2314 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6733 - acc: 0.2144 - val_loss: 0.5325 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6627 - acc: 0.2293 - val_loss: 0.5303 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6658 - acc: 0.2420 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6810 - acc: 0.2378 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6692 - acc: 0.2548 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6759 - acc: 0.2484 - val_loss: 0.5175 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6588 - acc: 0.2442 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6683 - acc: 0.2463 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6444 - acc: 0.2314 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6828 - acc: 0.2484 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6520 - acc: 0.2527 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6921 - acc: 0.2420 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6908 - acc: 0.2272 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6522 - acc: 0.2420 - val_loss: 0.5241 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6764 - acc: 0.2442 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6556 - acc: 0.2463 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6679 - acc: 0.2548 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6533 - acc: 0.2484 - val_loss: 0.5330 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6652 - acc: 0.2293 - val_loss: 0.5290 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6648 - acc: 0.2420 - val_loss: 0.5267 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6811 - acc: 0.2229 - val_loss: 0.5274 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6581 - acc: 0.2314 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6676 - acc: 0.2208 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6806 - acc: 0.2144 - val_loss: 0.5251 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6485 - acc: 0.2357 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6466 - acc: 0.2611 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6676 - acc: 0.2335 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 218us/step - loss: 0.6724 - acc: 0.2484 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6514 - acc: 0.2484 - val_loss: 0.5258 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6718 - acc: 0.2335 - val_loss: 0.5242 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6612 - acc: 0.2548 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6623 - acc: 0.2229 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6742 - acc: 0.2399 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6535 - acc: 0.2335 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6592 - acc: 0.2463 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6775 - acc: 0.2314 - val_loss: 0.5259 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6531 - acc: 0.2399 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6675 - acc: 0.2399 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6715 - acc: 0.2357 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6578 - acc: 0.2293 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6504 - acc: 0.2357 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6684 - acc: 0.2378 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6530 - acc: 0.2505 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6799 - acc: 0.2442 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6459 - acc: 0.2505 - val_loss: 0.5274 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6400 - acc: 0.2420 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6641 - acc: 0.2548 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6429 - acc: 0.2357 - val_loss: 0.5221 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6821 - acc: 0.2314 - val_loss: 0.5278 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6926 - acc: 0.2420 - val_loss: 0.5278 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6571 - acc: 0.2484 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6482 - acc: 0.2378 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6669 - acc: 0.2399 - val_loss: 0.5293 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6505 - acc: 0.2505 - val_loss: 0.5337 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6451 - acc: 0.2569 - val_loss: 0.5344 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6537 - acc: 0.2696 - val_loss: 0.5328 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6741 - acc: 0.2399 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6618 - acc: 0.2442 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6501 - acc: 0.2505 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6408 - acc: 0.2654 - val_loss: 0.5279 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6768 - acc: 0.2569 - val_loss: 0.5280 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6450 - acc: 0.2590 - val_loss: 0.5262 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6447 - acc: 0.2378 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6323 - acc: 0.2633 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6581 - acc: 0.2590 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6742 - acc: 0.2590 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6343 - acc: 0.2505 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 237us/step - loss: 0.6639 - acc: 0.2548 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6512 - acc: 0.2633 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6478 - acc: 0.2505 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6731 - acc: 0.2569 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6588 - acc: 0.2569 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6427 - acc: 0.2675 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6822 - acc: 0.2463 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6548 - acc: 0.2527 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6600 - acc: 0.2548 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6359 - acc: 0.2484 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6589 - acc: 0.2654 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6621 - acc: 0.2548 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6700 - acc: 0.2548 - val_loss: 0.5226 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6574 - acc: 0.2633 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6547 - acc: 0.2633 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6543 - acc: 0.2590 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6612 - acc: 0.2590 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6391 - acc: 0.2527 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6540 - acc: 0.2505 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6787 - acc: 0.2569 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6696 - acc: 0.2590 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6724 - acc: 0.2548 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6846 - acc: 0.2569 - val_loss: 0.5169 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6477 - acc: 0.2590 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6952 - acc: 0.2611 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6454 - acc: 0.2548 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6570 - acc: 0.2569 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6382 - acc: 0.2611 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6773 - acc: 0.2611 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6375 - acc: 0.2569 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 202us/step\n",
      "Test score: 0.5122688019529302\n",
      "Look! elu softsign sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_297 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1040 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_746 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1041 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_747 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1042 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 31s 65ms/step - loss: 1.5021 - acc: 0.2845 - val_loss: 0.5892 - val_acc: 0.3050\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.0512 - acc: 0.2357 - val_loss: 0.5426 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.9789 - acc: 0.3015 - val_loss: 0.5346 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.8178 - acc: 0.2527 - val_loss: 0.5333 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.8571 - acc: 0.2760 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.8262 - acc: 0.2484 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.8223 - acc: 0.2675 - val_loss: 0.5371 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7705 - acc: 0.2930 - val_loss: 0.5369 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7040 - acc: 0.2654 - val_loss: 0.5376 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7194 - acc: 0.2357 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.8649 - acc: 0.2972 - val_loss: 0.5332 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7817 - acc: 0.2739 - val_loss: 0.5345 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7843 - acc: 0.2718 - val_loss: 0.5314 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7141 - acc: 0.2781 - val_loss: 0.5341 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.9086 - acc: 0.2527 - val_loss: 0.5373 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.8185 - acc: 0.2696 - val_loss: 0.5352 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7728 - acc: 0.2590 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.8144 - acc: 0.2866 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.9003 - acc: 0.2569 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.9504 - acc: 0.2633 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7421 - acc: 0.2463 - val_loss: 0.5277 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8826 - acc: 0.2739 - val_loss: 0.5276 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7822 - acc: 0.2951 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7370 - acc: 0.2887 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7182 - acc: 0.2760 - val_loss: 0.5285 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6960 - acc: 0.2760 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7029 - acc: 0.2633 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7402 - acc: 0.2781 - val_loss: 0.5323 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7780 - acc: 0.2548 - val_loss: 0.5309 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7356 - acc: 0.2739 - val_loss: 0.5314 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6980 - acc: 0.2760 - val_loss: 0.5304 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7162 - acc: 0.3036 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7334 - acc: 0.2803 - val_loss: 0.5298 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7919 - acc: 0.2633 - val_loss: 0.5311 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7252 - acc: 0.2505 - val_loss: 0.5311 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7985 - acc: 0.2505 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7475 - acc: 0.2675 - val_loss: 0.5275 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8361 - acc: 0.2845 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7133 - acc: 0.2696 - val_loss: 0.5288 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7919 - acc: 0.2866 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 41/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 212us/step - loss: 0.8616 - acc: 0.2548 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8276 - acc: 0.2654 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7113 - acc: 0.2781 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7800 - acc: 0.2718 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.8594 - acc: 0.2887 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8181 - acc: 0.2760 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8541 - acc: 0.2951 - val_loss: 0.5284 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8314 - acc: 0.2527 - val_loss: 0.5289 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7805 - acc: 0.2887 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7778 - acc: 0.2909 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7399 - acc: 0.2909 - val_loss: 0.5323 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7770 - acc: 0.2824 - val_loss: 0.5336 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7574 - acc: 0.2845 - val_loss: 0.5353 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7152 - acc: 0.2760 - val_loss: 0.5362 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7388 - acc: 0.3036 - val_loss: 0.5399 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7837 - acc: 0.2845 - val_loss: 0.5406 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7867 - acc: 0.2845 - val_loss: 0.5402 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7305 - acc: 0.2951 - val_loss: 0.5420 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7968 - acc: 0.3121 - val_loss: 0.5388 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7000 - acc: 0.2909 - val_loss: 0.5421 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6902 - acc: 0.2845 - val_loss: 0.5440 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7137 - acc: 0.2718 - val_loss: 0.5448 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7689 - acc: 0.2760 - val_loss: 0.5490 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6719 - acc: 0.2696 - val_loss: 0.5468 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7068 - acc: 0.2739 - val_loss: 0.5459 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7102 - acc: 0.3036 - val_loss: 0.5479 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6723 - acc: 0.2696 - val_loss: 0.5492 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7478 - acc: 0.2866 - val_loss: 0.5465 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7467 - acc: 0.3142 - val_loss: 0.5440 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7560 - acc: 0.2845 - val_loss: 0.5414 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7285 - acc: 0.2760 - val_loss: 0.5408 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7275 - acc: 0.2909 - val_loss: 0.5411 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7056 - acc: 0.2696 - val_loss: 0.5409 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6993 - acc: 0.2824 - val_loss: 0.5442 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7791 - acc: 0.2845 - val_loss: 0.5486 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7044 - acc: 0.2845 - val_loss: 0.5498 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.8116 - acc: 0.3036 - val_loss: 0.5480 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7204 - acc: 0.2611 - val_loss: 0.5482 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7224 - acc: 0.2845 - val_loss: 0.5450 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6941 - acc: 0.2803 - val_loss: 0.5461 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6596 - acc: 0.2909 - val_loss: 0.5440 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7215 - acc: 0.2930 - val_loss: 0.5424 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6731 - acc: 0.2824 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8144 - acc: 0.2803 - val_loss: 0.5408 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8256 - acc: 0.2781 - val_loss: 0.5424 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7816 - acc: 0.2696 - val_loss: 0.5413 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7429 - acc: 0.2994 - val_loss: 0.5404 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8329 - acc: 0.2994 - val_loss: 0.5433 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7264 - acc: 0.2866 - val_loss: 0.5493 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6932 - acc: 0.3121 - val_loss: 0.5507 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8348 - acc: 0.3015 - val_loss: 0.5508 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7519 - acc: 0.2803 - val_loss: 0.5461 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8260 - acc: 0.2611 - val_loss: 0.5418 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7879 - acc: 0.3057 - val_loss: 0.5371 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8627 - acc: 0.2442 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7393 - acc: 0.2845 - val_loss: 0.5311 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7089 - acc: 0.2803 - val_loss: 0.5305 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.8131 - acc: 0.2739 - val_loss: 0.5351 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6619 - acc: 0.2760 - val_loss: 0.5383 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7615 - acc: 0.2590 - val_loss: 0.5448 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7133 - acc: 0.2569 - val_loss: 0.5487 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7930 - acc: 0.2781 - val_loss: 0.5519 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 239us/step - loss: 0.7258 - acc: 0.2803 - val_loss: 0.5510 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7256 - acc: 0.2527 - val_loss: 0.5467 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7220 - acc: 0.2527 - val_loss: 0.5421 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7602 - acc: 0.2781 - val_loss: 0.5378 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7814 - acc: 0.2590 - val_loss: 0.5282 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.8132 - acc: 0.2442 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7764 - acc: 0.2675 - val_loss: 0.5281 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.8548 - acc: 0.2781 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7571 - acc: 0.2781 - val_loss: 0.5283 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7988 - acc: 0.2866 - val_loss: 0.5304 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.8266 - acc: 0.2569 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.8011 - acc: 0.2803 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.7099 - acc: 0.2866 - val_loss: 0.5383 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7361 - acc: 0.2866 - val_loss: 0.5571 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7239 - acc: 0.2909 - val_loss: 0.5612 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6962 - acc: 0.2569 - val_loss: 0.5660 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7003 - acc: 0.2972 - val_loss: 0.5666 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6953 - acc: 0.2781 - val_loss: 0.5693 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 219us/step\n",
      "Test score: 0.5693385770134892\n",
      "Look! elu softsign hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_298 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1043 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_748 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1044 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_749 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1045 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 31s 65ms/step - loss: 3.3630 - acc: 0.2463 - val_loss: 1.5688 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.4351 - acc: 0.2399 - val_loss: 1.6272 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.1749 - acc: 0.2229 - val_loss: 1.5874 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.3185 - acc: 0.2569 - val_loss: 1.6209 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.5550 - acc: 0.2208 - val_loss: 1.6108 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.3484 - acc: 0.2357 - val_loss: 1.4881 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.5553 - acc: 0.2229 - val_loss: 3.7723 - val_acc: 0.2695\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.6289 - acc: 0.2314 - val_loss: 5.4952 - val_acc: 0.1560\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.1497 - acc: 0.2314 - val_loss: 5.5116 - val_acc: 0.1277\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.0600 - acc: 0.2187 - val_loss: 5.5217 - val_acc: 0.1277\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.6377 - acc: 0.2187 - val_loss: 3.9013 - val_acc: 0.1277\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.1714 - acc: 0.2229 - val_loss: 2.7038 - val_acc: 0.1277\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.8839 - acc: 0.2208 - val_loss: 2.5359 - val_acc: 0.1277\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.1543 - acc: 0.2229 - val_loss: 1.1033 - val_acc: 0.1277\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.5895 - acc: 0.2420 - val_loss: 0.7141 - val_acc: 0.1277\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.7352 - acc: 0.3121 - val_loss: 0.5999 - val_acc: 0.0922\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.9975 - acc: 0.2569 - val_loss: 0.5559 - val_acc: 0.4113\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.9666 - acc: 0.2972 - val_loss: 0.5200 - val_acc: 0.5957\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.7661 - acc: 0.2739 - val_loss: 0.5193 - val_acc: 0.0567\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.5439 - acc: 0.2378 - val_loss: 0.5161 - val_acc: 0.0496\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 1.5034 - acc: 0.2569 - val_loss: 0.5172 - val_acc: 0.0355\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.4672 - acc: 0.2527 - val_loss: 0.5226 - val_acc: 0.0355\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.5842 - acc: 0.2484 - val_loss: 0.6231 - val_acc: 0.0355\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.6188 - acc: 0.1932 - val_loss: 0.7970 - val_acc: 0.0355\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.4956 - acc: 0.1996 - val_loss: 0.8699 - val_acc: 0.0355\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.2910 - acc: 0.1656 - val_loss: 0.9478 - val_acc: 0.0355\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.4840 - acc: 0.1677 - val_loss: 0.9343 - val_acc: 0.0355\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.7548 - acc: 0.1401 - val_loss: 0.9027 - val_acc: 0.0355\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.4143 - acc: 0.1104 - val_loss: 0.8759 - val_acc: 0.0355\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.6842 - acc: 0.1062 - val_loss: 0.8491 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.7035 - acc: 0.1040 - val_loss: 0.8354 - val_acc: 0.0355\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.6480 - acc: 0.0828 - val_loss: 0.8312 - val_acc: 0.0355\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.7245 - acc: 0.0616 - val_loss: 0.8194 - val_acc: 0.0355\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.4061 - acc: 0.0828 - val_loss: 0.8063 - val_acc: 0.0355\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.7553 - acc: 0.0701 - val_loss: 0.7887 - val_acc: 0.0355\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.7481 - acc: 0.0594 - val_loss: 0.7541 - val_acc: 0.0355\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.7912 - acc: 0.0446 - val_loss: 0.6771 - val_acc: 0.0355\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.1396 - acc: 0.0531 - val_loss: 0.6522 - val_acc: 0.0355\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.0096 - acc: 0.0552 - val_loss: 0.6523 - val_acc: 0.0355\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.2973 - acc: 0.0488 - val_loss: 0.6237 - val_acc: 0.0355\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.5854 - acc: 0.0488 - val_loss: 0.6264 - val_acc: 0.0355\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.4827 - acc: 0.0446 - val_loss: 0.6192 - val_acc: 0.0355\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.9038 - acc: 0.0488 - val_loss: 0.6237 - val_acc: 0.0355\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.5714 - acc: 0.0446 - val_loss: 0.6194 - val_acc: 0.0355\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.4953 - acc: 0.0425 - val_loss: 0.6137 - val_acc: 0.0355\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.2355 - acc: 0.0446 - val_loss: 0.6437 - val_acc: 0.0355\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.3517 - acc: 0.0488 - val_loss: 0.6922 - val_acc: 0.0355\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.4360 - acc: 0.0467 - val_loss: 3.3151 - val_acc: 0.0355\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.9884 - acc: 0.0446 - val_loss: 5.5561 - val_acc: 0.0355\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.0830 - acc: 0.0467 - val_loss: 6.0288 - val_acc: 0.0355\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.5175 - acc: 0.0488 - val_loss: 6.4015 - val_acc: 0.0355\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.9926 - acc: 0.0510 - val_loss: 6.2212 - val_acc: 0.0355\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.7804 - acc: 0.0488 - val_loss: 5.1642 - val_acc: 0.0355\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.7973 - acc: 0.0552 - val_loss: 3.5076 - val_acc: 0.0355\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 3.6945 - acc: 0.0510 - val_loss: 3.3992 - val_acc: 0.0355\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.0732 - acc: 0.0531 - val_loss: 3.3773 - val_acc: 0.0355\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.6008 - acc: 0.0658 - val_loss: 3.6583 - val_acc: 0.0355\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.4993 - acc: 0.0552 - val_loss: 5.0048 - val_acc: 0.0355\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 3.7542 - acc: 0.0552 - val_loss: 3.4562 - val_acc: 0.0355\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 3.6082 - acc: 0.0616 - val_loss: 3.3443 - val_acc: 0.0355\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.0884 - acc: 0.0658 - val_loss: 3.2850 - val_acc: 0.0355\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 3.0294 - acc: 0.0913 - val_loss: 3.2678 - val_acc: 0.0355\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.7863 - acc: 0.1040 - val_loss: 3.1361 - val_acc: 0.0355\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.6251 - acc: 0.1083 - val_loss: 2.8850 - val_acc: 0.0355\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.1181 - acc: 0.1062 - val_loss: 3.0266 - val_acc: 0.0355\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.7132 - acc: 0.1168 - val_loss: 2.4722 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.9629 - acc: 0.1465 - val_loss: 2.4114 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 2.6499 - acc: 0.1614 - val_loss: 2.0395 - val_acc: 0.0709\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.3346 - acc: 0.1805 - val_loss: 1.9312 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.5054 - acc: 0.1656 - val_loss: 1.7307 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.4229 - acc: 0.2251 - val_loss: 0.8175 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.2089 - acc: 0.2038 - val_loss: 0.6452 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.6746 - acc: 0.2484 - val_loss: 0.6051 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.1332 - acc: 0.2633 - val_loss: 0.5652 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.1901 - acc: 0.2590 - val_loss: 0.5460 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.1274 - acc: 0.2760 - val_loss: 0.5398 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.0794 - acc: 0.2420 - val_loss: 0.5450 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.1403 - acc: 0.2803 - val_loss: 0.5601 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 2.4655 - acc: 0.2675 - val_loss: 0.5754 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.2559 - acc: 0.2930 - val_loss: 0.5788 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.9678 - acc: 0.2378 - val_loss: 0.5667 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 1.7060 - acc: 0.2803 - val_loss: 0.5568 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.7449 - acc: 0.2675 - val_loss: 0.5539 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.5911 - acc: 0.2909 - val_loss: 0.5528 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.5227 - acc: 0.2590 - val_loss: 0.5539 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.5654 - acc: 0.2505 - val_loss: 0.5498 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.7045 - acc: 0.2633 - val_loss: 0.5595 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.4922 - acc: 0.2866 - val_loss: 0.5490 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.3638 - acc: 0.2866 - val_loss: 0.5419 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.2277 - acc: 0.2399 - val_loss: 0.5414 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.3608 - acc: 0.2845 - val_loss: 0.5368 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.3674 - acc: 0.2420 - val_loss: 0.5414 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.2713 - acc: 0.2590 - val_loss: 0.5369 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.2799 - acc: 0.2696 - val_loss: 0.5349 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.0237 - acc: 0.2654 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.1839 - acc: 0.2420 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.9379 - acc: 0.2696 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.0485 - acc: 0.2548 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.0340 - acc: 0.2611 - val_loss: 0.5229 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.9562 - acc: 0.2548 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.1124 - acc: 0.2803 - val_loss: 0.5261 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.1777 - acc: 0.2803 - val_loss: 0.5298 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.9890 - acc: 0.2633 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.9467 - acc: 0.2590 - val_loss: 0.5345 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.2264 - acc: 0.2803 - val_loss: 0.5348 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.0948 - acc: 0.2781 - val_loss: 0.5344 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.0756 - acc: 0.2675 - val_loss: 0.5332 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.0249 - acc: 0.2654 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.0157 - acc: 0.2633 - val_loss: 0.5325 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.8226 - acc: 0.2484 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8835 - acc: 0.2527 - val_loss: 0.5263 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.9787 - acc: 0.2420 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.9367 - acc: 0.2335 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7764 - acc: 0.2420 - val_loss: 0.5286 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8577 - acc: 0.2272 - val_loss: 0.5314 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.9516 - acc: 0.2590 - val_loss: 0.5374 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.9222 - acc: 0.2887 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.8183 - acc: 0.2293 - val_loss: 0.5389 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7284 - acc: 0.2335 - val_loss: 0.5385 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.0030 - acc: 0.2102 - val_loss: 0.5335 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 198us/step\n",
      "Test score: 0.5335399419703382\n",
      "Look! elu softsign linear Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_299 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1046 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_750 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1047 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_751 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1048 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 31s 66ms/step - loss: 5.1692 - acc: 0.2102 - val_loss: 4.7923 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 5.7031 - acc: 0.1975 - val_loss: 4.6905 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 5.1422 - acc: 0.2144 - val_loss: 4.8256 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 5.3228 - acc: 0.1890 - val_loss: 4.7377 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 5.1503 - acc: 0.2017 - val_loss: 3.6792 - val_acc: 0.1418\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.5519 - acc: 0.2378 - val_loss: 3.3959 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 4.3877 - acc: 0.2357 - val_loss: 3.5353 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.3172 - acc: 0.2484 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 4.5741 - acc: 0.2335 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 4.5443 - acc: 0.2399 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 4.3708 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.4270 - acc: 0.2484 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3844 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 4.4152 - acc: 0.2484 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.1978 - acc: 0.2633 - val_loss: 3.5418 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.0304 - acc: 0.2760 - val_loss: 3.5392 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 4.6704 - acc: 0.2314 - val_loss: 3.5256 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.3165 - acc: 0.2527 - val_loss: 3.5183 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.4204 - acc: 0.2399 - val_loss: 3.5237 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.1705 - acc: 0.2633 - val_loss: 3.5435 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.4081 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.2052 - acc: 0.2611 - val_loss: 3.5319 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.1828 - acc: 0.2569 - val_loss: 3.5021 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.0310 - acc: 0.2696 - val_loss: 3.4091 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 4.1397 - acc: 0.2569 - val_loss: 3.4986 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.2115 - acc: 0.2569 - val_loss: 3.5417 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.0891 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.4148 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.4060 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.3618 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.3149 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.4231 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.5164 - acc: 0.2463 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.3765 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.4596 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 4.3461 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 4.3591 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.2748 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3215 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.4393 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 4.3842 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 4.2771 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 4.3301 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 4.3013 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 4.2740 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 4.2251 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.3642 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.2931 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.2126 - acc: 0.2675 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.3863 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 4.2553 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 4.1418 - acc: 0.2696 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 4.3217 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.2610 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.4906 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.3788 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3756 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3771 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 4.2827 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.3161 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.3239 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.2818 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.3656 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.3740 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 4.2763 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.3154 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 4.4154 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.3050 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 4.3726 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3329 - acc: 0.2590 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.2092 - acc: 0.2696 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.3078 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 4.4230 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.2534 - acc: 0.2675 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.1573 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3459 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 189us/step - loss: 4.1944 - acc: 0.2696 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 4.3905 - acc: 0.2548 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.9013 - acc: 0.2760 - val_loss: 3.4855 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 4.5290 - acc: 0.2399 - val_loss: 2.5783 - val_acc: 0.2553\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.9744 - acc: 0.2017 - val_loss: 2.9332 - val_acc: 0.2340\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.1955 - acc: 0.2590 - val_loss: 3.5312 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.3432 - acc: 0.2505 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.1367 - acc: 0.2760 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.9957 - acc: 0.2696 - val_loss: 3.5168 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.3801 - acc: 0.2505 - val_loss: 3.0705 - val_acc: 0.2340\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 4.3367 - acc: 0.2463 - val_loss: 3.1390 - val_acc: 0.2270\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.4190 - acc: 0.2505 - val_loss: 3.4560 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.1027 - acc: 0.2696 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 4.0542 - acc: 0.2739 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 4.1912 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.3569 - acc: 0.2569 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.2455 - acc: 0.2633 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.1949 - acc: 0.2654 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.1699 - acc: 0.2696 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.0921 - acc: 0.2718 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.3121 - acc: 0.2611 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 4.2286 - acc: 0.2611 - val_loss: 3.5398 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.2395 - acc: 0.2548 - val_loss: 3.3874 - val_acc: 0.2199\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.2413 - acc: 0.2590 - val_loss: 2.9796 - val_acc: 0.2340\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.9985 - acc: 0.2654 - val_loss: 2.5267 - val_acc: 0.2624\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 4.2677 - acc: 0.2505 - val_loss: 2.6892 - val_acc: 0.2553\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 4.1800 - acc: 0.2569 - val_loss: 3.0428 - val_acc: 0.2340\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 4.1985 - acc: 0.2654 - val_loss: 3.3280 - val_acc: 0.2199\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.0319 - acc: 0.2739 - val_loss: 3.4344 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 4.0895 - acc: 0.2696 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 4.3259 - acc: 0.2527 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 4.0604 - acc: 0.2675 - val_loss: 3.5437 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 4.0667 - acc: 0.2696 - val_loss: 3.5131 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 4.0606 - acc: 0.2718 - val_loss: 3.4572 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 4.2082 - acc: 0.2675 - val_loss: 3.4088 - val_acc: 0.2199\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 4.1063 - acc: 0.2675 - val_loss: 3.3824 - val_acc: 0.2199\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 4.0667 - acc: 0.2590 - val_loss: 3.1539 - val_acc: 0.2340\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 4.1343 - acc: 0.2696 - val_loss: 3.0888 - val_acc: 0.2340\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 4.0017 - acc: 0.2696 - val_loss: 2.7707 - val_acc: 0.2482\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.9986 - acc: 0.2739 - val_loss: 2.2864 - val_acc: 0.2766\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.9994 - acc: 0.2611 - val_loss: 2.3515 - val_acc: 0.2695\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 4.0912 - acc: 0.2611 - val_loss: 2.2784 - val_acc: 0.2837\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.7295 - acc: 0.2803 - val_loss: 2.3011 - val_acc: 0.2766\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 4.3558 - acc: 0.2399 - val_loss: 2.3421 - val_acc: 0.2766\n",
      "141/141 [==============================] - 0s 194us/step\n",
      "Test score: 2.3421138871646097\n",
      "Look! elu relu softmax Test accuracy: 0.276595745737671\n",
      "max there  0.6241134772909448 elu softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_300 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1049 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_752 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1050 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_753 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1051 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 31s 67ms/step - loss: 3.6776 - acc: 0.1762 - val_loss: 1.4679 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.8214 - acc: 0.1911 - val_loss: 1.3573 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.1975 - acc: 0.2399 - val_loss: 1.2585 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.9105 - acc: 0.2399 - val_loss: 0.5646 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.8917 - acc: 0.2081 - val_loss: 0.5442 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.5739 - acc: 0.1932 - val_loss: 0.5501 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.3493 - acc: 0.2548 - val_loss: 0.5166 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.2678 - acc: 0.2229 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.0577 - acc: 0.1975 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.8771 - acc: 0.2463 - val_loss: 0.5140 - val_acc: 0.2128\n",
      "Epoch 11/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 209us/step - loss: 1.0580 - acc: 0.2399 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.9873 - acc: 0.2505 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.9053 - acc: 0.2251 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.8916 - acc: 0.2399 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.8969 - acc: 0.2335 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.9547 - acc: 0.2314 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.8598 - acc: 0.2845 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7019 - acc: 0.2357 - val_loss: 0.5272 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7690 - acc: 0.2654 - val_loss: 0.5308 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 0.7972 - acc: 0.2675 - val_loss: 0.5322 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7729 - acc: 0.2569 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7124 - acc: 0.2696 - val_loss: 0.5302 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7655 - acc: 0.2123 - val_loss: 0.5280 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7049 - acc: 0.2420 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7236 - acc: 0.2399 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7473 - acc: 0.2654 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7259 - acc: 0.2378 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6996 - acc: 0.2548 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7469 - acc: 0.2442 - val_loss: 0.5224 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6503 - acc: 0.2781 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6749 - acc: 0.2527 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6909 - acc: 0.2548 - val_loss: 0.5200 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6863 - acc: 0.2654 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.8030 - acc: 0.2527 - val_loss: 0.5178 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6852 - acc: 0.2633 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6764 - acc: 0.2696 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6702 - acc: 0.2590 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6868 - acc: 0.2611 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6452 - acc: 0.2505 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7103 - acc: 0.2484 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6358 - acc: 0.2527 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6625 - acc: 0.2633 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7287 - acc: 0.2633 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6476 - acc: 0.2548 - val_loss: 0.5139 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.6748 - acc: 0.2654 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6641 - acc: 0.2505 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7450 - acc: 0.2590 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6830 - acc: 0.2548 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6955 - acc: 0.2696 - val_loss: 0.5115 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7496 - acc: 0.2484 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6351 - acc: 0.2654 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6902 - acc: 0.2590 - val_loss: 0.5089 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6751 - acc: 0.2527 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6452 - acc: 0.2527 - val_loss: 0.5127 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6431 - acc: 0.2611 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.7105 - acc: 0.2484 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6687 - acc: 0.2569 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6660 - acc: 0.2611 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6740 - acc: 0.2633 - val_loss: 0.5121 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6964 - acc: 0.2548 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6432 - acc: 0.2527 - val_loss: 0.5103 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6727 - acc: 0.2505 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6876 - acc: 0.2696 - val_loss: 0.5089 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6660 - acc: 0.2590 - val_loss: 0.5104 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6640 - acc: 0.2505 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6580 - acc: 0.2548 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6255 - acc: 0.2718 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6685 - acc: 0.2611 - val_loss: 0.5142 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6776 - acc: 0.2569 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6365 - acc: 0.2654 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6297 - acc: 0.2611 - val_loss: 0.5092 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6519 - acc: 0.2633 - val_loss: 0.5090 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6334 - acc: 0.2611 - val_loss: 0.5086 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6462 - acc: 0.2569 - val_loss: 0.5082 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6742 - acc: 0.2590 - val_loss: 0.5081 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6605 - acc: 0.2633 - val_loss: 0.5078 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6705 - acc: 0.2548 - val_loss: 0.5071 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6221 - acc: 0.2569 - val_loss: 0.5060 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6842 - acc: 0.2590 - val_loss: 0.5043 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7153 - acc: 0.2654 - val_loss: 0.5026 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.6988 - acc: 0.2590 - val_loss: 0.5018 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6258 - acc: 0.2611 - val_loss: 0.5014 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6976 - acc: 0.2611 - val_loss: 0.5033 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6769 - acc: 0.2611 - val_loss: 0.5052 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6276 - acc: 0.2633 - val_loss: 0.5057 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6586 - acc: 0.2611 - val_loss: 0.5055 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6286 - acc: 0.2527 - val_loss: 0.5043 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6235 - acc: 0.2527 - val_loss: 0.5031 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6735 - acc: 0.2611 - val_loss: 0.5021 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6308 - acc: 0.2548 - val_loss: 0.5014 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6538 - acc: 0.2611 - val_loss: 0.5013 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6188 - acc: 0.2633 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6284 - acc: 0.2633 - val_loss: 0.5030 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6158 - acc: 0.2611 - val_loss: 0.5033 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6242 - acc: 0.2590 - val_loss: 0.5030 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6129 - acc: 0.2675 - val_loss: 0.5016 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6310 - acc: 0.2527 - val_loss: 0.4998 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6724 - acc: 0.2590 - val_loss: 0.4991 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6298 - acc: 0.2569 - val_loss: 0.4981 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6341 - acc: 0.2633 - val_loss: 0.5006 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6524 - acc: 0.2611 - val_loss: 0.5023 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6281 - acc: 0.2569 - val_loss: 0.5029 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6752 - acc: 0.2505 - val_loss: 0.5032 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6254 - acc: 0.2611 - val_loss: 0.5033 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6259 - acc: 0.2505 - val_loss: 0.5024 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6084 - acc: 0.2675 - val_loss: 0.5010 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6440 - acc: 0.2633 - val_loss: 0.4992 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6748 - acc: 0.2654 - val_loss: 0.4977 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6263 - acc: 0.2675 - val_loss: 0.4965 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6106 - acc: 0.2611 - val_loss: 0.4953 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6488 - acc: 0.2633 - val_loss: 0.4946 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6590 - acc: 0.2527 - val_loss: 0.4951 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6398 - acc: 0.2548 - val_loss: 0.4951 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6177 - acc: 0.2675 - val_loss: 0.4945 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6013 - acc: 0.2611 - val_loss: 0.4933 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6034 - acc: 0.2633 - val_loss: 0.4914 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6413 - acc: 0.2548 - val_loss: 0.4896 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6476 - acc: 0.2590 - val_loss: 0.4883 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6163 - acc: 0.2654 - val_loss: 0.4875 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7513 - acc: 0.2569 - val_loss: 0.4870 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 187us/step\n",
      "Test score: 0.4870018113589456\n",
      "Look! elu relu elu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_301 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1052 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_754 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1053 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_755 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1054 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 31s 65ms/step - loss: 3.6801 - acc: 0.2739 - val_loss: 1.3947 - val_acc: 0.1418\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.0738 - acc: 0.2760 - val_loss: 0.9489 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.3761 - acc: 0.2527 - val_loss: 0.6984 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.0044 - acc: 0.2420 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.5659 - acc: 0.2611 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.6203 - acc: 0.2314 - val_loss: 0.5248 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.5537 - acc: 0.2314 - val_loss: 0.5317 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.3223 - acc: 0.2335 - val_loss: 0.6362 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.3193 - acc: 0.2442 - val_loss: 0.7028 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.1223 - acc: 0.2527 - val_loss: 0.5599 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.1325 - acc: 0.2314 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.9854 - acc: 0.2484 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.0167 - acc: 0.2378 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.8994 - acc: 0.2420 - val_loss: 0.5119 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8339 - acc: 0.2803 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8993 - acc: 0.2803 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8806 - acc: 0.2527 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7802 - acc: 0.2611 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8816 - acc: 0.2654 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.8075 - acc: 0.2781 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7577 - acc: 0.2887 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.8313 - acc: 0.2633 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8045 - acc: 0.2760 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7470 - acc: 0.2739 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8004 - acc: 0.2463 - val_loss: 0.5239 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7719 - acc: 0.2484 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.8027 - acc: 0.2781 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7957 - acc: 0.2739 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7504 - acc: 0.2718 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7467 - acc: 0.2293 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7482 - acc: 0.2463 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 196us/step - loss: 0.7247 - acc: 0.2696 - val_loss: 0.5250 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6877 - acc: 0.2590 - val_loss: 0.5253 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6927 - acc: 0.2442 - val_loss: 0.5251 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7017 - acc: 0.2781 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7171 - acc: 0.2569 - val_loss: 0.5260 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6672 - acc: 0.2633 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7029 - acc: 0.2675 - val_loss: 0.5265 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6655 - acc: 0.2463 - val_loss: 0.5264 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7931 - acc: 0.2527 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6771 - acc: 0.2590 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6560 - acc: 0.2611 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6866 - acc: 0.2569 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6835 - acc: 0.2696 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7045 - acc: 0.2590 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7061 - acc: 0.2463 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7077 - acc: 0.2484 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7424 - acc: 0.2611 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6663 - acc: 0.2675 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6757 - acc: 0.2463 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7033 - acc: 0.2569 - val_loss: 0.5159 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6773 - acc: 0.2505 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6629 - acc: 0.2675 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6935 - acc: 0.2590 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6934 - acc: 0.2633 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6702 - acc: 0.2484 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6780 - acc: 0.2569 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6896 - acc: 0.2505 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7100 - acc: 0.2484 - val_loss: 0.5136 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7293 - acc: 0.2654 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6609 - acc: 0.2569 - val_loss: 0.5134 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6360 - acc: 0.2633 - val_loss: 0.5132 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6771 - acc: 0.2654 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6833 - acc: 0.2527 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6398 - acc: 0.2675 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6903 - acc: 0.2611 - val_loss: 0.5124 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6779 - acc: 0.2548 - val_loss: 0.5120 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6777 - acc: 0.2548 - val_loss: 0.5116 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6351 - acc: 0.2633 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.7529 - acc: 0.2633 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6344 - acc: 0.2527 - val_loss: 0.5092 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7283 - acc: 0.2590 - val_loss: 0.5085 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7048 - acc: 0.2611 - val_loss: 0.5081 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6790 - acc: 0.2527 - val_loss: 0.5081 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6977 - acc: 0.2611 - val_loss: 0.5078 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6562 - acc: 0.2611 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6525 - acc: 0.2590 - val_loss: 0.5069 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6876 - acc: 0.2739 - val_loss: 0.5068 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7119 - acc: 0.2675 - val_loss: 0.5065 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6734 - acc: 0.2484 - val_loss: 0.5064 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6723 - acc: 0.2569 - val_loss: 0.5066 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6550 - acc: 0.2569 - val_loss: 0.5070 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6299 - acc: 0.2654 - val_loss: 0.5073 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6593 - acc: 0.2548 - val_loss: 0.5072 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6701 - acc: 0.2611 - val_loss: 0.5067 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6633 - acc: 0.2633 - val_loss: 0.5060 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6613 - acc: 0.2696 - val_loss: 0.5054 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7012 - acc: 0.2548 - val_loss: 0.5052 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6917 - acc: 0.2527 - val_loss: 0.5047 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6136 - acc: 0.2654 - val_loss: 0.5037 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6331 - acc: 0.2548 - val_loss: 0.5033 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6400 - acc: 0.2484 - val_loss: 0.5032 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6596 - acc: 0.2505 - val_loss: 0.5036 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6755 - acc: 0.2654 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6219 - acc: 0.2633 - val_loss: 0.5062 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6451 - acc: 0.2675 - val_loss: 0.5082 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6442 - acc: 0.2611 - val_loss: 0.5097 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6411 - acc: 0.2633 - val_loss: 0.5107 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6350 - acc: 0.2718 - val_loss: 0.5107 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6659 - acc: 0.2611 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6362 - acc: 0.2696 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6404 - acc: 0.2611 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6353 - acc: 0.2739 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6446 - acc: 0.2760 - val_loss: 0.5070 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6481 - acc: 0.2611 - val_loss: 0.5066 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6264 - acc: 0.2633 - val_loss: 0.5061 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6231 - acc: 0.2718 - val_loss: 0.5051 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6180 - acc: 0.2675 - val_loss: 0.5041 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6456 - acc: 0.2633 - val_loss: 0.5034 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6294 - acc: 0.2718 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6584 - acc: 0.2675 - val_loss: 0.5017 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6320 - acc: 0.2718 - val_loss: 0.5008 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6370 - acc: 0.2590 - val_loss: 0.5002 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6314 - acc: 0.2633 - val_loss: 0.4998 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6320 - acc: 0.2633 - val_loss: 0.4993 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6379 - acc: 0.2633 - val_loss: 0.4987 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6639 - acc: 0.2654 - val_loss: 0.4981 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6331 - acc: 0.2718 - val_loss: 0.4974 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6241 - acc: 0.2611 - val_loss: 0.4969 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6242 - acc: 0.2527 - val_loss: 0.4963 - val_acc: 0.2128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 208us/step\n",
      "Test score: 0.49625623902530536\n",
      "Look! elu relu selu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_302 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1055 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_756 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1056 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_757 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1057 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 32s 67ms/step - loss: 5.2462 - acc: 0.1210 - val_loss: 0.7500 - val_acc: 0.0355\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.2674 - acc: 0.1529 - val_loss: 0.5809 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.3978 - acc: 0.1868 - val_loss: 0.5460 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.1671 - acc: 0.2229 - val_loss: 0.5251 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.8706 - acc: 0.2654 - val_loss: 0.5207 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7993 - acc: 0.2633 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.8610 - acc: 0.2251 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7357 - acc: 0.2739 - val_loss: 0.5328 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7245 - acc: 0.2739 - val_loss: 0.5344 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7889 - acc: 0.2229 - val_loss: 0.5344 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6920 - acc: 0.2357 - val_loss: 0.5349 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6856 - acc: 0.2505 - val_loss: 0.5341 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7541 - acc: 0.2718 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7331 - acc: 0.2208 - val_loss: 0.5347 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6867 - acc: 0.2548 - val_loss: 0.5350 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7545 - acc: 0.2548 - val_loss: 0.5345 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6711 - acc: 0.2187 - val_loss: 0.5334 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7122 - acc: 0.2357 - val_loss: 0.5321 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6988 - acc: 0.2463 - val_loss: 0.5308 - val_acc: 0.2199\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6853 - acc: 0.2166 - val_loss: 0.5301 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6704 - acc: 0.2484 - val_loss: 0.5299 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7001 - acc: 0.2399 - val_loss: 0.5297 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6656 - acc: 0.2293 - val_loss: 0.5291 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6767 - acc: 0.2059 - val_loss: 0.5280 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6905 - acc: 0.2569 - val_loss: 0.5269 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6624 - acc: 0.2208 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6948 - acc: 0.2463 - val_loss: 0.5247 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6922 - acc: 0.2314 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6811 - acc: 0.1911 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6962 - acc: 0.2527 - val_loss: 0.5219 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6678 - acc: 0.2420 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6922 - acc: 0.2378 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6876 - acc: 0.2399 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6936 - acc: 0.2527 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6938 - acc: 0.2590 - val_loss: 0.5236 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7263 - acc: 0.2378 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6501 - acc: 0.2654 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6512 - acc: 0.2527 - val_loss: 0.5244 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6722 - acc: 0.2272 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6757 - acc: 0.2357 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6535 - acc: 0.2718 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6483 - acc: 0.2484 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6399 - acc: 0.2654 - val_loss: 0.5211 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.6573 - acc: 0.2505 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6865 - acc: 0.2548 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6489 - acc: 0.2675 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7092 - acc: 0.2569 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.6577 - acc: 0.2378 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6629 - acc: 0.2590 - val_loss: 0.5196 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6313 - acc: 0.2442 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 223us/step - loss: 0.7024 - acc: 0.2484 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6457 - acc: 0.2569 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6482 - acc: 0.2675 - val_loss: 0.5214 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7351 - acc: 0.2420 - val_loss: 0.5218 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6639 - acc: 0.2420 - val_loss: 0.5216 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6559 - acc: 0.2527 - val_loss: 0.5212 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6401 - acc: 0.2718 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.6533 - acc: 0.2569 - val_loss: 0.5194 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.6704 - acc: 0.2633 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.6522 - acc: 0.2718 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6471 - acc: 0.2527 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6630 - acc: 0.2505 - val_loss: 0.5181 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 238us/step - loss: 0.6456 - acc: 0.2420 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 239us/step - loss: 0.6526 - acc: 0.2505 - val_loss: 0.5163 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.6442 - acc: 0.2442 - val_loss: 0.5154 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6543 - acc: 0.2420 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6486 - acc: 0.2463 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6392 - acc: 0.2548 - val_loss: 0.5126 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6357 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6241 - acc: 0.2611 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6219 - acc: 0.2527 - val_loss: 0.5099 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6353 - acc: 0.2675 - val_loss: 0.5084 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6708 - acc: 0.2611 - val_loss: 0.5062 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6368 - acc: 0.2654 - val_loss: 0.5046 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6451 - acc: 0.2633 - val_loss: 0.5047 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6559 - acc: 0.2590 - val_loss: 0.5047 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6315 - acc: 0.2527 - val_loss: 0.5048 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6287 - acc: 0.2527 - val_loss: 0.5051 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6247 - acc: 0.2675 - val_loss: 0.5041 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6177 - acc: 0.2696 - val_loss: 0.5029 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6218 - acc: 0.2527 - val_loss: 0.5024 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6262 - acc: 0.2484 - val_loss: 0.5014 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6685 - acc: 0.2569 - val_loss: 0.5000 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6328 - acc: 0.2527 - val_loss: 0.4990 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6277 - acc: 0.2696 - val_loss: 0.4984 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6441 - acc: 0.2718 - val_loss: 0.4987 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6527 - acc: 0.2611 - val_loss: 0.4995 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6293 - acc: 0.2633 - val_loss: 0.4990 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6342 - acc: 0.2718 - val_loss: 0.4982 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6321 - acc: 0.2442 - val_loss: 0.4971 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6608 - acc: 0.2569 - val_loss: 0.4963 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6260 - acc: 0.2505 - val_loss: 0.4955 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.6099 - acc: 0.2611 - val_loss: 0.4944 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6256 - acc: 0.2548 - val_loss: 0.4936 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6108 - acc: 0.2675 - val_loss: 0.4925 - val_acc: 0.2199\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6358 - acc: 0.2718 - val_loss: 0.4923 - val_acc: 0.2199\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6140 - acc: 0.2845 - val_loss: 0.4943 - val_acc: 0.2340\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6165 - acc: 0.2739 - val_loss: 0.4943 - val_acc: 0.2340\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6429 - acc: 0.2718 - val_loss: 0.4953 - val_acc: 0.2340\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6098 - acc: 0.2803 - val_loss: 0.4968 - val_acc: 0.2340\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6117 - acc: 0.2803 - val_loss: 0.4973 - val_acc: 0.2340\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6174 - acc: 0.2781 - val_loss: 0.4965 - val_acc: 0.2340\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6197 - acc: 0.2739 - val_loss: 0.4949 - val_acc: 0.2340\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6307 - acc: 0.2633 - val_loss: 0.4951 - val_acc: 0.2340\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6552 - acc: 0.2781 - val_loss: 0.4958 - val_acc: 0.2199\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6166 - acc: 0.2590 - val_loss: 0.4956 - val_acc: 0.2199\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6133 - acc: 0.2696 - val_loss: 0.4947 - val_acc: 0.2199\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6410 - acc: 0.2803 - val_loss: 0.4932 - val_acc: 0.2199\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6326 - acc: 0.2675 - val_loss: 0.4917 - val_acc: 0.2199\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.6024 - acc: 0.2548 - val_loss: 0.4901 - val_acc: 0.2270\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6531 - acc: 0.2611 - val_loss: 0.4884 - val_acc: 0.2270\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 239us/step - loss: 0.6425 - acc: 0.2760 - val_loss: 0.4873 - val_acc: 0.2270\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 0.6064 - acc: 0.2803 - val_loss: 0.4862 - val_acc: 0.2270\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6033 - acc: 0.2930 - val_loss: 0.4851 - val_acc: 0.2270\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6222 - acc: 0.2781 - val_loss: 0.4841 - val_acc: 0.2270\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6637 - acc: 0.2569 - val_loss: 0.4860 - val_acc: 0.2199\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6498 - acc: 0.2675 - val_loss: 0.4906 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6164 - acc: 0.2675 - val_loss: 0.4979 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6248 - acc: 0.2569 - val_loss: 0.5020 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6645 - acc: 0.2718 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 227us/step\n",
      "Test score: 0.503549465050934\n",
      "Look! elu relu softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu softsign relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_303 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1058 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_758 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1059 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_759 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1060 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 31s 66ms/step - loss: 3.2165 - acc: 0.2824 - val_loss: 2.1719 - val_acc: 0.1348\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.0514 - acc: 0.2781 - val_loss: 2.5149 - val_acc: 0.2411\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 3.2107 - acc: 0.3291 - val_loss: 3.7723 - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.7278 - acc: 0.3418 - val_loss: 3.6580 - val_acc: 0.5957\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.7522 - acc: 0.3482 - val_loss: 4.1153 - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.8869 - acc: 0.3800 - val_loss: 0.8574 - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.9040 - acc: 0.3843 - val_loss: 0.8555 - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 2.7079 - acc: 0.4098 - val_loss: 0.8537 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.3761 - acc: 0.3800 - val_loss: 0.9432 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.5398 - acc: 0.4183 - val_loss: 1.1348 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.2231 - acc: 0.4140 - val_loss: 1.2563 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.4383 - acc: 0.4183 - val_loss: 2.0406 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 2.6779 - acc: 0.4161 - val_loss: 2.3333 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 2.7803 - acc: 0.4756 - val_loss: 2.2523 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 2.7403 - acc: 0.4098 - val_loss: 2.1536 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.7621 - acc: 0.4416 - val_loss: 1.9669 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 3.1146 - acc: 0.4459 - val_loss: 1.8161 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.9164 - acc: 0.4013 - val_loss: 1.4473 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.6977 - acc: 0.3949 - val_loss: 1.3518 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.7674 - acc: 0.4161 - val_loss: 1.3667 - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.7302 - acc: 0.4586 - val_loss: 1.3687 - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.7749 - acc: 0.4395 - val_loss: 1.1687 - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.9532 - acc: 0.4586 - val_loss: 1.1701 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.1711 - acc: 0.4437 - val_loss: 1.1686 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 2.7332 - acc: 0.4713 - val_loss: 1.2696 - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.9363 - acc: 0.4862 - val_loss: 1.3189 - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.0694 - acc: 0.4628 - val_loss: 2.2542 - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.4855 - acc: 0.4565 - val_loss: 2.1425 - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.3860 - acc: 0.4522 - val_loss: 1.6146 - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.7391 - acc: 0.4777 - val_loss: 1.3267 - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.0179 - acc: 0.4544 - val_loss: 1.3413 - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.4551 - acc: 0.4225 - val_loss: 1.3515 - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.2690 - acc: 0.4777 - val_loss: 1.3536 - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.5094 - acc: 0.4459 - val_loss: 1.5348 - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.6348 - acc: 0.4544 - val_loss: 1.7085 - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.7845 - acc: 0.4098 - val_loss: 2.5539 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 234us/step - loss: 2.9843 - acc: 0.4076 - val_loss: 2.6563 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.1159 - acc: 0.4459 - val_loss: 2.9744 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.1642 - acc: 0.4289 - val_loss: 2.9721 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 3.0957 - acc: 0.4289 - val_loss: 2.9749 - val_acc: 0.6241\n",
      "Epoch 41/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 205us/step - loss: 3.1688 - acc: 0.4416 - val_loss: 2.6557 - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.2019 - acc: 0.4713 - val_loss: 2.5571 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.6401 - acc: 0.4204 - val_loss: 2.3423 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.6133 - acc: 0.4628 - val_loss: 2.0177 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.6067 - acc: 0.4650 - val_loss: 1.9217 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.9050 - acc: 0.4522 - val_loss: 2.0125 - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.9786 - acc: 0.4310 - val_loss: 2.2664 - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.9896 - acc: 0.4544 - val_loss: 4.2296 - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.7432 - acc: 0.4395 - val_loss: 3.8088 - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.5445 - acc: 0.3970 - val_loss: 3.5530 - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.1446 - acc: 0.3503 - val_loss: 3.5610 - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 4.2527 - acc: 0.3928 - val_loss: 3.6484 - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 3.9991 - acc: 0.3439 - val_loss: 3.8052 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.2553 - acc: 0.3439 - val_loss: 4.0009 - val_acc: 0.1631\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.3295 - acc: 0.3312 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.4329 - acc: 0.2824 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 3.3132 - acc: 0.2781 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 3.8535 - acc: 0.3418 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 2.7975 - acc: 0.3015 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.5300 - acc: 0.3036 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.7638 - acc: 0.2803 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 2.8667 - acc: 0.2463 - val_loss: 3.9013 - val_acc: 0.1277\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.1604 - acc: 0.2590 - val_loss: 3.7836 - val_acc: 0.1277\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.1782 - acc: 0.2972 - val_loss: 1.3632 - val_acc: 0.1277\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.7692 - acc: 0.2824 - val_loss: 0.8430 - val_acc: 0.1631\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.0467 - acc: 0.3588 - val_loss: 0.8446 - val_acc: 0.5035\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.8003 - acc: 0.3822 - val_loss: 0.8370 - val_acc: 0.4610\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.9934 - acc: 0.3163 - val_loss: 0.8335 - val_acc: 0.1773\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.8173 - acc: 0.3631 - val_loss: 1.1382 - val_acc: 0.1206\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.4874 - acc: 0.3270 - val_loss: 3.5693 - val_acc: 0.1206\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.8126 - acc: 0.3291 - val_loss: 3.3738 - val_acc: 0.1206\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.8414 - acc: 0.2930 - val_loss: 2.8345 - val_acc: 0.1277\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.6462 - acc: 0.3461 - val_loss: 2.8346 - val_acc: 0.1702\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 2.4653 - acc: 0.3694 - val_loss: 2.5468 - val_acc: 0.3262\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.8521 - acc: 0.3822 - val_loss: 3.4705 - val_acc: 0.6099\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.7901 - acc: 0.3673 - val_loss: 3.3677 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.3624 - acc: 0.3418 - val_loss: 3.4648 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.8086 - acc: 0.3652 - val_loss: 3.1654 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.8853 - acc: 0.3631 - val_loss: 3.7873 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.0032 - acc: 0.4565 - val_loss: 3.8866 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 2.3533 - acc: 0.4565 - val_loss: 2.9721 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.7414 - acc: 0.4480 - val_loss: 2.9721 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.7993 - acc: 0.4947 - val_loss: 2.9721 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.8483 - acc: 0.4437 - val_loss: 2.9721 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.6790 - acc: 0.4820 - val_loss: 2.9721 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.9237 - acc: 0.4268 - val_loss: 2.9721 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.9583 - acc: 0.4480 - val_loss: 2.9721 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.9284 - acc: 0.4331 - val_loss: 2.9721 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.9215 - acc: 0.4416 - val_loss: 3.3151 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 3.3376 - acc: 0.4161 - val_loss: 4.3439 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.0353 - acc: 0.4034 - val_loss: 4.0009 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.1514 - acc: 0.3885 - val_loss: 4.0009 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.4881 - acc: 0.4140 - val_loss: 4.0009 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.5086 - acc: 0.3546 - val_loss: 4.0009 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 3.1664 - acc: 0.3673 - val_loss: 4.0009 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 3.3605 - acc: 0.3843 - val_loss: 4.0009 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.3564 - acc: 0.3694 - val_loss: 4.0009 - val_acc: 0.6383\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.7476 - acc: 0.3503 - val_loss: 4.0009 - val_acc: 0.1560\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 3.1293 - acc: 0.3439 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 3.5189 - acc: 0.3206 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.0457 - acc: 0.3333 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.7834 - acc: 0.3100 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.5236 - acc: 0.2909 - val_loss: 4.0009 - val_acc: 0.1277\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 2.7405 - acc: 0.3185 - val_loss: 0.8467 - val_acc: 0.1277\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 2.5089 - acc: 0.3142 - val_loss: 0.8467 - val_acc: 0.1277\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.9565 - acc: 0.3376 - val_loss: 0.8467 - val_acc: 0.1277\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.9227 - acc: 0.3227 - val_loss: 0.8467 - val_acc: 0.1277\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.5417 - acc: 0.2951 - val_loss: 0.8467 - val_acc: 0.1277\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.5082 - acc: 0.3079 - val_loss: 0.8467 - val_acc: 0.1277\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.4811 - acc: 0.2569 - val_loss: 0.8466 - val_acc: 0.1277\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.5157 - acc: 0.2633 - val_loss: 0.8466 - val_acc: 0.1277\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.5762 - acc: 0.2654 - val_loss: 0.8465 - val_acc: 0.1277\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.4714 - acc: 0.2505 - val_loss: 0.8466 - val_acc: 0.1277\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.2422 - acc: 0.2781 - val_loss: 0.8469 - val_acc: 0.1277\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.4178 - acc: 0.3163 - val_loss: 0.8470 - val_acc: 0.2270\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 1.5989 - acc: 0.3100 - val_loss: 0.8471 - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.6732 - acc: 0.3418 - val_loss: 0.8472 - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.3561 - acc: 0.3270 - val_loss: 0.8472 - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.7792 - acc: 0.3631 - val_loss: 0.8472 - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.5257 - acc: 0.3652 - val_loss: 0.8472 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 207us/step\n",
      "Test score: 0.8472187709301076\n",
      "Look! elu relu softsign Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu relu softsign\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_304 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1061 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_760 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1062 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_761 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1063 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 32s 67ms/step - loss: nan - acc: 0.4459 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 199us/step\n",
      "Test score: nan\n",
      "Look! elu relu relu Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu relu relu\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_305 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1064 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_762 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1065 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_763 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1066 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 32s 68ms/step - loss: nan - acc: 0.4820 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 27/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: nan - acc: 0.5435 - val_loss: nan - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 207us/step\n",
      "Test score: nan\n",
      "Look! elu relu tanh Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu relu tanh\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_306 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1067 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_764 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1068 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_765 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1069 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 32s 68ms/step - loss: 1.6600 - acc: 0.4395 - val_loss: 0.7458 - val_acc: 0.5248\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.3079 - acc: 0.4055 - val_loss: 0.9850 - val_acc: 0.5603\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.4944 - acc: 0.4119 - val_loss: 1.0079 - val_acc: 0.5957\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.2376 - acc: 0.4756 - val_loss: 1.0079 - val_acc: 0.6028\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.0541 - acc: 0.4883 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 1.0305 - acc: 0.4883 - val_loss: 0.9118 - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.9620 - acc: 0.5329 - val_loss: 0.6834 - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.9688 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.8114 - acc: 0.5499 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8849 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8684 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.8137 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7728 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.8249 - acc: 0.5287 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7521 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.8221 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.8340 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7309 - acc: 0.5499 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7926 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7600 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 21/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 224us/step - loss: 0.7417 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7321 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7908 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7310 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7944 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7657 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7619 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7557 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.7344 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7574 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7346 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7338 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7334 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7328 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7571 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.7394 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7350 - acc: 0.5308 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7332 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7334 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7340 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7368 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7350 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7716 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7352 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7340 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7659 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7984 - acc: 0.5308 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7358 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7349 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7351 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7340 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7356 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7350 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7352 - acc: 0.5499 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7341 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7647 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7358 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7666 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7346 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7665 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7352 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7322 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7352 - acc: 0.5520 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7340 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7358 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7354 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7352 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.7346 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7358 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7358 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7345 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7340 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7373 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7344 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7339 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7336 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7352 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7354 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7331 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7657 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7338 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7341 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7559 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.7358 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.7490 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 0.7665 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7346 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7350 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7349 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7358 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7346 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7352 - acc: 0.5456 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 234us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7358 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.7352 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7352 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.7358 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7358 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.7671 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.7395 - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7358 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 0.7366 - acc: 0.5350 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7355 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7344 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7358 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7363 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7671 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.7352 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.7566 - acc: 0.5414 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7358 - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "141/141 [==============================] - 0s 214us/step\n",
      "Test score: 0.5997443816340562\n",
      "Look! elu relu sigmoid Test accuracy: 0.6241134772909448\n",
      "max there  0.6241134772909448 elu relu sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_307 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1070 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_766 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1071 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_767 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1072 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 32s 68ms/step - loss: nan - acc: 0.3715 - val_loss: 3.6709 - val_acc: 0.6241\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 3.9075 - acc: 0.4395 - val_loss: 1.2624 - val_acc: 0.6241\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: nan - acc: 0.5287 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.8157 - acc: 0.5329 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.7952 - acc: 0.5520 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.1961 - acc: 0.5499 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.3327 - acc: 0.5372 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5435 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.0325 - acc: 0.5393 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: nan - acc: 0.5478 - val_loss: 0.5997 - val_acc: 0.6241\n",
      "Epoch 11/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 219us/step - loss: 1.1493 - acc: 0.5499 - val_loss: 0.7005 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.2384 - acc: 0.5393 - val_loss: 0.7614 - val_acc: 0.6241\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.5783 - acc: 0.5350 - val_loss: 0.9548 - val_acc: 0.6241\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.3833 - acc: 0.5393 - val_loss: 1.0156 - val_acc: 0.6241\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.0328 - acc: 0.5329 - val_loss: 1.0102 - val_acc: 0.6241\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.2568 - acc: 0.5308 - val_loss: 1.0086 - val_acc: 0.6241\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.9296 - acc: 0.5478 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.2196 - acc: 0.5244 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.3883 - acc: 0.5180 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.2216 - acc: 0.5074 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.2522 - acc: 0.5096 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.3944 - acc: 0.5138 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.3049 - acc: 0.5074 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.4630 - acc: 0.5287 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.4360 - acc: 0.5032 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.3116 - acc: 0.5202 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.4323 - acc: 0.5180 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.3479 - acc: 0.5053 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.3049 - acc: 0.5117 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.3740 - acc: 0.5180 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.2390 - acc: 0.5053 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.2752 - acc: 0.4820 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.2688 - acc: 0.4968 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.2364 - acc: 0.5011 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.4587 - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 1.5732 - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.6024 - acc: 0.4544 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.5546 - acc: 0.4395 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.8082 - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: nan - acc: 0.3885 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.3608 - acc: 0.4289 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.4346 - acc: 0.4671 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: nan - acc: 0.4310 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: nan - acc: 0.4437 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.5152 - acc: 0.4586 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.5636 - acc: 0.4076 - val_loss: 1.0067 - val_acc: 0.6170\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 191us/step - loss: 1.6287 - acc: 0.4161 - val_loss: 1.1843 - val_acc: 0.4184\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.5843 - acc: 0.3992 - val_loss: 1.6307 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.6832 - acc: 0.3822 - val_loss: 1.7239 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.7751 - acc: 0.3609 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.6368 - acc: 0.3652 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.9923 - acc: 0.3439 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.8906 - acc: 0.3907 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: nan - acc: 0.3800 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.8274 - acc: 0.3758 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: nan - acc: 0.3546 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.9383 - acc: 0.3694 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.8846 - acc: 0.3248 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.9350 - acc: 0.3737 - val_loss: 1.0079 - val_acc: 0.6099\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.6072 - acc: 0.4310 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.6163 - acc: 0.4119 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.5574 - acc: 0.4544 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.5270 - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.4971 - acc: 0.4777 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.3756 - acc: 0.5074 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.4371 - acc: 0.4586 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 1.4976 - acc: 0.4926 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.7196 - acc: 0.4544 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.5423 - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.6916 - acc: 0.4310 - val_loss: 1.0089 - val_acc: 0.6170\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.6145 - acc: 0.4161 - val_loss: 1.0092 - val_acc: 0.6028\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.6824 - acc: 0.4289 - val_loss: 1.0086 - val_acc: 0.6170\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.5679 - acc: 0.3907 - val_loss: 1.0080 - val_acc: 0.6099\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.5538 - acc: 0.4268 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.4723 - acc: 0.4140 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.7662 - acc: 0.3992 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.4776 - acc: 0.4522 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.7592 - acc: 0.4055 - val_loss: 1.0079 - val_acc: 0.6099\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.3706 - acc: 0.4352 - val_loss: 1.0079 - val_acc: 0.6170\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.6170 - acc: 0.4437 - val_loss: 1.0077 - val_acc: 0.6170\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.6010 - acc: 0.4331 - val_loss: 1.0091 - val_acc: 0.6170\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.6479 - acc: 0.4119 - val_loss: 1.2076 - val_acc: 0.5816\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.6722 - acc: 0.3715 - val_loss: 1.1073 - val_acc: 0.5816\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.7472 - acc: 0.4013 - val_loss: 1.0071 - val_acc: 0.6312\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.8093 - acc: 0.4183 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.6854 - acc: 0.4013 - val_loss: 1.0080 - val_acc: 0.6099\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.7674 - acc: 0.4013 - val_loss: 1.7240 - val_acc: 0.2199\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.6548 - acc: 0.4013 - val_loss: 1.4577 - val_acc: 0.4255\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 1.8144 - acc: 0.3992 - val_loss: 1.0073 - val_acc: 0.6170\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 1.5803 - acc: 0.4183 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.6583 - acc: 0.4268 - val_loss: 1.0079 - val_acc: 0.6241\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.4698 - acc: 0.4352 - val_loss: 1.0068 - val_acc: 0.6170\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.6855 - acc: 0.4246 - val_loss: 1.1932 - val_acc: 0.5816\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.6200 - acc: 0.3843 - val_loss: 1.6226 - val_acc: 0.2340\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.5416 - acc: 0.4098 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.7805 - acc: 0.3503 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 1.9508 - acc: 0.3907 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.6905 - acc: 0.4055 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.9410 - acc: 0.3588 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.9545 - acc: 0.3673 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.7296 - acc: 0.3503 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.8389 - acc: 0.3355 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.0885 - acc: 0.3312 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.9169 - acc: 0.3227 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 186us/step - loss: 1.9476 - acc: 0.3057 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.9482 - acc: 0.3503 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.8819 - acc: 0.3163 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 178us/step - loss: 1.9064 - acc: 0.3248 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.0130 - acc: 0.2972 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 1.9071 - acc: 0.3142 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.0417 - acc: 0.2994 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.0343 - acc: 0.3036 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.0929 - acc: 0.3036 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 2.1168 - acc: 0.2781 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 2.0625 - acc: 0.2803 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 2.0900 - acc: 0.2675 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 2.1493 - acc: 0.2760 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.1886 - acc: 0.2569 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.0852 - acc: 0.2994 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.0950 - acc: 0.2696 - val_loss: 1.7220 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 195us/step\n",
      "Test score: 1.7220306261211422\n",
      "Look! elu relu hard_sigmoid Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu relu sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_308 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1073 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_768 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1074 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_769 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1075 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 32s 68ms/step - loss: 3.5500 - acc: 0.1699 - val_loss: 4.5729 - val_acc: 0.1702\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 3.7227 - acc: 0.1423 - val_loss: 4.8011 - val_acc: 0.0355\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 3.3258 - acc: 0.1380 - val_loss: 3.3326 - val_acc: 0.0355\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 3.2853 - acc: 0.1359 - val_loss: 3.1410 - val_acc: 0.0355\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 3.0365 - acc: 0.1295 - val_loss: 3.0406 - val_acc: 0.0355\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.3215 - acc: 0.1911 - val_loss: 3.0543 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.0270 - acc: 0.1826 - val_loss: 3.0129 - val_acc: 0.2128\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.8715 - acc: 0.1847 - val_loss: 1.9843 - val_acc: 0.2128\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 2.9489 - acc: 0.2208 - val_loss: 1.4305 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.6248 - acc: 0.2187 - val_loss: 1.2604 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.3600 - acc: 0.2144 - val_loss: 1.2272 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 2.5017 - acc: 0.2272 - val_loss: 1.2233 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.3183 - acc: 0.2166 - val_loss: 1.2300 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.9009 - acc: 0.2059 - val_loss: 1.2302 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.8044 - acc: 0.2102 - val_loss: 1.2310 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.6070 - acc: 0.2527 - val_loss: 1.2291 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 1.6967 - acc: 0.2229 - val_loss: 1.2302 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 1.4699 - acc: 0.2123 - val_loss: 1.2312 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 234us/step - loss: 1.4513 - acc: 0.2123 - val_loss: 1.2304 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.8159 - acc: 0.2017 - val_loss: 1.2284 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.6754 - acc: 0.2335 - val_loss: 1.2292 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.4188 - acc: 0.2208 - val_loss: 1.2363 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.4817 - acc: 0.2420 - val_loss: 1.2469 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 234us/step - loss: 1.3836 - acc: 0.2187 - val_loss: 1.2528 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.3267 - acc: 0.2187 - val_loss: 1.1816 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.2888 - acc: 0.2166 - val_loss: 1.1829 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.6088 - acc: 0.2293 - val_loss: 1.2496 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.7400 - acc: 0.2378 - val_loss: 1.2507 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.8061 - acc: 0.2399 - val_loss: 1.2560 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.6453 - acc: 0.2166 - val_loss: 1.2804 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.6788 - acc: 0.2357 - val_loss: 1.3624 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.8631 - acc: 0.2484 - val_loss: 1.2684 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.5990 - acc: 0.2293 - val_loss: 1.2443 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 1.7390 - acc: 0.2081 - val_loss: 1.2317 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.8356 - acc: 0.2527 - val_loss: 1.2260 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.7143 - acc: 0.2335 - val_loss: 1.2110 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.8375 - acc: 0.2314 - val_loss: 1.2037 - val_acc: 0.2199\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.7095 - acc: 0.2314 - val_loss: 1.1953 - val_acc: 0.2340\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.3112 - acc: 0.2251 - val_loss: 1.1876 - val_acc: 0.2340\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.2940 - acc: 0.2420 - val_loss: 1.1861 - val_acc: 0.2199\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.0721 - acc: 0.2144 - val_loss: 1.1816 - val_acc: 0.2199\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.2946 - acc: 0.2081 - val_loss: 1.1788 - val_acc: 0.2199\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 2.0767 - acc: 0.2357 - val_loss: 1.2100 - val_acc: 0.2340\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.2728 - acc: 0.2251 - val_loss: 1.5530 - val_acc: 0.2411\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.3616 - acc: 0.2123 - val_loss: 1.5499 - val_acc: 0.2340\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.4401 - acc: 0.2081 - val_loss: 1.2830 - val_acc: 0.2411\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 2.6041 - acc: 0.1996 - val_loss: 1.2374 - val_acc: 0.2199\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.8463 - acc: 0.2357 - val_loss: 1.1915 - val_acc: 0.1489\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.6512 - acc: 0.2038 - val_loss: 1.1837 - val_acc: 0.1418\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 2.8133 - acc: 0.2166 - val_loss: 1.1901 - val_acc: 0.1560\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 2.7488 - acc: 0.1953 - val_loss: 1.0947 - val_acc: 0.1631\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 3.0666 - acc: 0.2017 - val_loss: 1.0684 - val_acc: 0.1348\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 2.6636 - acc: 0.1975 - val_loss: 1.0261 - val_acc: 0.1277\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.4398 - acc: 0.2017 - val_loss: 1.0114 - val_acc: 0.1277\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 3.3786 - acc: 0.1890 - val_loss: 1.0265 - val_acc: 0.1277\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.9265 - acc: 0.1444 - val_loss: 1.0278 - val_acc: 0.1277\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 2.7780 - acc: 0.1699 - val_loss: 1.0532 - val_acc: 0.1277\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.8464 - acc: 0.1486 - val_loss: 1.0650 - val_acc: 0.1277\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 2.8910 - acc: 0.1507 - val_loss: 1.0535 - val_acc: 0.1277\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.7826 - acc: 0.1762 - val_loss: 0.9875 - val_acc: 0.1277\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 3.1804 - acc: 0.1699 - val_loss: 1.1549 - val_acc: 0.1277\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.7184 - acc: 0.1741 - val_loss: 6.0586 - val_acc: 0.1277\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 2.7697 - acc: 0.1444 - val_loss: 2.4627 - val_acc: 0.1277\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.1946 - acc: 0.1359 - val_loss: 0.7786 - val_acc: 0.1277\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 2.2763 - acc: 0.1146 - val_loss: 0.6435 - val_acc: 0.0426\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.5526 - acc: 0.1125 - val_loss: 0.5983 - val_acc: 0.0355\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.2349 - acc: 0.1295 - val_loss: 0.5786 - val_acc: 0.0355\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.8592 - acc: 0.0701 - val_loss: 0.5670 - val_acc: 0.0355\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.8026 - acc: 0.0637 - val_loss: 0.5595 - val_acc: 0.0355\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.9752 - acc: 0.0849 - val_loss: 0.5541 - val_acc: 0.0355\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.8448 - acc: 0.0934 - val_loss: 0.5500 - val_acc: 0.0355\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.9408 - acc: 0.0870 - val_loss: 0.5467 - val_acc: 0.0355\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.9299 - acc: 0.0998 - val_loss: 0.5437 - val_acc: 0.0355\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.8778 - acc: 0.0870 - val_loss: 0.5407 - val_acc: 0.0355\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7946 - acc: 0.0977 - val_loss: 0.5378 - val_acc: 0.0355\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8467 - acc: 0.1231 - val_loss: 0.5352 - val_acc: 0.0355\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.8034 - acc: 0.1062 - val_loss: 0.5328 - val_acc: 0.0355\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.7560 - acc: 0.1295 - val_loss: 0.5308 - val_acc: 0.0355\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7282 - acc: 0.1359 - val_loss: 0.5302 - val_acc: 0.0355\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.8156 - acc: 0.1168 - val_loss: 0.5298 - val_acc: 0.0355\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7443 - acc: 0.1359 - val_loss: 0.5298 - val_acc: 0.0355\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7568 - acc: 0.1486 - val_loss: 0.5301 - val_acc: 0.0355\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7645 - acc: 0.1529 - val_loss: 0.5304 - val_acc: 0.0355\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.7372 - acc: 0.1550 - val_loss: 0.5305 - val_acc: 0.0355\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6994 - acc: 0.1699 - val_loss: 0.5297 - val_acc: 0.0355\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7208 - acc: 0.1762 - val_loss: 0.5293 - val_acc: 0.0355\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.7439 - acc: 0.1911 - val_loss: 0.5286 - val_acc: 0.0355\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.8316 - acc: 0.1911 - val_loss: 0.5290 - val_acc: 0.0355\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.8314 - acc: 0.1847 - val_loss: 0.5294 - val_acc: 0.0355\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7115 - acc: 0.1699 - val_loss: 0.5295 - val_acc: 0.0355\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8286 - acc: 0.1592 - val_loss: 0.5299 - val_acc: 0.0355\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7181 - acc: 0.1847 - val_loss: 0.5307 - val_acc: 0.0355\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7196 - acc: 0.1699 - val_loss: 0.5307 - val_acc: 0.0355\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7321 - acc: 0.1614 - val_loss: 0.5303 - val_acc: 0.0355\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7588 - acc: 0.1720 - val_loss: 0.5303 - val_acc: 0.0355\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6863 - acc: 0.1975 - val_loss: 0.5299 - val_acc: 0.0355\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7308 - acc: 0.1932 - val_loss: 0.5294 - val_acc: 0.0355\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6743 - acc: 0.1890 - val_loss: 0.5288 - val_acc: 0.0355\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7143 - acc: 0.1911 - val_loss: 0.5277 - val_acc: 0.0355\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6684 - acc: 0.1996 - val_loss: 0.5269 - val_acc: 0.0355\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6969 - acc: 0.1635 - val_loss: 0.5266 - val_acc: 0.0355\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7482 - acc: 0.2038 - val_loss: 0.5261 - val_acc: 0.0355\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6949 - acc: 0.1783 - val_loss: 0.5256 - val_acc: 0.0355\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7262 - acc: 0.1932 - val_loss: 0.5251 - val_acc: 0.0355\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.7393 - acc: 0.2144 - val_loss: 0.5247 - val_acc: 0.0355\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7196 - acc: 0.1529 - val_loss: 0.5244 - val_acc: 0.0355\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7109 - acc: 0.1720 - val_loss: 0.5241 - val_acc: 0.0355\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7169 - acc: 0.1677 - val_loss: 0.5247 - val_acc: 0.0355\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.7223 - acc: 0.1359 - val_loss: 0.5254 - val_acc: 0.0355\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7265 - acc: 0.1677 - val_loss: 0.5258 - val_acc: 0.0355\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.7112 - acc: 0.1125 - val_loss: 0.5263 - val_acc: 0.0355\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6727 - acc: 0.0998 - val_loss: 0.5262 - val_acc: 0.0355\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6486 - acc: 0.1104 - val_loss: 0.5259 - val_acc: 0.0355\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6906 - acc: 0.1274 - val_loss: 0.5253 - val_acc: 0.0355\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6823 - acc: 0.1083 - val_loss: 0.5249 - val_acc: 0.0355\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7023 - acc: 0.0764 - val_loss: 0.5243 - val_acc: 0.0355\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.7640 - acc: 0.1146 - val_loss: 0.5236 - val_acc: 0.0355\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6910 - acc: 0.1146 - val_loss: 0.5230 - val_acc: 0.0355\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7722 - acc: 0.1380 - val_loss: 0.5225 - val_acc: 0.0355\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.7244 - acc: 0.1380 - val_loss: 0.5225 - val_acc: 0.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 181us/step\n",
      "Test score: 0.5224897261206985\n",
      "Look! elu relu linear Test accuracy: 0.03546099290780142\n",
      "max there  0.6241134772909448 elu relu sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_309 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1076 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_770 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1077 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_771 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1078 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 32s 69ms/step - loss: 1.3416 - acc: 0.1783 - val_loss: 0.6248 - val_acc: 0.1064\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.0504 - acc: 0.2442 - val_loss: 0.6600 - val_acc: 0.1418\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 242us/step - loss: 1.0081 - acc: 0.2675 - val_loss: 0.6586 - val_acc: 0.2199\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.0425 - acc: 0.2420 - val_loss: 0.7035 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 234us/step - loss: 0.9084 - acc: 0.2420 - val_loss: 0.8251 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 0.9963 - acc: 0.2484 - val_loss: 0.8510 - val_acc: 0.2128\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.0724 - acc: 0.2611 - val_loss: 0.8022 - val_acc: 0.2199\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.9607 - acc: 0.2590 - val_loss: 0.7172 - val_acc: 0.2199\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.9988 - acc: 0.2420 - val_loss: 0.6874 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.8899 - acc: 0.2760 - val_loss: 0.6842 - val_acc: 0.2128\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.9213 - acc: 0.2357 - val_loss: 0.6523 - val_acc: 0.1986\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.9447 - acc: 0.2463 - val_loss: 0.6126 - val_acc: 0.2199\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 0.9643 - acc: 0.2166 - val_loss: 0.5915 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.9594 - acc: 0.2123 - val_loss: 0.5823 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.9453 - acc: 0.2442 - val_loss: 0.5782 - val_acc: 0.1986\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 0.8953 - acc: 0.2463 - val_loss: 0.5694 - val_acc: 0.2057\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.8833 - acc: 0.2463 - val_loss: 0.5861 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 0.9916 - acc: 0.2229 - val_loss: 0.5997 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 238us/step - loss: 0.9088 - acc: 0.2442 - val_loss: 0.5894 - val_acc: 0.2057\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 242us/step - loss: 0.8455 - acc: 0.2251 - val_loss: 0.5422 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.9426 - acc: 0.2335 - val_loss: 0.5312 - val_acc: 0.2199\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 239us/step - loss: 0.9179 - acc: 0.2272 - val_loss: 0.5414 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.8395 - acc: 0.2420 - val_loss: 0.5368 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.8417 - acc: 0.2760 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.8315 - acc: 0.2654 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.9342 - acc: 0.2229 - val_loss: 0.5070 - val_acc: 0.2199\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.8538 - acc: 0.2569 - val_loss: 0.5295 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 0.8411 - acc: 0.2399 - val_loss: 0.5453 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.8396 - acc: 0.2505 - val_loss: 0.5523 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.8485 - acc: 0.2229 - val_loss: 0.5441 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 236us/step - loss: 0.7870 - acc: 0.2463 - val_loss: 0.5201 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.8487 - acc: 0.2803 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.8269 - acc: 0.2675 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 238us/step - loss: 0.7845 - acc: 0.2654 - val_loss: 0.5160 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.8229 - acc: 0.2696 - val_loss: 0.5155 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 234us/step - loss: 0.7910 - acc: 0.2760 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7484 - acc: 0.2611 - val_loss: 0.5477 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7826 - acc: 0.2569 - val_loss: 0.5493 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7909 - acc: 0.2527 - val_loss: 0.5567 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.7702 - acc: 0.2781 - val_loss: 0.5488 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7958 - acc: 0.2484 - val_loss: 0.5363 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 0.7562 - acc: 0.2590 - val_loss: 0.5375 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.8122 - acc: 0.2420 - val_loss: 0.5439 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 240us/step - loss: 0.7962 - acc: 0.2166 - val_loss: 0.5357 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.8527 - acc: 0.2272 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7571 - acc: 0.2866 - val_loss: 0.5087 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7707 - acc: 0.2696 - val_loss: 0.4959 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.7782 - acc: 0.2484 - val_loss: 0.5078 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 252us/step - loss: 0.8171 - acc: 0.2378 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 236us/step - loss: 0.7883 - acc: 0.2442 - val_loss: 0.5401 - val_acc: 0.2128\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 238us/step - loss: 0.7594 - acc: 0.2611 - val_loss: 0.5554 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 0.7399 - acc: 0.2760 - val_loss: 0.5634 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.7429 - acc: 0.2718 - val_loss: 0.5561 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.7908 - acc: 0.2335 - val_loss: 0.5281 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.7393 - acc: 0.2654 - val_loss: 0.5241 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7153 - acc: 0.2357 - val_loss: 0.5243 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7527 - acc: 0.2611 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.7109 - acc: 0.2718 - val_loss: 0.5180 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.8106 - acc: 0.2017 - val_loss: 0.5164 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7941 - acc: 0.2081 - val_loss: 0.5238 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.7160 - acc: 0.2633 - val_loss: 0.5372 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 0.7083 - acc: 0.2527 - val_loss: 0.5388 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7294 - acc: 0.2675 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7002 - acc: 0.2633 - val_loss: 0.5281 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7414 - acc: 0.2590 - val_loss: 0.5249 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.7520 - acc: 0.2378 - val_loss: 0.5273 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.7293 - acc: 0.2527 - val_loss: 0.5266 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.7519 - acc: 0.2378 - val_loss: 0.5217 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7128 - acc: 0.2739 - val_loss: 0.5182 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7067 - acc: 0.2463 - val_loss: 0.5144 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7147 - acc: 0.2442 - val_loss: 0.5206 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.6743 - acc: 0.2633 - val_loss: 0.5296 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7356 - acc: 0.2420 - val_loss: 0.5304 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 0.7172 - acc: 0.2654 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.7343 - acc: 0.2272 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6766 - acc: 0.2569 - val_loss: 0.5249 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6977 - acc: 0.2463 - val_loss: 0.5203 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7164 - acc: 0.2314 - val_loss: 0.5135 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.7230 - acc: 0.2357 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.6751 - acc: 0.2527 - val_loss: 0.5125 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6943 - acc: 0.2527 - val_loss: 0.5223 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.7351 - acc: 0.2357 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6776 - acc: 0.2420 - val_loss: 0.5204 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 0.6905 - acc: 0.2484 - val_loss: 0.5209 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 0.6804 - acc: 0.2739 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6862 - acc: 0.2463 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7378 - acc: 0.2463 - val_loss: 0.5228 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 249us/step - loss: 0.6722 - acc: 0.2484 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6752 - acc: 0.2505 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6676 - acc: 0.2569 - val_loss: 0.5094 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7080 - acc: 0.2463 - val_loss: 0.4953 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.6748 - acc: 0.2335 - val_loss: 0.4922 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.7058 - acc: 0.2314 - val_loss: 0.4904 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 0.6866 - acc: 0.2293 - val_loss: 0.4985 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 243us/step - loss: 0.6649 - acc: 0.2569 - val_loss: 0.5022 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.6954 - acc: 0.2293 - val_loss: 0.5024 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 240us/step - loss: 0.6873 - acc: 0.2463 - val_loss: 0.5078 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6793 - acc: 0.2442 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6901 - acc: 0.2505 - val_loss: 0.5170 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6593 - acc: 0.2590 - val_loss: 0.5152 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6821 - acc: 0.2335 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6991 - acc: 0.2420 - val_loss: 0.5148 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6604 - acc: 0.2590 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.6861 - acc: 0.2293 - val_loss: 0.5087 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6839 - acc: 0.2590 - val_loss: 0.5070 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.6619 - acc: 0.2463 - val_loss: 0.5061 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6625 - acc: 0.2527 - val_loss: 0.5053 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 0.6737 - acc: 0.2760 - val_loss: 0.5043 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6651 - acc: 0.2484 - val_loss: 0.4996 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6399 - acc: 0.2654 - val_loss: 0.4985 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 233us/step - loss: 0.6472 - acc: 0.2505 - val_loss: 0.4960 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 234us/step - loss: 0.6625 - acc: 0.2505 - val_loss: 0.4988 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 232us/step - loss: 0.6451 - acc: 0.2760 - val_loss: 0.5022 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.6682 - acc: 0.2378 - val_loss: 0.4987 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.6531 - acc: 0.2718 - val_loss: 0.4959 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 238us/step - loss: 0.6481 - acc: 0.2527 - val_loss: 0.4985 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.6857 - acc: 0.2569 - val_loss: 0.4998 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6427 - acc: 0.2442 - val_loss: 0.4997 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 0.6530 - acc: 0.2590 - val_loss: 0.5006 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.6849 - acc: 0.2569 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 201us/step\n",
      "Test score: 0.5074559230330988\n",
      "Look! elu tanh softmax Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu relu sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_310 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1079 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_772 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1080 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_773 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1081 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 32s 68ms/step - loss: 3.0321 - acc: 0.2208 - val_loss: 1.2411 - val_acc: 0.1986\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.8092 - acc: 0.2251 - val_loss: 1.2496 - val_acc: 0.2057\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 2.1558 - acc: 0.2548 - val_loss: 1.3371 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.5205 - acc: 0.2505 - val_loss: 1.6131 - val_acc: 0.2128\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.1820 - acc: 0.2293 - val_loss: 1.6002 - val_acc: 0.2128\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.2933 - acc: 0.2059 - val_loss: 1.5982 - val_acc: 0.1844\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.9041 - acc: 0.2378 - val_loss: 1.5035 - val_acc: 0.1560\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.0737 - acc: 0.2463 - val_loss: 1.5930 - val_acc: 0.2057\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.5335 - acc: 0.2314 - val_loss: 1.6083 - val_acc: 0.2128\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.0921 - acc: 0.2314 - val_loss: 1.6726 - val_acc: 0.2199\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.9633 - acc: 0.2335 - val_loss: 1.3422 - val_acc: 0.2057\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.5564 - acc: 0.2293 - val_loss: 1.5053 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 2.1229 - acc: 0.2527 - val_loss: 1.5934 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.4304 - acc: 0.2420 - val_loss: 1.6636 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.8854 - acc: 0.2144 - val_loss: 1.6397 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.8479 - acc: 0.2251 - val_loss: 1.6415 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.1425 - acc: 0.2208 - val_loss: 1.6579 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.9491 - acc: 0.2569 - val_loss: 1.6524 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.6189 - acc: 0.2442 - val_loss: 1.6542 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.6380 - acc: 0.2505 - val_loss: 1.6572 - val_acc: 0.2128\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.7489 - acc: 0.2505 - val_loss: 1.6756 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.7221 - acc: 0.2293 - val_loss: 1.4325 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.0463 - acc: 0.2335 - val_loss: 0.9580 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.3834 - acc: 0.2527 - val_loss: 0.9352 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.7260 - acc: 0.2527 - val_loss: 0.9420 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.5230 - acc: 0.2399 - val_loss: 0.9573 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.5597 - acc: 0.2420 - val_loss: 0.8760 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.6216 - acc: 0.2633 - val_loss: 0.7976 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.5234 - acc: 0.2675 - val_loss: 0.7177 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 237us/step - loss: 1.7467 - acc: 0.2463 - val_loss: 0.7093 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.5979 - acc: 0.2399 - val_loss: 0.6496 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.4776 - acc: 0.2335 - val_loss: 0.6251 - val_acc: 0.2199\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.3837 - acc: 0.2442 - val_loss: 0.6186 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.5400 - acc: 0.2484 - val_loss: 0.5365 - val_acc: 0.2270\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.5207 - acc: 0.2357 - val_loss: 0.6202 - val_acc: 0.1915\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.5652 - acc: 0.2229 - val_loss: 0.6436 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.1740 - acc: 0.2484 - val_loss: 0.7325 - val_acc: 0.2270\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.6505 - acc: 0.2484 - val_loss: 0.5821 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.6114 - acc: 0.2335 - val_loss: 0.5460 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 234us/step - loss: 1.4771 - acc: 0.2378 - val_loss: 0.5190 - val_acc: 0.2270\n",
      "Epoch 41/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 218us/step - loss: 1.3628 - acc: 0.2505 - val_loss: 0.5152 - val_acc: 0.2411\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.2249 - acc: 0.2633 - val_loss: 0.5196 - val_acc: 0.2340\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.3975 - acc: 0.2505 - val_loss: 0.5234 - val_acc: 0.2270\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.2580 - acc: 0.2718 - val_loss: 0.5232 - val_acc: 0.2270\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.1779 - acc: 0.2251 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.9537 - acc: 0.2505 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.3479 - acc: 0.2399 - val_loss: 0.5172 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.3260 - acc: 0.2590 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.1098 - acc: 0.2548 - val_loss: 0.5133 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.5178 - acc: 0.2208 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.1658 - acc: 0.2527 - val_loss: 0.5254 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 1.3090 - acc: 0.2569 - val_loss: 0.5234 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.2782 - acc: 0.2654 - val_loss: 0.5193 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.2739 - acc: 0.2208 - val_loss: 0.5232 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.0770 - acc: 0.2611 - val_loss: 0.5252 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.2269 - acc: 0.2803 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 1.2959 - acc: 0.2527 - val_loss: 0.5299 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.1310 - acc: 0.2357 - val_loss: 0.5286 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.0130 - acc: 0.2463 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.0049 - acc: 0.2548 - val_loss: 0.5233 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.0143 - acc: 0.2760 - val_loss: 0.5268 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.1305 - acc: 0.2505 - val_loss: 0.5286 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.9976 - acc: 0.2718 - val_loss: 0.5310 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.9774 - acc: 0.2824 - val_loss: 0.5326 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.0032 - acc: 0.2675 - val_loss: 0.5300 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 0.9836 - acc: 0.2399 - val_loss: 0.5256 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.8989 - acc: 0.2696 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.9399 - acc: 0.2781 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.9334 - acc: 0.2675 - val_loss: 0.5187 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.0637 - acc: 0.2590 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.9401 - acc: 0.2399 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.0800 - acc: 0.2675 - val_loss: 0.5184 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.9501 - acc: 0.2229 - val_loss: 0.5186 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.0825 - acc: 0.2293 - val_loss: 0.5190 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.8713 - acc: 0.2611 - val_loss: 0.5185 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.9501 - acc: 0.2505 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.8560 - acc: 0.2484 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7130 - acc: 0.2527 - val_loss: 0.5189 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 1.0025 - acc: 0.2335 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.9745 - acc: 0.2590 - val_loss: 0.5205 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 0.9378 - acc: 0.2611 - val_loss: 0.5222 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.8300 - acc: 0.2420 - val_loss: 0.5199 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.8395 - acc: 0.2781 - val_loss: 0.5220 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.9572 - acc: 0.2251 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.8050 - acc: 0.2590 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7975 - acc: 0.2442 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.8732 - acc: 0.2675 - val_loss: 0.5257 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.8629 - acc: 0.2548 - val_loss: 0.5237 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.7730 - acc: 0.2187 - val_loss: 0.5213 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8384 - acc: 0.2803 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.8352 - acc: 0.2420 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.8242 - acc: 0.2335 - val_loss: 0.5235 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.9196 - acc: 0.2548 - val_loss: 0.5246 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.9740 - acc: 0.2611 - val_loss: 0.5225 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.7632 - acc: 0.2590 - val_loss: 0.5197 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7902 - acc: 0.2569 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 0.7743 - acc: 0.2463 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7264 - acc: 0.2420 - val_loss: 0.5230 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8125 - acc: 0.2442 - val_loss: 0.5231 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7779 - acc: 0.2463 - val_loss: 0.5245 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.8141 - acc: 0.2442 - val_loss: 0.5240 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.7698 - acc: 0.2484 - val_loss: 0.5215 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.8058 - acc: 0.2378 - val_loss: 0.5195 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.7761 - acc: 0.2293 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7017 - acc: 0.2548 - val_loss: 0.5202 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7758 - acc: 0.2505 - val_loss: 0.5227 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.7457 - acc: 0.2781 - val_loss: 0.5279 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7577 - acc: 0.2442 - val_loss: 0.5312 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.7440 - acc: 0.2548 - val_loss: 0.5318 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.7445 - acc: 0.2314 - val_loss: 0.5321 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7159 - acc: 0.2505 - val_loss: 0.5319 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.8134 - acc: 0.2569 - val_loss: 0.5306 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7161 - acc: 0.2166 - val_loss: 0.5310 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.7757 - acc: 0.2399 - val_loss: 0.5340 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7360 - acc: 0.2569 - val_loss: 0.5365 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.7255 - acc: 0.2654 - val_loss: 0.5381 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 0.7193 - acc: 0.2590 - val_loss: 0.5384 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 0.7720 - acc: 0.2399 - val_loss: 0.5383 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 0.7079 - acc: 0.2463 - val_loss: 0.5390 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6913 - acc: 0.2611 - val_loss: 0.5363 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 191us/step\n",
      "Test score: 0.5362581285179084\n",
      "Look! elu tanh elu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu relu sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_311 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1082 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_774 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1083 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_775 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1084 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 32s 69ms/step - loss: 3.5422 - acc: 0.2399 - val_loss: 2.2836 - val_acc: 0.1135\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 3.6020 - acc: 0.2229 - val_loss: 2.5565 - val_acc: 0.0993\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.0550 - acc: 0.2144 - val_loss: 2.2605 - val_acc: 0.1064\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 3.1959 - acc: 0.2272 - val_loss: 2.2870 - val_acc: 0.0993\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.1382 - acc: 0.1868 - val_loss: 1.5882 - val_acc: 0.0638\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.2411 - acc: 0.1868 - val_loss: 3.1581 - val_acc: 0.0355\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.3164 - acc: 0.2569 - val_loss: 4.9429 - val_acc: 0.2270\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 3.6311 - acc: 0.2718 - val_loss: 4.4768 - val_acc: 0.5603\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.4690 - acc: 0.3100 - val_loss: 1.5239 - val_acc: 0.6241\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 3.6492 - acc: 0.2654 - val_loss: 1.8522 - val_acc: 0.6241\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 2.9861 - acc: 0.3163 - val_loss: 1.0573 - val_acc: 0.6241\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 3.0865 - acc: 0.3206 - val_loss: 0.8528 - val_acc: 0.5887\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.9394 - acc: 0.2654 - val_loss: 1.0104 - val_acc: 0.3191\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 2.4523 - acc: 0.2675 - val_loss: 0.9713 - val_acc: 0.2624\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.5887 - acc: 0.2335 - val_loss: 0.9617 - val_acc: 0.2411\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 2.4564 - acc: 0.2590 - val_loss: 0.8552 - val_acc: 0.2482\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.5371 - acc: 0.2633 - val_loss: 0.9787 - val_acc: 0.1560\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 2.2751 - acc: 0.2654 - val_loss: 1.5076 - val_acc: 0.0993\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.4218 - acc: 0.2059 - val_loss: 1.4848 - val_acc: 0.1064\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 2.6154 - acc: 0.2102 - val_loss: 1.5602 - val_acc: 0.1986\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 2.5407 - acc: 0.2484 - val_loss: 1.5383 - val_acc: 0.2057\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.2224 - acc: 0.2314 - val_loss: 1.5296 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.1849 - acc: 0.2335 - val_loss: 1.5310 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 2.6504 - acc: 0.2335 - val_loss: 1.5336 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.5950 - acc: 0.2123 - val_loss: 1.5295 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 3.1290 - acc: 0.2293 - val_loss: 1.5266 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 2.4769 - acc: 0.2123 - val_loss: 1.5279 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 2.4958 - acc: 0.2229 - val_loss: 1.5246 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 2.4195 - acc: 0.2229 - val_loss: 1.5218 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.4060 - acc: 0.2633 - val_loss: 1.5519 - val_acc: 0.2128\n",
      "Epoch 31/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 222us/step - loss: 2.1386 - acc: 0.2442 - val_loss: 1.4873 - val_acc: 0.2270\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.2298 - acc: 0.2569 - val_loss: 1.5802 - val_acc: 0.2199\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 2.1097 - acc: 0.2208 - val_loss: 1.3274 - val_acc: 0.2199\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.5697 - acc: 0.2144 - val_loss: 1.1482 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 2.5646 - acc: 0.2590 - val_loss: 1.3501 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.3449 - acc: 0.1996 - val_loss: 1.5236 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 2.0348 - acc: 0.2845 - val_loss: 1.5192 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 2.3592 - acc: 0.2505 - val_loss: 1.2758 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 1.7390 - acc: 0.2654 - val_loss: 1.0359 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.9132 - acc: 0.2824 - val_loss: 1.0025 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 2.0102 - acc: 0.2484 - val_loss: 0.9886 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 1.9798 - acc: 0.2696 - val_loss: 0.9886 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.2741 - acc: 0.2314 - val_loss: 0.8976 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.4993 - acc: 0.2442 - val_loss: 0.8952 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.8114 - acc: 0.2463 - val_loss: 0.8952 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 2.3178 - acc: 0.2251 - val_loss: 0.8867 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 2.0023 - acc: 0.2569 - val_loss: 0.8769 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 2.0793 - acc: 0.2590 - val_loss: 0.8720 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.2639 - acc: 0.2505 - val_loss: 0.8689 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 2.0377 - acc: 0.2038 - val_loss: 0.8643 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 2.0353 - acc: 0.2548 - val_loss: 0.8550 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.9952 - acc: 0.2548 - val_loss: 0.8552 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 2.3757 - acc: 0.2335 - val_loss: 0.8528 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.7695 - acc: 0.2335 - val_loss: 0.8501 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.1661 - acc: 0.2251 - val_loss: 0.8402 - val_acc: 0.2199\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.8763 - acc: 0.2420 - val_loss: 0.8433 - val_acc: 0.2270\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 1.9215 - acc: 0.2442 - val_loss: 0.8740 - val_acc: 0.1277\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.0780 - acc: 0.1953 - val_loss: 0.8779 - val_acc: 0.1702\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 1.9229 - acc: 0.2378 - val_loss: 0.8861 - val_acc: 0.1631\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.8295 - acc: 0.2378 - val_loss: 0.9545 - val_acc: 0.2199\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.8111 - acc: 0.2123 - val_loss: 0.8675 - val_acc: 0.2057\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.8435 - acc: 0.2739 - val_loss: 0.8740 - val_acc: 0.1631\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.6921 - acc: 0.2378 - val_loss: 0.8803 - val_acc: 0.1489\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.9453 - acc: 0.2166 - val_loss: 0.8823 - val_acc: 0.1489\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.8592 - acc: 0.2505 - val_loss: 0.8841 - val_acc: 0.1489\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 2.1026 - acc: 0.2654 - val_loss: 0.8857 - val_acc: 0.1489\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.6751 - acc: 0.2633 - val_loss: 0.8816 - val_acc: 0.1986\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 1.7002 - acc: 0.2463 - val_loss: 0.8734 - val_acc: 0.2199\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.8683 - acc: 0.2611 - val_loss: 0.8617 - val_acc: 0.1986\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.7532 - acc: 0.2399 - val_loss: 0.8825 - val_acc: 0.1915\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.7565 - acc: 0.2335 - val_loss: 0.8866 - val_acc: 0.1844\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.7738 - acc: 0.2314 - val_loss: 0.8862 - val_acc: 0.1631\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.5992 - acc: 0.2102 - val_loss: 0.8759 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 1.6905 - acc: 0.2314 - val_loss: 0.8684 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.7104 - acc: 0.2144 - val_loss: 0.8672 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 1.7649 - acc: 0.2081 - val_loss: 0.8691 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 1.7779 - acc: 0.2187 - val_loss: 0.8713 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.7225 - acc: 0.2505 - val_loss: 0.8697 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.6111 - acc: 0.2463 - val_loss: 0.8687 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 1.6603 - acc: 0.2633 - val_loss: 0.8685 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.5984 - acc: 0.2378 - val_loss: 0.8718 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 1.5214 - acc: 0.2442 - val_loss: 0.8715 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.5066 - acc: 0.2166 - val_loss: 0.8751 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.6934 - acc: 0.2357 - val_loss: 0.8805 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 235us/step - loss: 1.7742 - acc: 0.2420 - val_loss: 0.8799 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 1.3202 - acc: 0.2272 - val_loss: 0.8813 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.6729 - acc: 0.2611 - val_loss: 0.8828 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.6187 - acc: 0.2357 - val_loss: 0.8839 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.3709 - acc: 0.2548 - val_loss: 0.8796 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.4435 - acc: 0.2420 - val_loss: 0.8778 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.4359 - acc: 0.2739 - val_loss: 0.8771 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.4669 - acc: 0.2144 - val_loss: 0.8852 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.4660 - acc: 0.2633 - val_loss: 0.8857 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.3492 - acc: 0.2357 - val_loss: 0.8877 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 1.4699 - acc: 0.2569 - val_loss: 0.8894 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 234us/step - loss: 1.4266 - acc: 0.2102 - val_loss: 0.8901 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.3194 - acc: 0.2845 - val_loss: 0.8914 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.3748 - acc: 0.2569 - val_loss: 0.8942 - val_acc: 0.1986\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.4392 - acc: 0.2378 - val_loss: 0.8954 - val_acc: 0.1915\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 1.5892 - acc: 0.2272 - val_loss: 0.8952 - val_acc: 0.1986\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 1.3824 - acc: 0.2463 - val_loss: 0.8941 - val_acc: 0.1915\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.2636 - acc: 0.2548 - val_loss: 0.8941 - val_acc: 0.1986\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.2007 - acc: 0.2081 - val_loss: 0.8957 - val_acc: 0.2057\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 1.2871 - acc: 0.2357 - val_loss: 0.8965 - val_acc: 0.2057\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.3612 - acc: 0.2208 - val_loss: 0.8973 - val_acc: 0.1915\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 1.2906 - acc: 0.2229 - val_loss: 0.8963 - val_acc: 0.2057\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 1.4336 - acc: 0.2293 - val_loss: 0.8950 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 1.4206 - acc: 0.2144 - val_loss: 0.8926 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.3208 - acc: 0.2463 - val_loss: 0.8945 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.2659 - acc: 0.2208 - val_loss: 0.8943 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 1.5505 - acc: 0.2314 - val_loss: 0.8941 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 1.3552 - acc: 0.2399 - val_loss: 0.8943 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.2880 - acc: 0.2420 - val_loss: 0.8947 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 1.2938 - acc: 0.2484 - val_loss: 0.8948 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.2108 - acc: 0.2611 - val_loss: 0.9000 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 1.1640 - acc: 0.2378 - val_loss: 0.9027 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 228us/step - loss: 1.4109 - acc: 0.2420 - val_loss: 0.9010 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 1.3626 - acc: 0.2527 - val_loss: 0.9001 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 1.2636 - acc: 0.2442 - val_loss: 0.8993 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 1.4543 - acc: 0.2484 - val_loss: 0.8991 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 218us/step\n",
      "Test score: 0.8990755935087271\n",
      "Look! elu tanh selu Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu relu sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_312 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1085 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_776 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1086 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_777 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1087 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 32s 69ms/step - loss: 0.9395 - acc: 0.2378 - val_loss: 0.5176 - val_acc: 0.2128\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7475 - acc: 0.2569 - val_loss: 0.5464 - val_acc: 0.2128\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 0.8304 - acc: 0.2442 - val_loss: 0.5517 - val_acc: 0.2128\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7694 - acc: 0.2654 - val_loss: 0.5500 - val_acc: 0.2199\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7654 - acc: 0.2357 - val_loss: 0.5327 - val_acc: 0.2199\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.7463 - acc: 0.2569 - val_loss: 0.5266 - val_acc: 0.2340\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6936 - acc: 0.2251 - val_loss: 0.5333 - val_acc: 0.2340\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7099 - acc: 0.2399 - val_loss: 0.5375 - val_acc: 0.2340\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.7798 - acc: 0.2781 - val_loss: 0.5302 - val_acc: 0.2340\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.7137 - acc: 0.2696 - val_loss: 0.5184 - val_acc: 0.2553\n",
      "Epoch 11/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.7642 - acc: 0.2357 - val_loss: 0.5132 - val_acc: 0.2837\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.7039 - acc: 0.2442 - val_loss: 0.5089 - val_acc: 0.2270\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.7019 - acc: 0.2420 - val_loss: 0.5080 - val_acc: 0.2128\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6851 - acc: 0.2378 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.7095 - acc: 0.2527 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 204us/step - loss: 0.6951 - acc: 0.2420 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6804 - acc: 0.2484 - val_loss: 0.5064 - val_acc: 0.2128\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6918 - acc: 0.2420 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6623 - acc: 0.2590 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6780 - acc: 0.2378 - val_loss: 0.5191 - val_acc: 0.2128\n",
      "Epoch 21/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 212us/step - loss: 0.6907 - acc: 0.2611 - val_loss: 0.5192 - val_acc: 0.2128\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6732 - acc: 0.2463 - val_loss: 0.5177 - val_acc: 0.2128\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6572 - acc: 0.2675 - val_loss: 0.5210 - val_acc: 0.2128\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6644 - acc: 0.2463 - val_loss: 0.5158 - val_acc: 0.2128\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6746 - acc: 0.2463 - val_loss: 0.5156 - val_acc: 0.2128\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6792 - acc: 0.2314 - val_loss: 0.5149 - val_acc: 0.2128\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6670 - acc: 0.2442 - val_loss: 0.5096 - val_acc: 0.2128\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6828 - acc: 0.2357 - val_loss: 0.5087 - val_acc: 0.2128\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6684 - acc: 0.2420 - val_loss: 0.5105 - val_acc: 0.2128\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6583 - acc: 0.2420 - val_loss: 0.5102 - val_acc: 0.2128\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6719 - acc: 0.2505 - val_loss: 0.5167 - val_acc: 0.2128\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6625 - acc: 0.2420 - val_loss: 0.5129 - val_acc: 0.2128\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 217us/step - loss: 0.6472 - acc: 0.2420 - val_loss: 0.5113 - val_acc: 0.2128\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6644 - acc: 0.2357 - val_loss: 0.5151 - val_acc: 0.2128\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6603 - acc: 0.2399 - val_loss: 0.5128 - val_acc: 0.2128\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6742 - acc: 0.2548 - val_loss: 0.5145 - val_acc: 0.2128\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 0.6698 - acc: 0.2527 - val_loss: 0.5070 - val_acc: 0.2128\n",
      "Epoch 38/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6438 - acc: 0.2633 - val_loss: 0.5091 - val_acc: 0.2128\n",
      "Epoch 39/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6605 - acc: 0.2357 - val_loss: 0.5173 - val_acc: 0.2128\n",
      "Epoch 40/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6658 - acc: 0.2378 - val_loss: 0.5161 - val_acc: 0.2128\n",
      "Epoch 41/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6410 - acc: 0.2569 - val_loss: 0.5146 - val_acc: 0.2128\n",
      "Epoch 42/120\n",
      "471/471 [==============================] - 0s 190us/step - loss: 0.6667 - acc: 0.2314 - val_loss: 0.5150 - val_acc: 0.2128\n",
      "Epoch 43/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6632 - acc: 0.2569 - val_loss: 0.5084 - val_acc: 0.2128\n",
      "Epoch 44/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6575 - acc: 0.2548 - val_loss: 0.5047 - val_acc: 0.2128\n",
      "Epoch 45/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6689 - acc: 0.2399 - val_loss: 0.5095 - val_acc: 0.2128\n",
      "Epoch 46/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6547 - acc: 0.2420 - val_loss: 0.5090 - val_acc: 0.2128\n",
      "Epoch 47/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6390 - acc: 0.2505 - val_loss: 0.5100 - val_acc: 0.2128\n",
      "Epoch 48/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6558 - acc: 0.2611 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 49/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6397 - acc: 0.2590 - val_loss: 0.5112 - val_acc: 0.2128\n",
      "Epoch 50/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6671 - acc: 0.2442 - val_loss: 0.5138 - val_acc: 0.2128\n",
      "Epoch 51/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6733 - acc: 0.2590 - val_loss: 0.5110 - val_acc: 0.2128\n",
      "Epoch 52/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6277 - acc: 0.2654 - val_loss: 0.5117 - val_acc: 0.2128\n",
      "Epoch 53/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6481 - acc: 0.2505 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 54/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6449 - acc: 0.2527 - val_loss: 0.5085 - val_acc: 0.2128\n",
      "Epoch 55/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6518 - acc: 0.2654 - val_loss: 0.5123 - val_acc: 0.2128\n",
      "Epoch 56/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6593 - acc: 0.2527 - val_loss: 0.5141 - val_acc: 0.2128\n",
      "Epoch 57/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6432 - acc: 0.2590 - val_loss: 0.5130 - val_acc: 0.2128\n",
      "Epoch 58/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6514 - acc: 0.2442 - val_loss: 0.5137 - val_acc: 0.2128\n",
      "Epoch 59/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6392 - acc: 0.2675 - val_loss: 0.5131 - val_acc: 0.2128\n",
      "Epoch 60/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6232 - acc: 0.2548 - val_loss: 0.5118 - val_acc: 0.2128\n",
      "Epoch 61/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6722 - acc: 0.2378 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 62/120\n",
      "471/471 [==============================] - 0s 199us/step - loss: 0.6510 - acc: 0.2335 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 63/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6466 - acc: 0.2505 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 64/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6608 - acc: 0.2569 - val_loss: 0.5103 - val_acc: 0.2128\n",
      "Epoch 65/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6458 - acc: 0.2314 - val_loss: 0.5070 - val_acc: 0.2128\n",
      "Epoch 66/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6356 - acc: 0.2442 - val_loss: 0.5083 - val_acc: 0.2128\n",
      "Epoch 67/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6434 - acc: 0.2611 - val_loss: 0.5108 - val_acc: 0.2128\n",
      "Epoch 68/120\n",
      "471/471 [==============================] - 0s 192us/step - loss: 0.6256 - acc: 0.2633 - val_loss: 0.5114 - val_acc: 0.2128\n",
      "Epoch 69/120\n",
      "471/471 [==============================] - 0s 194us/step - loss: 0.6281 - acc: 0.2548 - val_loss: 0.5064 - val_acc: 0.2128\n",
      "Epoch 70/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6538 - acc: 0.2633 - val_loss: 0.5059 - val_acc: 0.2128\n",
      "Epoch 71/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6460 - acc: 0.2569 - val_loss: 0.5029 - val_acc: 0.2128\n",
      "Epoch 72/120\n",
      "471/471 [==============================] - 0s 201us/step - loss: 0.6405 - acc: 0.2675 - val_loss: 0.5025 - val_acc: 0.2128\n",
      "Epoch 73/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 0.6287 - acc: 0.2590 - val_loss: 0.5000 - val_acc: 0.2128\n",
      "Epoch 74/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6404 - acc: 0.2590 - val_loss: 0.5030 - val_acc: 0.2128\n",
      "Epoch 75/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6415 - acc: 0.2548 - val_loss: 0.5052 - val_acc: 0.2128\n",
      "Epoch 76/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6090 - acc: 0.2654 - val_loss: 0.5049 - val_acc: 0.2128\n",
      "Epoch 77/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6395 - acc: 0.2611 - val_loss: 0.5069 - val_acc: 0.2128\n",
      "Epoch 78/120\n",
      "471/471 [==============================] - 0s 211us/step - loss: 0.6405 - acc: 0.2527 - val_loss: 0.5079 - val_acc: 0.2128\n",
      "Epoch 79/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6366 - acc: 0.2569 - val_loss: 0.5057 - val_acc: 0.2128\n",
      "Epoch 80/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 0.6309 - acc: 0.2633 - val_loss: 0.5059 - val_acc: 0.2128\n",
      "Epoch 81/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6413 - acc: 0.2569 - val_loss: 0.5028 - val_acc: 0.2128\n",
      "Epoch 82/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6659 - acc: 0.2590 - val_loss: 0.5026 - val_acc: 0.2128\n",
      "Epoch 83/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6516 - acc: 0.2590 - val_loss: 0.5035 - val_acc: 0.2128\n",
      "Epoch 84/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6440 - acc: 0.2633 - val_loss: 0.5033 - val_acc: 0.2128\n",
      "Epoch 85/120\n",
      "471/471 [==============================] - 0s 202us/step - loss: 0.6422 - acc: 0.2633 - val_loss: 0.4988 - val_acc: 0.2128\n",
      "Epoch 86/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6427 - acc: 0.2505 - val_loss: 0.5015 - val_acc: 0.2128\n",
      "Epoch 87/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6318 - acc: 0.2548 - val_loss: 0.5023 - val_acc: 0.2128\n",
      "Epoch 88/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6407 - acc: 0.2569 - val_loss: 0.5041 - val_acc: 0.2128\n",
      "Epoch 89/120\n",
      "471/471 [==============================] - 0s 195us/step - loss: 0.6362 - acc: 0.2548 - val_loss: 0.5019 - val_acc: 0.2128\n",
      "Epoch 90/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6140 - acc: 0.2739 - val_loss: 0.4990 - val_acc: 0.2128\n",
      "Epoch 91/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6413 - acc: 0.2505 - val_loss: 0.4986 - val_acc: 0.2128\n",
      "Epoch 92/120\n",
      "471/471 [==============================] - 0s 197us/step - loss: 0.6341 - acc: 0.2548 - val_loss: 0.4986 - val_acc: 0.2128\n",
      "Epoch 93/120\n",
      "471/471 [==============================] - 0s 213us/step - loss: 0.6591 - acc: 0.2505 - val_loss: 0.4983 - val_acc: 0.2128\n",
      "Epoch 94/120\n",
      "471/471 [==============================] - 0s 207us/step - loss: 0.6352 - acc: 0.2569 - val_loss: 0.4964 - val_acc: 0.2128\n",
      "Epoch 95/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6559 - acc: 0.2569 - val_loss: 0.4960 - val_acc: 0.2128\n",
      "Epoch 96/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6291 - acc: 0.2654 - val_loss: 0.4962 - val_acc: 0.2128\n",
      "Epoch 97/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6402 - acc: 0.2654 - val_loss: 0.4968 - val_acc: 0.2128\n",
      "Epoch 98/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6397 - acc: 0.2548 - val_loss: 0.4992 - val_acc: 0.2128\n",
      "Epoch 99/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6427 - acc: 0.2590 - val_loss: 0.5019 - val_acc: 0.2128\n",
      "Epoch 100/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 0.6263 - acc: 0.2548 - val_loss: 0.5040 - val_acc: 0.2128\n",
      "Epoch 101/120\n",
      "471/471 [==============================] - 0s 198us/step - loss: 0.6276 - acc: 0.2718 - val_loss: 0.5044 - val_acc: 0.2128\n",
      "Epoch 102/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6209 - acc: 0.2611 - val_loss: 0.5041 - val_acc: 0.2128\n",
      "Epoch 103/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6439 - acc: 0.2527 - val_loss: 0.5058 - val_acc: 0.2128\n",
      "Epoch 104/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 0.6360 - acc: 0.2590 - val_loss: 0.5080 - val_acc: 0.2128\n",
      "Epoch 105/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 0.6320 - acc: 0.2611 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 106/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 0.6331 - acc: 0.2569 - val_loss: 0.5074 - val_acc: 0.2128\n",
      "Epoch 107/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6407 - acc: 0.2590 - val_loss: 0.5069 - val_acc: 0.2128\n",
      "Epoch 108/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6427 - acc: 0.2548 - val_loss: 0.5071 - val_acc: 0.2128\n",
      "Epoch 109/120\n",
      "471/471 [==============================] - 0s 210us/step - loss: 0.6275 - acc: 0.2611 - val_loss: 0.5075 - val_acc: 0.2128\n",
      "Epoch 110/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 0.6401 - acc: 0.2527 - val_loss: 0.5082 - val_acc: 0.2128\n",
      "Epoch 111/120\n",
      "471/471 [==============================] - 0s 203us/step - loss: 0.6375 - acc: 0.2548 - val_loss: 0.5097 - val_acc: 0.2128\n",
      "Epoch 112/120\n",
      "471/471 [==============================] - 0s 200us/step - loss: 0.6493 - acc: 0.2675 - val_loss: 0.5109 - val_acc: 0.2128\n",
      "Epoch 113/120\n",
      "471/471 [==============================] - 0s 193us/step - loss: 0.6381 - acc: 0.2633 - val_loss: 0.5111 - val_acc: 0.2128\n",
      "Epoch 114/120\n",
      "471/471 [==============================] - 0s 205us/step - loss: 0.6376 - acc: 0.2527 - val_loss: 0.5093 - val_acc: 0.2128\n",
      "Epoch 115/120\n",
      "471/471 [==============================] - 0s 206us/step - loss: 0.6256 - acc: 0.2569 - val_loss: 0.5068 - val_acc: 0.2128\n",
      "Epoch 116/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 0.6348 - acc: 0.2590 - val_loss: 0.5043 - val_acc: 0.2128\n",
      "Epoch 117/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6378 - acc: 0.2569 - val_loss: 0.5037 - val_acc: 0.2128\n",
      "Epoch 118/120\n",
      "471/471 [==============================] - 0s 209us/step - loss: 0.6503 - acc: 0.2569 - val_loss: 0.5051 - val_acc: 0.2128\n",
      "Epoch 119/120\n",
      "471/471 [==============================] - 0s 208us/step - loss: 0.6413 - acc: 0.2569 - val_loss: 0.5050 - val_acc: 0.2128\n",
      "Epoch 120/120\n",
      "471/471 [==============================] - 0s 212us/step - loss: 0.6336 - acc: 0.2611 - val_loss: 0.5048 - val_acc: 0.2128\n",
      "141/141 [==============================] - 0s 200us/step\n",
      "Test score: 0.5048365204046804\n",
      "Look! elu tanh softplus Test accuracy: 0.21276595808090049\n",
      "max there  0.6241134772909448 elu relu sigmoid\n",
      "Buidl model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_313 (InputLayer)       (None, 1364)              0         \n",
      "_________________________________________________________________\n",
      "dense_1088 (Dense)           (None, 128)               174720    \n",
      "_________________________________________________________________\n",
      "dropout_778 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1089 (Dense)           (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_779 (Dropout)        (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1090 (Dense)           (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 191,748\n",
      "Trainable params: 191,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 471 samples, validate on 141 samples\n",
      "Epoch 1/120\n",
      "471/471 [==============================] - 33s 70ms/step - loss: 2.5424 - acc: 0.1805 - val_loss: 2.0103 - val_acc: 0.1277\n",
      "Epoch 2/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.9836 - acc: 0.1911 - val_loss: 1.3238 - val_acc: 0.1277\n",
      "Epoch 3/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.1468 - acc: 0.1783 - val_loss: 1.7797 - val_acc: 0.1277\n",
      "Epoch 4/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.7473 - acc: 0.1677 - val_loss: 2.6740 - val_acc: 0.1277\n",
      "Epoch 5/120\n",
      "471/471 [==============================] - 0s 216us/step - loss: 2.7567 - acc: 0.1996 - val_loss: 3.5881 - val_acc: 0.1277\n",
      "Epoch 6/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 2.8751 - acc: 0.2187 - val_loss: 3.9004 - val_acc: 0.1277\n",
      "Epoch 7/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 3.0563 - acc: 0.1762 - val_loss: 3.0864 - val_acc: 0.1348\n",
      "Epoch 8/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 3.3275 - acc: 0.1932 - val_loss: 3.2008 - val_acc: 0.1348\n",
      "Epoch 9/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 3.5435 - acc: 0.2187 - val_loss: 4.9154 - val_acc: 0.1418\n",
      "Epoch 10/120\n",
      "471/471 [==============================] - 0s 215us/step - loss: 2.8834 - acc: 0.1847 - val_loss: 5.4870 - val_acc: 0.1560\n",
      "Epoch 11/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/471 [==============================] - 0s 224us/step - loss: 3.0923 - acc: 0.1826 - val_loss: 5.4870 - val_acc: 0.2128\n",
      "Epoch 12/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 3.3438 - acc: 0.2166 - val_loss: 5.4874 - val_acc: 0.2128\n",
      "Epoch 13/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.5220 - acc: 0.1868 - val_loss: 5.3880 - val_acc: 0.1773\n",
      "Epoch 14/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 3.8374 - acc: 0.2229 - val_loss: 5.3911 - val_acc: 0.1631\n",
      "Epoch 15/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.6341 - acc: 0.1953 - val_loss: 5.3951 - val_acc: 0.1418\n",
      "Epoch 16/120\n",
      "471/471 [==============================] - 0s 220us/step - loss: 3.5758 - acc: 0.1932 - val_loss: 5.4898 - val_acc: 0.1348\n",
      "Epoch 17/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 3.4649 - acc: 0.2187 - val_loss: 5.3906 - val_acc: 0.1348\n",
      "Epoch 18/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 3.5811 - acc: 0.1932 - val_loss: 5.2938 - val_acc: 0.1277\n",
      "Epoch 19/120\n",
      "471/471 [==============================] - 0s 218us/step - loss: 3.3708 - acc: 0.1911 - val_loss: 5.0962 - val_acc: 0.1277\n",
      "Epoch 20/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 3.1257 - acc: 0.1762 - val_loss: 4.9831 - val_acc: 0.1277\n",
      "Epoch 21/120\n",
      "471/471 [==============================] - 0s 223us/step - loss: 3.6847 - acc: 0.1720 - val_loss: 4.8892 - val_acc: 0.1277\n",
      "Epoch 22/120\n",
      "471/471 [==============================] - 0s 227us/step - loss: 3.3586 - acc: 0.1550 - val_loss: 5.1759 - val_acc: 0.1277\n",
      "Epoch 23/120\n",
      "471/471 [==============================] - 0s 230us/step - loss: 4.0888 - acc: 0.1911 - val_loss: 5.1850 - val_acc: 0.1277\n",
      "Epoch 24/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 3.2688 - acc: 0.1805 - val_loss: 3.6133 - val_acc: 0.1277\n",
      "Epoch 25/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 3.3439 - acc: 0.2123 - val_loss: 2.4910 - val_acc: 0.1277\n",
      "Epoch 26/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 3.9462 - acc: 0.1953 - val_loss: 2.2805 - val_acc: 0.1277\n",
      "Epoch 27/120\n",
      "471/471 [==============================] - 0s 214us/step - loss: 3.6777 - acc: 0.1783 - val_loss: 2.2731 - val_acc: 0.1277\n",
      "Epoch 28/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.7979 - acc: 0.1805 - val_loss: 2.2763 - val_acc: 0.1277\n",
      "Epoch 29/120\n",
      "471/471 [==============================] - 0s 224us/step - loss: 3.0679 - acc: 0.1932 - val_loss: 2.2505 - val_acc: 0.1277\n",
      "Epoch 30/120\n",
      "471/471 [==============================] - 0s 222us/step - loss: 2.7982 - acc: 0.1614 - val_loss: 2.1688 - val_acc: 0.1277\n",
      "Epoch 31/120\n",
      "471/471 [==============================] - 0s 231us/step - loss: 3.1290 - acc: 0.1614 - val_loss: 2.2635 - val_acc: 0.1277\n",
      "Epoch 32/120\n",
      "471/471 [==============================] - 0s 219us/step - loss: 2.8279 - acc: 0.1826 - val_loss: 2.2454 - val_acc: 0.1277\n",
      "Epoch 33/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 2.9434 - acc: 0.1826 - val_loss: 2.2353 - val_acc: 0.1277\n",
      "Epoch 34/120\n",
      "471/471 [==============================] - 0s 229us/step - loss: 3.3411 - acc: 0.2166 - val_loss: 2.2328 - val_acc: 0.1277\n",
      "Epoch 35/120\n",
      "471/471 [==============================] - 0s 226us/step - loss: 2.8237 - acc: 0.1656 - val_loss: 2.5807 - val_acc: 0.1277\n",
      "Epoch 36/120\n",
      "471/471 [==============================] - 0s 225us/step - loss: 2.9695 - acc: 0.1932 - val_loss: 2.2162 - val_acc: 0.1277\n",
      "Epoch 37/120\n",
      "471/471 [==============================] - 0s 221us/step - loss: 3.0171 - acc: 0.1890 - val_loss: 3.2685 - val_acc: 0.1277\n",
      "Epoch 38/120\n",
      "128/471 [=======>......................] - ETA: 0s - loss: 3.0768 - acc: 0.1719"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-3bf608bb2f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test score:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1219\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                             \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m                             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;31m# hdf5 datasets only support list objects as indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val=0\n",
    "label=''\n",
    "l_activation=['softmax','elu','selu','softplus','softsign','relu','tanh','sigmoid','hard_sigmoid','linear']\n",
    "for i in l_activation:\n",
    "    for j in l_activation:\n",
    "        for k in l_activation:\n",
    "            print('Buidl model...')\n",
    "            output_dense=128\n",
    "            batch_size=128\n",
    "            model=Sequential()\n",
    "            model.add(InputLayer(input_shape=(1364,)))\n",
    "            model.add(Dense(output_dense, activation=i))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(output_dense, activation=j))\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(4,activation=k))\n",
    "            model.summary()\n",
    "            model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            print('Train...')\n",
    "            model.fit(x_train, y_train,batch_size=batch_size,epochs=120,validation_data=(x_test, y_test))\n",
    "            score, acc = model.evaluate(x_test, y_test,batch_size=batch_size)\n",
    "            print('Test score:', score)\n",
    "            print('Look! '+i+' '+j+' '+k+' Test accuracy:', acc)\n",
    "            if val<=acc:\n",
    "                label=''\n",
    "                val=acc\n",
    "                label+=i+' '+j+' '+k\n",
    "            del model\n",
    "            print('max there ',val,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
